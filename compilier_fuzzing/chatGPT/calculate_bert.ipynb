{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_feather('../data/chatgpt/chatgpt_yaml.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of playbooks created: 130\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of playbooks created:\", (df.output != '').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['valid'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>prompt</th>\n",
       "      <th>output</th>\n",
       "      <th>valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"is defined\" reporting false for variable that...</td>\n",
       "      <td>### Summary\\n\\nGiven the following variable:\\r...</td>\n",
       "      <td>Create an Ansible playbook to exhibit the foll...</td>\n",
       "      <td>\\n\\n---\\n\\n- hosts: all\\n  become: true\\n  tas...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Systemd user services cannot be enabled globally</td>\n",
       "      <td>### Summary\\n\\nWhen trying to install a system...</td>\n",
       "      <td>Create an Ansible playbook to exhibit the foll...</td>\n",
       "      <td>\\n\\n---\\n- name: Install yum on RHEL5\\n  hosts...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Conditionnal bug report</td>\n",
       "      <td>### Summary\\n\\nHello, I am just trying to chec...</td>\n",
       "      <td>Create an Ansible playbook to exhibit the foll...</td>\n",
       "      <td>\\n\\n---\\n- name: install yum package on RHEL5\\...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apt_repository: The repository ...  does not h...</td>\n",
       "      <td>### Summary\\r\\n\\r\\nGiven:  \\r\\n\\r\\n```\\r\\n- na...</td>\n",
       "      <td>Create an Ansible playbook to exhibit the foll...</td>\n",
       "      <td>\\n\\n---\\n- name: Install yum package on RHEL5\\...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gcp_compute_instance_facts problem with the \"~...</td>\n",
       "      <td>### Summary\\n\\nWhen I try to use the \"contains...</td>\n",
       "      <td>Create an Ansible playbook to exhibit the foll...</td>\n",
       "      <td>\\n\\n---\\n- name: Install yum package on RHEL5\\...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Gathering facts fails after setting login shel...</td>\n",
       "      <td>### Summary\\n\\nAfter setting login shell to [n...</td>\n",
       "      <td>Create an Ansible playbook to exhibit the foll...</td>\n",
       "      <td>(\"Please enter a number:\");\\n\\nif (num % 2 ===...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>include_role with when condition causes exception</td>\n",
       "      <td>### Summary\\n\\nWhen including a role with \\r\\n...</td>\n",
       "      <td>Create an Ansible playbook to exhibit the foll...</td>\n",
       "      <td>\\n\\nA prompt is a message that appears on the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>meta flush_handlers doesn't work in role</td>\n",
       "      <td>### Summary\\n\\nTriggering handlers with `ansib...</td>\n",
       "      <td>Create an Ansible playbook to exhibit the foll...</td>\n",
       "      <td>\\n\\nA prompt is a message or question that app...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ansible_fqdn has disappeared from ansible_facts</td>\n",
       "      <td>### Summary\\r\\n\\r\\nHaving come back to a playb...</td>\n",
       "      <td>Create an Ansible playbook to exhibit the foll...</td>\n",
       "      <td>(\\n        'What is the name of the current Ja...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Ansible git module stopped working with a Type...</td>\n",
       "      <td>### Summary\\r\\n\\r\\nI use `ansible-pull` to man...</td>\n",
       "      <td>Create an Ansible playbook to exhibit the foll...</td>\n",
       "      <td>(message, defaultValue)\\n\\nconst message = 'Wh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0   \"is defined\" reporting false for variable that...   \n",
       "1    Systemd user services cannot be enabled globally   \n",
       "2                             Conditionnal bug report   \n",
       "3   apt_repository: The repository ...  does not h...   \n",
       "4   gcp_compute_instance_facts problem with the \"~...   \n",
       "..                                                ...   \n",
       "95  Gathering facts fails after setting login shel...   \n",
       "96  include_role with when condition causes exception   \n",
       "97           meta flush_handlers doesn't work in role   \n",
       "98    ansible_fqdn has disappeared from ansible_facts   \n",
       "99  Ansible git module stopped working with a Type...   \n",
       "\n",
       "                                                 body  \\\n",
       "0   ### Summary\\n\\nGiven the following variable:\\r...   \n",
       "1   ### Summary\\n\\nWhen trying to install a system...   \n",
       "2   ### Summary\\n\\nHello, I am just trying to chec...   \n",
       "3   ### Summary\\r\\n\\r\\nGiven:  \\r\\n\\r\\n```\\r\\n- na...   \n",
       "4   ### Summary\\n\\nWhen I try to use the \"contains...   \n",
       "..                                                ...   \n",
       "95  ### Summary\\n\\nAfter setting login shell to [n...   \n",
       "96  ### Summary\\n\\nWhen including a role with \\r\\n...   \n",
       "97  ### Summary\\n\\nTriggering handlers with `ansib...   \n",
       "98  ### Summary\\r\\n\\r\\nHaving come back to a playb...   \n",
       "99  ### Summary\\r\\n\\r\\nI use `ansible-pull` to man...   \n",
       "\n",
       "                                               prompt  \\\n",
       "0   Create an Ansible playbook to exhibit the foll...   \n",
       "1   Create an Ansible playbook to exhibit the foll...   \n",
       "2   Create an Ansible playbook to exhibit the foll...   \n",
       "3   Create an Ansible playbook to exhibit the foll...   \n",
       "4   Create an Ansible playbook to exhibit the foll...   \n",
       "..                                                ...   \n",
       "95  Create an Ansible playbook to exhibit the foll...   \n",
       "96  Create an Ansible playbook to exhibit the foll...   \n",
       "97  Create an Ansible playbook to exhibit the foll...   \n",
       "98  Create an Ansible playbook to exhibit the foll...   \n",
       "99  Create an Ansible playbook to exhibit the foll...   \n",
       "\n",
       "                                               output  valid  \n",
       "0   \\n\\n---\\n\\n- hosts: all\\n  become: true\\n  tas...      1  \n",
       "1   \\n\\n---\\n- name: Install yum on RHEL5\\n  hosts...      1  \n",
       "2   \\n\\n---\\n- name: install yum package on RHEL5\\...      1  \n",
       "3   \\n\\n---\\n- name: Install yum package on RHEL5\\...      1  \n",
       "4   \\n\\n---\\n- name: Install yum package on RHEL5\\...      1  \n",
       "..                                                ...    ...  \n",
       "95  (\"Please enter a number:\");\\n\\nif (num % 2 ===...      1  \n",
       "96  \\n\\nA prompt is a message that appears on the ...      1  \n",
       "97  \\n\\nA prompt is a message or question that app...      1  \n",
       "98  (\\n        'What is the name of the current Ja...      1  \n",
       "99  (message, defaultValue)\\n\\nconst message = 'Wh...      1  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from bert_score import score\n",
    "scores = []\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "predictions = [\"hello there\", \"general kenobi\"]\n",
    "references = [\"hello there\", \"general kenobi\"]\n",
    "P, R, F1 = score(predictions, references, model_type=\"distilbert-base-uncased\", device=device)\n",
    "scores.append(F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     \\n\\n---\\n\\n- hosts: all\\n  become: true\\n  tas...\n",
       "1     \\n\\n---\\n- name: Install yum on RHEL5\\n  hosts...\n",
       "2     \\n\\n---\\n- name: install yum package on RHEL5\\...\n",
       "3     \\n\\n---\\n- name: Install yum package on RHEL5\\...\n",
       "4     \\n\\n---\\n- name: Install yum package on RHEL5\\...\n",
       "                            ...                        \n",
       "95    (\"Please enter a number:\");\\n\\nif (num % 2 ===...\n",
       "96    \\n\\nA prompt is a message that appears on the ...\n",
       "97    \\n\\nA prompt is a message or question that app...\n",
       "98    (\\n        'What is the name of the current Ja...\n",
       "99    (message, defaultValue)\\n\\nconst message = 'Wh...\n",
       "Name: output, Length: 100, dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[361], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m     reference \u001b[39m=\u001b[39m [sentences[i]]\n\u001b[1;32m     13\u001b[0m     candidate \u001b[39m=\u001b[39m [sentences[j]]\n\u001b[0;32m---> 14\u001b[0m     P, R, F1 \u001b[39m=\u001b[39m score(candidate, reference, model_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdistilbert-base-uncased\u001b[39;49m\u001b[39m\"\u001b[39;49m, device\u001b[39m=\u001b[39;49mdevice)\n\u001b[1;32m     15\u001b[0m     scores\u001b[39m.\u001b[39mappend((i, j, F1[\u001b[39m0\u001b[39m]))\n\u001b[1;32m     17\u001b[0m \u001b[39mprint\u001b[39m(scores)\n",
      "File \u001b[0;32m/data/minh/anaconda3/envs/ansible/lib/python3.10/site-packages/bert_score/score.py:98\u001b[0m, in \u001b[0;36mscore\u001b[0;34m(cands, refs, model_type, num_layers, verbose, idf, device, batch_size, nthreads, all_layers, lang, return_hash, rescale_with_baseline, baseline_path, use_fast_tokenizer)\u001b[0m\n\u001b[1;32m     95\u001b[0m     num_layers \u001b[39m=\u001b[39m model2layers[model_type]\n\u001b[1;32m     97\u001b[0m tokenizer \u001b[39m=\u001b[39m get_tokenizer(model_type, use_fast_tokenizer)\n\u001b[0;32m---> 98\u001b[0m model \u001b[39m=\u001b[39m get_model(model_type, num_layers, all_layers)\n\u001b[1;32m     99\u001b[0m \u001b[39mif\u001b[39;00m device \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m     device \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m/data/minh/anaconda3/envs/ansible/lib/python3.10/site-packages/bert_score/utils.py:255\u001b[0m, in \u001b[0;36mget_model\u001b[0;34m(model_type, num_layers, all_layers)\u001b[0m\n\u001b[1;32m    253\u001b[0m     model \u001b[39m=\u001b[39m T5EncoderModel\u001b[39m.\u001b[39mfrom_pretrained(model_type)\n\u001b[1;32m    254\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 255\u001b[0m     model \u001b[39m=\u001b[39m AutoModel\u001b[39m.\u001b[39;49mfrom_pretrained(model_type)\n\u001b[1;32m    256\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[1;32m    258\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(model, \u001b[39m\"\u001b[39m\u001b[39mdecoder\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(model, \u001b[39m\"\u001b[39m\u001b[39mencoder\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:464\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mtype\u001b[39m(config) \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    463\u001b[0m     model_class \u001b[39m=\u001b[39m _get_model_class(config, \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 464\u001b[0m     \u001b[39mreturn\u001b[39;00m model_class\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m    465\u001b[0m         pretrained_model_name_or_path, \u001b[39m*\u001b[39;49mmodel_args, config\u001b[39m=\u001b[39;49mconfig, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mhub_kwargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    466\u001b[0m     )\n\u001b[1;32m    467\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    468\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized configuration class \u001b[39m\u001b[39m{\u001b[39;00mconfig\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m for this kind of AutoModel: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    469\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel type should be one of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(c\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    470\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/modeling_utils.py:2362\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2359\u001b[0m     init_contexts\u001b[39m.\u001b[39mappend(init_empty_weights())\n\u001b[1;32m   2361\u001b[0m \u001b[39mwith\u001b[39;00m ContextManagers(init_contexts):\n\u001b[0;32m-> 2362\u001b[0m     model \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m(config, \u001b[39m*\u001b[39;49mmodel_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs)\n\u001b[1;32m   2364\u001b[0m \u001b[39m# Check first if we are `from_pt`\u001b[39;00m\n\u001b[1;32m   2365\u001b[0m \u001b[39mif\u001b[39;00m use_keep_in_fp32_modules:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py:470\u001b[0m, in \u001b[0;36mDistilBertModel.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, config: PretrainedConfig):\n\u001b[1;32m    468\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(config)\n\u001b[0;32m--> 470\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings \u001b[39m=\u001b[39m Embeddings(config)  \u001b[39m# Embeddings\u001b[39;00m\n\u001b[1;32m    471\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer \u001b[39m=\u001b[39m Transformer(config)  \u001b[39m# Encoder\u001b[39;00m\n\u001b[1;32m    473\u001b[0m     \u001b[39m# Initialize weights and apply final processing\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py:95\u001b[0m, in \u001b[0;36mEmbeddings.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, config: PretrainedConfig):\n\u001b[1;32m     94\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[0;32m---> 95\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mword_embeddings \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mEmbedding(config\u001b[39m.\u001b[39;49mvocab_size, config\u001b[39m.\u001b[39;49mdim, padding_idx\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mpad_token_id)\n\u001b[1;32m     96\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_embeddings \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mEmbedding(config\u001b[39m.\u001b[39mmax_position_embeddings, config\u001b[39m.\u001b[39mdim)\n\u001b[1;32m     97\u001b[0m     \u001b[39mif\u001b[39;00m config\u001b[39m.\u001b[39msinusoidal_pos_embds:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/sparse.py:142\u001b[0m, in \u001b[0;36mEmbedding.__init__\u001b[0;34m(self, num_embeddings, embedding_dim, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse, _weight, device, dtype)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mif\u001b[39;00m _weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    141\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight \u001b[39m=\u001b[39m Parameter(torch\u001b[39m.\u001b[39mempty((num_embeddings, embedding_dim), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfactory_kwargs))\n\u001b[0;32m--> 142\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreset_parameters()\n\u001b[1;32m    143\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mlist\u001b[39m(_weight\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m [num_embeddings, embedding_dim], \\\n\u001b[1;32m    145\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mShape of weight does not match num_embeddings and embedding_dim\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/sparse.py:151\u001b[0m, in \u001b[0;36mEmbedding.reset_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreset_parameters\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 151\u001b[0m     init\u001b[39m.\u001b[39;49mnormal_(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight)\n\u001b[1;32m    152\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fill_padding_idx_with_zero()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/init.py:155\u001b[0m, in \u001b[0;36mnormal_\u001b[0;34m(tensor, mean, std)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39moverrides\u001b[39m.\u001b[39mhas_torch_function_variadic(tensor):\n\u001b[1;32m    154\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39moverrides\u001b[39m.\u001b[39mhandle_torch_function(normal_, (tensor,), tensor\u001b[39m=\u001b[39mtensor, mean\u001b[39m=\u001b[39mmean, std\u001b[39m=\u001b[39mstd)\n\u001b[0;32m--> 155\u001b[0m \u001b[39mreturn\u001b[39;00m _no_grad_normal_(tensor, mean, std)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/init.py:19\u001b[0m, in \u001b[0;36m_no_grad_normal_\u001b[0;34m(tensor, mean, std)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_no_grad_normal_\u001b[39m(tensor, mean, std):\n\u001b[1;32m     18\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> 19\u001b[0m         \u001b[39mreturn\u001b[39;00m tensor\u001b[39m.\u001b[39;49mnormal_(mean, std)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.logging.set_verbosity_error()\n",
    "import torch\n",
    "import numpy as np\n",
    "from bert_score import score\n",
    "from tqdm import tqdm\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "scores = []\n",
    "sentences = df['output']\n",
    "i = 0\n",
    "for j in range(i+1, len(sentences)):\n",
    "    reference = [sentences[i]]\n",
    "    candidate = [sentences[j]]\n",
    "    P, R, F1 = score(candidate, reference, model_type=\"distilbert-base-uncased\", device=device)\n",
    "    scores.append((i, j, F1[0]))\n",
    "\n",
    "print(scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bert_score'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting BertScore: 100it [1:32:49, 55.69s/it]\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.logging.set_verbosity_error()\n",
    "import torch\n",
    "import numpy as np\n",
    "from bert_score import score\n",
    "from tqdm import tqdm\n",
    "\n",
    "with tqdm(total=None, desc=\"Getting BertScore\") as pbar:\n",
    "    for i in df.index:\n",
    "        scores = []\n",
    "        if df.loc[i, 'bert_score'] == '':\n",
    "            for j in df.index:\n",
    "                if i != j:\n",
    "                    reference = [df.loc[i, 'output']]\n",
    "                    candidate = [df.loc[j, 'output']]\n",
    "                    P, R, F1 = score(candidate, reference, model_type=\"distilbert-base-uncased\", device=device)\n",
    "                    scores.append(F1[0])\n",
    "                else:\n",
    "                    scores.append(torch.tensor(0))\n",
    "        df.at[i, 'bert_score'] = scores\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('bert.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "transformers.logging.set_verbosity_error()\n",
    "import torch\n",
    "import numpy as np\n",
    "from bert_score import score\n",
    "scores = []\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "predictions = [df['output'][0]]\n",
    "references = [df['output'][2]]\n",
    "P, R, F1 = score(predictions, references, model_type=\"distilbert-base-uncased\", device=device)\n",
    "scores.append(F1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8792)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ansible",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8e7d1722b9540128cc6c4f9aed36155fb4486e41c5d7b4b70de65ffd48074c1d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
