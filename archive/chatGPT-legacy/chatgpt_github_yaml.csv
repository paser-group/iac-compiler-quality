,IssueID,IssueTitle,IssueBody,CreationTimestamp,CommentCount,Prompt,Output,Valid,Code
0,80249,"community.general.lxd ""url: https://"" [Errno 2] No such file or directory","### Summary

I'm trying to list remote hosts using community.general.lxd using the url parameter.  Perhaps I'm doing something incorrectly.


$ansible-inventory -i lxd.yml --list
[WARNING]:  * Failed to parse /home/me/inventory-lxd/lxd.yml with auto plugin: [Errno 2] No such file or directory
[WARNING]:  * Failed to parse /home/me/inventory-lxd/lxd.yml with yaml plugin: Plugin configuration YAML file, not YAML inventory
[WARNING]:  * Failed to parse /home/me/inventory-lxd/lxd.yml with ini plugin: Invalid host pattern 'plugin:' supplied, ending in ':' is not
allowed, this character is reserved to provide a port.
[WARNING]: Unable to parse /home/me/inventory-lxd/lxd.yml as an inventory source
[WARNING]: No inventory was parsed, only implicit localhost is available
{
    ""_meta"": {
        ""hostvars"": {}
    },
    ""all"": {
        ""children"": [
            ""ungrouped""
        ]
    }
}


### Issue Type

Bug Report

### Component Name

community.general.lxd

### Ansible Version

```console
$ ansible --version
ansible [core 2.14.3]
  config file = /etc/ansible/ansible.cfg
  configured module search path = ['/home/me/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /home/me/.local/lib/python3.10/site-packages/ansible
  ansible collection location = /home/me/.ansible/collections:/usr/share/ansible/collections
  executable location = /home/cmccaddo/.local/bin/ansible
  python version = 3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0] (/usr/bin/python3)
  jinja version = 3.0.3
  libyaml = True
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
CONFIG_FILE() = /etc/ansible/ansible.cfg
```


### OS / Environment

Ubuntu 22.04

### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->
```
#lxd.yml
plugin: community.general.lxd
url: https://192.168.1.10:8443
```


### Expected Results

I have added remote hosts to my lxd's remote host list and can use lxc remote list to show the remote hosts. I expect that running the script should get the remote hosts container list. 

### Actual Results

```console
ansible-inventory [core 2.14.3]
  config file = /etc/ansible/ansible.cfg
  configured module search path = ['/home/me/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /home/me/.local/lib/python3.10/site-packages/ansible
  ansible collection location = /home/me/.ansible/collections:/usr/share/ansible/collections
  executable location = /home/me/.local/bin/ansible-inventory
  python version = 3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0] (/usr/bin/python3)
  jinja version = 3.0.3
  libyaml = True
Using /etc/ansible/ansible.cfg as config file
setting up inventory plugins
host_list declined parsing /home/me/inventory-lxd/lxd.yml as it did not pass its verify_file() method
script declined parsing /home/me/inventory-lxd/lxd.yml as it did not pass its verify_file() method
Loading collection community.general from /home/me/.ansible/collections/ansible_collections/community/general
Using inventory plugin 'ansible_collections.community.general.plugins.inventory.lxd' to process inventory source '/home/me/inventory-lxd/lxd.yml'
toml declined parsing /home/me/inventory-lxd/lxd.yml as it did not pass its verify_file() method
[WARNING]:  * Failed to parse /home/me/inventory-lxd/lxd.yml with auto plugin: [Errno 2] No such file or directory
  File ""/home/me/.local/lib/python3.10/site-packages/ansible/inventory/manager.py"", line 293, in parse_source
    plugin.parse(self._inventory, self._loader, source, cache=cache)
  File ""/home/me/.local/lib/python3.10/site-packages/ansible/plugins/inventory/auto.py"", line 59, in parse
    plugin.parse(inventory, loader, path, cache=cache)
  File ""/home/me/.ansible/collections/ansible_collections/community/general/plugins/inventory/lxd.py"", line 1099, in parse
    self._populate()
  File ""/home/me/.ansible/collections/ansible_collections/community/general/plugins/inventory/lxd.py"", line 1036, in _populate
    self.socket = self._connect_to_socket()
  File ""/home/me/.ansible/collections/ansible_collections/community/general/plugins/inventory/lxd.py"", line 289, in _connect_to_socket
    socket_connection = LXDClient(url, self.client_key, self.client_cert, self.debug)
  File ""/home/me/.ansible/collections/ansible_collections/community/general/plugins/module_utils/lxd.py"", line 64, in __init__
    ctx.load_cert_chain(cert_file, keyfile=key_file)
[WARNING]:  * Failed to parse /home/me/inventory-lxd/lxd.yml with yaml plugin: Plugin configuration YAML file, not YAML inventory
  File ""/home/me/.local/lib/python3.10/site-packages/ansible/inventory/manager.py"", line 293, in parse_source
    plugin.parse(self._inventory, self._loader, source, cache=cache)
  File ""/home/me/.local/lib/python3.10/site-packages/ansible/plugins/inventory/yaml.py"", line 114, in parse
    raise AnsibleParserError('Plugin configuration YAML file, not YAML inventory')
[WARNING]:  * Failed to parse /home/me/inventory-lxd/lxd.yml with ini plugin: Invalid host pattern 'plugin:' supplied, ending in ':' is not
allowed, this character is reserved to provide a port.
  File ""/home/me/.local/lib/python3.10/site-packages/ansible/inventory/manager.py"", line 293, in parse_source
    plugin.parse(self._inventory, self._loader, source, cache=cache)
  File ""/home/me/.local/lib/python3.10/site-packages/ansible/plugins/inventory/ini.py"", line 137, in parse
    raise AnsibleParserError(e)
[WARNING]: Unable to parse /home/me/inventory-lxd/lxd.yml as an inventory source
[WARNING]: No inventory was parsed, only implicit localhost is available
{
    ""_meta"": {
        ""hostvars"": {}
    },
    ""all"": {
        ""children"": [
            ""ungrouped""
        ]
    }
}
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-03-17T14:12:47Z,2,"Create a YAML Ansible playbook to exhibit the following issue: community.general.lxd ""url: https://"" [Errno 2] No such file or directory","```
---
- name: Test Playbook
  hosts: localhost
  gather_facts: no

  tasks:
  - name: Execute community.general.lxd
    community.general.lxd:
      url: https://
    ignore_errors: yes
```
",1,"
---
- name: Test Playbook
  hosts: localhost
  gather_facts: no

  tasks:
  - name: Execute community.general.lxd
    community.general.lxd:
      url: https://
    ignore_errors: yes
"
1,80230,Integer variable value has trailing zero truncated.,"### Summary

I have 2 vars files containing versions stored as integer values, this is because in some scripts  I need to be able to manipulate those values due to our version numbering differing from the build numbering.

If I have a version of `128.9` or `128.11` these are interpreted correctly and my scripts don't fail, if I use the version number of `128.10` it is interpreted as `128.1` causing the scripts to fail.

You can also reproduce this by taking a string value and using `float` to convert back into an integer and it produces the same result.




### Issue Type

Bug Report

### Component Name

debug

### Ansible Version

```console
ansible [core 2.13.3]
  config file = /home/smcc/github/onprem-ansible/ansible.cfg
  configured module search path = ['/home/smcc/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /usr/lib/python3.9/site-packages/ansible
  ansible collection location = /home/smcc/.ansible/collections:/usr/share/ansible/collections
  executable location = /usr/bin/ansible
  python version = 3.9.13 (main, Nov 16 2022, 10:51:39) [GCC 8.5.0 20210514 (Red Hat 8.5.0-15)]
  jinja version = 3.1.2
  libyaml = True
```


### Configuration

```console
CACHE_PLUGIN(/home/smcc/github/onprem-ansible/ansible.cfg) = jsonfile
CACHE_PLUGIN_CONNECTION(/home/smcc/github/onprem-ansible/ansible.cfg) = ./cachedir
CACHE_PLUGIN_TIMEOUT(/home/smcc/github/onprem-ansible/ansible.cfg) = 86400
CALLBACKS_ENABLED(/home/smcc/github/onprem-ansible/ansible.cfg) = ['profile_tasks']
DEFAULT_FORKS(/home/smcc/github/onprem-ansible/ansible.cfg) = 4
DEFAULT_GATHERING(/home/smcc/github/onprem-ansible/ansible.cfg) = explicit
DEFAULT_HOST_LIST(/home/smcc/github/onprem-ansible/ansible.cfg) = ['/home/smcc/github/onprem-ansible/hosts']
DEFAULT_STDOUT_CALLBACK(/home/smcc/github/onprem-ansible/ansible.cfg) = yaml
DEFAULT_TIMEOUT(/home/smcc/github/onprem-ansible/ansible.cfg) = 30
DISPLAY_SKIPPED_HOSTS(/home/smcc/github/onprem-ansible/ansible.cfg) = False
HOST_KEY_CHECKING(/home/smcc/github/onprem-ansible/ansible.cfg) = False
RETRY_FILES_ENABLED(/home/smcc/github/onprem-ansible/ansible.cfg) = False

CACHE:
=====

jsonfile:
________
_timeout(/home/smcc/github/onprem-ansible/ansible.cfg) = 86400
_uri(/home/smcc/github/onprem-ansible/ansible.cfg) = /home/smcc/github/onprem-ansible/cachedir

CALLBACK:
========

default:
_______
display_skipped_hosts(/home/smcc/github/onprem-ansible/ansible.cfg) = False

CONNECTION:
==========

paramiko_ssh:
____________
host_key_checking(/home/smcc/github/onprem-ansible/ansible.cfg) = False

ssh:
___
host_key_checking(/home/smcc/github/onprem-ansible/ansible.cfg) = False
timeout(/home/smcc/github/onprem-ansible/ansible.cfg) = 30
```


### OS / Environment

Alma 8.5


### Steps to Reproduce

**version.yaml**

```version: 128.10```

**docker-vars.yaml**

``` 
---
- images:

    128.10:
            - { hash: '1ae425c8e834', name: web,       group: web,       tarball: 'web.tar.gz' }
  ```


`test-version.yaml`

```
---
- name: Push docker images
  hosts: web

  vars_files:
    - vars/docker-vars.yaml
    - vars/version.yaml

  tasks:

    - debug: msg=""{{ version }}""
```




### Expected Results

If you pass a value in as `128.11` it will give the correct output.

Another way to reproduce this is if you take a string value and use `{{ version | float }}`  with `128.10` it does the same thing and truncates the zero, however if given the value of `128.11` produces the correct output.

`ansible-playbook -K  -e version='128.11' test-version.yaml`

```
TASK [debug] ***************************************************************************************************************************
ok: [web] =>
  msg: '128.11'
```

### Actual Results

```console
Using the value `128.10` produces the output, which is clearly incorrect.


TASK [debug] ***************************************************************************************************************************
ok: [web] =>
  msg: '128.1'
```
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-03-15T14:45:46Z,4,Create a YAML Ansible playbook to exhibit the following issue: Integer variable value has trailing zero truncated.,"```
---
- name: Exhibit integer variable issue
  hosts: localhost
  gather_facts: false

  vars:
    number: 5000

  tasks:
    - name: Display number variable
      debug:
        var: number

    - name: Divide number by 10
      set_fact:
        number_truncated: ""{{ number / 10 }}""

    - name: Display truncated number
      debug:
        var: number_truncated
...
```",1,"
---
- name: Exhibit integer variable issue
  hosts: localhost
  gather_facts: false

  vars:
    number: 5000

  tasks:
    - name: Display number variable
      debug:
        var: number

    - name: Divide number by 10
      set_fact:
        number_truncated: ""{{ number / 10 }}""

    - name: Display truncated number
      debug:
        var: number_truncated
...
"
2,80228,rescue module did not work when in handlers,"### Summary

I used block in handlers ,the program seems to have gone to the block module, but did not execute the rescure module after fail, the same code in task module is ok

### Issue Type

Bug Report

### Component Name

block,rescue,handlers

### Ansible Version

```console
$ ansible --version
ansible [core 2.14.3]
  config file = /Users/chenqian/.ansible.cfg
  configured module search path = ['/Users/chenqian/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /Users/chenqian/venv/lib/python3.10/site-packages/ansible
  ansible collection location = /Users/chenqian/.ansible/collections:/usr/share/ansible/collections
  executable location = /Users/chenqian/venv/bin/ansible
  python version = 3.10.4 (v3.10.4:9d38120e33, Mar 23 2022, 17:29:05) [Clang 13.0.0 (clang-1300.0.29.30)] (/Users/chenqian/venv/bin/python3)
  jinja version = 3.1.2
  libyaml = True
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
```


### OS / Environment

macos Ventura 13.2.1

### Steps to Reproduce

handlers/main.yml:
---
- name: reload_nginx
  include_tasks: tasks/reload_nginx.yml

tasks/reload_nginx.yml:
---
- name: Nginx server load new config
  block:
    - name: Reload nginx block
      command: nginx -s reload
  rescue:
    - name: Reload server fail, restore file
      copy:
        remote_src: true
        src: ""{{ config_file.backup_file }}""
        dest: /etc/nginx/conf.d/allow_host

### Expected Results

command in block excute fail, excute task in rescue module

### Actual Results

```console
RUNNING HANDLER [config_nginx : Reload nginx block] *****************************************************************************************************************
fatal: [10.237.79.14]: FAILED! => {""changed"": true, ""cmd"": [""nginx"", ""-s"", ""reload""], ""delta"": ""0:00:00.051688"", ""end"": ""2023-03-15 15:04:28.647219"", ""msg"": ""non-zero return code"", ""rc"": 1, ""start"": ""2023-03-15 15:04:28.595531"", ""stderr"": ""nginx: [emerg] unexpected \"";\"" in /etc/nginx/conf.d/allow_host:73"", ""stderr_lines"": [""nginx: [emerg] unexpected \"";\"" in /etc/nginx/conf.d/allow_host:73""], ""stdout"": """", ""stdout_lines"": []}

PLAY RECAP **********************************************************************************************************************************************************
10.237.79.14               : ok=4    changed=1    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-03-15T07:04:45Z,2,Create a YAML Ansible playbook to exhibit the following issue: rescue module did not work when in handlers,"```
---
- hosts: localhost
  gather_facts: false

  tasks:
    - name: Simulate an error
      command: /bin/false
      register: result
      ignore_errors: true

  handlers:
    - name: Rescue task
      command: echo ""This is the rescue task""

  post_tasks:
    - name: Trigger the handler
      command: echo ""Trigger the handler""
      notify: Rescue task
...
```",1,"
---
- hosts: localhost
  gather_facts: false

  tasks:
    - name: Simulate an error
      command: /bin/false
      register: result
      ignore_errors: true

  handlers:
    - name: Rescue task
      command: echo ""This is the rescue task""

  post_tasks:
    - name: Trigger the handler
      command: echo ""Trigger the handler""
      notify: Rescue task
...
"
3,80199,lineinfile append to string replaces whole line,"### Summary

If you want to append a string to an existing string via lineinfile the string is replaced. Added replace example where the regex find works.

### Issue Type

Bug Report

### Component Name

lineinfile

### Ansible Version

```console
$ ansible --version
ansible [core 2.14.3]
  config file = None
  configured module search path = ['/home/setsua/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /home/setsua/.local/lib/python3.9/site-packages/ansible
  ansible collection location = /home/setsua/.ansible/collections:/usr/share/ansible/collections
  executable location = /home/setsua/.local/bin/ansible
  python version = 3.9.2 (default, Feb 28 2021, 17:03:44) [GCC 10.2.1 20210110] (/usr/bin/python3)
  jinja version = 3.1.2
  libyaml = True
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
CONFIG_FILE() = None
```


### OS / Environment

PRETTY_NAME=""Debian GNU/Linux 11 (bullseye)""
NAME=""Debian GNU/Linux""
VERSION_ID=""11""
VERSION=""11 (bullseye)""
VERSION_CODENAME=bullseye
ID=debian
HOME_URL=""https://www.debian.org/""
SUPPORT_URL=""https://www.debian.org/support""
BUG_REPORT_URL=""https://bugs.debian.org/""

### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->
```plaintext
#demo.txt content
demo,test,foo
```

```yaml (paste below)
- name: Test
  hosts: localhost
  connection: local
  tasks:

    - name: Test lineinfile
      ansible.builtin.lineinfile:
        regex: '^(demo.*)$'
        line: '\1,foobar'
        path: ""{{ playbook_dir }}/demo.txt""

    - name: Test replace
      ansible.builtin.replace:
        regexp: '^(demo.*)$'
        replace: '\1,foobar'
        path: ""{{ playbook_dir }}/demo.txt""

```

### Expected Results

demo.txt content:
demo,test,foo -> demo,test,foo,foobar

### Actual Results

```console
demo.txt content:
demo,test,foo -> \1,foobar
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-03-13T09:53:35Z,4,Create a YAML Ansible playbook to exhibit the following issue: lineinfile append to string replaces whole line,"```
---
- name: An example playbook to exhibit the issue with lineinfile
  hosts: localhost
  gather_facts: no
  tasks:
    - name: Append to string using the lineinfile module
      lineinfile:
        path: /tmp/testfile
        line: 'Hello, World!'
        regexp: '^#greeting:'
        state: present
        insertafter: '^#greeting:'
      #- become: yes
      #- become_user: root
```
Note: Ensure that the file (/tmp/testfile) already exists and has a line that begins with ""#greeting:"".",1,"
---
- name: An example playbook to exhibit the issue with lineinfile
  hosts: localhost
  gather_facts: no
  tasks:
    - name: Append to string using the lineinfile module
      lineinfile:
        path: /tmp/testfile
        line: 'Hello, World!'
        regexp: '^#greeting:'
        state: present
        insertafter: '^#greeting:'
      #- become: yes
      #- become_user: root
"
4,80193,Unable to run dnf or yum modules in Python3 venv with Ansible 2.10,"### Summary

I am trying to run a playbook in a Python3 venv that should install a package using yum. I have explicitly specified the ansible_python_interpretor to be used as python2. However, during playbook run, I am observing that it is attempting to do the install using dnf and failing. How can I successfully get this playbook to run ? 

Please see details of system, environment, code and execution details below. Any pointers would be of immense help in working around this bug! Thank you.

Playbook:
```
---
- name: Prepare vcsa installation
  hosts: localhost
  gather_facts: no
  connection: local
  pre_tasks:
    - name: Install 7z
      yum:
        name:
          - p7zip
          - p7zip-plugins
        state: latest
      vars:
        ansible_python_interpreter: /usr/bin/python2
```
Playbook Run Output:
Here, it appears to be using dnf instead of yum.
```
(python3) [root@TestVM-01 esxi-automation]# ansible-playbook vcsa-deploy.yml
[WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

PLAY [Prepare vcsa installation] *****************************************************************************************************************************

TASK [Install 7z] ********************************************************************************************************************************************
fatal: [localhost]: FAILED! => {""ansible_facts"": {""pkg_mgr"": ""dnf""}, ""changed"": false, ""cmd"": ""dnf install -y python2-dnf"", ""msg"": ""Could not import the dnf python module using /usr/bin/python2 (2.7.18 (default, Oct 18 2022, 11:09:45) [GCC 8.5.0 20210514 (Red Hat 8.5.0-15)]). Please install `python2-dnf` package or ensure you have specified the correct ansible_python_interpreter."", ""rc"": 1, ""results"": [], ""stderr"": ""Error: Unable to find a match: python2-dnf\n"", ""stderr_lines"": [""Error: Unable to find a match: python2-dnf""], ""stdout"": ""Last metadata expiration check: 22:06:19 ago on Thu 09 Mar 2023 06:29:57 AM PST.\nNo match for argument: python2-dnf\n"", ""stdout_lines"": [""Last metadata expiration check: 22:06:19 ago on Thu 09 Mar 2023 06:29:57 AM PST."", ""No match for argument: python2-dnf""]}

PLAY RECAP ***************************************************************************************************************************************************
localhost                  : ok=1    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0  
``` 
I did read [here](https://github.com/ansible/ansible/issues/56583) about a workaround that overrides the ansible_fact for pkg_mgr - but, attempting to set this using 'set_fact' module at the top of my playbook did not work, resulting in a different but similar, error.

```
(python3) [root@TesterVM-01 esxi-automation]# cat vcsa-deploy.yml 
---
- name: Prepare vcsa installation
  hosts: localhost
  gather_facts: no
  connection: local

  pre_tasks:
    - name: Set pkg_mgr fact
      set_fact:
        ansible_facts:
          pkg_mgr: yum

    - name: Install 7z
      yum:
        name:
          - p7zip
          - p7zip-plugins
        state: latest
      vars:
        ansible_python_interpreter: /usr/bin/python2
```

Execution with the above change (set_fact) produced the following error:

```
(python3) [root@TestVM-01 esxi-automation]# ansible-playbook vcsa-deploy.yml 
[WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

PLAY [Prepare vcsa installation] *****************************************************************************************************************************

TASK [Set pkg_mgr fact] **************************************************************************************************************************************
ok: [localhost]

TASK [Install 7z] ********************************************************************************************************************************************
fatal: [localhost]: FAILED! => {""changed"": false, ""msg"": ""The Python 2 bindings for rpm are needed for this module. If you require Python 3 support use the `d
nf` Ansible module instead.. The Python 2 yum module is needed for this module. If you require Python 3 support use the `dnf` Ansible module instead.""}

PLAY RECAP ***************************************************************************************************************************************************
localhost                  : ok=2    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

(python3) [root@TestVM-01 esxi-automation]# yum --version
4.7.0
  Installed: dnf-0:4.7.0-11.el8.alma.noarch at Thu 26 Jan 2023 04:29:12 PM GMT
  Built    : AlmaLinux Packaging Team <packager@almalinux.org> at Wed 12 Oct 2022 09:46:34 AM GMT

  Installed: rpm-0:4.14.3-24.el8_7.x86_64 at Fri 03 Feb 2023 01:10:22 AM GMT
  Built    : AlmaLinux Packaging Team <packager@almalinux.org> at Wed 09 Nov 2022 03:50:55 PM GMT
(python3) [root@TestVM-01 esxi-automation]# 
```


### Issue Type

Bug Report

### Component Name

yum, dnf

### Ansible Version

```console
$ ansible --version
ansible 2.10.17
  config file = /root/esxi-automation/ansible.cfg
  configured module search path = ['/root/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /root/.venv/python3/lib/python3.9/site-packages/ansible
  executable location = /root/.venv/python3/bin/ansible
  python version = 3.9.13 (main, Nov 16 2022, 10:51:39) [GCC 8.5.0 20210514 (Red Hat 8.5.0-15)]
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
(python3) [root@TestVM-01 esxi-automation]# ansible-config dump --only-changed 
(python3) [root@TestVM-01 esxi-automation]#
```


### OS / Environment

```
(python3) [root@TestVM-01 esxi-automation]# hostnamectl
   Static hostname: TestVM-01
         Icon name: computer-vm
           Chassis: vm
        Machine ID: xxxx
           Boot ID: xxxx
    Virtualization: vmware
  Operating System: AlmaLinux 8.7 (Stone Smilodon)
       CPE OS Name: cpe:/o:almalinux:almalinux:8::baseos
            Kernel: Linux 4.18.0-425.3.1.el8.x86_64
      Architecture: x86-64
(python3) [root@TestVM-01 esxi-automation]# 

(python3) [root@TestVM-01 esxi-automation]# python --version
Python 3.9.13
(python3) [root@TestVM-01 esxi-automation]# python2 --version
Python 2.7.18
(python3) [root@TestVM-01 esxi-automation]# python3 --version
Python 3.9.13
(python3) [root@TestVM-01 esxi-automation]# ansible --version
ansible 2.10.17
  config file = /root/esxi-automation/ansible.cfg
  configured module search path = ['/root/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /root/.venv/python3/lib/python3.9/site-packages/ansible
  executable location = /root/.venv/python3/bin/ansible
  python version = 3.9.13 (main, Nov 16 2022, 10:51:39) [GCC 8.5.0 20210514 (Red Hat 8.5.0-15)]
(python3) [root@TestVM-01 esxi-automation]# 
```


### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->
Please check summary for sample minimal playbook, as well as modifications tried.

Playbook:
```
---
- name: Prepare vcsa installation
  hosts: localhost
  gather_facts: no
  connection: local

  pre_tasks:
    - name: Set pkg_mgr fact
      set_fact:
        ansible_facts:
          pkg_mgr: yum

    - name: Install 7z
      yum:
        name:
          - p7zip
          - p7zip-plugins
        state: latest
      vars:
        ansible_python_interpreter: /usr/bin/python2
```

Run playbook as below:
```yaml (paste below)
ansible-playbook vcsa-deploy.yml 
```


### Expected Results

I expected the packages. to be installed using yum

### Actual Results

```console
ansible-playbook 2.10.17
  config file = /root/esxi-automation/ansible.cfg
  configured module search path = ['/root/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /root/.venv/python3/lib/python3.9/site-packages/ansible
  executable location = /root/.venv/python3/bin/ansible-playbook
  python version = 3.9.13 (main, Nov 16 2022, 10:51:39) [GCC 8.5.0 20210514 (Red Hat 8.5.0-15)]
Using /root/esxi-automation/ansible.cfg as config file
host_list declined parsing /etc/ansible/hosts as it did not pass its verify_file() method
script declined parsing /etc/ansible/hosts as it did not pass its verify_file() method
auto declined parsing /etc/ansible/hosts as it did not pass its verify_file() method
[WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details
Parsed /etc/ansible/hosts inventory source with ini plugin
Skipping callback 'default', as we already have a stdout callback.
Skipping callback 'minimal', as we already have a stdout callback.
Skipping callback 'oneline', as we already have a stdout callback.

PLAYBOOK: vcsa-deploy.yml ************************************************************************************************************************************
4 plays in vcsa-deploy.yml

PLAY [Prepare vcsa installation] *****************************************************************************************************************************

TASK [Set pkg_mgr fact] **************************************************************************************************************************************
task path: /root/esxi-automation/vcsa-deploy.yml:14
ok: [localhost] => {
    ""ansible_facts"": {
        ""ansible_facts"": {
            ""pkg_mgr"": ""yum""
        }
    },
    ""changed"": false
}

TASK [Install 7z] ********************************************************************************************************************************************
task path: /root/esxi-automation/vcsa-deploy.yml:19
<127.0.0.1> ESTABLISH LOCAL CONNECTION FOR USER: root
<127.0.0.1> EXEC /bin/sh -c 'echo ~root && sleep 0'
<127.0.0.1> EXEC /bin/sh -c '( umask 77 && mkdir -p ""` echo /root/.ansible/tmp `""&& mkdir ""` echo /root/.ansible/tmp/ansible-tmp-1678475001.3120584-3480-20713
2204351504 `"" && echo ansible-tmp-1678475001.3120584-3480-207132204351504=""` echo /root/.ansible/tmp/ansible-tmp-1678475001.3120584-3480-207132204351504 `"" ) 
&& sleep 0'
Using module file /root/.venv/python3/lib/python3.9/site-packages/ansible/modules/yum.py
<127.0.0.1> PUT /root/.ansible/tmp/ansible-local-3461li9_ryd9/tmpgideekfl TO /root/.ansible/tmp/ansible-tmp-1678475001.3120584-3480-207132204351504/AnsiballZ_
yum.py
<127.0.0.1> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1678475001.3120584-3480-207132204351504/ /root/.ansible/tmp/ansible-tmp-1678475001.31205
84-3480-207132204351504/AnsiballZ_yum.py && sleep 0'
<127.0.0.1> EXEC /bin/sh -c '/usr/bin/python2 /root/.ansible/tmp/ansible-tmp-1678475001.3120584-3480-207132204351504/AnsiballZ_yum.py && sleep 0'
<127.0.0.1> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1678475001.3120584-3480-207132204351504/ > /dev/null 2>&1 && sleep 0'
The full traceback is:
WARNING: The below traceback may *not* be related to the actual failure.
  File ""/tmp/ansible_ansible.legacy.yum_payload_Z6uHJK/ansible_ansible.legacy.yum_payload.zip/ansible/modules/yum.py"", line 371, in <module>
fatal: [localhost]: FAILED! => {
    ""changed"": false,
    ""invocation"": {
        ""module_args"": {
            ""allow_downgrade"": false,
            ""autoremove"": false,
            ""bugfix"": false,
            ""conf_file"": null,
            ""disable_excludes"": null,
            ""disable_gpg_check"": false,
            ""disable_plugin"": [],
            ""disablerepo"": [],
            ""download_dir"": null,
            ""download_only"": false,
            ""enable_plugin"": [],
            ""enablerepo"": [],
            ""exclude"": [],
            ""install_repoquery"": true,
            ""install_weak_deps"": true,
            ""installroot"": ""/"",
            ""list"": null,
            ""lock_timeout"": 30,
            ""name"": [
                ""p7zip"",
                ""p7zip-plugins""
            ],
            ""releasever"": null,
            ""security"": false,
            ""skip_broken"": false,
            ""state"": ""latest"",
            ""update_cache"": false,
            ""update_only"": false,
            ""use_backend"": ""auto"",
            ""validate_certs"": true
        }
    },
    ""msg"": ""The Python 2 bindings for rpm are needed for this module. If you require Python 3 support use the `dnf` Ansible module instead.. The Python 2 yum 
module is needed for this module. If you require Python 3 support use the `dnf` Ansible module instead.""
}

PLAY RECAP ***************************************************************************************************************************************************
localhost                  : ok=2    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-03-10T19:07:00Z,5,Create a YAML Ansible playbook to exhibit the following issue: Unable to run dnf or yum modules in Python3 venv with Ansible 2.10,"```
---
- name: Test playbook for dnf/yum modules in Python3 venv
  hosts: all
  become: true

  tasks:
    - name: Activate Python3 venv
      ansible.builtin.shell: source /path/to/my/venv/bin/activate

    - name: Ensure dnf/yum packages are installed
      ansible.builtin.dnf:
        name: httpd
        state: present
    
    - name: Deactivate Python3 venv
      ansible.builtin.shell: deactivate

...
```",1,"
---
- name: Test playbook for dnf/yum modules in Python3 venv
  hosts: all
  become: true

  tasks:
    - name: Activate Python3 venv
      ansible.builtin.shell: source /path/to/my/venv/bin/activate

    - name: Ensure dnf/yum packages are installed
      ansible.builtin.dnf:
        name: httpd
        state: present
    
    - name: Deactivate Python3 venv
      ansible.builtin.shell: deactivate

...
"
5,80191,Using lookup() in authorized_key as shown in doc example crashes,"### Summary

The [documented example](https://docs.ansible.com/ansible/latest/collections/ansible/posix/authorized_key_module.html#examples) of how to add authorized_keys to a user from github by way of the `lookup()` method causes ansible to crash

### Issue Type

Bug Report

### Component Name

authorize_user

### Ansible Version

```console
$ ansible --version
ansible [core 2.14.3]
  config file = None
  configured module search path = ['/Users/twood5/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /opt/homebrew/Cellar/ansible/7.3.0/libexec/lib/python3.11/site-packages/ansible
  ansible collection location = /Users/twood5/.ansible/collections:/usr/share/ansible/collections
  executable location = /opt/homebrew/bin/ansible
  python version = 3.11.2 (main, Feb 16 2023, 02:55:59) [Clang 14.0.0 (clang-1400.0.29.202)] (/opt/homebrew/Cellar/ansible/7.3.0/libexec/bin/python3.11)
  jinja version = 3.1.2
  libyaml = True
```


### Configuration

```console
$ ansible-config dump --only-changed -t all
CONFIG_FILE() = None
```


### OS / Environment

Client OS: MacOS Ventura 13.2.1 (Apple M1)
Target OS:  Ubuntu 22.04

### Steps to Reproduce

Using the following example code in a loop -- https://docs.ansible.com/ansible/latest/collections/ansible/posix/authorized_key_module.html#examples
```yaml (paste below)
vars:
  local_users:
    - tedwardd
- name: Create local users
  ansible.builtin.user:
    name: ""{{ item }}""
    shell: /bin/bash
    state: present
  loop: ""{{ local_users }}""
- name: Set authorized keys taken from url using lookup
  ansible.posix.authorized_key:
    user: ""{{ item }}""
    state: present
    key: ""{{ lookup('url', 'https://github.com/tedwardd.keys', split_lines=False) }}""
  loop: ""{{ local_users }}""
```


### Expected Results

Should not crash

### Actual Results

```console
[Create authorized_keys for local users] ***************************************************************************************************************************************
objc[33184]: +[__NSCFConstantString initialize] may have been in progress in another thread when fork() was called.
objc[33184]: +[__NSCFConstantString initialize] may have been in progress in another thread when fork() was called. We cannot safely call it or ignore it in the fork() child process. Crashing instead. Set a breakpoint on objc_initializeAfterForkError to debug.
ERROR! A worker was found in a dead state
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-03-10T16:24:44Z,3,Create a YAML Ansible playbook to exhibit the following issue: Using lookup() in authorized_key as shown in doc example crashes,"```
---
- hosts: localhost
  tasks:
    - name: Add authorized key
      authorized_key:
        user: testuser
        key: ""{{ lookup('file', '/path/to/public_key.pub') }}""
```

Note: Please replace `/path/to/public_key.pub` with the actual path to your desired public key.",1,"
---
- hosts: localhost
  tasks:
    - name: Add authorized key
      authorized_key:
        user: testuser
        key: ""{{ lookup('file', '/path/to/public_key.pub') }}""
"
6,80186,ansible_become sets its value everywhere if setting ansible_become as variable of an import_role task,"### Summary

When i set a value in ansible_become in the `vars` of a task which use the `import_role` module, i expect that `ansible_become` value has its value set only in the scopes that it should have a specific value..
In my reproducible example i set `ansible_become: false` in `vars` of some tasks, but if i run the code then all debug prints show that `ansible_become` is `false` everywhere in the play even if it's not set.

As conseguence the `whoami` result shows that the current user is the `ansible_user` and not the `ansible_become_user` or root even if i used `become: yes`.


### Issue Type

Bug Report

### Component Name

import_role

### Ansible Version

```console
$ ansible --version
ansible 2.10.8
  config file = None
  configured module search path = ['/home/user/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /usr/lib/python3/dist-packages/ansible
  executable location = /usr/bin/ansible
  python version = 3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed
```


### OS / Environment

- Ubuntu 22.04.2 LTS
- Debian GNU/Linux 11 (bullseye)

### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->

The playbook:
```yaml (paste below)

- hosts: localhost
  connection: local
  gather_facts: yes
  tasks: 

    - block: 
        - name: This should not be defined
          debug:
            var: ansible_become
        
        - name: ""This should be the ansible_become_user but it's the ansible_user""
          shell:
            cmd: whoami
          register: my_whoami_result

        - debug:
            var: my_whoami_result
      become: yes

    - name: ""my test 1: This should not be defined""
      debug:
        var: ansible_become

    - name: Importing a random role in this way doesnt cause issues
      block:
        - name: ""This should be false""
          debug:
            var: ansible_become
        - name: ""importing a role""
          ansible.builtin.import_role:
            name: empty
      vars:
        ansible_become: false

    
    - name: ""my test 2: This should not be defined""
      debug:
        var: ansible_become
    
    # Issue: if this task is commented or include_role is used then all results in the playbook are right, otherwise ansible_become is false everywhere
    - name: ""Importing a random role in this way cause issues: ansible_become is false everywhere in all tasks""
      ansible.builtin.import_role:
        name: empty
      vars:
        ansible_become: false

    - name: ""my test 3: This should not be defined""
      debug:
        var: ansible_become

```

The mailn.yml  of the ""empty"" role
```yaml (paste below)

- name: Test in imported role
  debug:
    var: ansible_become

```

### Expected Results

I expect to find the same result of what i get if i replace `import_role` with `include_role`, so the following (correct) result:

```
PLAY [localhost] *******************************************************************************************************

TASK [Gathering Facts] *************************************************************************************************
ok: [localhost]

TASK [This should not be defined] **************************************************************************************
ok: [localhost] => {
    ""ansible_become"": ""VARIABLE IS NOT DEFINED!""
}

TASK [This should be the ansible_become_user but it's the ansible_user] ************************************************
changed: [localhost]

TASK [debug] ***********************************************************************************************************
ok: [localhost] => {
    ""my_whoami_result"": {
        ""changed"": true,
        ""cmd"": ""whoami"",
        ""delta"": ""0:00:00.003625"",
        ""end"": ""2023-03-09 19:37:38.857000"",
        ""failed"": false,
        ""rc"": 0,
        ""start"": ""2023-03-09 19:37:38.853375"",
        ""stderr"": """",
        ""stderr_lines"": [],
        ""stdout"": ""root"",
        ""stdout_lines"": [
            ""root""
        ]
    }
}

TASK [my test 1: This should not be defined] ***************************************************************************
ok: [localhost] => {
    ""ansible_become"": ""VARIABLE IS NOT DEFINED!""
}

TASK [This should be false] ********************************************************************************************
ok: [localhost] => {
    ""ansible_become"": false
}

TASK [empty : Test in imported role] ***********************************************************************************
ok: [localhost] => {
    ""ansible_become"": false
}

TASK [my test 2: This should not be defined] ***************************************************************************
ok: [localhost] => {
    ""ansible_become"": ""VARIABLE IS NOT DEFINED!""
}

TASK [Importing a random role in this way cause issues: ansible_become is false everywhere in all tasks] ***************

TASK [empty : Test in imported role] ***********************************************************************************
ok: [localhost] => {
    ""ansible_become"": false
}

TASK [my test 3: This should not be defined] ***************************************************************************
ok: [localhost] => {
    ""ansible_become"": ""VARIABLE IS NOT DEFINED!""
}

PLAY RECAP *************************************************************************************************************
localhost                  : ok=10   changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0

```


### Actual Results

```console
PLAY [localhost] *******************************************************************************************************

TASK [Gathering Facts] *************************************************************************************************
ok: [localhost]

TASK [This should not be defined] **************************************************************************************
ok: [localhost] => {
    ""ansible_become"": false
}

TASK [This should be the ansible_become_user but it's the ansible_user] ************************************************
changed: [localhost]

TASK [debug] ***********************************************************************************************************
ok: [localhost] => {
    ""my_whoami_result"": {
        ""changed"": true,
        ""cmd"": ""whoami"",
        ""delta"": ""0:00:00.002888"",
        ""end"": ""2023-03-09 19:30:49.876900"",
        ""failed"": false,
        ""rc"": 0,
        ""start"": ""2023-03-09 19:30:49.874012"",
        ""stderr"": """",
        ""stderr_lines"": [],
        ""stdout"": ""user"",
        ""stdout_lines"": [
            ""user""
        ]
    }
}

TASK [my test 1: This should not be defined] ***************************************************************************
ok: [localhost] => {
    ""ansible_become"": false
}

TASK [This should be false] ********************************************************************************************
ok: [localhost] => {
    ""ansible_become"": false
}

TASK [empty : Test in imported role] ***********************************************************************************
ok: [localhost] => {
    ""ansible_become"": false
}

TASK [my test 2: This should not be defined] ***************************************************************************
ok: [localhost] => {
    ""ansible_become"": false
}

TASK [empty : Test in imported role] ***********************************************************************************
ok: [localhost] => {
    ""ansible_become"": false
}

TASK [my test 3: This should not be defined] ***************************************************************************
ok: [localhost] => {
    ""ansible_become"": false
}

PLAY RECAP *************************************************************************************************************
localhost                  : ok=10   changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-03-09T18:55:35Z,2,Create a YAML Ansible playbook to exhibit the following issue: ansible_become sets its value everywhere if setting ansible_become as variable of an import_role task,"```
---
- name: Test playbook for ansible_become issue
  hosts: localhost
  become: true
  
  tasks:
    - name: Import role with ansible_become as variable
      import_role:
        name: example_role
        vars:
          ansible_become: false
```
Note: In the above playbook, the ansible_become variable is set to false while importing the role ""example_role"". However, since ansible_become is a global setting in Ansible, setting it within the role will override the value set in the playbook, causing all subsequent tasks that execute under the role to run as the specified become user. This can be used to demonstrate the issue where ansible_become sets its value everywhere if set as a variable of an import_role task.",1,"
---
- name: Test playbook for ansible_become issue
  hosts: localhost
  become: true
  
  tasks:
    - name: Import role with ansible_become as variable
      import_role:
        name: example_role
        vars:
          ansible_become: false
"
7,80185,ansible serial do not continue when one host failed,"### Summary

I am using ansible [core 2.11.4]

I realized that when I run ansible in serial mode ( to run some tasks on multiple hosts ) and task is failed on one host, then ansible breaks at all.
Is it a bug or ?

### Issue Type

Bug Report

### Component Name

pip

### Ansible Version

```console
$ ansible --version
ansible [core 2.11.4]
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
DEFAULT_HOST_LIST(/opt/mie_ansible_control/ansible.cfg) = ['/opt/mie_ansible_control/hosts']
DEFAULT_LOG_PATH(/opt/mie_ansible_control/ansible.cfg) = /root/mie_ansible_control.log
DEFAULT_ROLES_PATH(/opt/mie_ansible_control/ansible.cfg) = ['/root/roles', '/opt/mie_ansible_control/roles']
```


### OS / Environment

RHEL 8.7

### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->
```yaml (paste below)

```


### Expected Results

in standard linear ( non-serial) mode it works normally, it continue with other host

### Actual Results

```console
TASK [Compare ver. after Patching - when not patched] ********************************************************************************************
fatal: [rh8-test]: FAILED! => {
    ""msg"": ""Req. new patch bundle 1Q2023 was not applied ! Check logs. Current 3Q2022... ""
}

PLAY RECAP ***************************************************************************************************************************************
rh8-test            : ok=9    changed=4    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-03-09T15:35:43Z,2,Create a YAML Ansible playbook to exhibit the following issue: ansible serial do not continue when one host failed,"```
---
- name: Example Playbook
  hosts: all
  serial: 1
  tasks:
    - name: Some task that will fail on one host
      command: /nonexistent_command
      ignore_errors: true
```
",1,"
---
- name: Example Playbook
  hosts: all
  serial: 1
  tasks:
    - name: Some task that will fail on one host
      command: /nonexistent_command
      ignore_errors: true
"
8,80183,"[For clarification] Any reasons to keep filename/folder with special character such as ""ansible-testé.cfg"" ","### Summary

Reason for filing this bug as I was thinking the filenames should have printable ASCII characters. looking for a guidance here.

Could see few files/folders under test folder having this special character in their names.

test/integration/targets/ansible/ansible-testé.cfg
test/integration/targets/ansible-vault/vault-café.yml
test/integration/targets/template/templates/café.j2
test/integration/targets/unarchive/files/test-unarchive-nonascii-くらとみ.tar.gz
test/integration/targets/unicode/křížek-ansible-project/ansible.cfg

### Issue Type

Bug Report

### Component Name

test/Integration/targets

### Ansible Version

```console
2.14.3
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
```


### OS / Environment

Centos 8

### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->
```yaml (paste below)

```


### Expected Results

build should succeed

### Actual Results

```console
build fails
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-03-09T07:43:43Z,4,"Create a YAML Ansible playbook to exhibit the following issue: [For clarification] Any reasons to keep filename/folder with special character such as ""ansible-testé.cfg"" ","```
---

- name: Testing Special Characters in File Name
  hosts: all
  gather_facts: true

  tasks:
    - name: Create directory with special character
      file:
        path: ""/tmp/ansible-testé""
        state: directory
        mode: 0777

    - name: Create file with special character
      file:
        path: ""/tmp/ansible-testé/ansible-testé.cfg""
        state: touch
        mode: 0666
      register: file_output

    - name: Display output
      debug:
        var: file_output

---

```",0,"
---

- name: Testing Special Characters in File Name
  hosts: all
  gather_facts: true

  tasks:
    - name: Create directory with special character
      file:
        path: ""/tmp/ansible-testé""
        state: directory
        mode: 0777

    - name: Create file with special character
      file:
        path: ""/tmp/ansible-testé/ansible-testé.cfg""
        state: touch
        mode: 0666
      register: file_output

    - name: Display output
      debug:
        var: file_output

---

"
9,80167,async_status fails when jinja2_native is enabled,"### Summary

`async_status` fails with the error `could not find job` if `jinja2_native` is enabled. I guess `jinja2_native` causes `ansible_job_id` to be interpreted as float number, resulting in trailing zeros being cut off.

This playbook works for `jinja2_native = False` but fails for `jinja2_native = True`.

#77450 may or may not describe the same issue.

### Issue Type

Bug Report

### Component Name

async_status

### Ansible Version

```console
$ ansible --version
ansible [core 2.14.3]
  config file = /etc/ansible/ansible.cfg
  configured module search path = ['/home/au/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /usr/local/lib/python3.11/ansible-2.14/lib/python3.11/site-packages/ansible
  ansible collection location = /home/au/.ansible/collections:/usr/local/share/ansible/collections:/usr/share/ansible/collections
  executable location = /usr/local/lib/python3.11/ansible-2.14/bin/ansible
  python version = 3.11.2 (main, Feb  8 2023, 14:49:25) [GCC 11.3.0] (/usr/local/lib/python3.11/ansible-2.14/bin/python3.11)
  jinja version = 3.1.2
  libyaml = True
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
COLLECTIONS_PATHS(/etc/ansible/ansible.cfg) = ['/home/au/.ansible/collections', '/usr/local/share/ansible/collections', '/usr/share/ansible/collections']
CONFIG_FILE() = /etc/ansible/ansible.cfg
DEFAULT_ASK_VAULT_PASS(/etc/ansible/ansible.cfg) = False
DEFAULT_FORKS(/etc/ansible/ansible.cfg) = 50
DEFAULT_GATHERING(/etc/ansible/ansible.cfg) = implicit
DEFAULT_HOST_LIST(/etc/ansible/ansible.cfg) = ['/etc/redacted/environment']
DEFAULT_JINJA2_EXTENSIONS(/etc/ansible/ansible.cfg) = jinja2.ext.do,jinja2.ext.i18n
DEFAULT_JINJA2_NATIVE(/etc/ansible/ansible.cfg) = True
DEFAULT_LOG_PATH(/etc/ansible/ansible.cfg) = /var/log/ansible/ansible.log
DEFAULT_VAULT_PASSWORD_FILE(env: ANSIBLE_VAULT_PASSWORD_FILE) = /home/au/.ansible_vault_password.txt

CONNECTION:
==========

paramiko_ssh:
____________
ssh_args(/etc/ansible/ansible.cfg) = -C -o ControlMaster=auto -o ControlPersist=3600s -o PreferredAuthentications=publickey

ssh:
___
pipelining(/etc/ansible/ansible.cfg) = True
ssh_args(/etc/ansible/ansible.cfg) = -C -o ControlMaster=auto -o ControlPersist=3600s -o PreferredAuthentications=publickey
```


### OS / Environment

Ubuntu 22.04, Python v3.11

### Steps to Reproduce

```yaml (paste below)
- hosts: repository
  become: false
  gather_facts: false
  vars:
    foo:
      - 1
      - 2
      - 3
      - 4
  tasks:
    - name: ""Run jobs""
      delegate_to: localhost
      ansible.builtin.wait_for:
        timeout: '{{ item }}'
      loop: '{{ foo }}'
      async: 900
      poll: 0
      register: jobs
    - debug: var=jobs
      delegate_to: localhost
    - name: ""Wait for jobs to complete""
      delegate_to: localhost
      ansible.builtin.async_status:
        jid: '{{ item.ansible_job_id }}'
      loop: '{{ jobs.results }}'
      register: job_result
      until: 'job_result.finished'
      delay: 1
      retries: 20
```


### Expected Results

`async_status` works correctly with any `jinja2_native` setting.

### Actual Results

```console
TASK [Wait for jobs to complete] *******************************************************************************************************************************
ok: [n0216 -> localhost] => (item={'failed': 0, 'started': 1, 'finished': 0, 'ansible_job_id': '2472848566.371113', 'results_file': '/home/au/.ansible_async/2472848566.371113', 'changed': True, 'item': 1, 'ansible_loop_var': 'item'})
failed: [n0214 -> localhost] (item={'failed': 0, 'started': 1, 'finished': 0, 'ansible_job_id': '213235788261.371115', 'results_file': '/home/au/.ansible_async/213235788261.371115', 'changed': True, 'item': 1, 'ansible_loop_var': 'item'}) => {""ansible_job_id"": ""213235788261.37112"", ""ansible_loop_var"": ""item"", ""attempts"": 1, ""changed"": false, ""finished"": 1, ""item"": {""ansible_job_id"": ""213235788261.371115"", ""ansible_loop_var"": ""item"", ""changed"": true, ""failed"": 0, ""finished"": 0, ""item"": 1, ""results_file"": ""/home/au/.ansible_async/213235788261.371115"", ""started"": 1}, ""msg"": ""could not find job"", ""results_file"": ""/home/au/.ansible_async/213235788261.37112"", ""started"": 1, ""stderr"": """", ""stderr_lines"": [], ""stdout"": """", ""stdout_lines"": []}
failed: [n0216 -> localhost] (item={'failed': 0, 'started': 1, 'finished': 0, 'ansible_job_id': '116415498736.371180', 'results_file': '/home/au/.ansible_async/116415498736.371180', 'changed': True, 'item': 2, 'ansible_loop_var': 'item'}) => {""ansible_job_id"": ""116415498736.37119"", ""ansible_loop_var"": ""item"", ""attempts"": 1, ""changed"": false, ""finished"": 1, ""item"": {""ansible_job_id"": ""116415498736.371180"", ""ansible_loop_var"": ""item"", ""changed"": true, ""failed"": 0, ""finished"": 0, ""item"": 2, ""results_file"": ""/home/au/.ansible_async/116415498736.371180"", ""started"": 1}, ""msg"": ""could not find job"", ""results_file"": ""/home/au/.ansible_async/116415498736.37119"", ""started"": 1, ""stderr"": """", ""stderr_lines"": [], ""stdout"": """", ""stdout_lines"": []}
failed: [n0214 -> localhost] (item={'failed': 0, 'started': 1, 'finished': 0, 'ansible_job_id': '919958937976.371172', 'results_file': '/home/au/.ansible_async/919958937976.371172', 'changed': True, 'item': 2, 'ansible_loop_var': 'item'}) => {""ansible_job_id"": ""919958937976.3712"", ""ansible_loop_var"": ""item"", ""attempts"": 1, ""changed"": false, ""finished"": 1, ""item"": {""ansible_job_id"": ""919958937976.371172"", ""ansible_loop_var"": ""item"", ""changed"": true, ""failed"": 0, ""finished"": 0, ""item"": 2, ""results_file"": ""/home/au/.ansible_async/919958937976.371172"", ""started"": 1}, ""msg"": ""could not find job"", ""results_file"": ""/home/au/.ansible_async/919958937976.3712"", ""started"": 1, ""stderr"": """", ""stderr_lines"": [], ""stdout"": """", ""stdout_lines"": []}
failed: [n0216 -> localhost] (item={'failed': 0, 'started': 1, 'finished': 0, 'ansible_job_id': '5652918489.371230', 'results_file': '/home/au/.ansible_async/5652918489.371230', 'changed': True, 'item': 3, 'ansible_loop_var': 'item'}) => {""ansible_job_id"": ""5652918489.37123"", ""ansible_loop_var"": ""item"", ""attempts"": 1, ""changed"": false, ""finished"": 1, ""item"": {""ansible_job_id"": ""5652918489.371230"", ""ansible_loop_var"": ""item"", ""changed"": true, ""failed"": 0, ""finished"": 0, ""item"": 3, ""results_file"": ""/home/au/.ansible_async/5652918489.371230"", ""started"": 1}, ""msg"": ""could not find job"", ""results_file"": ""/home/au/.ansible_async/5652918489.37123"", ""started"": 1, ""stderr"": """", ""stderr_lines"": [], ""stdout"": """", ""stdout_lines"": []}
failed: [n0214 -> localhost] (item={'failed': 0, 'started': 1, 'finished': 0, 'ansible_job_id': '914125962854.371228', 'results_file': '/home/au/.ansible_async/914125962854.371228', 'changed': True, 'item': 3, 'ansible_loop_var': 'item'}) => {""ansible_job_id"": ""914125962854.3712"", ""ansible_loop_var"": ""item"", ""attempts"": 1, ""changed"": false, ""finished"": 1, ""item"": {""ansible_job_id"": ""914125962854.371228"", ""ansible_loop_var"": ""item"", ""changed"": true, ""failed"": 0, ""finished"": 0, ""item"": 3, ""results_file"": ""/home/au/.ansible_async/914125962854.371228"", ""started"": 1}, ""msg"": ""could not find job"", ""results_file"": ""/home/au/.ansible_async/914125962854.3712"", ""started"": 1, ""stderr"": """", ""stderr_lines"": [], ""stdout"": """", ""stdout_lines"": []}
failed: [n0216 -> localhost] (item={'failed': 0, 'started': 1, 'finished': 0, 'ansible_job_id': '389454738748.371280', 'results_file': '/home/au/.ansible_async/389454738748.371280', 'changed': True, 'item': 4, 'ansible_loop_var': 'item'}) => {""ansible_job_id"": ""389454738748.3713"", ""ansible_loop_var"": ""item"", ""attempts"": 1, ""changed"": false, ""finished"": 1, ""item"": {""ansible_job_id"": ""389454738748.371280"", ""ansible_loop_var"": ""item"", ""changed"": true, ""failed"": 0, ""finished"": 0, ""item"": 4, ""results_file"": ""/home/au/.ansible_async/389454738748.371280"", ""started"": 1}, ""msg"": ""could not find job"", ""results_file"": ""/home/au/.ansible_async/389454738748.3713"", ""started"": 1, ""stderr"": """", ""stderr_lines"": [], ""stdout"": """", ""stdout_lines"": []}
failed: [n0214 -> localhost] (item={'failed': 0, 'started': 1, 'finished': 0, 'ansible_job_id': '453752779188.371273', 'results_file': '/home/au/.ansible_async/453752779188.371273', 'changed': True, 'item': 4, 'ansible_loop_var': 'item'}) => {""ansible_job_id"": ""453752779188.3713"", ""ansible_loop_var"": ""item"", ""attempts"": 1, ""changed"": false, ""finished"": 1, ""item"": {""ansible_job_id"": ""453752779188.371273"", ""ansible_loop_var"": ""item"", ""changed"": true, ""failed"": 0, ""finished"": 0, ""item"": 4, ""results_file"": ""/home/au/.ansible_async/453752779188.371273"", ""started"": 1}, ""msg"": ""could not find job"", ""results_file"": ""/home/au/.ansible_async/453752779188.3713"", ""started"": 1, ""stderr"": """", ""stderr_lines"": [], ""stdout"": """", ""stdout_lines"": []}
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-03-08T16:20:25Z,4,Create a YAML Ansible playbook to exhibit the following issue: async_status fails when jinja2_native is enabled,"```yaml
---
- name: Ansible Playbook to demonstrate async_status failure with jinja2_native
  hosts: all
  become: true
  vars:
    my_var: ""{{ my_list | length }}""
    my_list:
      - one
      - two
      - three
  tasks:
    - name: Task 1
      command: ""echo 'Task 1 execution'""
      async: 10
      register: task_output
      poll: 2
    - name: Task 2
      command: ""echo 'Task 2 execution'""
      when: task_output is not failed
      async_status:
        jinja2_native: true
        query_interval: 1
        max_retries: 30
        timeout: 300
      register: task_status
    - name: Task 3
      debug:
        var: task_status
...
```",0,"yaml
---
- name: Ansible Playbook to demonstrate async_status failure with jinja2_native
  hosts: all
  become: true
  vars:
    my_var: ""{{ my_list | length }}""
    my_list:
      - one
      - two
      - three
  tasks:
    - name: Task 1
      command: ""echo 'Task 1 execution'""
      async: 10
      register: task_output
      poll: 2
    - name: Task 2
      command: ""echo 'Task 2 execution'""
      when: task_output is not failed
      async_status:
        jinja2_native: true
        query_interval: 1
        max_retries: 30
        timeout: 300
      register: task_status
    - name: Task 3
      debug:
        var: task_status
...
"
10,80163,Unique identifier is not UUID but it is referred to as such,"### Summary

Unique identifier[0] used by playbooks is referred to as `uuid`, and it looks a lot like it. But it is using custom algorithm with once generated random number, MAC address and increments of global variable `_cur_id`, rather than time and MAC address specified by RFC4122 [1] for UUIDv1.

At the same time this implementation doesn't follow other versions of UUID. Version 4, does use random numbers, but not MAC nor time. Versions 3 and 5 rely on namespaces and hashing. Finally, UUIDv2 also uses time, in addition to local domain identifiers[2].

IDs produced by the existing code should be relatively collision resistant, as the `cur_id` is 12 hex digits long.
So this isn't a security issue. But it's not exactly documentation issue either, because addressing it may require changes in the source.

[0]https://github.com/search?q=repo%3Aansible/ansible%20get_unique_id&type=code
[1]https://www.rfc-editor.org/rfc/rfc4122.html#section-4.1.1
[2]https://pubs.opengroup.org/onlinepubs/9696989899/chap5.htm#tagcjh_08_02_01_01

### Issue Type

Bug Report

### Component Name

 ansible.utils.vars

### Ansible Version

```console
$ ansible --version
devel
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
```


### OS / Environment

All

### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->
```yaml (paste below)
ansible.utils.vars.get_unique_id()
```


### Expected Results

I expected to receive UUID as defined by RFC4122.

### Actual Results

```console
I've received a custom identifier.
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-03-08T09:57:01Z,2,Create a YAML Ansible playbook to exhibit the following issue: Unique identifier is not UUID but it is referred to as such,"```
---
- name: exhibit unique identifier name issue
  hosts: servers
  gather_facts: false

  vars:
    unique_id: ""1241""

  tasks:
    - name: display unique id
      debug:
        msg: ""The value of unique id is {{unique_id}} and it is referred to as UUID.""

...
```",1,"
---
- name: exhibit unique identifier name issue
  hosts: servers
  gather_facts: false

  vars:
    unique_id: ""1241""

  tasks:
    - name: display unique id
      debug:
        msg: ""The value of unique id is {{unique_id}} and it is referred to as UUID.""

...
"
11,80142,service module in service mode does not restart auditd,"### Summary

The bug is kinda elaborated here: https://stackoverflow.com/a/47442135/2897386 (answer and comments)

Explanation: Due to issue https://access.redhat.com/solutions/2664811 , auditd cannot be restarted using Ansible on CentOS 7 using systemd . The recommended solution is to use `service` instead, which in Ansible can be accomplished by using the `service` module using the `use: service` argument.

However, while this completes successfully and without error it does not, in fact, restart the service.

It is notable that this behaviour is different than if you use the same Ansible context and simply run service using `command: /sbin/service auditd restart` instead. Therefore this is clearly a module bug.

### Issue Type

Bug Report

### Component Name

service module

### Ansible Version

```console
$ ansible --version
ansible [core 2.13.4]
  config file = /home/username/dev-jsah/ansible.cfg
  configured module search path = ['/home/username/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /usr/local/lib/python3.9/site-packages/ansible
  ansible collection location = /home/username/.ansible/collections:/usr/share/ansible/collections
  executable location = /usr/local/bin/ansible
  python version = 3.9.7 (default, Sep 21 2021, 00:13:39) [GCC 8.5.0 20210514 (Red Hat 8.5.0-3)]
  jinja version = 3.1.2
  libyaml = True
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
DEFAULT_NO_LOG(/home/username/dev-jsah/ansible.cfg) = False
DEFAULT_ROLES_PATH(/home/username/dev-jsah/ansible.cfg) = ['/home/username/dev-jsah/roles', '/usr/share/ansible/roles']
DEFAULT_STDOUT_CALLBACK(/home/username/dev-jsah/ansible.cfg) = yaml
HOST_KEY_CHECKING(/home/username/dev-jsah/ansible.cfg) = False

CONNECTION:
==========

paramiko_ssh:
____________
host_key_checking(/home/username/dev-jsah/ansible.cfg) = False

ssh:
___
host_key_checking(/home/username/dev-jsah/ansible.cfg) = False
```


### OS / Environment

Managed device is CentOS 7.9.2009 .

### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->
```yaml (paste below)
- service: name=auditd state=restarted use=service
```


### Expected Results

Expected step to complete without error and service to be restarted.

### Actual Results

```console
Step was completed without error, but the service was not restarted.
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-03-06T10:05:07Z,5,Create a YAML Ansible playbook to exhibit the following issue: service module in service mode does not restart auditd,"```
---
- name: Playbook to exhibit service module issue
  hosts: all
  become: true
  
  tasks:
    - name: Stop auditd service
      service:
        name: auditd
        state: stopped
    
    - name: Ensure auditd service is running
      service:
        name: auditd
        state: started
```
",1,"
---
- name: Playbook to exhibit service module issue
  hosts: all
  become: true
  
  tasks:
    - name: Stop auditd service
      service:
        name: auditd
        state: stopped
    
    - name: Ensure auditd service is running
      service:
        name: auditd
        state: started
"
12,80139,Ansible shell commands with apt or apt-get install commands are flaky may fail with MODULE FAILURE,"### Summary


The following task fails 50-70% of the time in my Ansible playbook:

```
- name: Install OpenJDK 8
  tags: java
  become: yes
  become_user: root
  become_method: sudo
  shell: |
    sudo apt install -y --force-yes openjdk-8-jdk
```
and other apt install tasks can fail too. This is at the very beginning of my playbook.

I tried to tweak the SSH configs but it didn't seem to make a difference. The task may just be stuck there and die after ~30-40 minutes while printing out MODULE FAILURE with no helpful error.



### Issue Type

Bug Report

### Component Name

shell,apt

### Ansible Version

```console
2.0.2.0
```


### Configuration

```console
Using Ansible wrapped in HashiCorp packer so this `ansible-config dump` command doesn't apply here.
```


### OS / Environment

Ubuntu 20.04

### Steps to Reproduce

```
- name: Install OpenJDK 8
  tags: java
  become: yes
  become_user: root
  become_method: sudo
  shell: |
    sudo apt install -y --force-yes openjdk-8-jdk
```


### Expected Results

It should succeed with no errors.

### Actual Results

```console
Detailed logs:

    azure-arm: TASK [common : Install OpenJDK 8] **********************************************
    azure-arm: <127.0.0.1> ESTABLISH SSH CONNECTION FOR USER: ubuntu
    azure-arm: <127.0.0.1> SSH: EXEC ssh -C -vvv -C -o ControlMaster=no -o StrictHostKeyChecking=no -o Port=42385 -o 'IdentityFile=""/tmp/ansible-key3374820541""' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o User=ubuntu -o ConnectTimeout=10 '-o IdentitiesOnly=yes' 127.0.0.1 '/bin/sh -c '""'""'( umask 22 && mkdir -p ""` echo $HOME/.ansible/tmp/ansible-tmp-1677969672.19-195965380432543 `"" && echo ""` echo $HOME/.ansible/tmp/ansible-tmp-1677969672.19-195965380432543 `"" )'""'""''
    azure-arm: <127.0.0.1> PUT /tmp/tmpG2TgH7 TO /home/packer/.ansible/tmp/ansible-tmp-1677969672.19-195965380432543/command
    azure-arm: <127.0.0.1> SSH: EXEC scp -C -vvv -C -o ControlMaster=no -o StrictHostKeyChecking=no -o Port=42385 -o 'IdentityFile=""/tmp/ansible-key3374820541""' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o User=ubuntu -o ConnectTimeout=10 /tmp/tmpG2TgH7 '[127.0.0.1]:/home/packer/.ansible/tmp/ansible-tmp-1677969672.19-195965380432543/command'
    azure-arm: <127.0.0.1> ESTABLISH SSH CONNECTION FOR USER: ubuntu
    azure-arm: <127.0.0.1> SSH: EXEC ssh -C -vvv -C -o ControlMaster=no -o StrictHostKeyChecking=no -o Port=42385 -o 'IdentityFile=""/tmp/ansible-key3374820541""' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o User=ubuntu -o ConnectTimeout=10 '-o IdentitiesOnly=yes' -tt 127.0.0.1 '/bin/sh -c '""'""'sudo -H -S -n -u root /bin/sh -c '""'""'""'""'""'""'""'""'echo BECOME-SUCCESS-bmjzcymjlnuzrkuhrppbryqpwsfllfxf; LANG=C.UTF-8 LC_ALL=C.UTF-8 LC_MESSAGES=C.UTF-8 /usr/bin/python /home/packer/.ansible/tmp/ansible-tmp-1677969672.19-195965380432543/command; rm -rf ""/home/packer/.ansible/tmp/ansible-tmp-1677969672.19-195965380432543/"" > /dev/null 2>&1'""'""'""'""'""'""'""'""''""'""''
    azure-arm: fatal: [default]: FAILED! => {""changed"": false, ""failed"": true, ""invocation"": {""module_name"": ""command""}, ""module_stderr"": ""OpenSSH_7.9p1 Ubuntu-10~ubuntu18.04.fips.0.2, OpenSSL 1.1.1  11 Sep 2018\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 19: Applying options for *\r\ndebug2: resolve_canonicalize: hostname 127.0.0.1 is address\r\nFIPS mode initialized\r\ndebug2: ssh_connect_direct\r\ndebug1: Connecting to 127.0.0.1 [127.0.0.1] port 42385.\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug1: fd 3 clearing O_NONBLOCK\r\ndebug1: Connection established.\r\ndebug3: timeout: 10000 ms remain after connect\r\ndebug1: identity file /tmp/ansible-key3374820541 type -1\r\ndebug1: identity file /tmp/ansible-key3374820541-cert type -1\r\ndebug1: Local version string SSH-2.0-OpenSSH_7.9p1 Ubuntu-10~ubuntu18.04.fips.0.2\r\ndebug1: Remote protocol version 2.0, remote software version Go\r\ndebug1: no match: Go\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug1: Authenticating to 127.0.0.1:42385 as 'ubuntu'\r\ndebug3: put_host_port: [127.0.0.1]:42385\r\ndebug3: hostkeys_foreach: reading file \""/home/ubuntu/.ssh/known_hosts\""\r\ndebug3: record_hostkey: found key type RSA in file /home/ubuntu/.ssh/known_hosts:5\r\ndebug3: load_hostkeys: loaded 1 keys from [127.0.0.1]:42385\r\ndebug3: order_hostkeyalgs: prefer hostkeyalgs: ssh-rsa-cert-v01@openssh.com,rsa-sha2-512,rsa-sha2-256,ssh-rsa\r\ndebug3: send packet: type 20\r\ndebug1: SSH2_MSG_KEXINIT sent\r\ndebug3: receive packet: type 20\r\ndebug1: SSH2_MSG_KEXINIT received\r\ndebug2: local client KEXINIT proposal\r\ndebug2: KEX algorithms: ecdh-sha2-nistp256,ecdh-sha2-nistp384,ecdh-sha2-nistp521,diffie-hellman-group-exchange-sha256,diffie-hellman-group16-sha512,diffie-hellman-group18-sha512,diffie-hellman-group14-sha256,ext-info-c\r\ndebug2: host key algorithms: ssh-rsa-cert-v01@openssh.com,rsa-sha2-512,rsa-sha2-256,ssh-rsa,ecdsa-sha2-nistp256-cert-v01@openssh.com,ecdsa-sha2-nistp384-cert-v01@openssh.com,ecdsa-sha2-nistp521-cert-v01@openssh.com,ecdsa-sha2-nistp256,ecdsa-sha2-nistp384,ecdsa-sha2-nistp521\r\ndebug2: ciphers ctos: aes128-ctr,aes192-ctr,aes256-ctr,aes128-cbc,3des-cbc,aes192-cbc,aes256-cbc,rijndael-cbc@lysator.liu.se,aes128-gcm@openssh.com,aes256-gcm@openssh.com\r\ndebug2: ciphers stoc: aes128-ctr,aes192-ctr,aes256-ctr,aes128-cbc,3des-cbc,aes192-cbc,aes256-cbc,rijndael-cbc@lysator.liu.se,aes128-gcm@openssh.com,aes256-gcm@openssh.com\r\ndebug2: MACs ctos: hmac-sha1,hmac-sha2-256,hmac-sha2-512,hmac-sha1-etm@openssh.com,hmac-sha2-256-etm@openssh.com,hmac-sha2-512-etm@openssh.com\r\ndebug2: MACs stoc: hmac-sha1,hmac-sha2-256,hmac-sha2-512,hmac-sha1-etm@openssh.com,hmac-sha2-256-etm@openssh.com,hmac-sha2-512-etm@openssh.com\r\ndebug2: compression ctos: zlib@openssh.com,zlib,none\r\ndebug2: compression stoc: zlib@openssh.com,zlib,none\r\ndebug2: languages ctos: \r\ndebug2: languages stoc: \r\ndebug2: first_kex_follows 0 \r\ndebug2: reserved 0 \r\ndebug2: peer server KEXINIT proposal\r\ndebug2: KEX algorithms: curve25519-sha256@libssh.org,ecdh-sha2-nistp256,ecdh-sha2-nistp384,ecdh-sha2-nistp521,diffie-hellman-group14-sha1\r\ndebug2: host key algorithms: ssh-rsa\r\ndebug2: ciphers ctos: aes128-gcm@openssh.com,chacha20-poly1305@openssh.com,aes128-ctr,aes192-ctr,aes256-ctr\r\ndebug2: ciphers stoc: aes128-gcm@openssh.com,chacha20-poly1305@openssh.com,aes128-ctr,aes192-ctr,aes256-ctr\r\ndebug2: MACs ctos: hmac-sha2-256-etm@openssh.com,hmac-sha2-256,hmac-sha1,hmac-sha1-96\r\ndebug2: MACs stoc: hmac-sha2-256-etm@openssh.com,hmac-sha2-256,hmac-sha1,hmac-sha1-96\r\ndebug2: compression ctos: none\r\ndebug2: compression stoc: none\r\ndebug2: languages ctos: \r\ndebug2: languages stoc: \r\ndebug2: first_kex_follows 0 \r\ndebug2: reserved 0 \r\ndebug1: kex: algorithm: ecdh-sha2-nistp256\r\ndebug1: kex: host key algorithm: ssh-rsa\r\ndebug1: kex: server->client cipher: aes128-ctr MAC: hmac-sha1 compression: none\r\ndebug1: kex: client->server cipher: aes128-ctr MAC: hmac-sha1 compression: none\r\ndebug1: kex: ecdh-sha2-nistp256 need=20 dh_need=20\r\ndebug1: kex: ecdh-sha2-nistp256 need=20 dh_need=20\r\ndebug3: send packet: type 30\r\ndebug1: sending SSH2_MSG_KEX_ECDH_INIT\r\ndebug1: expecting SSH2_MSG_KEX_ECDH_REPLY\r\ndebug3: receive packet: type 31\r\ndebug1: Server host key: ssh-rsa SHA256:ipZDKeBLAaF03cr2mvtw2ZO3xFJXNnN7IOSECgrJZ10\r\ndebug3: put_host_port: [127.0.0.1]:42385\r\ndebug3: put_host_port: [127.0.0.1]:42385\r\ndebug3: hostkeys_foreach: reading file \""/home/ubuntu/.ssh/known_hosts\""\r\ndebug3: record_hostkey: found key type RSA in file /home/ubuntu/.ssh/known_hosts:5\r\ndebug3: load_hostkeys: loaded 1 keys from [127.0.0.1]:42385\r\ndebug1: Host '[127.0.0.1]:42385' is known and matches the RSA host key.\r\ndebug1: Found key in /home/ubuntu/.ssh/known_hosts:5\r\ndebug3: send packet: type 21\r\ndebug2: set_newkeys: mode 1\r\ndebug1: rekey after 4294967296 blocks\r\ndebug1: SSH2_MSG_NEWKEYS sent\r\ndebug1: expecting SSH2_MSG_NEWKEYS\r\ndebug3: receive packet: type 21\r\ndebug1: SSH2_MSG_NEWKEYS received\r\ndebug2: set_newkeys: mode 0\r\ndebug1: rekey after 4294967296 blocks\r\ndebug1: Will attempt key: /tmp/ansible-key3374820541  explicit\r\ndebug2: pubkey_prepare: done\r\ndebug3: send packet: type 5\r\ndebug3: receive packet: type 6\r\ndebug2: service_accept: ssh-userauth\r\ndebug1: SSH2_MSG_SERVICE_ACCEPT received\r\ndebug3: send packet: type 50\r\ndebug3: receive packet: type 51\r\ndebug1: Authentications that can continue: publickey\r\ndebug3: start over, passed a different list publickey\r\ndebug3: preferred gssapi-with-mic,gssapi-keyex,hostbased,publickey\r\ndebug3: authmethod_lookup publickey\r\ndebug3: remaining preferred: ,gssapi-keyex,hostbased,publickey\r\ndebug3: authmethod_is_enabled publickey\r\ndebug1: Next authentication method: publickey\r\ndebug1: Trying private key: /tmp/ansible-key3374820541\r\ndebug3: sign_and_send_pubkey: RSA SHA256:8RpabcZI+vFpES1s6kF/jJ2eaB1vCbAw/OnjvopMDaE\r\ndebug3: sign_and_send_pubkey: signing using ssh-rsa\r\ndebug3: send packet: type 50\r\ndebug2: we sent a publickey packet, wait for reply\r\ndebug3: receive packet: type 52\r\ndebug1: Authentication succeeded (publickey).\r\nAuthenticated to 127.0.0.1 ([127.0.0.1]:42385).\r\ndebug2: fd 5 setting O_NONBLOCK\r\ndebug2: fd 6 setting O_NONBLOCK\r\ndebug1: channel 0: new [client-session]\r\ndebug3: ssh_session2_open: channel_new: 0\r\ndebug2: channel 0: send open\r\ndebug3: send packet: type 90\r\ndebug1: Entering interactive session.\r\ndebug1: pledge: network\r\ndebug3: receive packet: type 91\r\ndebug2: channel_input_open_confirmation: channel 0: callback start\r\ndebug2: fd 3 setting TCP_NODELAY\r\ndebug3: ssh_packet_set_tos: set IP_TOS 0x10\r\ndebug2: client_session2_setup: id 0\r\ndebug2: channel 0: request pty-req confirm 1\r\ndebug3: send packet: type 98\r\ndebug1: Sending environment.\r\ndebug3: Ignored env ANSIBLE_HOST_KEY_CHECKING\r\ndebug3: Ignored env CLIENT_ID\r\ndebug3: Ignored env TEST_RUNNER_SENTRY_DSN\r\ndebug1: Sending env LANG = C.UTF-8\r\ndebug2: channel 0: request env confirm 0\r\ndebug3: send packet: type 98\r\ndebug3: Ignored env ANSIBLE_SCP_IF_SSH\r\ndebug3: Ignored env SUDO_GID\r\ndebug3: Ignored env OLDPWD\r\ndebug3: Ignored env USERNAME\r\ndebug3: Ignored env SUDO_COMMAND\r\ndebug3: Ignored env USE_DEV_BAZEL_CACHE\r\ndebug3: Ignored env RUNBOT_RUN_ID\r\ndebug3: Ignored env PACKER_PLUGIN_MAGIC_COOKIE\r\ndebug3: Ignored env ANSIBLE_SSH_ARGS\r\ndebug3: Ignored env USER\r\ndebug3: Ignored env PWD\r\ndebug3: Ignored env HOME\r\ndebug3: Ignored env CAPSULE8_TOKEN\r\ndebug3: Ignored env DB_HOME\r\ndebug3: Ignored env SUDO_USER\r\ndebug3: Ignored env RUNBOT_BUILD_NAME\r\ndebug3: Ignored env ANSIBLE_PERSISTENT_CONNECT_TIMEOUT\r\ndebug3: Ignored env RUNBOT_WORKER_ID\r\ndebug3: Ignored env PACKER_PLUGIN_MIN_PORT\r\ndebug3: Ignored env RUNBOT_DEPLOYMENT_NAME\r\ndebug3: Ignored env BUILD_WORKSPACE_DIRECTORY\r\ndebug3: Ignored env SUDO_UID\r\ndebug3: Ignored env MAIL\r\ndebug3: Ignored env PACKER_RUN_UUID\r\ndebug3: Ignored env TERM\r\ndebug3: Ignored env SHELL\r\ndebug3: Ignored env RUNBOT_HOST_URL\r\ndebug3: Ignored env CLIENT_SECRET\r\ndebug3: Ignored env SHLVL\r\ndebug3: Ignored env SENTRY_DSN\r\ndebug3: Ignored env PACKER_PLUGIN_MAX_PORT\r\ndebug3: Ignored env LOGNAME\r\ndebug3: Ignored env ANSIBLE_PERSISTENT_COMMAND_TIMEOUT\r\ndebug3: Ignored env PATH\r\ndebug3: Ignored env RUNFILES_DIR\r\ndebug3: Ignored env BUILD_WORKING_DIRECTORY\r\ndebug3: Ignored env _\r\ndebug1: Sending command: /bin/sh -c 'sudo -H -S -n -u root /bin/sh -c '\""'\""'echo BECOME-SUCCESS-bmjzcymjlnuzrkuhrppbryqpwsfllfxf; LANG=C.UTF-8 LC_ALL=C.UTF-8 LC_MESSAGES=C.UTF-8 /usr/bin/python /home/packer/.ansible/tmp/ansible-tmp-1677969672.19-195965380432543/command; rm -rf \""/home/packer/.ansible/tmp/ansible-tmp-1677969672.19-195965380432543/\"" > /dev/null 2>&1'\""'\""''\r\ndebug2: channel 0: request exec confirm 1\r\ndebug3: send packet: type 98\r\ndebug2: channel_input_open_confirmation: channel 0: callback done\r\ndebug2: channel 0: open confirm rwindow 2097152 rmax 32768\r\ndebug3: receive packet: type 99\r\ndebug2: channel_input_status_confirm: type 99 id 0\r\ndebug2: PTY allocation request accepted on channel 0\r\ndebug3: receive packet: type 99\r\ndebug2: channel_input_status_confirm: type 99 id 0\r\ndebug2: exec request accepted on channel 0\r\ndebug3: receive packet: type 98\r\ndebug1: client_input_channel_req: channel 0 rtype exit-status reply 0\r\ndebug3: receive packet: type 97\r\ndebug2: channel 0: rcvd close\r\ndebug2: channel 0: output open -> drain\r\ndebug2: channel 0: chan_shutdown_read (i0 o1 sock -1 wfd 4 efd 6 [write])\r\ndebug2: channel 0: input open -> closed\r\ndebug3: channel 0: will not send data after close\r\ndebug2: channel 0: obuf empty\r\ndebug2: channel 0: chan_shutdown_write (i3 o1 sock -1 wfd 5 efd 6 [write])\r\ndebug2: channel 0: output drain -> closed\r\ndebug2: channel 0: almost dead\r\ndebug2: channel 0: gc: notify user\r\ndebug2: channel 0: gc: user detached\r\ndebug2: channel 0: send close\r\ndebug3: send packet: type 97\r\ndebug2: channel 0: is dead\r\ndebug2: channel 0: garbage collecting\r\ndebug1: channel 0: free: client-session, nchannels 1\r\ndebug3: channel 0: status: The following connections are open:\r\n  #0 client-session (t4 r0 i3/0 o3/0 e[write]/0 fd -1/-1/6 sock -1 cc -1)\r\n\r\ndebug3: send packet: type 1\r\ndebug3: fd 1 is not O_NONBLOCK\r\ndebug1: fd 2 clearing O_NONBLOCK\r\nConnection to 127.0.0.1 closed.\r\nTransferred: sent 2768, received 1456 bytes, in 970.2 seconds\r\nBytes per second: sent 2.9, received 1.5\r\ndebug1: Exit status 2300218\r\n"", ""module_stdout"": """", ""msg"": ""MODULE FAILURE"", ""parsed"": false}
```
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-03-04T23:16:48Z,2,Create a YAML Ansible playbook to exhibit the following issue: Ansible shell commands with apt or apt-get install commands are flaky may fail with MODULE FAILURE,"```
---
- name: Demonstrate Issue with Shell and APT Module
  hosts: localhost
  gather_facts: False

  tasks:
  - name: Update apt cache
    apt:
      update_cache: yes

  - name: Install packages with apt-get through shell
    shell: apt-get -y install curl
    register: curl_output

  - name: Display output of the installed curl package
    debug: var=curl_output
```",1,"
---
- name: Demonstrate Issue with Shell and APT Module
  hosts: localhost
  gather_facts: False

  tasks:
  - name: Update apt cache
    apt:
      update_cache: yes

  - name: Install packages with apt-get through shell
    shell: apt-get -y install curl
    register: curl_output

  - name: Display output of the installed curl package
    debug: var=curl_output
"
13,80135,jinja2_native=true does not seem to work as expected in Ansible 2.14.3 vs 2.9,"### Summary

In Ansible 2.14.3, when loading a string, that happens to be a JSON object, into a variable, with jinja2_native=true, it still tries to template the value if possible.
The same playbook ran with Ansible 2.9.2 does not try to template the string and instead handles it as AnsibleUnsafeText.
The issue was originally noticed on Ansible 2.13.4, which I then updated to latest in order to confirm and file a bug.

example playbook
```
- hosts: localhost
  connection: local
  gather_facts: no


  vars:
    str: ""{{ lookup('pipe','cat /tmp/test.json') }}""

  tasks:

  - debug:
      msg: ""{{ lookup('config', 'DEFAULT_JINJA2_NATIVE')}}""

  - debug:
      msg: ""{{ str|type_debug }}""

  - lineinfile:
      create: yes
      dest: ""/tmp/test.txt""
      line: ""{{ str }}""
```

test.json
```
{""key1"": ""value1"", ""key2"": ""value2""}
```

2.9.2 output
```
tmp> ANSIBLE_JINJA2_NATIVE=true ansible-playbook test.yml 
[WARNING]: provided hosts list is empty, only localhost is available. Note that the implicit localhost does not match 'all'


PLAY [localhost] **************************************************************************************************************************************************************************************

TASK [debug] ******************************************************************************************************************************************************************************************
ok: [localhost] => {
    ""msg"": true
}

TASK [debug] ******************************************************************************************************************************************************************************************
ok: [localhost] => {
    ""msg"": ""AnsibleUnsafeText""
}

TASK [lineinfile] *************************************************************************************************************************************************************************************
changed: [localhost]

PLAY RECAP ********************************************************************************************************************************************************************************************
localhost                  : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

tmp> cat test.txt 
{""key1"": ""value1"", ""key2"": ""value2""}
tmp> ANSIBLE_JINJA2_NATIVE=false ansible-playbook test.yml 
[WARNING]: provided hosts list is empty, only localhost is available. Note that the implicit localhost does not match 'all'


PLAY [localhost] **************************************************************************************************************************************************************************************

TASK [debug] ******************************************************************************************************************************************************************************************
ok: [localhost] => {
    ""msg"": false
}

TASK [debug] ******************************************************************************************************************************************************************************************
ok: [localhost] => {
    ""msg"": ""dict""
}

TASK [lineinfile] *************************************************************************************************************************************************************************************
[WARNING]: The value {'key1': 'value1', 'key2': 'value2'} (type dict) in a string field was converted to ""{'key1': 'value1', 'key2': 'value2'}"" (type string). If this does not look like what you
expect, quote the entire value to ensure it does not change.

changed: [localhost]

PLAY RECAP ********************************************************************************************************************************************************************************************
localhost                  : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

tmp> cat test.txt 
{""key1"": ""value1"", ""key2"": ""value2""}
{'key1': 'value1', 'key2': 'value2'}
```

2.14.3 output
```
tmp> ANSIBLE_JINJA2_NATIVE=true ansible-playbook test.yml
[WARNING]: No inventory was parsed, only implicit localhost is available
[WARNING]: provided hosts list is empty, only localhost is available. Note that the implicit localhost does not match 'all'

PLAY [localhost] **************************************************************************************************************************************************************************************

TASK [debug] ******************************************************************************************************************************************************************************************
ok: [localhost] => {
    ""msg"": true
}

TASK [debug] ******************************************************************************************************************************************************************************************
ok: [localhost] => {
    ""msg"": ""dict""
}

TASK [lineinfile] *************************************************************************************************************************************************************************************
changed: [localhost]

PLAY RECAP ********************************************************************************************************************************************************************************************
localhost                  : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

tmp> cat test.txt
{'key1': 'value1', 'key2': 'value2'}
tmp> ANSIBLE_JINJA2_NATIVE=false ansible-playbook test.yml
[WARNING]: No inventory was parsed, only implicit localhost is available
[WARNING]: provided hosts list is empty, only localhost is available. Note that the implicit localhost does not match 'all'

PLAY [localhost] **************************************************************************************************************************************************************************************

TASK [debug] ******************************************************************************************************************************************************************************************
ok: [localhost] => {
    ""msg"": false
}

TASK [debug] ******************************************************************************************************************************************************************************************
ok: [localhost] => {
    ""msg"": ""dict""
}

TASK [lineinfile] *************************************************************************************************************************************************************************************
ok: [localhost]

PLAY RECAP ********************************************************************************************************************************************************************************************
localhost                  : ok=3    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

tmp> cat test.txt
{'key1': 'value1', 'key2': 'value2'}
```

Unsure if it's helpful but copy module will always print out the correct, double quoted string, regardless of jinja2_native value on both 2.9 and 2.14.3.


### Issue Type

Bug Report

### Component Name

jinja2_native

### Ansible Version

```console
tmp> ansible --version
ansible [core 2.14.3]
  config file = None
  configured module search path = ['/home/kntouskos/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /home/kntouskos/.local/lib/python3.10/site-packages/ansible
  ansible collection location = /home/kntouskos/.ansible/collections:/usr/share/ansible/collections
  executable location = /usr/local/bin/ansible
  python version = 3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0] (/usr/bin/python3)
  jinja version = 3.0.3
  libyaml = True
```


### Configuration

```console
tmp> ansible-config dump --only-changed -t all
CONFIG_FILE() = None
DEFAULT_JINJA2_NATIVE(env: ANSIBLE_JINJA2_NATIVE) = True
```


### OS / Environment

2.14.3 tests : Linux Mint 21 Vanessa
2.9.2 tests : Ubuntu 18.04.6 LTS

### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->
```yaml (paste below)
- hosts: localhost
  connection: local
  gather_facts: no


  vars:
    str: ""{{ lookup('pipe','cat /tmp/test.json') }}""

  tasks:

  - debug:
      msg: ""{{ lookup('config', 'DEFAULT_JINJA2_NATIVE')}}""

  - debug:
      msg: ""{{ str|type_debug }}""

  - lineinfile:
      create: yes
      dest: ""/tmp/test.txt""
      line: ""{{ str }}""
```


### Expected Results

I expect that jinja2_native=true would stop jinja2 from trying to template strings it thinks might be python dictionaries, as for example suggested here : 
https://github.com/ansible/ansible/issues/44897

### Actual Results

```console
ansible-playbook [core 2.14.3]
  config file = None
  configured module search path = ['/home/kntouskos/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /home/kntouskos/.local/lib/python3.10/site-packages/ansible
  ansible collection location = /home/kntouskos/.ansible/collections:/usr/share/ansible/collections
  executable location = /usr/local/bin/ansible-playbook
  python version = 3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0] (/usr/bin/python3)
  jinja version = 3.0.3
  libyaml = True
No config file found; using defaults
setting up inventory plugins
host_list declined parsing /etc/ansible/hosts as it did not pass its verify_file() method
Skipping due to inventory source not existing or not being readable by the current user
script declined parsing /etc/ansible/hosts as it did not pass its verify_file() method
auto declined parsing /etc/ansible/hosts as it did not pass its verify_file() method
Skipping due to inventory source not existing or not being readable by the current user
yaml declined parsing /etc/ansible/hosts as it did not pass its verify_file() method
Skipping due to inventory source not existing or not being readable by the current user
ini declined parsing /etc/ansible/hosts as it did not pass its verify_file() method
Skipping due to inventory source not existing or not being readable by the current user
toml declined parsing /etc/ansible/hosts as it did not pass its verify_file() method
[WARNING]: No inventory was parsed, only implicit localhost is available
[WARNING]: provided hosts list is empty, only localhost is available. Note that the implicit localhost does not match 'all'
Loading callback plugin default of type stdout, v2.0 from /home/kntouskos/.local/lib/python3.10/site-packages/ansible/plugins/callback/default.py
Attempting to use 'default' callback.
Skipping callback 'default', as we already have a stdout callback.
Attempting to use 'junit' callback.
Attempting to use 'minimal' callback.
Skipping callback 'minimal', as we already have a stdout callback.
Attempting to use 'oneline' callback.
Skipping callback 'oneline', as we already have a stdout callback.
Attempting to use 'tree' callback.

PLAYBOOK: test.yml ************************************************************************************************************************************************************************************
Positional arguments: test.yml
verbosity: 7
connection: smart
timeout: 10
become_method: sudo
tags: ('all',)
inventory: ('/etc/ansible/hosts',)
forks: 5
1 plays in test.yml

PLAY [localhost] **************************************************************************************************************************************************************************************

TASK [debug] ******************************************************************************************************************************************************************************************
task path: /tmp/test.yml:11
ok: [localhost] => {
    ""msg"": true
}

TASK [debug] ******************************************************************************************************************************************************************************************
task path: /tmp/test.yml:14
ok: [localhost] => {
    ""msg"": ""dict""
}

TASK [lineinfile] *************************************************************************************************************************************************************************************
task path: /tmp/test.yml:17
<127.0.0.1> ESTABLISH LOCAL CONNECTION FOR USER: kntouskos
<127.0.0.1> EXEC /bin/sh -c 'echo ~kntouskos && sleep 0'
<127.0.0.1> EXEC /bin/sh -c '( umask 77 && mkdir -p ""` echo /home/kntouskos/.ansible/tmp `""&& mkdir ""` echo /home/kntouskos/.ansible/tmp/ansible-tmp-1677844187.212781-810055-49576040887399 `"" && echo ansible-tmp-1677844187.212781-810055-49576040887399=""` echo /home/kntouskos/.ansible/tmp/ansible-tmp-1677844187.212781-810055-49576040887399 `"" ) && sleep 0'
Including module_utils file ansible/__init__.py
Including module_utils file ansible/module_utils/__init__.py
Including module_utils file ansible/module_utils/_text.py
Including module_utils file ansible/module_utils/basic.py
Including module_utils file ansible/module_utils/common/_collections_compat.py
Including module_utils file ansible/module_utils/common/__init__.py
Including module_utils file ansible/module_utils/common/_json_compat.py
Including module_utils file ansible/module_utils/common/_utils.py
Including module_utils file ansible/module_utils/common/arg_spec.py
Including module_utils file ansible/module_utils/common/file.py
Including module_utils file ansible/module_utils/common/locale.py
Including module_utils file ansible/module_utils/common/parameters.py
Including module_utils file ansible/module_utils/common/collections.py
Including module_utils file ansible/module_utils/common/process.py
Including module_utils file ansible/module_utils/common/sys_info.py
Including module_utils file ansible/module_utils/common/text/converters.py
Including module_utils file ansible/module_utils/common/text/__init__.py
Including module_utils file ansible/module_utils/common/text/formatters.py
Including module_utils file ansible/module_utils/common/validation.py
Including module_utils file ansible/module_utils/common/warnings.py
Including module_utils file ansible/module_utils/compat/selectors.py
Including module_utils file ansible/module_utils/compat/__init__.py
Including module_utils file ansible/module_utils/compat/_selectors2.py
Including module_utils file ansible/module_utils/compat/selinux.py
Including module_utils file ansible/module_utils/distro/__init__.py
Including module_utils file ansible/module_utils/distro/_distro.py
Including module_utils file ansible/module_utils/errors.py
Including module_utils file ansible/module_utils/parsing/convert_bool.py
Including module_utils file ansible/module_utils/parsing/__init__.py
Including module_utils file ansible/module_utils/pycompat24.py
Including module_utils file ansible/module_utils/six/__init__.py
Using module file /home/kntouskos/.local/lib/python3.10/site-packages/ansible/modules/lineinfile.py
<127.0.0.1> PUT /home/kntouskos/.ansible/tmp/ansible-local-810045682ej2_m/tmpwrq4ow6l TO /home/kntouskos/.ansible/tmp/ansible-tmp-1677844187.212781-810055-49576040887399/AnsiballZ_lineinfile.py
<127.0.0.1> EXEC /bin/sh -c 'chmod u+x /home/kntouskos/.ansible/tmp/ansible-tmp-1677844187.212781-810055-49576040887399/ /home/kntouskos/.ansible/tmp/ansible-tmp-1677844187.212781-810055-49576040887399/AnsiballZ_lineinfile.py && sleep 0'
<127.0.0.1> EXEC /bin/sh -c '/usr/bin/python3 /home/kntouskos/.ansible/tmp/ansible-tmp-1677844187.212781-810055-49576040887399/AnsiballZ_lineinfile.py && sleep 0'
<127.0.0.1> EXEC /bin/sh -c 'rm -f -r /home/kntouskos/.ansible/tmp/ansible-tmp-1677844187.212781-810055-49576040887399/ > /dev/null 2>&1 && sleep 0'
ok: [localhost] => {
    ""backup"": """",
    ""changed"": false,
    ""diff"": [
        {
            ""after"": """",
            ""after_header"": ""/tmp/test.txt (content)"",
            ""before"": """",
            ""before_header"": ""/tmp/test.txt (content)""
        },
        {
            ""after_header"": ""/tmp/test.txt (file attributes)"",
            ""before_header"": ""/tmp/test.txt (file attributes)""
        }
    ],
    ""invocation"": {
        ""module_args"": {
            ""attributes"": null,
            ""backrefs"": false,
            ""backup"": false,
            ""create"": true,
            ""dest"": ""/tmp/test.txt"",
            ""firstmatch"": false,
            ""group"": null,
            ""insertafter"": null,
            ""insertbefore"": null,
            ""line"": ""{'key1': 'value1', 'key2': 'value2'}"",
            ""mode"": null,
            ""owner"": null,
            ""path"": ""/tmp/test.txt"",
            ""regexp"": null,
            ""search_string"": null,
            ""selevel"": null,
            ""serole"": null,
            ""setype"": null,
            ""seuser"": null,
            ""state"": ""present"",
            ""unsafe_writes"": false,
            ""validate"": null
        }
    },
    ""msg"": """"
}

PLAY RECAP ********************************************************************************************************************************************************************************************
localhost                  : ok=3    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-03-03T11:50:11Z,6,Create a YAML Ansible playbook to exhibit the following issue: jinja2_native=true does not seem to work as expected in Ansible 2.14.3 vs 2.9,"```
---

- name: Testing jinja2_native in Ansible
  hosts: localhost
  become: true

  vars:
    ansible_version: ""{{ ansible_version }}""

  tasks:

    - name: Display Ansible version
      debug:
        msg: ""Ansible current version is: {{ ansible_version }}""

    - name: Set jinja2_native to true
      set_fact:
        ansible_jinja2_native: true
      when: ansible_version >= '2.14.3'

    - name: Display jinja2_native value
      debug:
        msg: ""jinja2_native is set to {{ ansible_jinja2_native|default(false) }}""
    
    - name: Test jinja2_native override
      debug:
        msg: ""{{ 'true' if ansible_jinja2_native else 'false' }}""
      vars:
        ansible_jinja2_native: false
      when: ansible_version < '2.14.3'

    - name: Test jinja2_native override
      debug:
        msg: ""{{ 'false' if ansible_jinja2_native else 'true' }}""
      vars:
        ansible_jinja2_native: true
      when: ansible_version < '2.14.3'

...
```",1,"
---

- name: Testing jinja2_native in Ansible
  hosts: localhost
  become: true

  vars:
    ansible_version: ""{{ ansible_version }}""

  tasks:

    - name: Display Ansible version
      debug:
        msg: ""Ansible current version is: {{ ansible_version }}""

    - name: Set jinja2_native to true
      set_fact:
        ansible_jinja2_native: true
      when: ansible_version >= '2.14.3'

    - name: Display jinja2_native value
      debug:
        msg: ""jinja2_native is set to {{ ansible_jinja2_native|default(false) }}""
    
    - name: Test jinja2_native override
      debug:
        msg: ""{{ 'true' if ansible_jinja2_native else 'false' }}""
      vars:
        ansible_jinja2_native: false
      when: ansible_version < '2.14.3'

    - name: Test jinja2_native override
      debug:
        msg: ""{{ 'false' if ansible_jinja2_native else 'true' }}""
      vars:
        ansible_jinja2_native: true
      when: ansible_version < '2.14.3'

...
"
14,80124,Paramiko connection module does not resolve templates as the OpenSSH connection module does,"### Summary

I try to use [Paramiko SSH](https://docs.ansible.com/ansible/latest/collections/ansible/builtin/paramiko_ssh_connection.html) (to avoid non-Python dependencies as other users of the same playbook may will try to use Windows to execute Ansible) instead of the [default OpenSSH module](https://docs.ansible.com/ansible/latest/collections/ansible/builtin/ssh_connection.html). And I try to use templates for the variables `ansible_user` & `ansible_ssh_password`. Doing both does not work as Paramiko seems to not resolve templates as the default OpenSSH module does.

### Issue Type

Bug Report

### Component Name

paramiko_ssh

### Ansible Version

```console
$ ansible --version
ansible [core 2.15.0.dev0]
  config file = /home/of4710/Repositories/ansible/playbook/ansible.cfg
  configured module search path = ['/home/of4710/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /home/of4710/Repositories/ansible/playbook/venv/lib/python3.9/site-packages/ansible
  ansible collection location = /home/of4710/Repositories/ansible/playbook
  executable location = /home/of4710/Repositories/ansible/playbook/venv/bin/ansible
  python version = 3.9.2 (default, Feb 28 2021, 17:03:44) [GCC 10.2.1 20210110] (/home/of4710/Repositories/ansible/playbook/venv/bin/python3)
  jinja version = 3.1.2
  libyaml = True
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
ANSIBLE_NOCOWS(env: ANSIBLE_NOCOWS) = True
CACHE_PLUGIN(/home/of4710/Repositories/ansible/playbook/ansible.cfg) = ansible.builtin.jsonfile
CACHE_PLUGIN_CONNECTION(/home/of4710/Repositories/ansible/playbook/ansible.cfg) = /tmp/ansible/facts
COLLECTIONS_PATHS(/home/of4710/Repositories/ansible/playbook/ansible.cfg) = ['/home/of4710/Repositories/ansible/playbook']
COLOR_DEBUG(env: ANSIBLE_COLOR_DEBUG) = bright gray
CONFIG_FILE() = /home/of4710/Repositories/ansible/playbook/ansible.cfg
DEFAULT_FORCE_HANDLERS(/home/of4710/Repositories/ansible/playbook/ansible.cfg) = True
DEFAULT_HOST_LIST(/home/of4710/Repositories/ansible/playbook/ansible.cfg) = ['/home/of4710/Repositories/ansible/playbook/inventory']
DEFAULT_VAULT_IDENTITY_LIST(/home/of4710/Repositories/ansible/playbook/ansible.cfg) = ['ieh-keepass-2023-02-28@prompt']
DIFF_ALWAYS(/home/of4710/Repositories/ansible/playbook/ansible.cfg) = True
EDITOR(env: EDITOR) = vim
INTERPRETER_PYTHON(/home/of4710/Repositories/ansible/playbook/ansible.cfg) = auto
INVENTORY_CACHE_ENABLED(/home/of4710/Repositories/ansible/playbook/ansible.cfg) = True
INVENTORY_CACHE_PLUGIN_CONNECTION(/home/of4710/Repositories/ansible/playbook/ansible.cfg) = /tmp/ansible/inventory
PAGER(env: PAGER) = less
RETRY_FILES_ENABLED(/home/of4710/Repositories/ansible/playbook/ansible.cfg) = False

CACHE:
=====

jsonfile:
________
_uri(/home/of4710/Repositories/ansible/playbook/ansible.cfg) = /tmp/ansible/facts
```


### OS / Environment

Debian GNU/Linux 11 (bullseye) on Windows WSL2
Kernel: 5.15.79.1-microsoft-standard-WSL2

### Steps to Reproduce

The vars for the host(s) look like that:
```yaml
ansible_connection: paramiko  # when commeting this line out, it works

admin_username: admin

ansible_host: host.example
ansible_user: ""{{ admin_username }}""
ansible_ssh_password: ""{{ admin_password }}""
ansible_become_password: ""{{ admin_password }}""
```

while this is defined in a vault (which can be encrypted successfully):
```
admin_password: MySuperSecretPassword
```

Executing following command does show the bug
```sh
$ ansible -vvvv -m ping host
```

### Expected Results

I expected the template to be resolved, but it doesn't. Rather it used `{{ admin_username }}` literally as username as can be seen in the log below below.

### Actual Results

```console
<host.example> ESTABLISH PARAMIKO SSH CONNECTION FOR USER: {{ admin_username }} on PORT 22 TO host.exaple
host | UNREACHABLE! => {
    ""changed"": false,
    ""msg"": ""Failed to authenticate: Authentication failed."",
    ""unreachable"": true
}
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-03-02T10:02:28Z,2,Create a YAML Ansible playbook to exhibit the following issue: Paramiko connection module does not resolve templates as the OpenSSH connection module does,"```
---
- name: Test Paramiko connection module
  hosts: localhost
  connection: paramiko
  tasks:
    - name: Resolve template using Paramiko
      template:
        src: test_template.j2
        dest: /tmp/test_paramiko.txt
```
Note: Make sure to have a template file named `test_template.j2` in the same directory as the playbook, and that it references a variable that is either defined in the same playbook or in an external variables file.",1,"
---
- name: Test Paramiko connection module
  hosts: localhost
  connection: paramiko
  tasks:
    - name: Resolve template using Paramiko
      template:
        src: test_template.j2
        dest: /tmp/test_paramiko.txt
"
15,80123,constructed inventory plugin not working,"### Summary

Hi,

constructed inventory plugin intersection is not working as expected with netbox :

Could you please take a look and also documentation is also not clear especially group_names  is a keyword or the name of the group we need to pass?

Thanks

### Issue Type

Bug Report

### Component Name

ansible.builtin.constructed inventory

### Ansible Version

```console
$ ansible --version
ansible [core 2.11.12]
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
None
```


### OS / Environment

MacOS - pyenv 3.6.15

### Steps to Reproduce

```
---
plugin: constructed
strict: true

groups:
group_test: inventory_hostname.startswith('web')
...
```

### Expected Results

group_test should be created with all hosts starting with web

### Actual Results

```console
Empty
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-03-02T09:44:03Z,11,Create a YAML Ansible playbook to exhibit the following issue: constructed inventory plugin not working,"```yaml
- name: Test Inventory Plugin
  hosts: all
  become: true
  gather_facts: no

  tasks:
  - name: Test inventory plugin
    debug:
      var: inventory_hostname
    
  - name: Debug inventory hostvars
    debug:
      var: hostvars[inventory_hostname]
```",0,"yaml
- name: Test Inventory Plugin
  hosts: all
  become: true
  gather_facts: no

  tasks:
  - name: Test inventory plugin
    debug:
      var: inventory_hostname
    
  - name: Debug inventory hostvars
    debug:
      var: hostvars[inventory_hostname]
"
16,80109,`lookup` does not work on macOS Ventura 13.2.1,"### Summary

I have some difficulties to get `lookup` working on my end. On **Linux** it looks fine (after having asked some colleagues).

### Issue Type

Bug Report

### Component Name

lookup plugin

### Ansible Version

```console
$ ansible --version
ansible [core 2.14.2]
  config file = None
  configured module search path = ['/Users/christianr/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /Users/christianr/.venv/ansible/lib/python3.10/site-packages/ansible
  ansible collection location = /Users/christianr/.ansible/collections:/usr/share/ansible/collections
  executable location = /Users/christianr/.venv/ansible/bin/ansible
  python version = 3.10.8 (main, Nov 23 2022, 08:16:41) [Clang 14.0.0 (clang-1400.0.29.202)] (/Users/christianr/.venv/ansible/bin/python)
  jinja version = 3.1.2
  libyaml = True
```
If I ask **pip**, I get _7.2.0_.

### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
```

No configuration set

### OS / Environment

macOS Ventura 13.2.1

### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->
#### playbook.yml
```yaml (paste below)
- hosts: all
  tasks:
    - name: Test lookup
      ansible.builtin.set_fact:
        node_exporter_version: ""{{ lookup('url', 'https://api.github.com/repos/prometheus/node_exporter/releases/latest') }}""
```

#### inventory/hosts.yml
```yml
all:
  children:
    local:
      hosts:
        myhost:
          ansible_connection: local
```

Given both files, I run `ansible-playbook -i inventory/hosts.yml playbook.yml -l local`.

### Expected Results

It should work.

### Actual Results

```console
PLAY [all] ***************************************************************************************************************************************************************************

TASK [Gathering Facts] ***************************************************************************************************************************************************************
[WARNING]: Platform darwin on host myhost is using the discovered Python interpreter at /Users/christianr/.pyenv/shims/python3.11, but future installation of another Python
interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-core/2.14/reference_appendices/interpreter_discovery.html for more information.
ok: [myhost]

TASK [Test lookup] *******************************************************************************************************************************************************************
ERROR! A worker was found in a dead state
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-02-28T12:49:52Z,16,Create a YAML Ansible playbook to exhibit the following issue: `lookup` does not work on macOS Ventura 13.2.1,"```
---
- name: Test Lookup Issue on macOS Ventura 13.2.1
  hosts: localhost
  gather_facts: no

  tasks:
    - name: Show Lookup Issue
      debug:
        var: lookup('file', '/etc/hosts')
```
Note: This playbook will produce the error message ""lookup_plugin_file: FileNotFoundError: [Errno 2] No such file or directory: '/etc/hosts'"" because lookup is unable to find the file ""/etc/hosts"". This is an example demonstration of a lookup issue on macOS Ventura 13.2.1.",1,"
---
- name: Test Lookup Issue on macOS Ventura 13.2.1
  hosts: localhost
  gather_facts: no

  tasks:
    - name: Show Lookup Issue
      debug:
        var: lookup('file', '/etc/hosts')
"
17,80108,ERROR: Ansible requires blocking IO on stdin/stdout/stderr. Non-blocking file handles detected: <stdout>,"### Summary

When I run ansible-playbook against target os, I saw this error: ERROR: Ansible requires blocking IO on stdin/stdout/stderr. Non-blocking file handles detected: <stdout> ,  and It only happens on Centos Stream 8, it works well on RHEL and Fedora.

The reason I report this bug is that this error happened 100% in our github CI test on Centos Stream 8 and caused CI result failed, which blocks our pull request to be merged. And the tricky thing is that, when I login the CI runner machine(the same machine) and rerun command, it can succeed. I have no idea but I suspect there must be something wrong there, and I need to find out.

I reported this bug here to see if I can get some help, anyone see this error before? or maybe it is caused by cpu/memory limit?

### Issue Type

Bug Report

### Component Name

ansible-playbook

### Ansible Version

```console
$ ansible --version
[root@centos-stream-8 osbuild-composer]# ansible --version
ansible [core 2.14.2]
  config file = /etc/ansible/ansible.cfg
  configured module search path = ['/root/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /usr/lib/python3.9/site-packages/ansible
  ansible collection location = /root/.ansible/collections:/usr/share/ansible/collections
  executable location = /usr/bin/ansible
  python version = 3.9.6 (default, Aug  2 2021, 15:37:19) [GCC 8.5.0 20210514 (Red Hat 8.5.0-3)] (/usr/bin/python3.9)
  jinja version = 3.1.2
  libyaml = True
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
None
```


### OS / Environment

CentOS Stream 8

### Steps to Reproduce

ansible-playbook

### Expected Results

No error

### Actual Results

```console
error happened at line 2444 of https://gitlab.com/redhat/services/products/image-builder/ci/osbuild-composer/-/jobs/3824249899 , when try to run ansible-playbook command.
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-02-28T12:20:02Z,5,Create a YAML Ansible playbook to exhibit the following issue: ERROR: Ansible requires blocking IO on stdin/stdout/stderr. Non-blocking file handles detected: <stdout>,"```
---
- name: Play to exhibit Ansible Issue
  hosts: localhost
  gather_facts: false 

  tasks:
   - name: Set a variable
     set_fact:
       server: ""{{ inventory_hostname }}""

   - name: Command to print variable
     command: echo ""{{ server }}""

   - name: Print the variable
     debug:
       var: server
```
",1,"
---
- name: Play to exhibit Ansible Issue
  hosts: localhost
  gather_facts: false 

  tasks:
   - name: Set a variable
     set_fact:
       server: ""{{ inventory_hostname }}""

   - name: Command to print variable
     command: echo ""{{ server }}""

   - name: Print the variable
     debug:
       var: server
"
18,80107,ansible-galaxy install seems to ignore umask and setguid,"### Summary

Running 

```sh
ansible-galaxy collection install -r requirements.yml
```

the set umask  and setguid on the configured COLLECTION_PATH are ignored.

### Issue Type

Bug Report

### Component Name

ansible-galaxy

### Ansible Version

```console
$ ansible --version
ansible [core 2.14.0]
  config file = /etc/ansible/ansible.cfg
  configured module search path = ['$HOME/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = <path to miniconda3>/envs/ansible/lib/python3.11/site-packages/ansible
  ansible collection location = <NFS mount>/usr/share/ansible/collections:$HOME/.ansible/collections:/usr/share/ansible/collections
  executable location = <path to miniconda3>/envs/ansible/bin/ansible
  python version = 3.11.0 | packaged by conda-forge | (main, Oct 25 2022, 06:24:40) [GCC 10.4.0] (<path to miniconda3>/envs/ansible/bin/python)
  jinja version = 3.1.2
  libyaml = True
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
COLLECTIONS_PATHS(/etc/ansible/ansible.cfg) = ['<NFS mount>/usr/share/ansible/collections', '$HOME/.ansible/collections', '/usr/share/ansible/collections']
CONFIG_FILE() = /etc/ansible/ansible.cfg
DEFAULT_FILTER_PLUGIN_PATH(/etc/ansible/ansible.cfg) = ['<NFS mount>/usr/share/ansible/plugins/filter', '$HOME/.ansible/plugins/filter', '/usr/share/ansible/plugins/filter']
DEFAULT_ROLES_PATH(/etc/ansible/ansible.cfg) = ['<NFS mount>/usr/share/ansible/roles', '$HOME/.ansible/roles', '/usr/share/ansible/roles', '/etc/ansible/roles', '/etc/ansible/roles'
GALAXY_COLLECTION_SKELETON(/etc/ansible/ansible.cfg) = <NFS mount>/usr/share/ansible/collection_skeletons/default
GALAXY_COLLECTION_SKELETON_IGNORE(/etc/ansible/ansible.cfg) = ['^.git$', '^.*/.git_keep$', '^.*/.gitkeep$']
```


### OS / Environment

CentOS7

### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->

Set the collection path in `ansbile.cfg`

```cfg
collections_path=<Some test dir>:~/.ansible/collections:/usr/share/ansible/collections
```

Next set the permissions on the directory `<Some test dir>`

```sh
cd <Some test dir>
umask 0007
chmod g+s <Some test dir>
chown root:admins <Some test dir>
```

Run the install

```sh
ansible-galaxy collection install -r requirements.yml
```

with 

```yml
---
collections:
  - name: ""git+https://<some collection repository>""
    type: git
    version: latest
```

and see how the set permissions are ignored.


### Expected Results

The install should respect the set permissions on the top level, i.e. the following permission should be set

- directories should have `[drwxrws--- root     admins  ]`
- files should have`[-rw-rw---- root     admins  ]`

### Actual Results

```console
There are only following permissions assigned to all files / directories

- directories: [drwxr-xr-x root     root    ]
- files: [-rw-r--r-- root     root    ]

except for the following

- [drwxrws--- root     admins  ]  <namespace>
- [drwxr-s--- root     admins  ]  <collection name>
- [-rw-r--r-- root     admins  ]  FILES.json
- [-rw-r--r-- root     admins  ]  MANIFEST.json
- [drwxr-xr-x root     admins  ]  playbooks
- [-rw-r--r-- root     admins  ]  README.md
- [drwxr-xr-x root     admins  ]  roles
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-02-28T12:00:05Z,7,Create a YAML Ansible playbook to exhibit the following issue: ansible-galaxy install seems to ignore umask and setguid,"```
---
- name: Test playbook
  hosts: all
  become: true
  tasks:
    - name: Install role from galaxy
      community.general.galaxy_collection:
        name: some_role
        state: present
      become: true
      environment:
        ANSIBLE_GALAXY_ROLE_DIR: /opt/ansible/roles
        ANSIBLE_CONFIG: /opt/ansible/ansible.cfg
        ANSIBLE_CONFIG_DEFAULTS: /opt/ansible/ansible.cfg
        ANSIBLE_ROLES_PATH: /opt/ansible/roles
        ANSIBLE_CALLBACK_PLUGINS: /usr/share/ansible/plugins/callback:/opt/ansible/plugins/callback
        ANSIBLE_ACTION_PLUGINS: /usr/share/ansible/plugins/action:/opt/ansible/plugins/action
        ANSIBLE_LOOKUP_PLUGINS: /usr/share/ansible/plugins/lookup:/opt/ansible/plugins/lookup
        ANSIBLE_FILTER_PLUGINS: /usr/share/ansible/plugins/filter:/opt/ansible/plugins/filter
        ANSIBLE_LIBRARY: /usr/share/ansible/modules:/opt/ansible/library
        ANSIBLE_RETRY_FILES_ENABLED: /opt/ansible/retry_files
        PATH: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
        LANG: C
        LC_ALL: C.UTF-8
        LC_MESSAGES: C.UTF-8
        SHELL: /bin/bash
        ANSIBLE_GALAXY_IGNORE_ERRORS: 'yes'
        ANSIBLE_GALAXY_IGNORE_WARNINGS: 'yes'
        ANSIBLE_GALAXY_SERVER_TOKEN: 'server-token-id'
        ANSIBLE_GALAXY_SERVER_TYPE: 'production'
        ANSIBLE_GALAXY_VERBOSE: 3
      environment:
        ANSIBLE_CONFIG: /root/.ansible.cfg
        PATH: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
      ignore_errors: yes
      ignore_unreachable: yes
      register: galaxy_status

    - debug:
        var: galaxy_status
```",1,"
---
- name: Test playbook
  hosts: all
  become: true
  tasks:
    - name: Install role from galaxy
      community.general.galaxy_collection:
        name: some_role
        state: present
      become: true
      environment:
        ANSIBLE_GALAXY_ROLE_DIR: /opt/ansible/roles
        ANSIBLE_CONFIG: /opt/ansible/ansible.cfg
        ANSIBLE_CONFIG_DEFAULTS: /opt/ansible/ansible.cfg
        ANSIBLE_ROLES_PATH: /opt/ansible/roles
        ANSIBLE_CALLBACK_PLUGINS: /usr/share/ansible/plugins/callback:/opt/ansible/plugins/callback
        ANSIBLE_ACTION_PLUGINS: /usr/share/ansible/plugins/action:/opt/ansible/plugins/action
        ANSIBLE_LOOKUP_PLUGINS: /usr/share/ansible/plugins/lookup:/opt/ansible/plugins/lookup
        ANSIBLE_FILTER_PLUGINS: /usr/share/ansible/plugins/filter:/opt/ansible/plugins/filter
        ANSIBLE_LIBRARY: /usr/share/ansible/modules:/opt/ansible/library
        ANSIBLE_RETRY_FILES_ENABLED: /opt/ansible/retry_files
        PATH: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
        LANG: C
        LC_ALL: C.UTF-8
        LC_MESSAGES: C.UTF-8
        SHELL: /bin/bash
        ANSIBLE_GALAXY_IGNORE_ERRORS: 'yes'
        ANSIBLE_GALAXY_IGNORE_WARNINGS: 'yes'
        ANSIBLE_GALAXY_SERVER_TOKEN: 'server-token-id'
        ANSIBLE_GALAXY_SERVER_TYPE: 'production'
        ANSIBLE_GALAXY_VERBOSE: 3
      environment:
        ANSIBLE_CONFIG: /root/.ansible.cfg
        PATH: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
      ignore_errors: yes
      ignore_unreachable: yes
      register: galaxy_status

    - debug:
        var: galaxy_status
"
19,80105,UnboundLocalError local variable datafile referenced before assignment KeyError(ansible_os_family),"### Summary

We have a Kubernetes cluster, deployed using Kubespray. It was working fine. We are trying to add one more worker node, and getting below error only on all worker nodes.

""ansible_os_family"": ""VARIABLE IS NOT DEFINED!: 'ansible_os_family' is undefined""

So we tried to to check ansible_os_family in gather facts,

ansible-playbook -i hosts.ini test.yaml -b -K -v

test.yaml

```yaml
---
- hosts: masternode1 workernode1
  gather_facts: true
  tasks:
    - name: Debug
      debug:
        var: ansible_os_family`

```

output of above:

```
PLAY [masternode1 workernode1] **********************************************************************************************************************************************************************************************************************

TASK [Gathering Facts] **********************************************************************************************************************************************************************************************************************
ok: [masternode1]
ok: [workernode1]

TASK [Gather host facts to get ansible_os_family] *******************************************************************************************************************************************************************************************
ok: [masternode1]
ok: [workernode1]

TASK [Debug] ********************************************************************************************************************************************************************************************************************************
ok: [masternode1] => {
    ""ansible_os_family"": ""Debian""
}
ok: [workernode1] => {
    ""ansible_os_family"": ""VARIABLE IS NOT DEFINED!: 'ansible_os_family' is undefined""
}

PLAY RECAP **********************************************************************************************************************************************************************************************************************************
masternode1                    : ok=3    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
workernode1                    : ok=3    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
```

debug: ansible_facts, below details are there for masternode but missing for all worker nodes.

```
""distribution"": ""Ubuntu"",
""distribution_file_parsed"": true,
""distribution_file_path"": ""/etc/os-release"",
""distribution_file_variety"": ""Debian"",
""distribution_major_version"": ""20"",
""distribution_release"": ""focal"",
""distribution_version"": ""20.04"",
""os_family"": ""Debian"",
""pkg_mgr"": ""apt""

```

tried playbook with -vvv option, getting below error

```
UnboundLocalError(""local variable \'datafile\' referenced before assignment"")\r\nKeyError(\'ansible_os_family\')...
```

### Issue Type

Bug Report

### Component Name

!component

### Ansible Version

```console
$ ansible --version
ansible [core 2.12.0]
  config file = None
  configured module search path = ['/home/administrator/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /usr/lib/python3/dist-packages/ansible
  ansible collection location = /home/administrator/.ansible/collections:/usr/share/ansible/collections
  executable location = /usr/bin/ansible
  python version = 3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]
  jinja version = 3.1.2
  libyaml = True
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
BECOME:
======

CACHE:
=====

CALLBACK:
========

CLICONF:
=======

CONNECTION:
==========

HTTPAPI:
=======

INVENTORY:
=========

LOOKUP:
======

config:
______
_terms(None) = None

dict:
____
_terms(None) = None

env:
___
_terms(None) = None

file:
____
_terms(None) = None

fileglob:
________
_terms(None) = None

indexed_items:
_____________
_terms(None) = None

ini:
___
_terms(None) = None

items:
_____
_terms(None) = None

lines:
_____
_terms(None) = None

password:
________
_terms(None) = None

pipe:
____
_terms(None) = None

subelements:
___________
_terms(None) = None

together:
________
_terms(None) = None

unvault:
_______
_terms(None) = None

varnames:
________
_terms(None) = None

vars:
____
_terms(None) = None

NETCONF:
=======

SHELL:
=====

VARS:
====
```


### OS / Environment

Ubuntu 20.04

### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->
```yaml (paste below)
---
- hosts: masternode1 workernode1
  gather_facts: true
  tasks:
    - name: Debug
      debug:
        var: ansible_os_family`

```


### Expected Results

TASK [Debug] ********************************************************************************************************************************************************************************************************************************
ok: [masternode1] => {
    ""ansible_os_family"": ""Debian""
}
ok: [workernode1] => {
    ""ansible_os_family"": ""Debian""
}

### Actual Results

```console
ok: [masternode1] => {
    ""ansible_os_family"": ""Debian""
}
ok: [workernode1] => {
    ""ansible_os_family"": ""VARIABLE IS NOT DEFINED!: 'ansible_os_family' is undefined""
}
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-02-28T10:04:52Z,3,Create a YAML Ansible playbook to exhibit the following issue: UnboundLocalError local variable datafile referenced before assignment KeyError(ansible_os_family),"```
---
- name: Playbook to exhibit UnboundLocalError and KeyError
  hosts: localhost
  vars:
    datafile: ""{{ lookup('file', 'testdata.txt') }}""
  tasks:
    - name: Shell command to print contents of datafile
      shell: cat {{ datafile }}
      register: ansible_os
    - name: Debug message showing ansible_os_family
      debug:
        var: ansible_os['ansible_os_family']
```
Note: Make sure to replace the file name ```testdata.txt``` with an actual file name that exists in the directory.",1,"
---
- name: Playbook to exhibit UnboundLocalError and KeyError
  hosts: localhost
  vars:
    datafile: ""{{ lookup('file', 'testdata.txt') }}""
  tasks:
    - name: Shell command to print contents of datafile
      shell: cat {{ datafile }}
      register: ansible_os
    - name: Debug message showing ansible_os_family
      debug:
        var: ansible_os['ansible_os_family']
"
20,80097,Ansible thinks the python interpreter is the same on localhost and remote hosts,"### Summary

When ansible reaches out to a remote host with the file module it will assume that all pythons in the universe will be the same as the python version detected on the remote host.

So if host running ansible has only python 3, and the remote host has only python 2.7, a local command will fail on the host running ansible, because there is no /usr/bin/python.

The discovery result should be local to one host, and not global.

 

### Issue Type

Bug Report

### Component Name

file module and ansible.builtin.wait_for

### Ansible Version

```console
$ ansible --version
ansible [core 2.14.2]
  config file = /home/ansible/test1/ansible.cfg
  configured module search path = ['/home/ansible/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /home/ansible/.local/lib/python3.9/site-packages/ansible
  ansible collection location = /home/ansible/.ansible/collections:/usr/share/ansible/collections
  executable location = /home/ansible/.local/bin/ansible
  python version = 3.9.2 (default, Feb 28 2021, 17:03:44) [GCC 10.2.1 20210110] (/usr/bin/python3)
  jinja version = 3.1.2
  libyaml = True
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
ANSIBLE_NOCOWS(env: ANSIBLE_NOCOWS) = True
CONFIG_FILE() = /home/ansible/test1/ansible.cfg
DEFAULT_BECOME(/home/ansible/test1/ansible.cfg) = True
DEFAULT_BECOME_ASK_PASS(/home/ansible/test1/ansible.cfg) = False
DEFAULT_BECOME_METHOD(/home/ansible/test1/ansible.cfg) = sudo
DEFAULT_BECOME_USER(/home/ansible/test1/ansible.cfg) = root
DEFAULT_HOST_LIST(/home/ansible/test1/ansible.cfg) = ['/home/ansible/test1/inventory.ini']

BECOME:
======

runas:
_____
become_user(/home/ansible/test1/ansible.cfg) = root

su:
__
become_user(/home/ansible/test1/ansible.cfg) = root

sudo:
____
become_user(/home/ansible/test1/ansible.cfg) = root
```


### OS / Environment

ansible running on Debian GNU/Linux 11 (bullseye) (with python 3 and no python 2.7)

target: Debian GNU/Linux 9 (stretch)   (with python 2.7, and no python 3)


### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->
```yaml (paste below)
- name: bug test
  hosts: xen
  gather_facts: no
  vars:
    #set bug: false to omit the mkdir
    bug: true

  tasks:

    - name: ""test mkdir""
      file:
        path: ""/tmp/a""
        state: directory
      when: bug == true


    - name: Wait 300 seconds for port 22 to become open and contain ""OpenSSH""
      become: false
      ansible.builtin.wait_for:
        port: 22
        host: 10.1.10.60
        search_regex: OpenSSH
        delay: 1
      vars:
        ansible_connection: local
          #uncomment the next line to hide the error
          #ansible_python_interpreter: /usr/bin/python3



```

ansible.cfg:
[defaults]
inventory=inventory.ini
[privilege_escalation]
remote_user=ansible
become=true
become_method=sudo
become_user=root
become_ask_pass=false



inventory.ini:
[xen]
10.1.1.11




### to reproduce:
install a debian 9 host with python 2.7 and no python3 , this is 10.1.1.11
install a debian 11 host with OpenSSH running on 22/tcp, this is 10.1.10.60
install debian 11 host with python3 and no python 2.7 as the host running ansible using pip3
ansible-playbook play3.yaml


### Expected Results

The ansible playbook should:

1. reach out to a debian 9 host (running python 2.7, without /usr/bin/python3) and make a directory /tmp/a
2. try to connect from localhost (the host running ansible) to 22/tcp to some IP and check if there in an OpenSSH banner

I since either of the commands runs fine, i expect them both to run fine too.


But in this example:

- task 1 only works ok

- task 2 only works ok (set bug: false in the playbook)

- task 1 and task 2 together don't work. Ansible thinks: hey, i've just conected to some random host on the internet (which has /usr/bin/python , python 2.7), and now i am sure that all pythons in the universe must be the same, including the one running on localhost (which has /usr/bin/python3 only). 

You can make both tasks work if ansible_python_interpreter: /usr/bin/python3 is set in task 2

- when the tasks are reversed (first check connection, then mkdir), then the mkdir fails, because ansible has deduced that all pythons are /usr/bin/python3 (and host 10.1.1.11 only has /usr/bin/python)


BTW i've tried to see if i can make ansible think that the omnipresent  python interpreter is /sbin/reboot, but i failed (maybe due to lack of knowledge about how ansible detects  the python version). If i could trick it to do that, than it would turn into a security problem, since some random target host could force ansible to execute unintended commands locally.

I've tried searching bug reports, and didn't find anything that matches exactly.

### Actual Results

```console
ansible@hades:~/test1$ ansible-playbook play3.yaml

PLAY [bug test] ******************************************************************************************************************************

TASK [test mkdir] ****************************************************************************************************************************
ok: [10.1.1.11]

TASK [Wait 300 seconds for port 22 to become open and contain ""OpenSSH""] *********************************************************************
fatal: [10.1.1.11]: FAILED! => {""changed"": false, ""module_stderr"": ""/bin/sh: 1: /usr/bin/python: not found\n"", ""module_stdout"": """", ""msg"": ""The module failed to execute correctly, you probably need to set the interpreter.\nSee stdout/stderr for the exact error"", ""rc"": 127}

PLAY RECAP ***********************************************************************************************************************************
10.1.1.11                  : ok=1    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-02-27T21:37:50Z,3,Create a YAML Ansible playbook to exhibit the following issue: Ansible thinks the python interpreter is the same on localhost and remote hosts,"```
---
- name: Exhibit interpreter issue
  hosts: all

  tasks:
  - name: Install Requests module
    pip:
      name: requests
      executable: python
```

Note: This playbook specifies that the `requests` Python module should be installed using the `python` interpreter. However, if the Python interpreter on the localhost and remote hosts are different (e.g. Python 2 on localhost and Python 3 on remote host), this playbook will cause an error because it assumes that the Python interpreter is the same on all hosts.",1,"
---
- name: Exhibit interpreter issue
  hosts: all

  tasks:
  - name: Install Requests module
    pip:
      name: requests
      executable: python
"
21,80093,Unintuitive become behaviour with connection: local and group_var,"### Summary

If you try to execute tasks using 
```yaml
- hosts: 127.0.0.1
  connection: local
  become: false
```
and have a group_var specifying `become: true`, ansible tries to execute the task with `become: true`.

I expected the `become: false` to have a higher priority.

### Issue Type

Bug Report

### Component Name

become

### Ansible Version

```console
$ ansible --version
ansible [core 2.14.2]
  config file = /etc/ansible/ansible.cfg
  configured module search path = ['/home/user/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /home/user/.cache/pypoetry/virtualenvs/ansible-bug-jkCMHdV7-py3.11/lib/python3.11/site-packages/ansible
  ansible collection location = /home/user/.ansible/collections:/usr/share/ansible/collections
  executable location = /home/user/.cache/pypoetry/virtualenvs/ansible-bug-jkCMHdV7-py3.11/bin/ansible
  python version = 3.11.1 (main, Jan  6 2023, 00:00:00) [GCC 12.2.1 20221121 (Red Hat 12.2.1-4)] (/home/user/.cache/pypoetry/virtualenvs/ansible-bug-jkCMHdV7-py3.11/bin/python)
  jinja version = 3.1.2
  libyaml = True
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
CONFIG_FILE() = /etc/ansible/ansible.cfg
```


### OS / Environment

Fedora 37


### Steps to Reproduce

https://github.com/Chasethechicken/Ansible-Become-Bug-Demo

**Playbook**
```yaml
---
- hosts: 127.0.0.1
  connection: local
  become: false
  tasks:
    - name: Print message
      ansible.builtin.debug:
        msg: Hello World!
```
group_vars/all.yml contains:
```yaml
---
ansible_become: true
```

### Expected Results

I expected the `become: false` to take precedence, as it is more specific.
Instead, the more generic `become: true` from `group_vars/all.yml` takes precedence and execution fails, because ansible expects a become password.

### Actual Results

```console
ansible-playbook -vvvv -i hosts bug.yml
ansible-playbook [core 2.14.2]
  config file = /etc/ansible/ansible.cfg
  configured module search path = ['/home/user/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /home/user/.cache/pypoetry/virtualenvs/ansible-bug-jkCMHdV7-py3.11/lib/python3.11/site-packages/ansible
  ansible collection location = /home/user/.ansible/collections:/usr/share/ansible/collections
  executable location = /home/user/.cache/pypoetry/virtualenvs/ansible-bug-jkCMHdV7-py3.11/bin/ansible-playbook
  python version = 3.11.1 (main, Jan  6 2023, 00:00:00) [GCC 12.2.1 20221121 (Red Hat 12.2.1-4)] (/home/user/.cache/pypoetry/virtualenvs/ansible-bug-jkCMHdV7-py3.11/bin/python)
  jinja version = 3.1.2
  libyaml = True
Using /etc/ansible/ansible.cfg as config file
setting up inventory plugins
host_list declined parsing /home/user/Sync/FSR/Admin/ansible-bug/hosts as it did not pass its verify_file() method
Skipping due to inventory source not existing or not being readable by the current user
script declined parsing /home/user/Sync/FSR/Admin/ansible-bug/hosts as it did not pass its verify_file() method
auto declined parsing /home/user/Sync/FSR/Admin/ansible-bug/hosts as it did not pass its verify_file() method
Skipping due to inventory source not existing or not being readable by the current user
yaml declined parsing /home/user/Sync/FSR/Admin/ansible-bug/hosts as it did not pass its verify_file() method
Skipping due to inventory source not existing or not being readable by the current user
ini declined parsing /home/user/Sync/FSR/Admin/ansible-bug/hosts as it did not pass its verify_file() method
Skipping due to inventory source not existing or not being readable by the current user
toml declined parsing /home/user/Sync/FSR/Admin/ansible-bug/hosts as it did not pass its verify_file() method
[WARNING]: Unable to parse /home/user/Sync/FSR/Admin/ansible-bug/hosts as an inventory source
[WARNING]: No inventory was parsed, only implicit localhost is available
[WARNING]: provided hosts list is empty, only localhost is available. Note that the implicit localhost does not match 'all'
Loading callback plugin default of type stdout, v2.0 from /home/user/.cache/pypoetry/virtualenvs/ansible-bug-jkCMHdV7-py3.11/lib/python3.11/site-packages/ansible/plugins/callback/default.py
Skipping callback 'default', as we already have a stdout callback.
Skipping callback 'minimal', as we already have a stdout callback.
Skipping callback 'oneline', as we already have a stdout callback.

PLAYBOOK: bug.yml ******************************************************************************************************************************
Positional arguments: bug.yml
verbosity: 4
connection: smart
timeout: 10
become_method: sudo
tags: ('all',)
inventory: ('/home/user/Sync/FSR/Admin/ansible-bug/hosts',)
forks: 5
1 plays in bug.yml

PLAY [127.0.0.1] *******************************************************************************************************************************

TASK [Gathering Facts] *************************************************************************************************************************
task path: /home/user/Sync/FSR/Admin/ansible-bug/bug.yml:3
<127.0.0.1> ESTABLISH LOCAL CONNECTION FOR USER: user
<127.0.0.1> EXEC /bin/sh -c 'echo ~user && sleep 0'
<127.0.0.1> EXEC /bin/sh -c '( umask 77 && mkdir -p ""` echo /home/user/.ansible/tmp `""&& mkdir ""` echo /home/user/.ansible/tmp/ansible-tmp-1677421640.1012506-247832-112389367309171 `"" && echo ansible-tmp-1677421640.1012506-247832-112389367309171=""` echo /home/user/.ansible/tmp/ansible-tmp-1677421640.1012506-247832-112389367309171 `"" ) && sleep 0'
Using module file /home/user/.cache/pypoetry/virtualenvs/ansible-bug-jkCMHdV7-py3.11/lib/python3.11/site-packages/ansible/modules/setup.py
<127.0.0.1> PUT /home/user/.ansible/tmp/ansible-local-247827nhfxwj34/tmpdnf1mrle TO /home/user/.ansible/tmp/ansible-tmp-1677421640.1012506-247832-112389367309171/AnsiballZ_setup.py
<127.0.0.1> EXEC /bin/sh -c 'chmod u+x /home/user/.ansible/tmp/ansible-tmp-1677421640.1012506-247832-112389367309171/ /home/user/.ansible/tmp/ansible-tmp-1677421640.1012506-247832-112389367309171/AnsiballZ_setup.py && sleep 0'
<127.0.0.1> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '""'""'echo BECOME-SUCCESS-iwvcygduvwoxlcazesfslwnamhnyihfx ; /home/user/.cache/pypoetry/virtualenvs/ansible-bug-jkCMHdV7-py3.11/bin/python /home/user/.ansible/tmp/ansible-tmp-1677421640.1012506-247832-112389367309171/AnsiballZ_setup.py'""'""' && sleep 0'
<127.0.0.1> EXEC /bin/sh -c 'rm -f -r /home/user/.ansible/tmp/ansible-tmp-1677421640.1012506-247832-112389367309171/ > /dev/null 2>&1 && sleep 0'
fatal: [127.0.0.1]: FAILED! => {
    ""ansible_facts"": {},
    ""changed"": false,
    ""failed_modules"": {
        ""ansible.legacy.setup"": {
            ""failed"": true,
            ""module_stderr"": ""sudo: Ein Passwort ist notwendig\n"",
            ""module_stdout"": """",
            ""msg"": ""MODULE FAILURE\nSee stdout/stderr for the exact error"",
            ""rc"": 1
        }
    },
    ""msg"": ""The following modules failed to execute: ansible.legacy.setup\n""
}

PLAY RECAP *************************************************************************************************************************************
127.0.0.1                  : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-02-26T14:39:18Z,3,Create a YAML Ansible playbook to exhibit the following issue: Unintuitive become behaviour with connection: local and group_var,"```
---
- name: Unintuitive become behaviour with connection: local and group_var
  hosts: localhost
  become: true
  gather_facts: false
  
  vars:
    ansible_become_method: su
    ansible_user: ""{{ ansible_env.SUDO_USER }}""
  
  tasks:
    - name: Check if become worked
      command: whoami
      register: result
      become: true
    - debug: var=result.stdout
```
",0,"
---
- name: Unintuitive become behaviour with connection: local and group_var
  hosts: localhost
  become: true
  gather_facts: false
  
  vars:
    ansible_become_method: su
    ansible_user: ""{{ ansible_env.SUDO_USER }}""
  
  tasks:
    - name: Check if become worked
      command: whoami
      register: result
      become: true
    - debug: var=result.stdout
"
22,80091,Inconsistant behavior of .split() when using multiline in YAML,"### Summary

Found a weird behavior while using the .split() method and not sure why this is happening.
The split along \n works well with inline templating but not when using multiline YAML syntax.

### Issue Type

Bug Report

### Component Name

core

### Ansible Version

```console
$ ansible --version
ansible 2.10.8
  config file = /etc/ansible/ansible.cfg
  ansible python module location = /usr/lib/python3/dist-packages/ansible
  executable location = /usr/bin/ansible
  python version = 3.9.2 (default, Feb 28 2021, 17:03:44) [GCC 10.2.1 20210110]
```


### Configuration

```console
$ ansible-config dump --only-changed -t all
ANSIBLE_NOCOWS(/etc/ansible/ansible.cfg) = True
HOST_KEY_CHECKING(/etc/ansible/ansible.cfg) = False
```


### OS / Environment

Linux 5.10.0-21-amd64 Debian 5.10.162-1 (2023-01-21) x86_64 GNU/Linux

### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->
```yaml (paste below)
- hosts: localhost
  gather_facts: false

  vars:
    foo: ""a\nb\nc""

  tasks:
    - debug:
        msg: ""{{ foo.split('\n') }}""
    - debug:
        msg: >-
          {{ foo.split('\n') }}
```


### Expected Results

Both debug tasks show the same result : the list `[""a"", ""b"", ""c""]` which results from correctly splitting ""a\nb\nc"".

### Actual Results

```console
PLAY [localhost] **************************************************************************************************************************************************************************************************

TASK [debug] ******************************************************************************************************************************************************************************************************
ok: [localhost] => {
    ""msg"": [
        ""a"",
        ""b"",
        ""c""
    ]
}

TASK [debug] ******************************************************************************************************************************************************************************************************
ok: [localhost] => {
    ""msg"": [
        ""a\nb\nc""
    ]
}

PLAY RECAP ********************************************************************************************************************************************************************************************************
localhost                  : ok=2    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-02-24T13:36:18Z,3,Create a YAML Ansible playbook to exhibit the following issue: Inconsistant behavior of .split() when using multiline in YAML,"```
---
- name: demonstrate .split() inconsistent behavior with multiline YAML
  hosts: localhost
  become: false

  vars:
    # Define a string with a newline character
    my_str: ""This is\na test string""

    # Define a dictionary with a key containing a string with a newline character
    my_dict:
      my_key: ""This is\na test string""

  tasks:
    - name: Demonstrate .split() inconsistency with single line string
      debug:
        msg: ""{{ my_str.split('\n') }}""

    - name: Demonstrate .split() inconsistency with multiline dictionary value
      debug:
        msg: ""{{ my_dict.my_key.split('\n') }}""
```",1,"
---
- name: demonstrate .split() inconsistent behavior with multiline YAML
  hosts: localhost
  become: false

  vars:
    # Define a string with a newline character
    my_str: ""This is\na test string""

    # Define a dictionary with a key containing a string with a newline character
    my_dict:
      my_key: ""This is\na test string""

  tasks:
    - name: Demonstrate .split() inconsistency with single line string
      debug:
        msg: ""{{ my_str.split('\n') }}""

    - name: Demonstrate .split() inconsistency with multiline dictionary value
      debug:
        msg: ""{{ my_dict.my_key.split('\n') }}""
"
23,80071,Isolate Galaxy Roles and Collections in Virtual Env,"### Summary

When installing Ansible in a virtual env, Galaxy roles and collections are still downloaded to ~/.ansible outside the virtual env. This way the idea of the virtual env is broken and dependencies are not isolated anymore.

While this can be changed via options and configuration file, I still expect the default to be isolated out of the box. 

This would allow also sharing local Ansible installations isolated between different users out of the box for example. Now every user has to use explicit options or configuration file to achieve the desired idea of isolation via a virtual env.

### Issue Type

Bug Report

### Component Name

venv

### Ansible Version

```console
$ ansible --version
ansible [core 2.14.2]
  config file = None
  configured module search path = ['/home/ubuntu/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /tmp/ansible/lib/python3.10/site-packages/ansible
  ansible collection location = /home/ubuntu/.ansible/collections:/usr/share/ansible/collections
  executable location = /tmp/ansible/bin/ansible
  python version = 3.10.7 (main, Nov 24 2022, 19:45:47) [GCC 12.2.0] (/tmp/ansible/bin/python)
  jinja version = 3.1.2
  libyaml = True
```


### Configuration

```console
$ ansible-config dump --only-changed -t all
CONFIG_FILE() = None
```


### OS / Environment

Ubuntu 22.10

### Steps to Reproduce

```yaml (paste below)
$ sudo apt install pip
$ pip install --user virtualenv
$ cd /tmp/
$ python3 -m virtualenv ansible
$ source ansible/bin/activate
$ ansible-galaxy install ontic.fonts
Starting galaxy role install process
- downloading role 'fonts', owned by ontic
- downloading role from https://github.com/ontic/ansible-role-fonts/archive/v2.4.0.tar.gz
- extracting ontic.fonts to /home/ubuntu/.ansible/roles/ontic.fonts
- ontic.fonts (v2.4.0) was installed successfully
```


### Expected Results

Galaxy Roles and Collections are isolated in the virtual environment by default.

### Actual Results

Galaxy Roles and Collections are installed outside the virtual environment in `~/.ansible`.


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-02-22T12:07:45Z,3,Create a YAML Ansible playbook to exhibit the following issue: Isolate Galaxy Roles and Collections in Virtual Env,"```
---

- name: Isolate Galaxy Roles and Collections in Virtual Env
  hosts: all
  gather_facts: true

  tasks:

    - name: Install python3-pip for virtual env
      become: true
      package:
        name: python3-pip
        state: present

    - name: Create virtual environment
      become: true
      command: virtualenv /opt/my-ansible-environment

    - name: Activate virtual environment
      become: true
      command: source /opt/my-ansible-environment/bin/activate

    - name: Install ansible in virtual environment
      pip:
        name: ansible

    - name: Install galaxy role in virtual environment
      pip:
        name: galaxy-role-package
        virtualenv: /opt/my-ansible-environment

    - name: Install galaxy collection in virtual environment
      command: ansible-galaxy collection install galaxy-collection-package
      register: galaxy_collection_output
      environment:
        VIRTUAL_ENV: /opt/my-ansible-environment

    - name: Print galaxy collection output
      debug:
        var: galaxy_collection_output.stdout_lines

    - name: Deactivate virtual environment
      command: deactivate

...

```",1,"
---

- name: Isolate Galaxy Roles and Collections in Virtual Env
  hosts: all
  gather_facts: true

  tasks:

    - name: Install python3-pip for virtual env
      become: true
      package:
        name: python3-pip
        state: present

    - name: Create virtual environment
      become: true
      command: virtualenv /opt/my-ansible-environment

    - name: Activate virtual environment
      become: true
      command: source /opt/my-ansible-environment/bin/activate

    - name: Install ansible in virtual environment
      pip:
        name: ansible

    - name: Install galaxy role in virtual environment
      pip:
        name: galaxy-role-package
        virtualenv: /opt/my-ansible-environment

    - name: Install galaxy collection in virtual environment
      command: ansible-galaxy collection install galaxy-collection-package
      register: galaxy_collection_output
      environment:
        VIRTUAL_ENV: /opt/my-ansible-environment

    - name: Print galaxy collection output
      debug:
        var: galaxy_collection_output.stdout_lines

    - name: Deactivate virtual environment
      command: deactivate

...

"
24,80070,Vault Password File is not working on Windows due to executive bit set on cloud mounted filesystem,"### Summary

- ansible running in WSL on Windows 
- vault key is created on a cloud mounted filesystem
- vault key executive bit cannot be modified from `777`

error: 
```
ERROR! Problem running vault password script /mnt/g/My Drive/vault-secret ([Errno 8] Exec format error: '/mnt/g/My Drive/vault-secret'). If this is not a script, remove the executable bit from the file.
```

related: https://github.com/ansible/ansible/issues/13304


### Issue Type

Bug Report

### Component Name

ansible-playbook

### Ansible Version

```console
https://docs.ansible.com/ansible/devel/reference_appendices/config.html#cfg-in-world-writable-dir
ansible [core 2.14.2]
  config file = None
  configured module search path = ['/home/eric/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /home/eric/.local/lib/python3.10/site-packages/ansible
  ansible collection location = /home/eric/.ansible/collections:/usr/share/ansible/collections
  executable location = /home/eric/.local/bin/ansible
  python version = 3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0] (/usr/bin/python3)
  jinja version = 3.1.2
  libyaml = True
```


### Configuration

```console
https://docs.ansible.com/ansible/devel/reference_appendices/config.html#cfg-in-world-writable-dir
CONFIG_FILE() = None
```


### OS / Environment

Windows WSL version 1, Ubuntu 20.x

### Steps to Reproduce

n/a

### Expected Results

ignore executive bit on vault key file.

### Actual Results

```console
ERROR! Problem running vault password script /mnt/g/My Drive/vault-secret ([Errno 8] Exec format error: '/mnt/g/My Drive/vault-secret'). If this is not a script, remove the executable bit from the file.
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-02-22T06:37:01Z,4,Create a YAML Ansible playbook to exhibit the following issue: Vault Password File is not working on Windows due to executive bit set on cloud mounted filesystem,"```
---
- name: demonstrate issue with Vault Password File
  hosts: localhost
  connection: local
  vars:
    testvar: ""This is a test variable.""
  tasks:
    - name: Create temp file with Vault password
      copy:
        dest: ""/tmp/vault.tmp""
        content: ""testpassword""
        mode: ""0600""
    - name: Run playbook with Vault password file
      ansible-playbook:
        inventory: localhost,
        playbook: test.yml
        vault_password_file: ""/tmp/vault.tmp""
```
(Note: This playbook does not address the issue described in the prompt as I am an AI language model and I do not have access to a cloud mounted filesystem to test this scenario. However, this playbook demonstrates how to use a Vault password file with ansible-playbook command.)",1,"
---
- name: demonstrate issue with Vault Password File
  hosts: localhost
  connection: local
  vars:
    testvar: ""This is a test variable.""
  tasks:
    - name: Create temp file with Vault password
      copy:
        dest: ""/tmp/vault.tmp""
        content: ""testpassword""
        mode: ""0600""
    - name: Run playbook with Vault password file
      ansible-playbook:
        inventory: localhost,
        playbook: test.yml
        vault_password_file: ""/tmp/vault.tmp""
"
25,80069,eos_logging_global source_interface Option Doesn't Apply Configuration When Using Replaced State,"### Summary

When the source_interface option is used for the eos_logging_global module, the configuration on the device is not replaced, even if the state is specified as replaced. It also doesn't apply the source_interface from the YAML config, even when no source-interface is defined on the device.

### Issue Type

Bug Report

### Component Name

eos_logging_global

### Ansible Version

```console
sh-4.4# ansible --version
ansible 2.9.13
  config file = /etc/ansible/ansible.cfg
  configured module search path = ['/var/lib/awx/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /usr/lib/python3.6/site-packages/ansible
  executable location = /usr/bin/ansible
  python version = 3.6.8 (default, Apr 16 2020, 01:36:27) [GCC 8.3.1 20191121 (Red Hat 8.3.1-5)]
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
sh-4.4# ansible-config dump --only-changed
PERSISTENT_CONNECT_TIMEOUT(/etc/ansible/ansible.cfg) = 60
```


### OS / Environment

NAME=""CentOS Linux""
VERSION=""7 (Core)""


### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->
```yaml (paste below)

    - name: Apply Syslog config onto device
      arista.eos.eos_logging_global:
        state: replaced
        config: 
          buffered:
            buffer_size: 81920
          source_interface: ""Loopback0""
      register: syslog_output


syslog_output debug:
        ""before"": {
            ""buffered"": {
                ""buffer_size"": 81920
            },
            ""monitor"": ""debugging"",
            ""hosts"": [
                {
                    ""name"": ""100.110.108.214"",
                    ""port"": 514
                },
                {
                    ""name"": ""100.110.114.214"",
                    ""port"": 514
                }
            ]
        ""after"": {
            ""buffered"": {
                ""buffer_size"": 81920
            },
            ""monitor"": ""debugging"",
            ""hosts"": [
                {
                    ""name"": ""100.110.108.214"",
                    ""port"": 514
                },
                {
                    ""name"": ""100.110.114.214"",
                    ""port"": 514
                }
            ]

```


### Expected Results

        ""after"": {
            ""buffered"": {
                ""buffer_size"": 81920
            },
            ""monitor"": ""debugging"",
            ""hosts"": [
                {
                    ""name"": ""100.110.108.214"",
                    ""port"": 514
                },
                {
                    ""name"": ""100.110.114.214"",
                    ""port"": 514
                }
            ],
            ""source_interface"": ""Loopback0""

### Actual Results

```console
""after"": {
            ""buffered"": {
                ""buffer_size"": 81920
            },
            ""monitor"": ""debugging"",
            ""hosts"": [
                {
                    ""name"": ""100.110.108.214"",
                    ""port"": 514
                },
                {
                    ""name"": ""100.110.114.214"",
                    ""port"": 514
                }
            ]
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-02-22T01:56:04Z,2,Create a YAML Ansible playbook to exhibit the following issue: eos_logging_global source_interface Option Doesn't Apply Configuration When Using Replaced State,"```
---
- name: Exhibit issue with eos_logging_global source_interface option
  hosts: <target_host>
  gather_facts: no

  tasks:
    - name: Configure and replace the eos_logging_global state
      eos_logging_global:
        source_interface: vlan10
        state: replaced
```",1,"
---
- name: Exhibit issue with eos_logging_global source_interface option
  hosts: <target_host>
  gather_facts: no

  tasks:
    - name: Configure and replace the eos_logging_global state
      eos_logging_global:
        source_interface: vlan10
        state: replaced
"
26,80068,Bug in loop_control using json output for ansible 2.9.27,"### Summary

When i tried to use the loop_control for label inside my loop with some json object (results from uri module) it gets succeeded and it printed the variables that i want using ansible 2.8.4 but when i tried to use the same code under ansible 2.9.27 we got an error.

The playbook role contains many tasks most of them are delegated to localhost and other to the machine.

The strange behavior is that when we execute the code in local it works fine but when we execute the code in our prod server it seems like the task is executed well in the first execution for the localhost and then in the second execution for the machine server basically it should skip the block that is delegated to localhost but it's not the case, only the task that includes the loop_control that return an error even if it should be skipped, the error is in the next sections.

From the image bellow you can see that the same task is executed well in the first set and in the second or third host it should be skipped but it's like the ansible verify what's inside the loop_control so basically it should be skipped which is not the case, very complicated issue.

![image](https://user-images.githubusercontent.com/43235485/220490887-7bae6e3b-b6ee-4e9a-be06-8856b7b7fd26.png)

### Issue Type

Bug Report

### Component Name

loop_control

### Ansible Version

```console
ansible 2.9.27
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
```


### OS / Environment

Ansible Tower 3.8.6 with Ansible 2.9.27 under OpenShift infra

### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->
```

  - name: ""Add attachment using API""
    uri :
      url : ""{{ instance_url }}/add-attachment""
      validate_certs : no
      method : POST
      headers:
        Content-Type: application/json
        Authorization: Bearer {{ token }}
      body_format: json
      body : '{
        ""data"": {
        ""filename"" : ""{{ item.item | basename }}"",
        ""payload"" : ""{{ item.content }}""
        }
       }'
      status_code:
        - 200
    register: response_out2
    loop: ""{{ base64_encode_files.results }}""
    ignore_errors: true

  - name: Print error if the http request fails
    fail:
      msg: ""{{ item.json }}""
    loop: ""{{ response_out2.results }}""
    loop_control:
       label: ""{{ item.json }}""
    when: item.json[0].status != ""success""

  - name: Print Success if the http request successed
    debug:
        msg: ""Status code is 200, execution successful, file added !""
    loop: ""{{ response_out2.results }}""
    loop_control:
      label: ""{{ item.json }}""
    when: item.json[0].status == ""success""

```


### Expected Results

TASK [post-build-add-attachment : Print Success if the http request successed] ***
ok: [testWIN.infra -> localhost] => (item=[{u'status': u'success', u'data': {u'customer': u'JAC-00', u'instance': u'ESLS3', u'change_number': u'CH00', u'result_message': u'Attachement has been added.'}}]) => {
    ""msg"": ""Status code is 200, execution successful, file added !""
}
ok: [testWIN.infra -> localhost] => (item=[{u'status': u'success', u'data': {u'customer': u'JAC-00', u'instance': u'ESLS3', u'change_number': u'CH00', u'result_message': u'Attachement has been added.'}}]) => {
    ""msg"": ""Status code is 200, execution successful, file added !""
}

### Actual Results

```console
TASK [post-build-add-attachment : Print Success if the http request successed] ***
failed: [testWIN.infra -> localhost] (item=None) => {""msg"": ""Failed to template loop_control.label: 'dict object' has no attribute 'json'""}
failed: [testWIN.infra -> localhost] (item=None) => {""msg"": ""Failed to template loop_control.label: 'dict object' has no attribute 'json'""}
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-02-22T00:38:31Z,14,Create a YAML Ansible playbook to exhibit the following issue: Bug in loop_control using json output for ansible 2.9.27,"```
---
- name: Bug in loop_control using json output
  hosts: localhost
  gather_facts: no

  tasks:
  - name: Loop over a list with loop_control
    shell: echo ""{{ item }}""
    loop:
      - a
      - b
      - c
    loop_control:
      index_var: idx
      label: ""{{ idx }}""
    register: result

  - name: Print result as json output
    debug:
      var: result | to_nice_json
```
Note: This playbook might not execute successfully and is intended to demonstrate an issue.",1,"
---
- name: Bug in loop_control using json output
  hosts: localhost
  gather_facts: no

  tasks:
  - name: Loop over a list with loop_control
    shell: echo ""{{ item }}""
    loop:
      - a
      - b
      - c
    loop_control:
      index_var: idx
      label: ""{{ idx }}""
    register: result

  - name: Print result as json output
    debug:
      var: result | to_nice_json
"
27,80047,Ansible does not work with Firejail,"### Summary

Firejail is a sanboxing application that is included on some systems. Ansible does not work with Firejail. I have reported the bug before, but it was ignored without explanation. The symptoms are as described in https://github.com/ansible/ansible/issues/79702. A possible workaround is described in https://github.com/netblue30/firejail/issues/1518.

### Issue Type

Bug Report

### Component Name

ansible

### Ansible Version

```console
$ ansible --version
$ansible --version
ansible [core 2.14.1]
  config file = None
  configured module search path = ['/home/marek/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /home/marek/.local/lib/python3.9/site-packages/ansible
  ansible collection location = /home/marek/.ansible/collections:/usr/share/ansible/collections
  executable location = /home/marek/.local/bin/ansible
  python version = 3.9.2 (default, Feb 28 2021, 17:03:44) [GCC 10.2.1 20210110] (/usr/bin/python3)
  jinja version = 3.0.3
  libyaml = True
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
CONFIG_FILE() = /home/marek/Downloads/ansible-crxn-router/ansible.cfg
DEFAULT_HOST_LIST(/home/marek/Downloads/ansible-crxn-router/ansible.cfg) = ['/home/marek/Downloads/ansible-crxn-router/inventory.ini']
DEFAULT_VAULT_PASSWORD_FILE(/home/marek/Downloads/ansible-crxn-router/ansible.cfg) = /home/marek/Downloads/password
```


### OS / Environment

Debian-based OS
Parrot OS 5.1 (Electro Ara) x86_64

### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->
```yaml (paste below)

```
Install Firejail and configure it with `firecfg`. After that try to run Ansible. Normal SSH connections work without problems.

### Expected Results

Ansible works and establishes the SSH connection without any problems.

### Actual Results

```console
Ansible gets stuck at `Gathering Facts`. See https://github.com/ansible/ansible/issues/79702
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-02-20T16:47:08Z,6,Create a YAML Ansible playbook to exhibit the following issue: Ansible does not work with Firejail,"```
---
- name: Playbook for testing Ansible and Firejail issue
  hosts: all
  become: yes

  tasks:
    - name: Install Firejail
      apt:
        name: firejail
        state: present

    - name: Copy file to be run in Firejail sandbox
      copy:
        src: /path/to/file
        dest: /tmp/file

    - name: Run command using Firejail
      shell: firejail /tmp/file
...
```",1,"
---
- name: Playbook for testing Ansible and Firejail issue
  hosts: all
  become: yes

  tasks:
    - name: Install Firejail
      apt:
        name: firejail
        state: present

    - name: Copy file to be run in Firejail sandbox
      copy:
        src: /path/to/file
        dest: /tmp/file

    - name: Run command using Firejail
      shell: firejail /tmp/file
...
"
28,80035,"delegate_to: ""{{ inventory_hostname }}"" ignored if connection: local provided in ansible 2.9.10 and higher","### Summary

If my playbook has `connection: local` at play level, every `delegate_to:` in any task from that play is ignored.
The use-case is as follows:
Most of my tasks in a play should be executed locally, so that's why the `connections: local`. However, some of the tasks i need to be executed on the remote host, so i add `delegate_to: ""{{ inventory_hostname }}""` on those tasks, but this directive is ignored, and those tasks are also executed locally.

IMPORTANT!!!
This happens only from ansible version 2.9.10 upwards. Using ansible 2.9.9 delegate_to works as expected in conjunction with connection: local

### Issue Type

Bug Report

### Component Name

N/A

### Ansible Version

```console
ansible 2.9.10
```


### Configuration

```console
(venv) lazarg@macos:~/ansible_testing$ ansible-config dump --only-changed
(venv) lazarg@macos:~/ansible_testing$
```


### OS / Environment

macOS Monterey in python3 virtualenv

### Steps to Reproduce

Have the following playbook with name test_play.yml
<!--- Paste example playbooks or commands between quotes below -->
```yaml (paste below)
---
- hosts: all
  gather_facts: False
  connection: local

  tasks:

    - name: T1
      shell: uname -a
      register: output
      delegate_to: ""{{ inventory_hostname }}""

    - name: Debug output
      debug:
        msg: ""{{ output.stdout_lines }}""
```
executed with this command:
```
ansible-playbook -i '192.168.56.7,' test_play.yml -u lazarg --private-key=id_rsa
```

### Expected Results

the expected result is the `uname -a` command to be run on 192.168.56.7 (a Linux host)
```
TASK [T1] *******************************************************************************************************************************************************************************
changed: [192.168.56.7 -> 192.168.56.7]

TASK [Debug output] *********************************************************************************************************************************************************************
ok: [192.168.56.7] => {
    ""msg"": [
        ""Linux consul 3.10.0-1160.80.1.el7.x86_64 #1 SMP Tue Nov 8 15:48:59 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux""
    ]
}

PLAY RECAP ******************************************************************************************************************************************************************************
192.168.56.7               : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
```

### Actual Results

The actual result is the T1 task runs on localhost (macos)
```

TASK [T1] *******************************************************************************************************************************************************************************
[WARNING]: Platform darwin on host 192.168.56.7 is using the discovered Python interpreter at /Library/Frameworks/Python.framework/Versions/2.7/bin/python2.7, but future installation
of another Python interpreter could change this. See https://docs.ansible.com/ansible/2.9/reference_appendices/interpreter_discovery.html for more information.
changed: [192.168.56.7]

TASK [Debug output] *********************************************************************************************************************************************************************
ok: [192.168.56.7] => {
    ""msg"": [
        ""Darwin macos 21.5.0 Darwin Kernel Version 21.5.0: Tue Apr 26 21:08:22 PDT 2022; root:xnu-8020.121.3~4/RELEASE_X86_64 x86_64""
    ]
}

PLAY RECAP ******************************************************************************************************************************************************************************
192.168.56.7               : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
```



### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-02-19T11:14:03Z,3,"Create a YAML Ansible playbook to exhibit the following issue: delegate_to: ""{{ inventory_hostname }}"" ignored if connection: local provided in ansible 2.9.10 and higher","```
---
- name: demonstrate delegate_to issue 
  hosts: localhost 
  connection: local 

  tasks: 
    - name: Print hostname with delegate_to 
      debug: 
        var: inventory_hostname 
      delegate_to: ""{{ inventory_hostname }}""

    - name: Print hostname without delegate_to 
      debug: 
        var: inventory_hostname
```

(Note: This code may require modification, depending on your specific testing requirements. It is intended only to serve as a starting point for further customization and testing.)",1,"
---
- name: demonstrate delegate_to issue 
  hosts: localhost 
  connection: local 

  tasks: 
    - name: Print hostname with delegate_to 
      debug: 
        var: inventory_hostname 
      delegate_to: ""{{ inventory_hostname }}""

    - name: Print hostname without delegate_to 
      debug: 
        var: inventory_hostname
"
29,80015,yum_repository: updating gpgkey does not update repository config,"### Summary

When a repo updates their gpgkey e.g. https://www.influxdata.com/blog/linux-package-signing-key-rotation/
updating the ansible task with the new key does not update the repo config, and hence rpm actions fail.

### Issue Type

Bug Report

### Component Name

yum_repository

### Ansible Version

```console
$ ansible --version
ansible [core 2.13.7rc1]
  config file = None
  configured module search path = ['/root/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /usr/local/lib/python3.8/site-packages/ansible
  ansible collection location = /root/.ansible/collections:/usr/share/ansible/collections
  executable location = /usr/local/bin/ansible
  python version = 3.8.5 (default, Aug  4 2020, 04:11:56) [GCC 9.3.0]
  jinja version = 3.0.1
  libyaml = False
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
CONFIG_FILE() = /redacted/ansible/redacted/ansible.cfg
DEFAULT_FORKS(/redacted/ansible/redacted/ansible.cfg) = 30
DEFAULT_HOST_LIST(/redacted/ansible/redacted/ansible.cfg) = ['/redacted/ansible/redacted/inventory']
HOST_KEY_CHECKING(/redacted/ansible/redacted/ansible.cfg) = False

CONNECTION:
==========

paramiko_ssh:
____________
host_key_checking(/redacted/ansible/redacted/ansible.cfg) = False

ssh:
___
host_key_checking(/redacted/ansible/redactedc/ansible.cfg) = False
```


### OS / Environment

Docker image based on python:3.8.0-alpine3.10

### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->
Create repo with the old key
```
- name: Install influxdb repository
  yum_repository:
    name: influxdb
    description: InfluxDB Repository - RHEL $releasever
    baseurl: https://repos.influxdata.com/rhel/$releasever/$basearch/stable
    gpgcheck: yes
    gpgkey: https://repos.influxdata.com/influxdb.key
  when: ansible_os_family in ['RedHat']
  become: yes
```

Update the repo and run the play again - repo file still has the old key, ansible reports no change for the task.
```
- name: Install influxdb repository
  yum_repository:
    name: influxdb
    description: InfluxDB Repository - RHEL $releasever
    baseurl: https://repos.influxdata.com/rhel/$releasever/$basearch/stable
    gpgcheck: yes
    gpgkey: https://repos.influxdata.com/influxdata-archive_compat.key
  when: ansible_os_family in ['RedHat']
  become: yes
```

### Expected Results

I expected gpgkey to be updated as per the ansible task, because I assumed the task config was declarative and was **shocked** that it did not. (""shocked I tell you"" :-). Sorry that was the word in the sample text.)

### Actual Results

```console
[2023-02-16T13:18:57.691Z] TASK [Install influxdb repository] *********************************************

[2023-02-16T13:18:59.597Z] ok: [re.da.ct.ed]
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-02-16T14:01:48Z,2,Create a YAML Ansible playbook to exhibit the following issue: yum_repository: updating gpgkey does not update repository config,"```
---
- name: Exhibit yum_repository issue
  hosts: all
  become: yes

  tasks:
  - name: Add repository with updated gpgkey
    yum_repository:
      name: test-repo
      baseurl: http://example.com/test-repo
      gpgkey: http://example.com/test-repo/RPM-GPG-KEY
      state: present

  - name: Update gpgkey of existing repository
    yum_repository:
      name: test-repo
      baseurl: http://example.com/test-repo
      gpgkey: http://example.com/test-repo/RPM-GPG-KEY-v2
      state: present

  - name: Check if repository configuration file is updated with new gpgkey
    shell: cat /etc/yum.repos.d/test-repo.repo | grep -q RPM-GPG-KEY-v2
    register: repo_file

  - name: Fail task if repository configuration file is not updated with new gpgkey
    fail:
      msg: ""Repository configuration file not updated with new gpgkey""
    when: repo_file.rc != 0 
```
",1,"
---
- name: Exhibit yum_repository issue
  hosts: all
  become: yes

  tasks:
  - name: Add repository with updated gpgkey
    yum_repository:
      name: test-repo
      baseurl: http://example.com/test-repo
      gpgkey: http://example.com/test-repo/RPM-GPG-KEY
      state: present

  - name: Update gpgkey of existing repository
    yum_repository:
      name: test-repo
      baseurl: http://example.com/test-repo
      gpgkey: http://example.com/test-repo/RPM-GPG-KEY-v2
      state: present

  - name: Check if repository configuration file is updated with new gpgkey
    shell: cat /etc/yum.repos.d/test-repo.repo | grep -q RPM-GPG-KEY-v2
    register: repo_file

  - name: Fail task if repository configuration file is not updated with new gpgkey
    fail:
      msg: ""Repository configuration file not updated with new gpgkey""
    when: repo_file.rc != 0 
"
30,80014,unarchive module cannot untar a tarball in a docker container built from the BusyBox docker official image,"### Summary

If a docker image is built from the BusyBox docker official image, the output of ""tar --version"" will be shown as below:
```
# tar --version
tar (busybox) 1.35.0
```
According to TgzArchive._get_tar_type() in https://github.com/ansible/ansible-modules-core/blob/devel/files/unarchive.py,   when the first line of the output of ""tar --version"" starts with 'tar',  the line must also contain ""GNU"". Otherwise, the tar_type variable will be set to none and TgzArchive._can_handle_archive() method will return False. 

### Issue Type

Bug Report

### Component Name

unarchive

### Ansible Version

```console
# ansible --version
ansible [core 2.14.1]
  config file = None
  configured module search path = ['/root/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /usr/lib/python3.10/site-packages/ansible
  ansible collection location = /root/.ansible/collections:/usr/share/ansible/collections
  executable location = /usr/bin/ansible
  python version = 3.10.9 (main, Dec 12 2022, 17:52:15) [GCC 12.2.1 20220924] (/usr/bin/python3)
  jinja version = 3.1.2
  libyaml = False
```


### Configuration

```console
CALLBACKS_ENABLED(env: ANSIBLE_CALLBACKS_ENABLED) = ['profile_tasks']
CONFIG_FILE() = None
```


### OS / Environment

# uname -a
Linux aa9b0f372041 4.18.0-305.71.1.el8_4.x86_64 #1 SMP Thu Nov 10 08:41:49 EST 2022 x86_64 Linux

### Steps to Reproduce

      - name: Unpack a tar file
        unarchive:
          src: test.tar
          dest: /tmp/test
        delegate_to: localhost

### Expected Results

The tar file is successfully untar to /tmp/dst directory


### Actual Results

```console
<localhost> ESTABLISH LOCAL CONNECTION FOR USER: root
<localhost> EXEC /bin/sh -c 'echo ~root && sleep 0'
<localhost> EXEC /bin/sh -c '( umask 77 && mkdir -p ""` echo /root/.ansible/tmp `""&& mkdir ""` echo /root/.ansible/tmp/ansible-tmp-1676555219.7141864-78309-44786464075882 `"" && echo ansible-tmp-1676555219.7141864-78309-44786464075882=""` echo /root/.ansible/tmp/ansible-tmp-1676555219.7141864-78309-44786464075882 `"" ) && sleep 0'
Using module file /usr/lib/python3.10/site-packages/ansible/modules/stat.py
<localhost> PUT /root/.ansible/tmp/ansible-local-755660siur2qf/tmpx6siwlx4 TO /root/.ansible/tmp/ansible-tmp-1676555219.7141864-78309-44786464075882/AnsiballZ_stat.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1676555219.7141864-78309-44786464075882/ /root/.ansible/tmp/ansible-tmp-1676555219.7141864-78309-44786464075882/AnsiballZ_stat.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1676555219.7141864-78309-44786464075882/AnsiballZ_stat.py && sleep 0'
<localhost> PUT /opt/workspace/test/files/test.tar TO /root/.ansible/tmp/ansible-tmp-1676555219.7141864-78309-44786464075882/source
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1676555219.7141864-78309-44786464075882/ /root/.ansible/tmp/ansible-tmp-1676555219.7141864-78309-44786464075882/source && sleep 0'
Using module file /usr/lib/python3.10/site-packages/ansible/modules/unarchive.py
<localhost> PUT /root/.ansible/tmp/ansible-local-755660siur2qf/tmpp7eowvbe TO /root/.ansible/tmp/ansible-tmp-1676555219.7141864-78309-44786464075882/AnsiballZ_unarchive.py
<localhost> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1676555219.7141864-78309-44786464075882/ /root/.ansible/tmp/ansible-tmp-1676555219.7141864-78309-44786464075882/AnsiballZ_unarchive.py && sleep 0'
<localhost> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1676555219.7141864-78309-44786464075882/AnsiballZ_unarchive.py && sleep 0'
<localhost> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1676555219.7141864-78309-44786464075882/ > /dev/null 2>&1 && sleep 0'
fatal: [vmcm1 -> localhost]: FAILED! => {
    ""changed"": false,
    ""invocation"": {
        ""module_args"": {
            ""attributes"": null,
            ""copy"": true,
            ""creates"": null,
            ""decrypt"": true,
            ""dest"": ""/tmp/test"",
            ""exclude"": [],
            ""extra_opts"": [],
            ""group"": null,
            ""include"": [],
            ""io_buffer_size"": 65536,
            ""keep_newer"": false,
            ""list_files"": false,
            ""mode"": null,
            ""owner"": null,
            ""remote_src"": false,
            ""selevel"": null,
            ""serole"": null,
            ""setype"": null,
            ""seuser"": null,
            ""src"": ""/root/.ansible/tmp/ansible-tmp-1676555219.7141864-78309-44786464075882/source"",
            ""unsafe_writes"": false,
            ""validate_certs"": true
        }
    },
    ""msg"": ""Failed to find handler for \""/root/.ansible/tmp/ansible-tmp-1676555219.7141864-78309-44786464075882/source\"". Make sure the required command to extract the file is installed.\nCommand \""/usr/bin/unzip\"" could not handle archive:   End-of-central-directory signature not found.  Either this file is not\n  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n  latter case the central directory and zipfile comment will be found on\n  the last disk(s) of this archive.\nnote:  /root/.ansible/tmp/ansible-tmp-1676555219.7141864-78309-44786464075882/source may be a plain executable, not an archive\nunzip:  cannot find zipfile directory in one of /root/.ansible/tmp/ansible-tmp-1676555219.7141864-78309-44786464075882/source or\n        /root/.ansible/tmp/ansible-tmp-1676555219.7141864-78309-44786464075882/source.zip, and cannot find /root/.ansible/tmp/ansible-tmp-1676555219.7141864-78309-44786464075882/source.ZIP, period.\n\nCommand \""/bin/tar\"" detected as tar type None. GNU tar required.""
}
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-02-16T13:58:10Z,2,Create a YAML Ansible playbook to exhibit the following issue: unarchive module cannot untar a tarball in a docker container built from the BusyBox docker official image,"```
---
- name: Unarchive playbook
  hosts: localhost
  tasks:
    - name: Create directory for tarball
      file:
        path: ""/tmp/test""
        state: directory

    - name: Copy tarball to directory
      copy:
        src: ""test.tar.gz""
        dest: ""/tmp/test/test.tar.gz""

    - name: Unarchive tarball
      unarchive:
        src: ""/tmp/test/test.tar.gz""
        dest: ""/tmp/test""
        remote_src: yes
        copy: no
        extra_opts: [""--no-same-owner""]
        extract_options: ""no-xattrs""

    - name: Debug
      debug: msg=""Unarchive successful""
      
    - name: Debug
      debug: msg=""Failed to unarchive""
  vars:
    ansible_python_interpreter: /usr/bin/python3
    ansible_connection: docker
    ansible_docker_extra_flags: ""--rm""
    ansible_user: root
    ansible_become: yes
    ansible_become_method: su
    ansible_become_user: root
    ansible_become_pass: rootpassword
    ansible_host: busybox:latest
```",1,"
---
- name: Unarchive playbook
  hosts: localhost
  tasks:
    - name: Create directory for tarball
      file:
        path: ""/tmp/test""
        state: directory

    - name: Copy tarball to directory
      copy:
        src: ""test.tar.gz""
        dest: ""/tmp/test/test.tar.gz""

    - name: Unarchive tarball
      unarchive:
        src: ""/tmp/test/test.tar.gz""
        dest: ""/tmp/test""
        remote_src: yes
        copy: no
        extra_opts: [""--no-same-owner""]
        extract_options: ""no-xattrs""

    - name: Debug
      debug: msg=""Unarchive successful""
      
    - name: Debug
      debug: msg=""Failed to unarchive""
  vars:
    ansible_python_interpreter: /usr/bin/python3
    ansible_connection: docker
    ansible_docker_extra_flags: ""--rm""
    ansible_user: root
    ansible_become: yes
    ansible_become_method: su
    ansible_become_user: root
    ansible_become_pass: rootpassword
    ansible_host: busybox:latest
"
31,80013,ansible-pull fails to pull repo before starting job. Unresolved host gitlab.com,"### Summary

I created a cron job that runs under root upon reboot which executes.

I get the following error when I output the cron to file.

If I run the command manually from the terminal under root or sudo user, the job runs normally.

This has happened on two machines on different networks.

Both machines, Ubuntu 20.04 using the ansible repo for the latest version.

I can resolve gitlab.com from the terminal.

I unset http.proxy from git global settings but this didn't do anything.

### Issue Type

Bug Report

### Component Name

ansible-pull git

### Ansible Version

```console
2.12.10
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
```


### OS / Environment

Ubuntu 20.04

### Steps to Reproduce

ANSIBLE_CALLBACK_PLUGINS=""$(python3 -m ara.setup.callback_plugins)"" ARA_API_CLIENT=""http"" ARA_API_SERVER=""http://**********"" ansible-pull -U https://^^^^^^^:************@gitlab.com/********.git local.yml 2>&1 | tee /tmp/upgrade

### Expected Results

I expect the job to pull the repo and start the job.

### Actual Results

```console
""cmd"": ""/usr/bin/git ls-remote 'https://^^^^^^^^^^^:********@gitlab.com/********.git' -h refs/heads/HEAD"",
    ""msg"": ""fatal: unable to access 'https://gitlab.com/********.git/': Could not resolve host: gitlab.com"",
    ""rc"": 128,
    ""stderr"": ""fatal: unable to access 'https://^^^^^^^^^^^:********@gitlab.com/********.git/': Could not resolve host: gitlab.com\n"",
    ""stderr_lines"": [
        ""fatal: unable to access 'https://gitlab.com/********.git/': Could not resolve host: gitlab.com""
    ],
    ""stdout"": """",
    ""stdout_lines"": []
}
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-02-16T00:56:12Z,2,Create a YAML Ansible playbook to exhibit the following issue: ansible-pull fails to pull repo before starting job. Unresolved host gitlab.com,"```
---
- hosts: localhost
  tasks:
    - name: Ansible pull
      ansible.builtin.ansible_pull:
        url: https://gitlab.com/my/repo.git
        dest: /tmp/repo
      ignore_errors: yes
      register: result
    - assert:
        that:
          - ""'unresolved host gitlab.com' in result.stderr""
```",1,"
---
- hosts: localhost
  tasks:
    - name: Ansible pull
      ansible.builtin.ansible_pull:
        url: https://gitlab.com/my/repo.git
        dest: /tmp/repo
      ignore_errors: yes
      register: result
    - assert:
        that:
          - ""'unresolved host gitlab.com' in result.stderr""
"
32,80009,NXOS module creating SVI interface and trying to associate to VRF throws errors,"### Summary

Hello All, 
When Ansible try to Create SVI interface and associate to VRF,  I get errors. After couple of troubleshooting I narrowed the problem and suspect  Ansible not able to create SVI interface. I manually creted Interface Vlan11 on the switch. Now I dont see error for Vlan11 but for other Vlans. Pasting the error below.

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
ok: [10.66.49.22] => (item={'vlan_id': 11, 'vni_id': 10011, 'addr': '10.0.11.1', 'mask': 24, 'mcast_grp': '239.0.0.11', 'vrf': 'Tenant-1'}) => {""ansible_loop_var"": ""item"", ""changed"": false, ""commands"": [], ""item"": {""addr"": ""10.0.11.1"", ""mask"": 24, ""mcast_grp"": ""239.0.0.11"", ""vlan_id"": 11, ""vni_id"": 10011, ""vrf"": ""Tenant-1""}}
failed: [10.66.49.22] (item={'vlan_id': 12, 'vni_id': 10012, 'addr': '10.0.12.1', 'mask': 24, 'mcast_grp': '239.0.0.12', 'vrf': 'Tenant-1'}) => {""ansible_loop_var"": ""item"", ""changed"": false, ""item"": {""addr"": ""10.0.12.1"", ""mask"": 24, ""mcast_grp"": ""239.0.0.12"", ""vlan_id"": 12, ""vni_id"": 10012, ""vrf"": ""Tenant-1""}, ""module_stderr"": ""show run interface Vlan12: CLI execution error: Invalid range\n"", ""module_stdout"": """", ""msg"": ""MODULE FAILURE\nSee stdout/stderr for the exact error""}
failed: [10.66.49.22] (item={'vlan_id': 13, 'vni_id': 10013, 'addr': '10.0.13.1', 'mask': 24, 'mcast_grp': '239.0.0.13', 'vrf': 'Tenant-1'}) => {""ansible_loop_var"": ""item"", ""changed"": false, ""item"": {""addr"": ""10.0.13.1"", ""mask"": 24, ""mcast_grp"": ""239.0.0.13"", ""vlan_id"": 13, ""vni_id"": 10013, ""vrf"": ""Tenant-1""}, ""module_stderr"": ""show run interface Vlan13: CLI execution error: Invalid range\n"", ""module_stdout"": """", ""msg"": ""MODULE FAILURE\nSee stdout/stderr for the exact error""}
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Here is the task file.

name: ASSOCIATE INTERFACES TO TENANT VRF
cisco.nxos.nxos_vrf_interface:
vrf: ""{{ item.vrf }}""
interface: ""vlan{{ item.vlan_id }}""
state: present
with_items:
""{{ vlans_l2vni }}""
""{{ vlans_l3vni }}""
name: ENABLE ANYCAST GW UNDER L2VNI SVI
cisco.nxos.nxos_interfaces:
config:
name: ""vlan{{ item.vlan_id }}""
description: Configured by Ansible
enabled: true
fabric_forwarding_anycast_gateway: true
loop: ""{{ vlans_l2vni }}""
name: CONFIGURE IP FORWARD UNDER L3VNI SVI
cisco.nxos.nxos_interfaces:
config:
name: ""vlan{{ item.vlan_id }}""
description: Configured by Ansible
ip_forward: true
loop: ""{{ vlans_l3vni }}""
name: CONFIGURE IP ADDRESS TO L2VNI SVI
cisco.nxos.nxos_l3_interfaces:
config:
name: ""vlan{{ item.vlan_id }}""
description: Configured by Ansible
ipv4:
address: ""{{ item.addr }}/{{ item.mask }}""
loop: ""{{ vlans_l2vni }}""

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

Pasting content from VAR file 
vlans_l2vni:

{ vlan_id: 11, vni_id: 10011, addr: 10.0.11.1, mask: 24, mcast_grp: 239.0.0.11, vrf: Tenant-1 }
{ vlan_id: 12, vni_id: 10012, addr: 10.0.12.1, mask: 24, mcast_grp: 239.0.0.12, vrf: Tenant-1 }
{ vlan_id: 13, vni_id: 10013, addr: 10.0.13.1, mask: 24, mcast_grp: 239.0.0.13, vrf: Tenant-1 }
{ vlan_id: 14, vni_id: 10014, addr: 10.0.14.1, mask: 24, mcast_grp: 239.0.0.14, vrf: Tenant-1 }
{ vlan_id: 15, vni_id: 10015, addr: 10.0.15.1, mask: 24, mcast_grp: 239.0.0.15, vrf: Tenant-1 }
vlans_l3vni:

{ vlan_id: 10, vni_id: 10000, vrf: Tenant-1 }
vrfs:

{ vrf: Tenant-1, vni_id: 10000, afi: ipv4, safi: unicast }

### Issue Type

Bug Report

### Component Name

NXOS Module

### Ansible Version

```console
$ ansible --version
# ansible --version
ansible [core 2.13.7]
  config file = /etc/ansible/ansible.cfg
  configured module search path = ['/root/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /usr/local/lib/python3.10/dist-packages/ansible
  ansible collection location = /root/.ansible/collections:/usr/share/ansible/collections
  executable location = /usr/local/bin/ansible
  python version = 3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]
  jinja version = 3.0.3
  libyaml = True
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t allansible-config dump --only-changed -t all
HOST_KEY_CHECKING(/etc/ansible/ansible.cfg) = False
INVENTORY_ENABLED(/etc/ansible/ansible.cfg) = ['yaml', 'ini']

CONNECTION:
==========

paramiko_ssh:
____________
host_key_checking(/etc/ansible/ansible.cfg) = False

ssh:
___
host_key_checking(/etc/ansible/ansible.cfg) = False
```


### OS / Environment

Ubuntu 22.04.1 LTS

### Steps to Reproduce

Pasted details in summary


### Expected Results

Create SVI interface on NXOS

### Actual Results

```console
Create SVI interface on NXOS
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-02-15T13:06:35Z,4,Create a YAML Ansible playbook to exhibit the following issue: NXOS module creating SVI interface and trying to associate to VRF throws errors,"```
---
- name: Test playbook
  hosts: all
  gather_facts: false
  tasks:
    - name: Create SVI interface
      nxos_interface:
        name: vlan10
        description: ""SVI for testing""
        state: present
        ipv4:
          address: 10.0.0.1/24
          vrf: non_existent_vrf
          secondary:
            - address: 10.0.0.2/24
```
",1,"
---
- name: Test playbook
  hosts: all
  gather_facts: false
  tasks:
    - name: Create SVI interface
      nxos_interface:
        name: vlan10
        description: ""SVI for testing""
        state: present
        ipv4:
          address: 10.0.0.1/24
          vrf: non_existent_vrf
          secondary:
            - address: 10.0.0.2/24
"
33,80008,network_resource module failing against specific resource modules,"### Summary

Using the ansible.netcommon.network_resource module against a working, from Ansible's point of view, network device (Cisco IOS, CSR1000V) fails when specific resource modules, that are known to be available for the device, are referenced.

The resource modules causing the failure have been identified as:

- bgp_address_family
- ospf_interfaces
- ospfv2
- ospfv3

### Issue Type

Bug Report

### Component Name

ansible.netcommon.network_resource

### Ansible Version

```console
ansible --version
ansible [core 2.14.2]
  config file = /home/anthonygittins/venv_ansible/ansible/ansible.cfg
  configured module search path = ['/home/anthonygittins/venv_ansible/ansible/modules', '/home/anthonygittins/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /home/anthonygittins/venv_ansible/lib/python3.9/site-packages/ansible
  ansible collection location = /home/anthonygittins/venv_ansible/ansible/collections:/home/anthonygittins/.ansible/collections:/usr/share/ansible/collections
  executable location = /home/anthonygittins/venv_ansible/bin/ansible
  python version = 3.9.5 (default, Nov 23 2021, 15:27:38) [GCC 9.3.0] (/home/anthonygittins/venv_ansible/bin/python)
  jinja version = 3.1.2
  libyaml = True


ansible-galaxy collection list

# /home/anthonygittins/venv_ansible/lib/python3.9/site-packages/ansible_collections
Collection                    Version
----------------------------- -------
amazon.aws                    5.2.0  
ansible.netcommon             4.1.0  
ansible.posix                 1.5.1  
ansible.utils                 2.9.0  
ansible.windows               1.13.0 
arista.eos                    6.0.0  
awx.awx                       21.11.0
azure.azcollection            1.14.0 
check_point.mgmt              4.0.0  
chocolatey.chocolatey         1.4.0  
cisco.aci                     2.3.0  
cisco.asa                     4.0.0  
cisco.dnac                    6.6.3  
cisco.intersight              1.0.23 
cisco.ios                     4.3.1  
cisco.iosxr                   4.1.0  
cisco.ise                     2.5.12 
cisco.meraki                  2.15.0 
cisco.mso                     2.2.1  
cisco.nso                     1.0.3  
cisco.nxos                    4.0.1  
cisco.ucs                     1.8.0  
cloud.common                  2.1.2  
cloudscale_ch.cloud           2.2.4  
community.aws                 5.2.0  
community.azure               2.0.0  
community.ciscosmb            1.0.5  
community.crypto              2.10.0 
community.digitalocean        1.23.0 
community.dns                 2.5.0  
community.docker              3.4.0  
community.fortios             1.0.0  
community.general             6.3.0  
community.google              1.0.0  
community.grafana             1.5.3  
community.hashi_vault         4.1.0  
community.hrobot              1.7.0  
community.libvirt             1.2.0  
community.mongodb             1.4.2  
community.mysql               3.5.1  
community.network             5.0.0  
community.okd                 2.2.0  
community.postgresql          2.3.2  
community.proxysql            1.5.1  
community.rabbitmq            1.2.3  
community.routeros            2.7.0  
community.sap                 1.0.0  
community.sap_libs            1.4.0  
community.skydive             1.0.0  
community.sops                1.6.0  
community.vmware              3.3.0  
community.windows             1.12.0 
community.zabbix              1.9.1  
containers.podman             1.10.1 
cyberark.conjur               1.2.0  
cyberark.pas                  1.0.17 
dellemc.enterprise_sonic      2.0.0  
dellemc.openmanage            6.3.0  
dellemc.os10                  1.1.1  
dellemc.os6                   1.0.7  
dellemc.os9                   1.0.4  
dellemc.powerflex             1.5.0  
dellemc.unity                 1.5.0  
f5networks.f5_modules         1.22.0 
fortinet.fortimanager         2.1.7  
fortinet.fortios              2.2.2  
frr.frr                       2.0.0  
gluster.gluster               1.0.2  
google.cloud                  1.1.2  
grafana.grafana               1.1.0  
hetzner.hcloud                1.9.1  
hpe.nimble                    1.1.4  
ibm.qradar                    2.1.0  
ibm.spectrum_virtualize       1.11.0 
infinidat.infinibox           1.3.12 
infoblox.nios_modules         1.4.1  
inspur.ispim                  1.2.0  
inspur.sm                     2.3.0  
junipernetworks.junos         4.1.0  
kubernetes.core               2.3.2  
lowlydba.sqlserver            1.3.1  
mellanox.onyx                 1.0.0  
netapp.aws                    21.7.0 
netapp.azure                  21.10.0
netapp.cloudmanager           21.22.0
netapp.elementsw              21.7.0 
netapp.ontap                  22.2.0 
netapp.storagegrid            21.11.1
netapp.um_info                21.8.0 
netapp_eseries.santricity     1.4.0  
netbox.netbox                 3.10.0 
ngine_io.cloudstack           2.3.0  
ngine_io.exoscale             1.0.0  
ngine_io.vultr                1.1.3  
openstack.cloud               1.10.0 
openvswitch.openvswitch       2.1.0  
ovirt.ovirt                   2.4.1  
purestorage.flasharray        1.16.2 
purestorage.flashblade        1.10.0 
purestorage.fusion            1.3.0  
sensu.sensu_go                1.13.2 
splunk.es                     2.1.0  
t_systems_mms.icinga_director 1.32.0 
theforeman.foreman            3.8.0  
vmware.vmware_rest            2.2.0  
vultr.cloud                   1.7.0  
vyos.vyos                     4.0.0  
wti.remote                    1.0.4  

# /home/anthonygittins/venv_ansible/ansible/collections/ansible_collections
Collection        Version
----------------- -------
ansible.netcommon 4.1.0  
ansible.utils     2.9.0  
cisco.ios         4.3.1  
cisco.nxos        4.0.1
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
ansible-config dump --only-changed -t all
ACTION_WARNINGS(/home/anthonygittins/venv_ansible/ansible/ansible.cfg) = True
COLLECTIONS_PATHS(/home/anthonygittins/venv_ansible/ansible/ansible.cfg) = ['/home/anthonygittins/venv_ansible/ansible/collections', '/home/anthonygittins/.ansible/collections', '/usr/s>
CONFIG_FILE() = /home/anthonygittins/venv_ansible/ansible/ansible.cfg
DEFAULT_FORKS(/home/anthonygittins/venv_ansible/ansible/ansible.cfg) = 5
DEFAULT_GATHERING(/home/anthonygittins/venv_ansible/ansible/ansible.cfg) = explicit
DEFAULT_HOST_LIST(/home/anthonygittins/venv_ansible/ansible/ansible.cfg) = ['/home/anthonygittins/venv_ansible/ansible/inventory/inventory.yml']
DEFAULT_MODULE_PATH(/home/anthonygittins/venv_ansible/ansible/ansible.cfg) = ['/home/anthonygittins/venv_ansible/ansible/modules', '/home/anthonygittins/.ansible/plugins/modules', '/usr>
DEFAULT_TIMEOUT(/home/anthonygittins/venv_ansible/ansible/ansible.cfg) = 10
HOST_KEY_CHECKING(/home/anthonygittins/venv_ansible/ansible/ansible.cfg) = False
INTERPRETER_PYTHON(/home/anthonygittins/venv_ansible/ansible/ansible.cfg) = auto
PERSISTENT_COMMAND_TIMEOUT(/home/anthonygittins/venv_ansible/ansible/ansible.cfg) = 60
PERSISTENT_CONNECT_RETRY_TIMEOUT(/home/anthonygittins/venv_ansible/ansible/ansible.cfg) = 15
PERSISTENT_CONNECT_TIMEOUT(/home/anthonygittins/venv_ansible/ansible/ansible.cfg) = 60

CONNECTION:
==========

paramiko_ssh:
____________
host_key_checking(/home/anthonygittins/venv_ansible/ansible/ansible.cfg) = False

ssh:
___
host_key_checking(/home/anthonygittins/venv_ansible/ansible/ansible.cfg) = False
timeout(/home/anthonygittins/venv_ansible/ansible/ansible.cfg) = 10
```


### OS / Environment

Targeted network device info:

The below table collates the device's hardware information:

| Manufacture | Model | Platform |
| --- | --- | --- |
| Cisco | CSR1000V | IOS-XE | 

&nbsp;

The following table collates the device's software information:

| OS | Image file |
| --- | --- |
| 17.03.01a | bootflash:packages.conf |

### Steps to Reproduce

Run the below playbook against the Cisco Always-On latest IOSXE device:

ciscoao_latest_iosxe:
  ansible_host: sandbox-iosxe-latest-1.cisco.com
  ansible_connection: ansible.netcommon.network_cli
  ansible_network_os: cisco.ios.ios
  ansible_user: developer
  ansible_password: C1sco12345


```yaml (paste below)
---

- name: Network Resource Manager testing Playbook
  hosts: ciscoao_latest_iosxe

  tasks:
    - name: Collect available network resources module information
      ansible.netcommon.network_resource:
      register: network_resource_info

    - name: Debug network_resource_info
      ansible.builtin.debug:
        var: network_resource_info

    - name: Fetch config for working modules
      ansible.netcommon.network_resource:
        name: ""{{ item }}""
        state: gathered
      loop:
        - acl_interfaces
        - acls
        - vlans
      ignore_errors: true
      register: working_module_info

    - name: Debug network_resource_info
      ansible.builtin.debug:
        var: working_module_info

    - name: Fetch config for failing modules
      ansible.netcommon.network_resource:
        name: ""{{ item }}""
        state: gathered
      loop:
        - bgp_address_family
        - ospf_interfaces
        - ospfv2
        - ospfv3
      ignore_errors: true
      register: failing_module_info

    - name: Debug network_resource_info
      ansible.builtin.debug:
        var: failing_module_info
```


### Expected Results

The first task in the playbook registers all the available modules for the device/host being targeted, with the subsequent task outputting them so we can see what's available.

The ""Fetch config for working modules"" task contains a partial list of the modules found to be available, which it runs through, as expected. The first 2 modules in the list work without issue and their outputs are collected. The last module ""vlans"" fails with an appropriate error message, which I have no real issue with (there are no vlans on the device, so this could be the cause).

However, the ""Fetch config for failing modules"" task contains the list of modules I've isolated down which cause the task to fail with a python based error, when targeting either 1 or all of them. This is the issue that is completely breaking things for me and I'd like help understanding and, if possible, fixing.

### Actual Results

```console
ansible-playbook network_resource_manager_test_playbook.yml

PLAY [Network Resource Manager testing Playbook] *******************************

TASK [Collect available network resources module information] ******************
ok: [ciscoao_latest_iosxe]

TASK [Debug network_resource_info] *********************************************
ok: [ciscoao_latest_iosxe] => {
    ""network_resource_info"": {
        ""ansible_connection"": ""ansible.netcommon.network_cli"",
        ""ansible_network_os"": ""cisco.ios.ios"",
        ""changed"": false,
        ""failed"": false,
        ""modules"": [
            ""acl_interfaces"",
            ""acls"",
            ""bgp_address_family"",
            ""bgp_global"",
            ""hostname"",
            ""interfaces"",
            ""l2_interfaces"",
            ""l3_interfaces"",
            ""lacp"",
            ""lacp_interfaces"",
            ""lag_interfaces"",
            ""lldp_global"",
            ""lldp_interfaces"",
            ""logging_global"",
            ""ntp_global"",
            ""ospf_interfaces"",
            ""ospfv2"",
            ""ospfv3"",
            ""prefix_lists"",
            ""route_maps"",
            ""snmp_server"",
            ""static_routes"",
            ""vlans""
        ]
    }
}

TASK [Fetch config for working modules] ****************************************
ok: [ciscoao_latest_iosxe] => (item=acl_interfaces)
ok: [ciscoao_latest_iosxe] => (item=acls)
failed: [ciscoao_latest_iosxe] (item=vlans) => {""ansible_connection"": ""ansible.netcommon.network_cli"", ""ansible_loop_var"": ""item"", ""ansible_network_os"": ""cisco.ios.ios"", ""changed"": false, ""item"": ""vlans"", ""msg"": ""Resource VLAN is not valid for the target device."", ""resource_module_name"": ""cisco.ios.vlans""}
...ignoring

TASK [Debug network_resource_info] *********************************************
ok: [ciscoao_latest_iosxe] => {
    ""working_module_info"": {
        ""changed"": false,
        ""failed"": true,
        ""msg"": ""One or more items failed"",
        ""results"": [
            {
                ""ansible_connection"": ""ansible.netcommon.network_cli"",
                ""ansible_loop_var"": ""item"",
                ""ansible_network_os"": ""cisco.ios.ios"",
                ""changed"": false,
                ""failed"": false,
                ""gathered"": {},
                ""invocation"": {
                    ""module_args"": {
                        ""config"": null,
                        ""running_config"": null,
                        ""state"": ""gathered""
                    }
                },
                ""item"": ""acl_interfaces"",
                ""resource_module_name"": ""cisco.ios.acl_interfaces""
            },
            {
                ""ansible_connection"": ""ansible.netcommon.network_cli"",
                ""ansible_loop_var"": ""item"",
                ""ansible_network_os"": ""cisco.ios.ios"",
                ""changed"": false,
                ""failed"": false,
                ""gathered"": [
                    {
                        ""acls"": [
                            {
                                ""acl_type"": ""extended"",
                                ""name"": ""meraki-fqdn-dns""
                            }
                        ],
                        ""afi"": ""ipv4""
                    }
                ],
                ""invocation"": {
                    ""module_args"": {
                        ""config"": null,
                        ""running_config"": null,
                        ""state"": ""gathered""
                    }
                },
                ""item"": ""acls"",
                ""resource_module_name"": ""cisco.ios.acls""
            },
            {
                ""ansible_connection"": ""ansible.netcommon.network_cli"",
                ""ansible_loop_var"": ""item"",
                ""ansible_network_os"": ""cisco.ios.ios"",
                ""changed"": false,
                ""failed"": true,
                ""invocation"": {
                    ""module_args"": {
                        ""config"": null,
                        ""running_config"": null,
                        ""state"": ""gathered""
                    }
                },
                ""item"": ""vlans"",
                ""msg"": ""Resource VLAN is not valid for the target device."",
                ""resource_module_name"": ""cisco.ios.vlans""
            }
        ],
        ""skipped"": false
    }
}

TASK [Fetch config for failing modules] ****************************************
An exception occurred during task execution. To see the full traceback, use -vvv. The error was: AttributeError: 'PluginLoader' object has no attribute 'find_plugin_with_name'
fatal: [ciscoao_latest_iosxe]: FAILED! => {""msg"": ""Unexpected failure during module execution: 'PluginLoader' object has no attribute 'find_plugin_with_name'"", ""stdout"": """"}
...ignoring

TASK [Debug network_resource_info] *********************************************
ok: [ciscoao_latest_iosxe] => {
    ""failing_module_info"": {
        ""exception"": ""Traceback (most recent call last):\n  File \""/home/anthonygittins/venv_ansible/ansible/collections/ansible_collections/ansible/netcommon/plugins/action/network.py\"", line 280, in _find_load_module\n    module = importlib.import_module(context.plugin_resolved_name)\n  File \""/usr/lib64/python3.9/importlib/__init__.py\"", line 118, in import_module\n    if name.startswith('.'):\nAttributeError: 'NoneType' object has no attribute 'startswith'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \""/usr/lib/python3.9/site-packages/ansible/executor/task_executor.py\"", line 119, in run\n    item_results = self._run_loop(items)\n  File \""/usr/lib/python3.9/site-packages/ansible/executor/task_executor.py\"", line 335, in _run_loop\n    res = self._execute(variables=task_vars)\n  File \""/usr/lib/python3.9/site-packages/ansible/executor/task_executor.py\"", line 629, in _execute\n    result = self._handler.run(task_vars=vars_copy)\n  File \""/home/anthonygittins/venv_ansible/ansible/collections/ansible_collections/ansible/netcommon/plugins/action/network_resource.py\"", line 76, in run\n    result = self._run_resource_module()\n  File \""/home/anthonygittins/venv_ansible/ansible/collections/ansible_collections/ansible/netcommon/plugins/action/network_resource.py\"", line 122, in _run_resource_module\n    result = action.run(task_vars=self._task_vars)\n  File \""/home/anthonygittins/venv_ansible/ansible/collections/ansible_collections/cisco/ios/plugins/action/ios.py\"", line 50, in run\n    result = super(ActionModule, self).run(task_vars=task_vars)\n  File \""/home/anthonygittins/venv_ansible/ansible/collections/ansible_collections/ansible/netcommon/plugins/action/network.py\"", line 42, in run\n    filename, module = self._find_load_module()\n  File \""/home/anthonygittins/venv_ansible/ansible/collections/ansible_collections/ansible/netcommon/plugins/action/network.py\"", line 283, in _find_load_module\n    fullname, filename = mloadr.find_plugin_with_name(\nAttributeError: 'PluginLoader' object has no attribute 'find_plugin_with_name'\n"",
        ""failed"": true,
        ""msg"": ""Unexpected failure during module execution: 'PluginLoader' object has no attribute 'find_plugin_with_name'"",
        ""stdout"": """"
    }
}

PLAY RECAP *********************************************************************
ciscoao_latest_iosxe       : ok=6    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=2
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-02-15T12:14:01Z,3,Create a YAML Ansible playbook to exhibit the following issue: network_resource module failing against specific resource modules,"```
---
- name: Network Resource Module Failing Playbook
  hosts: localhost
  tasks:
    - name: Create a network resource using an incorrect module
      network_resource:
        module: cisco_ios # incorrect module
        command_string: ""interface GigabitEthernet 1/0/1""
        provider:
          host: ""{{ inventory_hostname }}""
          username: ""{{ ansible_user }}""
          password: ""{{ ansible_password }}""
    failed_when: ""'not recognized command' not in ansible_failed_result.stdout_lines[0]""

    - name: Create a network resource using a correct module
      ios_config:
        lines:
          - ""interface GigabitEthernet 1/0/1""
        provider:
          host: ""{{ inventory_hostname }}""
          username: ""{{ ansible_user }}""
          password: ""{{ ansible_password }}""
```
",0,"
---
- name: Network Resource Module Failing Playbook
  hosts: localhost
  tasks:
    - name: Create a network resource using an incorrect module
      network_resource:
        module: cisco_ios # incorrect module
        command_string: ""interface GigabitEthernet 1/0/1""
        provider:
          host: ""{{ inventory_hostname }}""
          username: ""{{ ansible_user }}""
          password: ""{{ ansible_password }}""
    failed_when: ""'not recognized command' not in ansible_failed_result.stdout_lines[0]""

    - name: Create a network resource using a correct module
      ios_config:
        lines:
          - ""interface GigabitEthernet 1/0/1""
        provider:
          host: ""{{ inventory_hostname }}""
          username: ""{{ ansible_user }}""
          password: ""{{ ansible_password }}""
"
34,80007,unable to post ndjson file using ansible playbook,"### Summary

Hi i've written a playbook to import kibana dashboard. I've a ndjson file(exported standard dashboard). 

This is the command That I've added in the shell script which is executed by ansible script module.
curl -X POST ""REVERSE_PROXY_IP/kibana/api/saved_objects/_import?createNewCopies=true"" -H ""kbn-xsrf: true"" --form file=@./export.ndjson -u name:pwd

From ansible playbook this command gives the following error
The full traceback is:
NoneType: None
fatal: [10.0.2.4]: FAILED! => {
    ""changed"": true,
    ""msg"": ""non-zero return code"",
    ""rc"": 26,
    ""stderr"": ""OpenSSH_8.2p1 Ubuntu-4ubuntu0.5, OpenSSL 1.1.1f  31 Mar 2020\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 19: include /etc/ssh/ssh_config.d/*.conf matched no files\r\ndebug1: /etc/ssh/ssh_config line 21: Applying options for *\r\ndebug2: resolve_canonicalize: hostname 10.0.2.4 is address\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 3154\r\ndebug3: mux_client_request_session: session request sent\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 26\r\nShared connection to 10.0.2.4 closed.\r\n"",
    ""stderr_lines"": [
        ""OpenSSH_8.2p1 Ubuntu-4ubuntu0.5, OpenSSL 1.1.1f  31 Mar 2020"",
        ""debug1: Reading configuration data /etc/ssh/ssh_config"",
        ""debug1: /etc/ssh/ssh_config line 19: include /etc/ssh/ssh_config.d/*.conf matched no files"",
        ""debug1: /etc/ssh/ssh_config line 21: Applying options for *"",
        ""debug2: resolve_canonicalize: hostname 10.0.2.4 is address"",
        ""debug1: auto-mux: Trying existing master"",
        ""debug2: fd 3 setting O_NONBLOCK"",
        ""debug2: mux_client_hello_exchange: master version 4"",
        ""debug3: mux_client_forwards: request forwardings: 0 local, 0 remote"",
        ""debug3: mux_client_request_session: entering"",
        ""debug3: mux_client_request_alive: entering"",
        ""debug3: mux_client_request_alive: done pid = 3154"",
        ""debug3: mux_client_request_session: session request sent"",
        ""debug3: mux_client_read_packet: read header failed: Broken pipe"",
        ""debug2: Received exit status from master 26"",
        ""Shared connection to 10.0.2.4 closed.""
    ],
    ""stdout"": ""curl: (26) Failed to open/read local data from file/application\r\n"",
    ""stdout_lines"": [
        ""curl: (26) Failed to open/read local data from file/application""
    ]
}


However When i run this command directly from ansible machine it works fine.
Note ELK machine has a private ip only and is behind apache reverse proxy.
i access my kibana dashboard using apacheip/kibana

### Issue Type

Bug Report

### Component Name

curl

### Ansible Version

```console
$ ansible --version

ansible [core 2.12.10]
  config file = /etc/ansible/ansible.cfg
  configured module search path = ['/home/linuxuser/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /usr/lib/python3/dist-packages/ansible
  ansible collection location = /home/linuxuser/.ansible/collections:/usr/share/ansible/collections
  executable location = /usr/bin/ansible
  python version = 3.8.10 (default, Nov 14 2022, 12:59:47) [GCC 9.4.0]
  jinja version = 2.10.1
  libyaml = True
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
BECOME:
======

CACHE:
=====

CALLBACK:
========

CLICONF:
=======

CONNECTION:
==========

HTTPAPI:
=======

INVENTORY:
=========

LOOKUP:
======

NETCONF:
=======

SHELL:
=====

VARS:
====
```


### OS / Environment

cat /etc/os-release
NAME=""Ubuntu""
VERSION=""20.04.5 LTS (Focal Fossa)""
ID=ubuntu
ID_LIKE=debian
PRETTY_NAME=""Ubuntu 20.04.5 LTS""
VERSION_ID=""20.04""
HOME_URL=""https://www.ubuntu.com/""
SUPPORT_URL=""https://help.ubuntu.com/""
BUG_REPORT_URL=""https://bugs.launchpad.net/ubuntu/""
PRIVACY_POLICY_URL=""https://www.ubuntu.com/legal/terms-and-policies/privacy-policy""
VERSION_CODENAME=focal
UBUNTU_CODENAME=focal


### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->
```yaml (paste below)
---
- name: create index
  script: ../files/create_index.sh {{ index_name }} {{ elk_user }} {{ elk_password }} {{ elk_ip }} {{ apache_ip }}


create_index.sh
curl -X POST ""$5/kibana/api/saved_objects/_import?createNewCopies=true"" -H ""kbn-xsrf: true"" --form file=@./dashboard.ndjson -u $2:$3

```


### Expected Results

Curl command to post ndjson to kibana. I tried same with url module of anible too. but still getting same error. unable to read or open file/application

### Actual Results

```console
The full traceback is:
NoneType: None
fatal: [10.0.2.4]: FAILED! => {
    ""changed"": true,
    ""msg"": ""non-zero return code"",
    ""rc"": 26,
    ""stderr"": ""OpenSSH_8.2p1 Ubuntu-4ubuntu0.5, OpenSSL 1.1.1f  31 Mar 2020\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 19: include /etc/ssh/ssh_config.d/*.conf matched no files\r\ndebug1: /etc/ssh/ssh_config line 21: Applying options for *\r\ndebug2: resolve_canonicalize: hostname 10.0.2.4 is address\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 3154\r\ndebug3: mux_client_request_session: session request sent\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 26\r\nShared connection to 10.0.2.4 closed.\r\n"",
    ""stderr_lines"": [
        ""OpenSSH_8.2p1 Ubuntu-4ubuntu0.5, OpenSSL 1.1.1f  31 Mar 2020"",
        ""debug1: Reading configuration data /etc/ssh/ssh_config"",
        ""debug1: /etc/ssh/ssh_config line 19: include /etc/ssh/ssh_config.d/*.conf matched no files"",
        ""debug1: /etc/ssh/ssh_config line 21: Applying options for *"",
        ""debug2: resolve_canonicalize: hostname 10.0.2.4 is address"",
        ""debug1: auto-mux: Trying existing master"",
        ""debug2: fd 3 setting O_NONBLOCK"",
        ""debug2: mux_client_hello_exchange: master version 4"",
        ""debug3: mux_client_forwards: request forwardings: 0 local, 0 remote"",
        ""debug3: mux_client_request_session: entering"",
        ""debug3: mux_client_request_alive: entering"",
        ""debug3: mux_client_request_alive: done pid = 3154"",
        ""debug3: mux_client_request_session: session request sent"",
        ""debug3: mux_client_read_packet: read header failed: Broken pipe"",
        ""debug2: Received exit status from master 26"",
        ""Shared connection to 10.0.2.4 closed.""
    ],
    ""stdout"": ""curl: (26) Failed to open/read local data from file/application\r\n"",
    ""stdout_lines"": [
        ""curl: (26) Failed to open/read local data from file/application""
    ]
}
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-02-15T10:56:03Z,2,Create a YAML Ansible playbook to exhibit the following issue: unable to post ndjson file using ansible playbook,"```
---

- name: Unable to post ndjson file using ansible playbook
  hosts: localhost
  gather_facts: false
  
  vars:
    es_url: http://localhost:9200
    
  tasks:
  - name: Load ndjson file
    slurp:
      src: ""{{ playbook_dir }}/data/file.ndjson""
    register: file_content

  - name: Post file to ElasticSearch
    uri:
      url: ""{{ es_url }}/index/_bulk""
      method: POST
      body: ""{{ file_content.content | b64decode }}""
      return_content: true
    register: result

  - name: Debug result
    debug:
      var: result
  
...
```",1,"
---

- name: Unable to post ndjson file using ansible playbook
  hosts: localhost
  gather_facts: false
  
  vars:
    es_url: http://localhost:9200
    
  tasks:
  - name: Load ndjson file
    slurp:
      src: ""{{ playbook_dir }}/data/file.ndjson""
    register: file_content

  - name: Post file to ElasticSearch
    uri:
      url: ""{{ es_url }}/index/_bulk""
      method: POST
      body: ""{{ file_content.content | b64decode }}""
      return_content: true
    register: result

  - name: Debug result
    debug:
      var: result
  
...
"
35,80004,apt_repository adding GPG keys to /etc/apt/trusted.gpg,"### Summary

Hi all

Ubuntu's `add-apt-repository` command has been fixed and now adds GPG keys separately to the `/etc/apt/trusted.gpg.d` directory. However Ansible's `apt_repository` module still adds keys to /etc/apt/trusted.gpg file, which results in a deprecation warning. Would it be possible to update the behavior of the module to match the native command?

Cheers

### Issue Type

Bug Report

### Component Name

apt_repository

### Ansible Version

```console
2.14.2
```


### Configuration

```console
Not related to config
```


### OS / Environment

Ubuntu 22.04

### Steps to Reproduce

Install any PPA using apt_repository (for example ppa:ondrej/php)

### Expected Results

 The key should be saved as a separate file to the /etc/apt/trusted.gpg.d/ directory

### Actual Results

```console
The gpg key is added to /etc/apt/trusted.gpg
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-02-15T07:44:34Z,2,Create a YAML Ansible playbook to exhibit the following issue: apt_repository adding GPG keys to /etc/apt/trusted.gpg,"```
---
- name: Add apt repository with GPG key issue
  hosts: all
  tasks:
    - name: Add apt repository with GPG key
      apt_repository:
        repo: 'deb http://example.com/debian squeeze main'
        state: present
        filename: 'test-repo'
        keyserver_options: http-proxy=http://example.com:3128
        key_id: A0D655E3F182D7C9
      register: result
      
    - debug: var=result

...
```",1,"
---
- name: Add apt repository with GPG key issue
  hosts: all
  tasks:
    - name: Add apt repository with GPG key
      apt_repository:
        repo: 'deb http://example.com/debian squeeze main'
        state: present
        filename: 'test-repo'
        keyserver_options: http-proxy=http://example.com:3128
        key_id: A0D655E3F182D7C9
      register: result
      
    - debug: var=result

...
"
36,79992,reboot times out even while SSH successfully reconnected after boot,"### Summary

I opened #77353 in the past since rebooting servers often timed out even though the server finished reboot long time before timeout. Initially my suspicion was that it was caused by the host key changing during boot but even after we moved to certificates the issue still persists. The problem seems to happen 100% of times when `ansible-playbook` is logging in with user `root` and ""sometimes"" does not time out when run with `become` - though this may be due to chance and limited testing.  

It can be seen from the managed server logs that Ansible does login to the server after reboot and then disconnects after the 3 minute timeout.  
In `ansible-playbook -vvv` it can be seen that it does not understand that the SSH connection is successful and the error `Failed to connect to the host via ssh: Shared connection to 2001:db8::1 closed.` keeps repeating even though the SSH connection *is* actually logged in.  

To work around this problem a `wait_for_connection` task was added immediately following the `reboot` task and this second task succeeds in reconnecting 100% of runs.

In system log it can be seen that the user *is* actually logged in but it just disconnects after 3 minutes (the `reboot` timeout):
```
...rebooted...
Feb 14 15:44:07 host01 sshd[877]: Accepted publickey for root from 2001:db8::2 port 44114 ssh2: ED25519 SHA256:...
Feb 14 15:44:07 host01 systemd[881]: pam_unix(systemd-user:session): session opened for user root(uid=0) by (uid=0)
Feb 14 15:44:07 host01 sshd[877]: pam_unix(sshd:session): session opened for user root(uid=0) by (uid=0)
Feb 14 15:47:07 host01 sshd[891]: Received disconnect from 2001:db8::2 port 44114:11: disconnected by user
Feb 14 15:47:07 host01 sshd[891]: Disconnected from user root 2001:db8::2 port 44114
```

Rebooting starts, everything looks normal compared to a task that does not time out:
```
Using module file /home/ansible/lib64/python3.9/site-packages/ansible/modules/setup.py
Pipelining is enabled.
<2001:db8::1> ESTABLISH SSH CONNECTION FOR USER: root
<2001:db8::1> SSH: EXEC ssh -o ControlMaster=auto -o ControlPersist=300s -o ServerAliveInterval=10 -o 'IdentityFile=""/opt/gitlab-runner/builds/qaYsin1G/0/ansible/.test.key""' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=""root""' -o ConnectTimeout=50 -o 'ControlPath=""/tmp/.ansible-ssh.gitlab-runner/4e8c3cf076""' 2001:db8::1 '/bin/sh -c '""'""'/usr/bin/python3 && sleep 0'""'""''
<2001:db8::1> (0, b'\n{""ansible_facts"": {...}, ""invocation"": {""module_args"": {""gather_subset"": [""min""], ""gather_timeout"": 10, ""filter"": [], ""fact_path"": ""/etc/ansible/facts.d""}}}\n', b'')
<2001:db8::1> ESTABLISH SSH CONNECTION FOR USER: root
<2001:db8::1> SSH: EXEC ssh -o ControlMaster=auto -o ControlPersist=300s -o ServerAliveInterval=10 -o 'IdentityFile=""/opt/gitlab-runner/builds/qaYsin1G/0/ansible/.test.key""' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=""root""' -o ConnectTimeout=50 -o 'ControlPath=""/tmp/.ansible-ssh.gitlab-runner/4e8c3cf076""' -tt 2001:db8::1 '/bin/sh -c '""'""'cat /proc/sys/kernel/random/boot_id && sleep 0'""'""''
<2001:db8::1> (0, b'5b69fb55-ccb6-411a-8e32-1ad0f2b8e087\n', b'PTY allocation request failed\r\nShared connection to 2001:db8::1 closed.\r\n')
Using module file /home/ansible/lib64/python3.9/site-packages/ansible/modules/find.py
Pipelining is enabled.
<2001:db8::1> ESTABLISH SSH CONNECTION FOR USER: root
<2001:db8::1> SSH: EXEC ssh -o ControlMaster=auto -o ControlPersist=300s -o ServerAliveInterval=10 -o 'IdentityFile=""/opt/gitlab-runner/builds/qaYsin1G/0/ansible/.test.key""' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=""root""' -o ConnectTimeout=50 -o 'ControlPath=""/tmp/.ansible-ssh.gitlab-runner/4e8c3cf076""' 2001:db8::1 '/bin/sh -c '""'""'/usr/bin/python3 && sleep 0'""'""''
<2001:db8::1> (0, b'\n{""files"": [{""path"": ""/sbin/shutdown"", ""mode"": ""0777"", ""isdir"": false, ""ischr"": false, ""isblk"": false, ""isreg"": false, ""isfifo"": false, ""islnk"": true, ""issock"": false, ""uid"": 0, ""gid"": 0, ""size"": 16, ""inode"": 411327, ""dev"": 64768, ""nlink"": 1, ""atime"": 1676364229.3911805, ""mtime"": 1674504414.0, ""ctime"": 1676363717.7217865, ""gr_name"": ""root"", ""pw_name"": ""root"", ""wusr"": true, ""rusr"": true, ""xusr"": true, ""wgrp"": true, ""rgrp"": true, ""xgrp"": true, ""woth"": true, ""roth"": true, ""xoth"": true, ""isuid"": false, ""isgid"": false}, {""path"": ""/usr/sbin/shutdown"", ""mode"": ""0777"", ""isdir"": false, ""ischr"": false, ""isblk"": false, ""isreg"": false, ""isfifo"": false, ""islnk"": true, ""issock"": false, ""uid"": 0, ""gid"": 0, ""size"": 16, ""inode"": 411327, ""dev"": 64768, ""nlink"": 1, ""atime"": 1676364229.3911805, ""mtime"": 1674504414.0, ""ctime"": 1676363717.7217865, ""gr_name"": ""root"", ""pw_name"": ""root"", ""wusr"": true, ""rusr"": true, ""xusr"": true, ""wgrp"": true, ""rgrp"": true, ""xgrp"": true, ""woth"": true, ""roth"": true, ""xoth"": true, ""isuid"": false, ""isgid"": false}], ""changed"": false, ""msg"": ""All paths examined"", ""matched"": 2, ""examined"": 2772, ""skipped_paths"": {}, ""invocation"": {""module_args"": {""paths"": [""/sbin"", ""/bin"", ""/usr/sbin"", ""/usr/bin"", ""/usr/local/sbin""], ""patterns"": [""shutdown""], ""file_type"": ""any"", ""read_whole_file"": false, ""age_stamp"": ""mtime"", ""recurse"": false, ""hidden"": false, ""follow"": false, ""get_checksum"": false, ""use_regex"": false, ""excludes"": null, ""contains"": null, ""age"": null, ""size"": null, ""depth"": null}}}\n', b'')
ansible.builtin.reboot: rebooting server...
<2001:db8::1> ESTABLISH SSH CONNECTION FOR USER: root
<2001:db8::1> SSH: EXEC ssh -o ControlMaster=auto -o ControlPersist=300s -o ServerAliveInterval=10 -o 'IdentityFile=""/opt/gitlab-runner/builds/qaYsin1G/0/ansible/.test.key""' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=""root""' -o ConnectTimeout=50 -o 'ControlPath=""/tmp/.ansible-ssh.gitlab-runner/4e8c3cf076""' -tt 2001:db8::1 '/bin/sh -c '""'""'/sbin/shutdown -r 0 ""Server restart in 30 seconds."" && sleep 0'""'""''
<2001:db8::1> (0, b'', b""PTY allocation request failed\r\nReboot scheduled for Tue 2023-02-14 15:43:49 +09, use 'shutdown -c' to cancel.\nShared connection to 2001:db8::1 closed.\r\n"")
```

The SSH connection after reboot seems to never succeed *even though the user is actually logged in to the system*:
```
ansible.builtin.reboot: waiting an additional 15 seconds
ansible.builtin.reboot: validating reboot
ansible.builtin.reboot: attempting to get system boot time
<2001:db8::1> ESTABLISH SSH CONNECTION FOR USER: root
<2001:db8::1> SSH: EXEC ssh -o ControlMaster=auto -o ControlPersist=300s -o ServerAliveInterval=10 -o 'IdentityFile=""/opt/gitlab-runner/builds/qaYsin1G/0/ansible/.test.key""' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=""root""' -o ConnectTimeout=50 -o 'ControlPath=""/tmp/.ansible-ssh.gitlab-runner/4e8c3cf076""' -tt 2001:db8::1 '/bin/sh -c '""'""'cat /proc/sys/kernel/random/boot_id && sleep 0'""'""''
<2001:db8::1> (141, b'', b'Shared connection to 2001:db8::1 closed.\r\n')
<2001:db8::1> Failed to connect to the host via ssh: Shared connection to 2001:db8::1 closed.
ansible.builtin.reboot: attempting to get system boot time
<2001:db8::1> ESTABLISH SSH CONNECTION FOR USER: root
<2001:db8::1> SSH: EXEC ssh -o ControlMaster=auto -o ControlPersist=300s -o ServerAliveInterval=10 -o 'IdentityFile=""/opt/gitlab-runner/builds/qaYsin1G/0/ansible/.test.key""' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=""root""' -o ConnectTimeout=50 -o 'ControlPath=""/tmp/.ansible-ssh.gitlab-runner/4e8c3cf076""' -tt 2001:db8::1 '/bin/sh -c '""'""'cat /proc/sys/kernel/random/boot_id && sleep 0'""'""''
<2001:db8::1> (141, b'', b'Shared connection to 2001:db8::1 closed.\r\n')
<2001:db8::1> Failed to connect to the host via ssh: Shared connection to 2001:db8::1 closed.
ansible.builtin.reboot: attempting to get system boot time
<2001:db8::1> ESTABLISH SSH CONNECTION FOR USER: root
<2001:db8::1> SSH: EXEC ssh -o ControlMaster=auto -o ControlPersist=300s -o ServerAliveInterval=10 -o 'IdentityFile=""/opt/gitlab-runner/builds/qaYsin1G/0/ansible/.test.key""' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=""root""' -o ConnectTimeout=50 -o 'ControlPath=""/tmp/.ansible-ssh.gitlab-runner/4e8c3cf076""' -tt 2001:db8::1 '/bin/sh -c '""'""'cat /proc/sys/kernel/random/boot_id && sleep 0'""'""''
<2001:db8::1> (141, b'', b'Shared connection to 2001:db8::1 closed.\r\n')
<2001:db8::1> Failed to connect to the host via ssh: Shared connection to 2001:db8::1 closed.
ansible.builtin.reboot: attempting to get system boot time
<2001:db8::1> ESTABLISH SSH CONNECTION FOR USER: root
<2001:db8::1> SSH: EXEC ssh -o ControlMaster=auto -o ControlPersist=300s -o ServerAliveInterval=10 -o 'IdentityFile=""/opt/gitlab-runner/builds/qaYsin1G/0/ansible/.test.key""' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=""root""' -o ConnectTimeout=50 -o 'ControlPath=""/tmp/.ansible-ssh.gitlab-runner/4e8c3cf076""' -tt 2001:db8::1 '/bin/sh -c '""'""'cat /proc/sys/kernel/random/boot_id && sleep 0'""'""''
<2001:db8::1> (141, b'', b'Shared connection to 2001:db8::1 closed.\r\n')
<2001:db8::1> Failed to connect to the host via ssh: Shared connection to 2001:db8::1 closed.
ansible.builtin.reboot: attempting to get system boot time
<2001:db8::1> ESTABLISH SSH CONNECTION FOR USER: root
<2001:db8::1> SSH: EXEC ssh -o ControlMaster=auto -o ControlPersist=300s -o ServerAliveInterval=10 -o 'IdentityFile=""/opt/gitlab-runner/builds/qaYsin1G/0/ansible/.test.key""' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=""root""' -o ConnectTimeout=50 -o 'ControlPath=""/tmp/.ansible-ssh.gitlab-runner/4e8c3cf076""' -tt 2001:db8::1 '/bin/sh -c '""'""'cat /proc/sys/kernel/random/boot_id && sleep 0'""'""''
<2001:db8::1> (141, b'', b'Shared connection to 2001:db8::1 closed.\r\n')
<2001:db8::1> Failed to connect to the host via ssh: Shared connection to 2001:db8::1 closed.
ansible.builtin.reboot: attempting to get system boot time
<2001:db8::1> ESTABLISH SSH CONNECTION FOR USER: root
<2001:db8::1> SSH: EXEC ssh -o ControlMaster=auto -o ControlPersist=300s -o ServerAliveInterval=10 -o 'IdentityFile=""/opt/gitlab-runner/builds/qaYsin1G/0/ansible/.test.key""' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=""root""' -o ConnectTimeout=50 -o 'ControlPath=""/tmp/.ansible-ssh.gitlab-runner/4e8c3cf076""' -tt 2001:db8::1 '/bin/sh -c '""'""'cat /proc/sys/kernel/random/boot_id && sleep 0'""'""''
<2001:db8::1> (141, b'', b'Shared connection to 2001:db8::1 closed.\r\n')
<2001:db8::1> Failed to connect to the host via ssh: Shared connection to 2001:db8::1 closed.
ansible.builtin.reboot: attempting to get system boot time
<2001:db8::1> ESTABLISH SSH CONNECTION FOR USER: root
<2001:db8::1> SSH: EXEC ssh -o ControlMaster=auto -o ControlPersist=300s -o ServerAliveInterval=10 -o 'IdentityFile=""/opt/gitlab-runner/builds/qaYsin1G/0/ansible/.test.key""' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=""root""' -o ConnectTimeout=50 -o 'ControlPath=""/tmp/.ansible-ssh.gitlab-runner/4e8c3cf076""' -tt 2001:db8::1 '/bin/sh -c '""'""'cat /proc/sys/kernel/random/boot_id && sleep 0'""'""''
<2001:db8::1> (141, b'', b'Shared connection to 2001:db8::1 closed.\r\n')
<2001:db8::1> Failed to connect to the host via ssh: Shared connection to 2001:db8::1 closed.
ansible.builtin.reboot: attempting to get system boot time
<2001:db8::1> ESTABLISH SSH CONNECTION FOR USER: root
<2001:db8::1> SSH: EXEC ssh -o ControlMaster=auto -o ControlPersist=300s -o ServerAliveInterval=10 -o 'IdentityFile=""/opt/gitlab-runner/builds/qaYsin1G/0/ansible/.test.key""' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=""root""' -o ConnectTimeout=50 -o 'ControlPath=""/tmp/.ansible-ssh.gitlab-runner/4e8c3cf076""' -tt 2001:db8::1 '/bin/sh -c '""'""'cat /proc/sys/kernel/random/boot_id && sleep 0'""'""''
<2001:db8::1> (141, b'', b'Shared connection to 2001:db8::1 closed.\r\n')
<2001:db8::1> Failed to connect to the host via ssh: Shared connection to 2001:db8::1 closed.
ansible.builtin.reboot: attempting to get system boot time
<2001:db8::1> ESTABLISH SSH CONNECTION FOR USER: root
<2001:db8::1> SSH: EXEC ssh -o ControlMaster=auto -o ControlPersist=300s -o ServerAliveInterval=10 -o 'IdentityFile=""/opt/gitlab-runner/builds/qaYsin1G/0/ansible/.test.key""' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=""root""' -o ConnectTimeout=50 -o 'ControlPath=""/tmp/.ansible-ssh.gitlab-runner/4e8c3cf076""' -tt 2001:db8::1 '/bin/sh -c '""'""'cat /proc/sys/kernel/random/boot_id && sleep 0'""'""''
<2001:db8::1> (141, b'', b'Shared connection to 2001:db8::1 closed.\r\n')
<2001:db8::1> Failed to connect to the host via ssh: Shared connection to 2001:db8::1 closed.
ansible.builtin.reboot: attempting to get system boot time
<2001:db8::1> ESTABLISH SSH CONNECTION FOR USER: root
<2001:db8::1> SSH: EXEC ssh -o ControlMaster=auto -o ControlPersist=300s -o ServerAliveInterval=10 -o 'IdentityFile=""/opt/gitlab-runner/builds/qaYsin1G/0/ansible/.test.key""' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=""root""' -o ConnectTimeout=50 -o 'ControlPath=""/tmp/.ansible-ssh.gitlab-runner/4e8c3cf076""' -tt 2001:db8::1 '/bin/sh -c '""'""'cat /proc/sys/kernel/random/boot_id && sleep 0'""'""''
<2001:db8::1> (141, b'', b'Shared connection to 2001:db8::1 closed.\r\n')
<2001:db8::1> Failed to connect to the host via ssh: Shared connection to 2001:db8::1 closed.
ansible.builtin.reboot: attempting to get system boot time
<2001:db8::1> ESTABLISH SSH CONNECTION FOR USER: root
<2001:db8::1> SSH: EXEC ssh -o ControlMaster=auto -o ControlPersist=300s -o ServerAliveInterval=10 -o 'IdentityFile=""/opt/gitlab-runner/builds/qaYsin1G/0/ansible/.test.key""' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=""root""' -o ConnectTimeout=50 -o 'ControlPath=""/tmp/.ansible-ssh.gitlab-runner/4e8c3cf076""' -tt 2001:db8::1 '/bin/sh -c '""'""'cat /proc/sys/kernel/random/boot_id && sleep 0'""'""''
<2001:db8::1> (141, b'', b'Shared connection to 2001:db8::1 closed.\r\n')
<2001:db8::1> Failed to connect to the host via ssh: Shared connection to 2001:db8::1 closed.
ansible.builtin.reboot: attempting to get system boot time
<2001:db8::1> ESTABLISH SSH CONNECTION FOR USER: root
<2001:db8::1> SSH: EXEC ssh -o ControlMaster=auto -o ControlPersist=300s -o ServerAliveInterval=10 -o 'IdentityFile=""/opt/gitlab-runner/builds/qaYsin1G/0/ansible/.test.key""' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=""root""' -o ConnectTimeout=50 -o 'ControlPath=""/tmp/.ansible-ssh.gitlab-runner/4e8c3cf076""' -tt 2001:db8::1 '/bin/sh -c '""'""'cat /proc/sys/kernel/random/boot_id && sleep 0'""'""''
<2001:db8::1> (141, b'', b'Shared connection to 2001:db8::1 closed.\r\n')
<2001:db8::1> Failed to connect to the host via ssh: Shared connection to 2001:db8::1 closed.
ansible.builtin.reboot: attempting to get system boot time
<2001:db8::1> ESTABLISH SSH CONNECTION FOR USER: root
<2001:db8::1> SSH: EXEC ssh -o ControlMaster=auto -o ControlPersist=300s -o ServerAliveInterval=10 -o 'IdentityFile=""/opt/gitlab-runner/builds/qaYsin1G/0/ansible/.test.key""' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=""root""' -o ConnectTimeout=50 -o 'ControlPath=""/tmp/.ansible-ssh.gitlab-runner/4e8c3cf076""' -tt 2001:db8::1 '/bin/sh -c '""'""'cat /proc/sys/kernel/random/boot_id && sleep 0'""'""''
<2001:db8::1> (141, b'', b'Shared connection to 2001:db8::1 closed.\r\n')
<2001:db8::1> Failed to connect to the host via ssh: Shared connection to 2001:db8::1 closed.
ansible.builtin.reboot: attempting to get system boot time
<2001:db8::1> ESTABLISH SSH CONNECTION FOR USER: root
<2001:db8::1> SSH: EXEC ssh -o ControlMaster=auto -o ControlPersist=300s -o ServerAliveInterval=10 -o 'IdentityFile=""/opt/gitlab-runner/builds/qaYsin1G/0/ansible/.test.key""' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=""root""' -o ConnectTimeout=50 -o 'ControlPath=""/tmp/.ansible-ssh.gitlab-runner/4e8c3cf076""' -tt 2001:db8::1 '/bin/sh -c '""'""'cat /proc/sys/kernel/random/boot_id && sleep 0'""'""''
<2001:db8::1> (141, b'', b'Shared connection to 2001:db8::1 closed.\r\n')
<2001:db8::1> Failed to connect to the host via ssh: Shared connection to 2001:db8::1 closed.
ansible.builtin.reboot: attempting to get system boot time
<2001:db8::1> ESTABLISH SSH CONNECTION FOR USER: root
<2001:db8::1> SSH: EXEC ssh -o ControlMaster=auto -o ControlPersist=300s -o ServerAliveInterval=10 -o 'IdentityFile=""/opt/gitlab-runner/builds/qaYsin1G/0/ansible/.test.key""' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=""root""' -o ConnectTimeout=50 -o 'ControlPath=""/tmp/.ansible-ssh.gitlab-runner/4e8c3cf076""' -tt 2001:db8::1 '/bin/sh -c '""'""'cat /proc/sys/kernel/random/boot_id && sleep 0'""'""''
<2001:db8::1> (141, b'', b'Shared connection to 2001:db8::1 closed.\r\n')
<2001:db8::1> Failed to connect to the host via ssh: Shared connection to 2001:db8::1 closed.
ansible.builtin.reboot: attempting to get system boot time
<2001:db8::1> ESTABLISH SSH CONNECTION FOR USER: root
<2001:db8::1> SSH: EXEC ssh -o ControlMaster=auto -o ControlPersist=300s -o ServerAliveInterval=10 -o 'IdentityFile=""/opt/gitlab-runner/builds/qaYsin1G/0/ansible/.test.key""' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=""root""' -o ConnectTimeout=50 -o 'ControlPath=""/tmp/.ansible-ssh.gitlab-runner/4e8c3cf076""' -tt 2001:db8::1 '/bin/sh -c '""'""'cat /proc/sys/kernel/random/boot_id && sleep 0'""'""''
<2001:db8::1> (141, b'', b'Shared connection to 2001:db8::1 closed.\r\n')
<2001:db8::1> Failed to connect to the host via ssh: Shared connection to 2001:db8::1 closed.
ansible.builtin.reboot: attempting to get system boot time
<2001:db8::1> ESTABLISH SSH CONNECTION FOR USER: root
<2001:db8::1> SSH: EXEC ssh -o ControlMaster=auto -o ControlPersist=300s -o ServerAliveInterval=10 -o 'IdentityFile=""/opt/gitlab-runner/builds/qaYsin1G/0/ansible/.test.key""' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=""root""' -o ConnectTimeout=50 -o 'ControlPath=""/tmp/.ansible-ssh.gitlab-runner/4e8c3cf076""' -tt 2001:db8::1 '/bin/sh -c '""'""'cat /proc/sys/kernel/random/boot_id && sleep 0'""'""''
<2001:db8::1> (141, b'', b'Shared connection to 2001:db8::1 closed.\r\n')
<2001:db8::1> Failed to connect to the host via ssh: Shared connection to 2001:db8::1 closed.
TASK [server : restart machine] **************************
task path: /opt/gitlab-runner/builds/qaYsin1G/0/ansible/roles/server/tasks/main.yml:726
fatal: [host01.domain.com]: FAILED! => changed=false 
  elapsed: 198
  msg: Timed out waiting for last boot time check (timeout=180)
  rebooted: true
...ignoring
```

However, immediately following `wait_for_connection` task immediately succeeds:
```
wait_for_connection: attempting ping module test
sending connection check: [b'ssh', b'-o', b'ControlMaster=auto', b'-o', b'ControlPersist=300s', b'-o', b'ServerAliveInterval=10', b'-o', b'IdentityFile=""/opt/gitlab-runner/builds/qaYsin1G/0/ansible/.test.key""', b'-o', b'KbdInteractiveAuthentication=no', b'-o', b'PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey', b'-o', b'PasswordAuthentication=no', b'-o', b'User=""root""', b'-o', b'ConnectTimeout=50', b'-o', b'ControlPath=""/tmp/.ansible-ssh.gitlab-runner/4e8c3cf076""', b'-O', b'check', b'2001:db8::1']
sending connection stop: [b'ssh', b'-o', b'ControlMaster=auto', b'-o', b'ControlPersist=300s', b'-o', b'ServerAliveInterval=10', b'-o', b'IdentityFile=""/opt/gitlab-runner/builds/qaYsin1G/0/ansible/.test.key""', b'-o', b'KbdInteractiveAuthentication=no', b'-o', b'PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey', b'-o', b'PasswordAuthentication=no', b'-o', b'User=""root""', b'-o', b'ConnectTimeout=50', b'-o', b'ControlPath=""/tmp/.ansible-ssh.gitlab-runner/4e8c3cf076""', b'-O', b'stop', b'2001:db8::1']
Using module file /home/ansible/lib64/python3.9/site-packages/ansible/modules/ping.py
Pipelining is enabled.
<2001:db8::1> ESTABLISH SSH CONNECTION FOR USER: root
<2001:db8::1> SSH: EXEC ssh -o ControlMaster=auto -o ControlPersist=300s -o ServerAliveInterval=10 -o 'IdentityFile=""/opt/gitlab-runner/builds/qaYsin1G/0/ansible/.test.key""' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=""root""' -o ConnectTimeout=50 -o 'ControlPath=""/tmp/.ansible-ssh.gitlab-runner/4e8c3cf076""' 2001:db8::1 '/bin/sh -c '""'""'/usr/bin/python3 && sleep 0'""'""''
<2001:db8::1> (0, b'\n{""ping"": ""pong"", ""invocation"": {""module_args"": {""data"": ""pong""}}}\n', b'')
TASK [server : wait for server] *********************************
task path: /opt/gitlab-runner/builds/qaYsin1G/0/ansible/roles/server/tasks/main.yml:734
ok: [host01.domain.com] => changed=false 
  elapsed: 0
```

_Additionally_ during testing with the simple 2 task test case listed below a second variation was seen, maybe it is related to the main problem or it may be *a second bug*:
```
ansible.builtin.reboot: waiting an additional 15 seconds
ansible.builtin.reboot: validating reboot
ansible.builtin.reboot: attempting to get system boot time
<2001:db8::1> ESTABLISH SSH CONNECTION FOR USER: None
<2001:db8::1> SSH: EXEC ssh -o ControlMaster=auto -o ControlPersist=300s -o ServerAliveInterval=10 -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o ConnectTimeout=50 -o 'ControlPath=""/tmp/.ansible-ssh.user/4d...""' -tt 2001:db8::1 '/bin/sh -c '""'""'sudo -H -S -p ""[sudo via ansible, key=...] password:"" -u root /bin/sh -c '""'""'""'""'""'""'""'""'echo BECOME-SUCCESS-... ; cat /proc/sys/kernel/random/boot_id'""'""'""'""'""'""'""'""' && sleep 0'""'""''
<2001:db8::1> (255, b'', b'ssh: connect to host 2001:db8::1 port 22: Connection refused\r\n')
sending connection check: [b'ssh', b'-o', b'ControlMaster=auto', b'-o', b'ControlPersist=300s', b'-o', b'ServerAliveInterval=10', b'-o', b'KbdInteractiveAuthentication=no', b'-o', b'PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey', b'-o', b'PasswordAuthentication=no', b'-o', b'ConnectTimeout=50', b'-o', b'ControlPath=""/tmp/.ansible-ssh.user/4d...""', b'-O', b'check', b'2001:db8::1']
No connection to reset: Control socket connect(/tmp/.ansible-ssh.user/4d...): No such file or directory
```
Somehow the control socket is gone (the error above is true, it does not exist) - it disappears the same time the server reboots, I guess the SSH connection dies and the socket is correctly deleted due to that. _BUT:_ Why does Ansible not realize that it is gone and re-establish the connection, instead just loops the same failing command?  
The end result is the same: the `reboot` task times out and the `wait_for_connection` succeeds after it.

### Issue Type

Bug Report

### Component Name

reboot

### Ansible Version

```console
$ ansible --version
ansible [core 2.14.2]
  config file = /etc/ansible/ansible.cfg
  configured module search path = ['/home/ansible/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /home/ansible/lib64/python3.9/site-packages/ansible
  ansible collection location = /home/ansible/.ansible/collections:/usr/share/ansible/collections
  executable location = /home/ansible/bin/ansible
  python version = 3.9.14 (main, Nov  7 2022, 00:00:00) [GCC 11.3.1 20220421 (Red Hat 11.3.1-2)] (/home/ansible/bin/python3)
  jinja version = 3.1.2
  libyaml = True
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
CACHE_PLUGIN(/etc/ansible/ansible.cfg) = community.general.yaml
CACHE_PLUGIN_CONNECTION(/etc/ansible/ansible.cfg) = /tmp/.ansible-fact.$USER
CACHE_PLUGIN_TIMEOUT(/etc/ansible/ansible.cfg) = 5184000
CALLBACKS_ENABLED(/etc/ansible/ansible.cfg) = ['ansible.posix.timer']
CONFIG_FILE() = /etc/ansible/ansible.cfg
DEFAULT_FORKS(/etc/ansible/ansible.cfg) = 10
DEFAULT_LOCAL_TMP(/etc/ansible/ansible.cfg) = /tmp/.ansible.user/ansible-local-14767z15u0zq4
DEFAULT_LOG_PATH(/etc/ansible/ansible.cfg) = /var/log/ansible.log
DEFAULT_STDOUT_CALLBACK(/etc/ansible/ansible.cfg) = community.general.yaml
DEFAULT_STRATEGY(/etc/ansible/ansible.cfg) = ansible.builtin.free
DEFAULT_TIMEOUT(/etc/ansible/ansible.cfg) = 50
DEFAULT_VAULT_ID_MATCH(/etc/ansible/ansible.cfg) = True
INJECT_FACTS_AS_VARS(/etc/ansible/ansible.cfg) = False
INTERPRETER_PYTHON(/etc/ansible/ansible.cfg) = auto_silent
RETRY_FILES_SAVE_PATH(/etc/ansible/ansible.cfg) = /tmp/.ansible-retry.user

CACHE:
=====

jsonfile:
________
_timeout(/etc/ansible/ansible.cfg) = 5184000
_uri(/etc/ansible/ansible.cfg) = /tmp/.ansible-fact.user

CONNECTION:
==========

paramiko_ssh:
____________
ssh_args(/etc/ansible/ansible.cfg) = -o ControlMaster=auto -o ControlPersist=300s -o ServerAliveInterval=10

ssh:
___
control_path_dir(/etc/ansible/ansible.cfg) = /tmp/.ansible-ssh.$USER
pipelining(/etc/ansible/ansible.cfg) = True
ssh_args(/etc/ansible/ansible.cfg) = -o ControlMaster=auto -o ControlPersist=300s -o ServerAliveInterval=10
timeout(/etc/ansible/ansible.cfg) = 50

SHELL:
=====

sh:
__
remote_tmp(/etc/ansible/ansible.cfg) = /tmp/ansible.$USER
```


### OS / Environment

EL9

### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->
```yaml (paste below)
# test 180 second timeout on a VM that boots in <10 seconds, physical servers need up to 15 minutes or more
- name: restart machine
  ansible.builtin.reboot:
    msg: Server restart in 30 seconds.
    pre_reboot_delay: 30
    post_reboot_delay: 15
    reboot_timeout: 180
  ignore_errors: true

# added because the above task often times out and wait_for_connection always immediately succeeds 100%
- name: wait for server
  ansible.builtin.wait_for_connection:
    connect_timeout: 15
    sleep: 15
    timeout: 180
  ignore_errors: true
```

### Expected Results

The reboot task should understand that the SSH connection *really is* connected, as seen from system logs and the reboot task should not time out especially when the `wait_for_connection` task immediately after it always, 100%, succeeds immediately.

In the case of the missing control socket - it is useless to loop trying SSH if the control socket is gone, instead the connection needs to be re-established so that the control socket is created.

### Actual Results

The task times out even though SSH is reconnected until the 3 minutes timeout after reboot.
The error ""Failed to connect to the host via ssh: Shared connection to 2001:db8::1 closed."" keeps repeating as a result to the command to get boot ID.

It is as if somehow the SSH connection is not cleaned up/tracked correctly inside Ansible so it thinks that there is an error running the command after a reboot - while actually the user is logged in to the server.

The wait_for_connection task following the reboot task succeeds after doing ""sending connection check"" and ""sending connection stop"" - maybe somehow these ""connection cleanup"" (?) functions should be added to the reboot module?

Additionally during testing a second problem case was seen: the control socket was lost for some reason and the reboot timed out because every SSH attempt errored due to missing control socket.


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-02-14T10:38:44Z,5,Create a YAML Ansible playbook to exhibit the following issue: reboot times out even while SSH successfully reconnected after boot,"```yaml
- name: Reboot test
  hosts: your_server_name
  tasks:
    - name: Reboot server
      shell: sleep 2 && reboot
      async: 1
      poll: 0
      ignore_errors: true
      register: reboot_result

    - name: Wait for server to go down
      wait_for_connection:
        connect_timeout: 5
        sleep: 1
        timeout: 300

    - name: Wait for server to come back up
      wait_for_connection:
        sleep: 10
        timeout: 300

    - name: Ensure SSH connection is reestablished
      wait_for:
        port: 22
        host: ""{{ inventory_hostname }}""
        timeout: 30

    - name: Gather system facts
      setup:

    - name: Display uptime information
      debug:
        var: ansible_uptime_seconds
```",0,"yaml
- name: Reboot test
  hosts: your_server_name
  tasks:
    - name: Reboot server
      shell: sleep 2 && reboot
      async: 1
      poll: 0
      ignore_errors: true
      register: reboot_result

    - name: Wait for server to go down
      wait_for_connection:
        connect_timeout: 5
        sleep: 1
        timeout: 300

    - name: Wait for server to come back up
      wait_for_connection:
        sleep: 10
        timeout: 300

    - name: Ensure SSH connection is reestablished
      wait_for:
        port: 22
        host: ""{{ inventory_hostname }}""
        timeout: 30

    - name: Gather system facts
      setup:

    - name: Display uptime information
      debug:
        var: ansible_uptime_seconds
"
37,79990,'ansible.builtin.meta: refresh_inventory' no longer removes hosts added by host_add in ansible-core 2.14.x,"### Summary

We used `ansible.builtin.meta: refresh_inventory` extensivly to remove hosts added by host_add.  I see in the changelog that was intentional.  What's the best way to remove hosts from within a playbook now?

### Issue Type

Bug Report

### Component Name

ansible.builtin.meta

### Ansible Version

```console
$ ansible --version
ansible [core 2.14.2]
  config file = None
  configured module search path = ['/home/chylarides/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /usr/local/lib/python3.10/dist-packages/ansible
  ansible collection location = /home/chylarides/.ansible/collections:/usr/share/ansible/collections
  executable location = /usr/local/bin/ansible
  python version = 3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0] (/usr/bin/python3)
  jinja version = 3.0.3
  libyaml = True
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
```


### OS / Environment

Ubuntu 22.04

### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->
```yaml (paste below)
    - name: Refresh Inventory so upgrade_group gets reset for next include_playbook
      ansible.builtin.meta: refresh_inventory
```

Then hosts added via host_add have historically been removed, but now they don't

### Expected Results

Hosts/groups added by host_add get removed

### Actual Results

```console
The hosts remain and continue in subsequent plays, causing chaos.
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-02-13T20:22:24Z,6,Create a YAML Ansible playbook to exhibit the following issue: 'ansible.builtin.meta: refresh_inventory' no longer removes hosts added by host_add in ansible-core 2.14.x,"```
---
- name: Test refresh_inventory issue
  hosts: localhost
  gather_facts: false

  tasks:
    - name: Add new hosts
      add_host:
        name: ""new_host.example.com""
        groups: ""new_group""

    - name: Refresh inventory
      meta: refresh_inventory

    - name: Assert new host not in inventory
      fail:
        msg: ""New host still exists in inventory!""
      when: ""'new_host.example.com' in ansible_play_hosts""
```

Note: This playbook will add a new host to the inventory using the `add_host` module and a new group called 'new_group'. The `meta: refresh_inventory` task is then run to refresh the inventory. The final task will fail if the new host is still present in the inventory after running the refresh task.",1,"
---
- name: Test refresh_inventory issue
  hosts: localhost
  gather_facts: false

  tasks:
    - name: Add new hosts
      add_host:
        name: ""new_host.example.com""
        groups: ""new_group""

    - name: Refresh inventory
      meta: refresh_inventory

    - name: Assert new host not in inventory
      fail:
        msg: ""New host still exists in inventory!""
      when: ""'new_host.example.com' in ansible_play_hosts""
"
38,79987,NVM,,2023-02-12T23:08:00Z,2,Create a YAML Ansible playbook to exhibit the following issue: NVM,"```
---
- name: Install nvm
  hosts: servers
  become: true
  
  tasks:
  - name: Install NVM
    shell: |
      curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.35.3/install.sh | bash
      source ~/.bashrc
      nvm install 10.0
    register: result
  - debug:
      var: result
```",1,"
---
- name: Install nvm
  hosts: servers
  become: true
  
  tasks:
  - name: Install NVM
    shell: |
      curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.35.3/install.sh | bash
      source ~/.bashrc
      nvm install 10.0
    register: result
  - debug:
      var: result
"
39,79970,`ansible.builtin.uri` does not return `json` attribute when `Content-Type: text/plain`,"### Summary

When I interact with a web service using `ansible.builtin.uri`, which returns plaintext JSON (`Content-Type: text/plain`), the module does not add any `json` attribute, although it's expected. In an older version, this was supported.

The AWS Instance Identity document for example returns plaintext JSON:

> The instance identity document is exposed (in plaintext JSON format) through the Instance Metadata Service. - https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-identity-documents.html

This behaviour seems to have been changed somewhen between our current old version and the latest one: https://github.com/ansible/ansible/compare/v2.11.12..v2.14.2

I haven't fully checked the diff, but the main reason for this behaviour seems to be the missing `text` here:

```python
# v2.11.12
- JSON_CANDIDATES = ('text', 'json', 'javascript')
# v2.14.2
+ JSON_CANDIDATES = {'json', 'javascript'}
```

### Issue Type

Bug Report

### Component Name

ansible.builtin.uri

### Ansible Version

```console
$ ansible --version
ansible [core 2.14.2]
  config file = /home/skraetzig/Git/infrastructure/ansible.cfg
  configured module search path = ['/home/skraetzig/Git/infrastructure/ansible/library']
  ansible python module location = /usr/local/lib/python3.9/dist-packages/ansible
  ansible collection location = /usr/share/ansible/third-party/collections
  executable location = /usr/local/bin/ansible
  python version = 3.9.2 (default, Feb 28 2021, 17:03:44) [GCC 10.2.1 20210110] (/usr/bin/python3)
  jinja version = 3.1.2
  libyaml = True
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
ANSIBLE_FORCE_COLOR(env: ANSIBLE_FORCE_COLOR) = True
ANSIBLE_NOCOWS(/home/skraetzig/Git/infrastructure/ansible.cfg) = True
ANSIBLE_PIPELINING(/home/skraetzig/Git/infrastructure/ansible.cfg) = True
ANY_ERRORS_FATAL(/home/skraetzig/Git/infrastructure/ansible.cfg) = True
COLLECTIONS_PATHS(/home/skraetzig/Git/infrastructure/ansible.cfg) = ['/usr/shar>
CONFIG_FILE() = /home/skraetzig/Git/infrastructure/ansible.cfg
DEFAULT_FILTER_PLUGIN_PATH(/home/skraetzig/Git/infrastructure/ansible.cfg) = ['>
DEFAULT_FORKS(/home/skraetzig/Git/infrastructure/ansible.cfg) = 50
DEFAULT_LOCAL_TMP(env: ANSIBLE_LOCAL_TEMP) = /tmp/ansible-local-1pnubnjou
DEFAULT_MODULE_PATH(/home/skraetzig/Git/infrastructure/ansible.cfg) = ['/home/s>
DEFAULT_REMOTE_USER(/home/skraetzig/Git/infrastructure/ansible.cfg) = deploy
DEFAULT_ROLES_PATH(/home/skraetzig/Git/infrastructure/ansible.cfg) = ['/home/sk>
DIFF_ALWAYS(/home/skraetzig/Git/infrastructure/ansible.cfg) = True
DISPLAY_SKIPPED_HOSTS(env: ANSIBLE_DISPLAY_SKIPPED_HOSTS) = True
INTERPRETER_PYTHON(/home/skraetzig/Git/infrastructure/ansible.cfg) = /usr/bin/p>
MAX_FILE_SIZE_FOR_DIFF(/home/skraetzig/Git/infrastructure/ansible.cfg) = 1044480
RETRY_FILES_ENABLED(/home/skraetzig/Git/infrastructure/ansible.cfg) = False

CALLBACK:
========

default:
_______
display_ok_hosts(env: ANSIBLE_DISPLAY_OK_HOSTS) = True
display_skipped_hosts(env: ANSIBLE_DISPLAY_SKIPPED_HOSTS) = True

CONNECTION:
==========

local:
_____
pipelining(/home/skraetzig/Git/infrastructure/ansible.cfg) = True

paramiko_ssh:
____________
remote_user(/home/skraetzig/Git/infrastructure/ansible.cfg) = deploy
ssh_args(env: ANSIBLE_SSH_ARGS) = -C -o ControlMaster=auto -o ControlPersist=60>

psrp:
____
pipelining(/home/skraetzig/Git/infrastructure/ansible.cfg) = True

ssh:
___
pipelining(/home/skraetzig/Git/infrastructure/ansible.cfg) = True
remote_user(/home/skraetzig/Git/infrastructure/ansible.cfg) = deploy
ssh_args(env: ANSIBLE_SSH_ARGS) = -C -o ControlMaster=auto -o ControlPersist=60>

winrm:
_____
pipelining(/home/skraetzig/Git/infrastructure/ansible.cfg) = True
```


### OS / Environment

Debian 11 (Bullseye)

### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->
```yaml (paste below)
- hosts: an-aws-ec2-instance
  gather_facts: no
  tasks:
    - name: get instance identity
      ansible.builtin.uri:
        url: http://169.254.169.254/latest/dynamic/instance-identity/document
        method: GET
        return_content: true
        status_code: 200
        body_format: json
      register: instance_result
      check_mode: no

    - ansible.builtin.debug:
        var: instance_result
```


### Expected Results

I expected, that the registered variable contains a `json` attribute besides the `content` attribute, but it's missing.

### Actual Results

```console
The `json` attribute from the `ansible.builtin.uri` module is missing:


TASK [ansible.builtin.debug] ***************************************************
ok: [an-aws-ec2-instance] => {
    ""instance_result"": {
        ""accept_ranges"": ""none"",
        ""changed"": false,
        ""connection"": ""close"",
        ""content"": ""{\n  \""accountId\"" : \""1234567890\"",\n  \""architecture\"" : \""x86_64\"",\n  \""availabilityZone\"" : \""eu-central-1a\"",\n  \""billingProducts\"" : null,\n  \""devpayProductCodes\"" : null,\n  \""marketplaceProductCodes\"" : null,\n  \""imageId\"" : \""ami-026b9b6de9546bcab\"",\n  \""instanceId\"" : \""i-0d7fcd57df5239f67\"",\n  \""instanceType\"" : \""t3a.medium\"",\n  \""kernelId\"" : null,\n  \""pendingTime\"" : \""2023-02-10T07:00:08Z\"",\n  \""privateIp\"" : \""10.158.241.119\"",\n  \""ramdiskId\"" : null,\n  \""region\"" : \""eu-central-1\"",\n  \""version\"" : \""2017-09-30\""\n}"",
        ""content_length"": ""486"",
        ""content_type"": ""text/plain"",
        ""cookies"": {},
        ""cookies_string"": """",
        ""date"": ""Fri, 10 Feb 2023 15:50:51 GMT"",
        ""elapsed"": 0,
        ""failed"": false,
        ""last_modified"": ""Fri, 10 Feb 2023 15:31:41 GMT"",
        ""msg"": ""OK (486 bytes)"",
        ""redirected"": false,
        ""server"": ""EC2ws"",
        ""status"": 200,
        ""url"": ""http://169.254.169.254/latest/dynamic/instance-identity/document""
    }
}
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-02-10T16:01:19Z,6,Create a YAML Ansible playbook to exhibit the following issue: `ansible.builtin.uri` does not return `json` attribute when `Content-Type: text/plain`,"```
---
- name: Testing ansible.builtin.uri issue
  hosts: localhost
  gather_facts: false

  tasks:
    - name: Send HTTP request to an endpoint
      ansible.builtin.uri:
        url: https://jsonplaceholder.typicode.com/todos/1
        method: GET
        headers:
          Content-Type: text/plain
      register: response
      
    - debug:
        var: response.json
```
",1,"
---
- name: Testing ansible.builtin.uri issue
  hosts: localhost
  gather_facts: false

  tasks:
    - name: Send HTTP request to an endpoint
      ansible.builtin.uri:
        url: https://jsonplaceholder.typicode.com/todos/1
        method: GET
        headers:
          Content-Type: text/plain
      register: response
      
    - debug:
        var: response.json
"
40,79968,nested block in handler causes Exception,"### Summary

The ""block"" action is very useful, but unfortunately fails with the following error when nested inside of handlers.

> ERROR! Unexpected Exception, this is probably a bug: 'Block' object has no attribute 'is_host_notified'

```
Traceback (most recent call last):
  File ""/usr/local/lib/python3.9/dist-packages/ansible/cli/__init__.py"", line 647, in cli_executor
    exit_code = cli.run()
  File ""/usr/local/lib/python3.9/dist-packages/ansible/cli/playbook.py"", line 143, in run
    results = pbex.run()
  File ""/usr/local/lib/python3.9/dist-packages/ansible/executor/playbook_executor.py"", line 190, in run
    result = self._tqm.run(play=play)
  File ""/usr/local/lib/python3.9/dist-packages/ansible/executor/task_queue_manager.py"", line 333, in run
    play_return = strategy.run(iterator, play_context)
  File ""/usr/local/lib/python3.9/dist-packages/ansible/plugins/strategy/linear.py"", line 151, in run
    host_tasks = self._get_next_task_lockstep(hosts_left, iterator)
  File ""/usr/local/lib/python3.9/dist-packages/ansible/plugins/strategy/linear.py"", line 71, in _get_next_task_lockstep
    state, task = iterator.get_next_task_for_host(host, peek=True)
  File ""/usr/local/lib/python3.9/dist-packages/ansible/executor/play_iterator.py"", line 258, in get_next_task_for_host
    (s, task) = self._get_next_task_from_state(s, host=host)
  File ""/usr/local/lib/python3.9/dist-packages/ansible/executor/play_iterator.py"", line 452, in _get_next_task_from_state
    if task.is_host_notified(host):
AttributeError: 'Block' object has no attribute 'is_host_notified'
```

### Issue Type

Bug Report

### Component Name

core

### Ansible Version

```console
$ ansible --version
ansible [core 2.14.2]
  config file = None
  configured module search path = ['/root/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /usr/local/lib/python3.9/dist-packages/ansible
  ansible collection location = /root/.ansible/collections:/usr/share/ansible/collections
  executable location = /usr/local/bin/ansible
  python version = 3.9.2 (default, Feb 28 2021, 17:03:44) [GCC 10.2.1 20210110] (/usr/bin/python3)
  jinja version = 3.1.2
  libyaml = True
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
CONFIG_FILE() = None
```


### OS / Environment

Debian Bullseye

### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->
test.yml:
```yaml (paste below)
- hosts: localhost
  connection: local
  gather_facts: no
  tasks:
    - name: test task
      pause: """"
      changed_when: true
      notify: test handler
  handlers:
    - name: test handler
      block:
        - name: task in block
          pause: """"
        - name: nested block
          block:
            - name: task in nested block
              pause: """"
```

Run with:
```
ansible-playbook -vvv -i localhost, test.yml
```

### Expected Results

Should reach and execute ""task in nested block""

### Actual Results

```console
ansible-playbook [core 2.14.2]
  config file = None
  configured module search path = ['/root/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /usr/local/lib/python3.9/dist-packages/ansible
  ansible collection location = /root/.ansible/collections:/usr/share/ansible/collections
  executable location = /usr/local/bin/ansible-playbook
  python version = 3.9.2 (default, Feb 28 2021, 17:03:44) [GCC 10.2.1 20210110] (/usr/bin/python3)
  jinja version = 3.1.2
  libyaml = True
No config file found; using defaults
Parsed localhost, inventory source with host_list plugin
Skipping callback 'default', as we already have a stdout callback.
Skipping callback 'minimal', as we already have a stdout callback.
Skipping callback 'oneline', as we already have a stdout callback.

PLAYBOOK: test.yml *******************************************************************************************************************************************************************************1 plays in test.yml

PLAY [localhost] *********************************************************************************************************************************************************************************ERROR! Unexpected Exception, this is probably a bug: 'Block' object has no attribute 'is_host_notified'
the full traceback was:

Traceback (most recent call last):
  File ""/usr/local/lib/python3.9/dist-packages/ansible/cli/__init__.py"", line 647, in cli_executor
    exit_code = cli.run()
  File ""/usr/local/lib/python3.9/dist-packages/ansible/cli/playbook.py"", line 143, in run
    results = pbex.run()
  File ""/usr/local/lib/python3.9/dist-packages/ansible/executor/playbook_executor.py"", line 190, in run
    result = self._tqm.run(play=play)
  File ""/usr/local/lib/python3.9/dist-packages/ansible/executor/task_queue_manager.py"", line 333, in run
    play_return = strategy.run(iterator, play_context)
  File ""/usr/local/lib/python3.9/dist-packages/ansible/plugins/strategy/linear.py"", line 151, in run
    host_tasks = self._get_next_task_lockstep(hosts_left, iterator)
  File ""/usr/local/lib/python3.9/dist-packages/ansible/plugins/strategy/linear.py"", line 71, in _get_next_task_lockstep
    state, task = iterator.get_next_task_for_host(host, peek=True)
  File ""/usr/local/lib/python3.9/dist-packages/ansible/executor/play_iterator.py"", line 258, in get_next_task_for_host
    (s, task) = self._get_next_task_from_state(s, host=host)
  File ""/usr/local/lib/python3.9/dist-packages/ansible/executor/play_iterator.py"", line 452, in _get_next_task_from_state
    if task.is_host_notified(host):
AttributeError: 'Block' object has no attribute 'is_host_notified'
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-02-10T13:18:45Z,5,Create a YAML Ansible playbook to exhibit the following issue: nested block in handler causes Exception,"```
---

- name: An example playbook with nested block
  hosts: localhost
  gather_facts: no

  tasks:
  - name: Create a file
    file:
      path: /tmp/testfile
      state: touch

    handlers:
    - name: Restart the service
      service:
        name: httpd
        state: restarted
      block:
        - name: Start the service
          service:
            name: httpd
            state: started

... 
```",1,"
---

- name: An example playbook with nested block
  hosts: localhost
  gather_facts: no

  tasks:
  - name: Create a file
    file:
      path: /tmp/testfile
      state: touch

    handlers:
    - name: Restart the service
      service:
        name: httpd
        state: restarted
      block:
        - name: Start the service
          service:
            name: httpd
            state: started

... 
"
41,79967,Can't pass variables to command module's argv parameter,"### Summary

Can't pass variable to command module

### Issue Type

Bug Report

### Component Name

command

### Ansible Version

```console
$ ansible --version
ansible [core 2.13.7]
  config file = /etc/ansible/ansible.cfg
  configured module search path = ['/home/user/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /home/user/.local/lib/python3.8/site-packages/ansible
  ansible collection location = /home/user/.ansible/collections:/usr/share/ansible/collections
  executable location = /home/user/.local/bin/ansible
  python version = 3.8.2 (default, Apr  5 2022, 12:54:52) [GCC 8.3.1 20191121 (Red Hat 8.3.1-6)]
  jinja version = 3.0.3
  libyaml = True
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all

No output
```


### OS / Environment

CentOS

### Steps to Reproduce

I'm trying to write an Ansible role that configures [Redis cluster](https://redis.io/docs/management/scaling/).
The shell command that creates the cluster is:
```shell
$ /usr/bin/redis-cli --user admin --pass mypass --cluster create 10.226.2.194:6379 10.226.2.196:6379 10.226.2.195:6379 --cluster-replicas 1 --cluster-yes
```

I pass username, password, IP addresses of Redis servers and number of replicas as extra-vars in shell script:
```bash
#!/bin/sh
ansible-playbook /etc/ansible/playbook-redis.yml -vv \
--extra-vars='redis_admin_user=admin redis_admin_password=mypass' \
--extra-vars='redis_cluster_members=""10.226.2.194:6379 10.226.2.196:6379 10.226.2.195:6379"" redis_cluster_replicas=1'
```

I wrote the following task:
```yaml
    - name: Create Redis cluster
      ansible.builtin.command:
        argv:
          - /usr/bin/redis-cli
          - ""--user {{ redis_admin_user }}""
          - ""--pass {{ redis_admin_password }}""
          - ""--cluster create {{ redis_cluster_members }}""
          - ""--cluster-replicas {{ redis_cluster_replicas }}""
          - --cluster-yes
```

But when I run it I get the following error - `""Unrecognized option or bad number of args for: '--user admin'""` which seems to be error returned by redis-cli

I was able to get around the username and password by changing the task as following:
```yaml
    - name: Create Redis cluster
      ansible.builtin.command:
        argv:
          - /usr/bin/redis-cli
          - --user 
          - ""{{ redis_admin_user }}""
          - --pass
          - ""{{ redis_admin_password }}""
          - --cluster create
          - ""{{ redis_cluster_members }}""
          - --cluster-replicas
          - ""{{ redis_cluster_replicas }}""
          - --cluster-yes
```

But now it can't get past the `--cluster create` argument, it returns error `""Unrecognized option or bad number of args for: '--cluster create'""`

### Expected Results

To properly pass variables and to work the same way as the following:
```yaml
    - name: Create Redis cluster
      ansible.builtin.command:
        cmd: ""/usr/bin/redis-cli --user {{ redis_admin_user }} --pass {{ redis_admin_password }} --cluster create {{ redis_cluster_members }} --cluster-replicas {{ redis_cluster_replicas }} --cluster-yes""
```

### Actual Results

```console
fatal: [127.0.0.1]: FAILED! => {""changed"": true, ""cmd"": [""/usr/bin/redis-cli"", ""--user"", ""admin"", ""--pass"", ""mypass"", ""--cluster create"", ""10.226.2.194:6379 10.226.2.196:6379 10.226.2.195:6379"", ""--cluster-replicas"", ""0"", ""--cluster-yes""], ""delta"": ""0:00:00.007513"", ""end"": ""2023-02-10 13:51:41.051679"", ""msg"": ""non-zero return code"", ""rc"": 1, ""start"": ""2023-02-10 13:51:41.044166"", ""stderr"": ""Unrecognized option or bad number of args for: '--cluster create'"", ""stderr_lines"": [""Unrecognized option or bad number of args for: '--cluster create'""], ""stdout"": """", ""stdout_lines"": []}
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-02-10T11:39:35Z,6,Create a YAML Ansible playbook to exhibit the following issue: Can't pass variables to command module's argv parameter,"```
---
- name: Exhibit passing variables issue
  hosts: localhost
  vars:
    message: ""Hello, World!""
  tasks:
    - name: Pass variables to command module
      command:
        argv:
          - echo
          - ""{{ message }}""
      register: result
    - debug:
        var: result
...
```",1,"
---
- name: Exhibit passing variables issue
  hosts: localhost
  vars:
    message: ""Hello, World!""
  tasks:
    - name: Pass variables to command module
      command:
        argv:
          - echo
          - ""{{ message }}""
      register: result
    - debug:
        var: result
...
"
42,79961,Strange behavior with delegate_to and omit,"### Summary

When I set `delegate_to` to `{{omit}}`, the destination for the SSH connections changes to the inventory hostname instead of ansible_host.

### Issue Type

Bug Report

### Component Name

core

### Ansible Version

```console
$ ansible --version
/usr/lib/python3/dist-packages/paramiko/transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated
  ""class"": algorithms.Blowfish,
ansible [core 2.12.10]
  config file = /etc/ansible/ansible.cfg
  configured module search path = ['/home/nschelly/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /usr/lib/python3/dist-packages/ansible
  ansible collection location = /home/nschelly/.ansible/collections:/usr/share/ansible/collections
  executable location = /usr/bin/ansible
  python version = 3.9.2 (default, Feb 28 2021, 17:03:44) [GCC 10.2.1 20210110]
  jinja version = 3.1.2
  libyaml = True
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
/usr/lib/python3/dist-packages/paramiko/transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated
  ""class"": algorithms.Blowfish,

BECOME:
======

CACHE:
=====

CALLBACK:
========

CLICONF:
=======

CONNECTION:
==========

HTTPAPI:
=======

INVENTORY:
=========

LOOKUP:
======

NETCONF:
=======

SHELL:
=====

VARS:
====
```


### OS / Environment

Ansible is being run from a Debian Bullseye machine to connect to other Linux machines via SSH.

### Steps to Reproduce

Playbook:
```
---

- name: demo delegate_to and omit functions
  hosts: all
  tasks:
    - name: just print ansible_host
      shell: whoami
    - name: print ansible_host with delegate_to
      shell: whoami
      delegate_to: 127.0.0.1
    - name: print ansible_host with delegate_to set to omit
      shell: whoami
      delegate_to: ""{{omit}}""
```

Inventory:
```
localhostfakename ansible_host=localhost
```

### Expected Results

The first two tasks work fine. I'd expect the 3rd task work just like the first one, with an SSH connection formed to `localhost` as specified in the `ansible_host` variable. Instead, it's trying to connect to the inventory hostname (localhostfakename), which cannot be resolved in DNS.

### Actual Results

```console
$ ansible-playbook -vvv -i ansible_delegate.inventory ansible_delegate.yml 
/usr/lib/python3/dist-packages/paramiko/transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated
  ""class"": algorithms.Blowfish,
ansible-playbook [core 2.12.10]
  config file = /etc/ansible/ansible.cfg
  configured module search path = ['/home/nschelly/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /usr/lib/python3/dist-packages/ansible
  ansible collection location = /home/nschelly/.ansible/collections:/usr/share/ansible/collections
  executable location = /usr/bin/ansible-playbook
  python version = 3.9.2 (default, Feb 28 2021, 17:03:44) [GCC 10.2.1 20210110]
  jinja version = 3.1.2
  libyaml = True
Using /etc/ansible/ansible.cfg as config file
host_list declined parsing /home/nschelly/work/ansible_delegate.inventory as it did not pass its verify_file() method
script declined parsing /home/nschelly/work/ansible_delegate.inventory as it did not pass its verify_file() method
auto declined parsing /home/nschelly/work/ansible_delegate.inventory as it did not pass its verify_file() method
yaml declined parsing /home/nschelly/work/ansible_delegate.inventory as it did not pass its verify_file() method
Parsed /home/nschelly/work/ansible_delegate.inventory inventory source with ini plugin
Skipping callback 'default', as we already have a stdout callback.
Skipping callback 'minimal', as we already have a stdout callback.
Skipping callback 'oneline', as we already have a stdout callback.

PLAYBOOK: ansible_delegate.yml ***************************************************************************************************************************************************************************************************************************************************************************************************************************
1 plays in ansible_delegate.yml

PLAY [demo delegate_to and omit functions] ***************************************************************************************************************************************************************************************************************************************************************************************************************

TASK [Gathering Facts] ***********************************************************************************************************************************************************************************************************************************************************************************************************************************
task path: /home/nschelly/work/ansible_delegate.yml:3
<localhost> ESTABLISH SSH CONNECTION FOR USER: None
<localhost> SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o ConnectTimeout=10 -o 'ControlPath=""/home/nschelly/.ansible/cp/8a5a4c6a60""' localhost '/bin/sh -c '""'""'echo ~ && sleep 0'""'""''
<localhost> (0, b'/home/nschelly\n', b'')
<localhost> ESTABLISH SSH CONNECTION FOR USER: None
<localhost> SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o ConnectTimeout=10 -o 'ControlPath=""/home/nschelly/.ansible/cp/8a5a4c6a60""' localhost '/bin/sh -c '""'""'( umask 77 && mkdir -p ""` echo /home/nschelly/.ansible/tmp `""&& mkdir ""` echo /home/nschelly/.ansible/tmp/ansible-tmp-1675957880.2776134-309045-123099090495447 `"" && echo ansible-tmp-1675957880.2776134-309045-123099090495447=""` echo /home/nschelly/.ansible/tmp/ansible-tmp-1675957880.2776134-309045-123099090495447 `"" ) && sleep 0'""'""''                                     
<localhost> (0, b'ansible-tmp-1675957880.2776134-309045-123099090495447=/home/nschelly/.ansible/tmp/ansible-tmp-1675957880.2776134-309045-123099090495447\n', b'')
<localhostfakename> Attempting python interpreter discovery
<localhost> ESTABLISH SSH CONNECTION FOR USER: None
<localhost> SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o ConnectTimeout=10 -o 'ControlPath=""/home/nschelly/.ansible/cp/8a5a4c6a60""' localhost '/bin/sh -c '""'""'echo PLATFORM; uname; echo FOUND; command -v '""'""'""'""'""'""'""'""'python3.10'""'""'""'""'""'""'""'""'; command -v '""'""'""'""'""'""'""'""'python3.9'""'""'""'""'""'""'""'""'; command -v '""'""'""'""'""'""'""'""'python3.8'""'""'""'""'""'""'""'""'; command -v '""'""'""'""'""'""'""'""'python3.7'""'""'""'""'""'""'""'""'; command -v '""'""'""'""'""'""'""'""'python3.6'""'""'""'""'""'""'""'""'; command -v '""'""'""'""'""'""'""'""'python3.5'""'""'""'""'""'""'""'""'; command -v '""'""'""'""'""'""'""'""'/usr/bin/python3'""'""'""'""'""'""'""'""'; command -v '""'""'""'""'""'""'""'""'/usr/libexec/platform-python'""'""'""'""'""'""'""'""'; command -v '""'""'""'""'""'""'""'""'python2.7'""'""'""'""'""'""'""'""'; command -v '""'""'""'""'""'""'""'""'python2.6'""'""'""'""'""'""'""'""'; command -v '""'""'""'""'""'""'""'""'/usr/bin/python'""'""'""'""'""'""'""'""'; command -v '""'""'""'""'""'""'""'""'python'""'""'""'""'""'""'""'""'; echo ENDFOUND && sleep 0'""'""''                                                                                                                                                                                                                                                                                                           
<localhost> (0, b'PLATFORM\nLinux\nFOUND\n/usr/bin/python3.9\n/usr/bin/python3\nENDFOUND\n', b'')
<localhost> ESTABLISH SSH CONNECTION FOR USER: None
<localhost> SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o ConnectTimeout=10 -o 'ControlPath=""/home/nschelly/.ansible/cp/8a5a4c6a60""' localhost '/bin/sh -c '""'""'/usr/bin/python3.9 && sleep 0'""'""''                                                                                                                                                                                                                                                                                                                                                  
<localhost> (0, b'{""platform_dist_result"": [], ""osrelease_content"": ""PRETTY_NAME=\\""Debian GNU/Linux 11 (bullseye)\\""\\nNAME=\\""Debian GNU/Linux\\""\\nVERSION_ID=\\""11\\""\\nVERSION=\\""11 (bullseye)\\""\\nVERSION_CODENAME=bullseye\\nID=debian\\nHOME_URL=\\""https://www.debian.org/\\""\\nSUPPORT_URL=\\""https://www.debian.org/support\\""\\nBUG_REPORT_URL=\\""https://bugs.debian.org/\\""\\n""}\n', b'')                                                                                                                                                                                                                                                                                                           
Using module file /usr/lib/python3/dist-packages/ansible/modules/setup.py
<localhost> PUT /home/nschelly/.ansible/tmp/ansible-local-309041yhhv4f3g/tmp_gyfstkm TO /home/nschelly/.ansible/tmp/ansible-tmp-1675957880.2776134-309045-123099090495447/AnsiballZ_setup.py
<localhost> SSH: EXEC sftp -b - -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o ConnectTimeout=10 -o 'ControlPath=""/home/nschelly/.ansible/cp/8a5a4c6a60""' '[localhost]'
<localhost> (0, b'sftp> put /home/nschelly/.ansible/tmp/ansible-local-309041yhhv4f3g/tmp_gyfstkm /home/nschelly/.ansible/tmp/ansible-tmp-1675957880.2776134-309045-123099090495447/AnsiballZ_setup.py\n', b'')
<localhost> ESTABLISH SSH CONNECTION FOR USER: None
<localhost> SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o ConnectTimeout=10 -o 'ControlPath=""/home/nschelly/.ansible/cp/8a5a4c6a60""' localhost '/bin/sh -c '""'""'chmod u+x /home/nschelly/.ansible/tmp/ansible-tmp-1675957880.2776134-309045-123099090495447/ /home/nschelly/.ansible/tmp/ansible-tmp-1675957880.2776134-309045-123099090495447/AnsiballZ_setup.py && sleep 0'""'""''                                                                                                                                                                   
<localhost> (0, b'', b'')
<localhost> ESTABLISH SSH CONNECTION FOR USER: None
<localhost> SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o ConnectTimeout=10 -o 'ControlPath=""/home/nschelly/.ansible/cp/8a5a4c6a60""' -tt localhost '/bin/sh -c '""'""'/usr/bin/python3 /home/nschelly/.ansible/tmp/ansible-tmp-1675957880.2776134-309045-123099090495447/AnsiballZ_setup.py && sleep 0'""'""''                                                                                                                                                                                                                                           
<localhost> (0, b'\r\n{""ansible_facts"": {""ansible_system_capabilities_enforced"": ""True"", ""ansible_system_capabilities"": [""""], ""ansible_distribution"": ""Debian"", ""ansible_distribution_release"": ""bullseye"", ""ansible_distribution_version"": ""11"", ""ansible_distribution_major_version"": ""11"", ""ansible_distribution_file_path"": ""/etc/os-release"", ""ansible_distribution_file_variety"": ""Debian"", ""ansible_distribution_file_parsed"": true, ""ansible_os_family"": ""Debian"", ""ansible_iscsi_iqn"": """", ""ansible_dns"": {""nameservers"": [""192.168.23.12"", ""192.168.23.13"", ""192.168.23.12""], ""search"": [""localdomain""]}, ""ansible_virtualization_type"": ""kvm"", ""ansible_virtualization_role"": ""host"", ""ansible_virtualization_tech_guest"": [], ""ansible_virtualization_tech_host"": [""kvm""], ""ansible_ssh_host_key_rsa_public"": ""AAAAB3NzaC1yc2EAAAADAQABAAABAQDCwP3Ihd6Ffwl2ChitHEKFPK/6bmDYqFop3jucivGnDxC0h+JcWgHjijRnV/Vbj6IqSj6Z4Dm9ye5YaA9c3h1Wd2CPfHcDYLwtx+MPgzoueBvmOInOC/Y7DVxBZS4Z0PqG2U6c7+/z9gFud8M6VYR7wkxmECHm8zVINKnOtOkcH/wIUr2MmUGM4zksBefTRT6jQIJMdBj6N4bOjPtVsi0OPi1lhVD0bvrGBo3m1+7QKzc0nnzZhUdIN1EO2JBmlzJV3ffjncPxd/xPOvMy3mZSGF+co6ierWWuHt7DxbA9dlCo9+YbUhQXLtIy53oLY/pqaazmWGsyNAlms8NOV73l"", ""ansible_ssh_host_key_rsa_public_keytype"": ""ssh-rsa"", ""ansible_ssh_host_key_ecdsa_public"": ""AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBDSxtg1CQrVylOzc3EwiyxtG26UoDG0WcJGo1V3ZPRwYU4en5D96nulu6H0wclzttYIxwbzaDHK8TrjJsefXbUI="", ""ansible_ssh_host_key_ecdsa_public_keytype"": ""ecdsa-sha2-nistp256"", ""ansible_ssh_host_key_ed25519_public"": ""AAAAC3NzaC1lZDI1NTE5AAAAIKMvuVTsgXp3XD8UkaJs0sJKbbdqMMT4rR214oWlqG9E"", ""ansible_ssh_host_key_ed25519_public_keytype"": ""ssh-ed25519"", ""ansible_user_id"": ""nschelly"", ""ansible_user_uid"": 1000, ""ansible_user_gid"": 1000, ""ansible_user_gecos"": ""Neil Schelly,,,"", ""ansible_user_dir"": ""/home/nschelly"", ""ansible_user_shell"": ""/bin/bash"", ""ansible_real_user_id"": 1000, ""ansible_effective_user_id"": 1000, ""ansible_real_group_id"": 1000, ""ansible_effective_group_id"": 1000, ""ansible_hostnqn"": """", ""ansible_system"": ""Linux"", ""ansible_kernel"": ""5.10.0-21-amd64"", ""ansible_kernel_version"": ""#1 SMP Debian 5.10.162-1 (2023-01-21)"", ""ansible_machine"": ""x86_64"", ""ansible_python_version"": ""3.9.2"", ""ansible_fqdn"": ""roadtrip.iracing.at"", ""ansible_hostname"": ""roadtrip"", ""ansible_nodename"": ""roadtrip"", ""ansible_domain"": ""iracing.at"", ""ansible_userspace_bits"": ""64"", ""ansible_architecture"": ""x86_64"", ""ansible_userspace_architecture"": ""x86_64"", ""ansible_machine_id"": ""ed59b88a8e984c1585094b7c20de132b"", ""ansible_apparmor"": {""status"": ""enabled""}, ""ansible_python"": {""version"": {""major"": 3, ""minor"": 9, ""micro"": 2, ""releaselevel"": ""final"", ""serial"": 0}, ""version_info"": [3, 9, 2, ""final"", 0], ""executable"": ""/usr/bin/python3"", ""has_sslcontext"": true, ""type"": ""cpython""}, ""ansible_local"": {}, ""ansible_fibre_channel_wwn"": [], ""ansible_cmdline"": {""BOOT_IMAGE"": ""/vmlinuz-5.10.0-21-amd64"", ""root"": ""/dev/mapper/systemdisk-root"", ""ro"": true, ""quiet"": true}, ""ansible_proc_cmdline"": {""BOOT_IMAGE"": ""/vmlinuz-5.10.0-21-amd64"", ""root"": ""/dev/mapper/systemdisk-root"", ""ro"": true, ""quiet"": true}, ""ansible_env"": {""USER"": ""nschelly"", ""SSH_CLIENT"": ""::1 44904 22"", ""XDG_SESSION_TYPE"": ""tty"", ""SHLVL"": ""0"", ""MOTD_SHOWN"": ""pam"", ""HOME"": ""/home/nschelly"", ""SSH_TTY"": ""/dev/pts/9"", ""DBUS_SESSION_BUS_ADDRESS"": ""unix:path=/run/user/1000/bus"", ""LOGNAME"": ""nschelly"", ""_"": ""/bin/sh"", ""XDG_SESSION_CLASS"": ""user"", ""TERM"": ""xterm-256color"", ""XDG_SESSION_ID"": ""271"", ""PATH"": ""/usr/local/bin:/usr/bin:/bin:/usr/games"", ""XDG_RUNTIME_DIR"": ""/run/user/1000"", ""LANG"": ""en_US.UTF-8"", ""SHELL"": ""/bin/bash"", ""PWD"": ""/home/nschelly"", ""SSH_CONNECTION"": ""::1 44904 ::1 22""}, ""ansible_lsb"": {""id"": ""Debian"", ""description"": ""Debian GNU/Linux 11 (bullseye)"", ""release"": ""11"", ""codename"": ""bullseye"", ""major_release"": ""11""}, ""ansible_date_time"": {""year"": ""2023"", ""month"": ""02"", ""weekday"": ""Thursday"", ""weekday_number"": ""4"", ""weeknumber"": ""06"", ""day"": ""09"", ""hour"": ""10"", ""minute"": ""51"", ""second"": ""20"", ""epoch"": ""1675957880"", ""epoch_int"": ""1675957880"", ""date"": ""2023-02-09"", ""time"": ""10:51:20"", ""iso8601_micro"": ""2023-02-09T15:51:20.793967Z"", ""iso8601"": ""2023-02-09T15:51:20Z"", ""iso8601_basic"": ""20230209T105120793967"", ""iso8601_basic_short"": ""20230209T105120"", ""tz"": ""EST"", ""tz_dst"": ""EDT"", ""tz_offset"": ""-0500""}, ""ansible_is_chroot"": false, ""ansible_fips"": false, ""ansible_interfaces"": [""docker0"", ""lo"", ""ppp0"", ""wlp59s0"", ""enx98e743b8e295""], ""ansible_docker0"": {""device"": ""docker0"", ""macaddress"": ""02:42:72:ae:ae:b2"", ""mtu"": 1500, ""active"": false, ""type"": ""bridge"", ""interfaces"": [], ""id"": ""8000.024272aeaeb2"", ""stp"": false, ""speed"": -1, ""promisc"": false, ""ipv4"": {""address"": ""172.31.255.1"", ""broadcast"": ""172.31.255.255"", ""netmask"": ""255.255.255.0"", ""network"": ""172.31.255.0""}, ""features"": {""rx_checksumming"": ""off [fixed]"", ""tx_checksumming"": ""on"", ""tx_checksum_ipv4"": ""off [fixed]"", ""tx_checksum_ip_generic"": ""on"", ""tx_checksum_ipv6"": ""off [fixed]"", ""tx_checksum_fcoe_crc"": ""off [fixed]"", ""tx_checksum_sctp"": ""off [fixed]"", ""scatter_gather"": ""on"", ""tx_scatter_gather"": ""on"", ""tx_scatter_gather_fraglist"": ""on"", ""tcp_segmentation_offload"": ""on"", ""tx_tcp_segmentation"": ""on"", ""tx_tcp_ecn_segmentation"": ""on"", ""tx_tcp_mangleid_segmentation"": ""on"", ""tx_tcp6_segmentation"": ""on"", ""generic_segmentation_offload"": ""on"", ""generic_receive_offload"": ""on"", ""large_receive_offload"": ""off [fixed]"", ""rx_vlan_offload"": ""off [fixed]"", ""tx_vlan_offload"": ""on"", ""ntuple_filters"": ""off [fixed]"", ""receive_hashing"": ""off [fixed]"", ""highdma"": ""on"", ""rx_vlan_filter"": ""off [fixed]"", ""vlan_challenged"": ""off [fixed]"", ""tx_lockless"": ""on [fixed]"", ""netns_local"": ""on [fixed]"", ""tx_gso_robust"": ""on"", ""tx_fcoe_segmentation"": ""on"", ""tx_gre_segmentation"": ""on"", ""tx_gre_csum_segmentation"": ""on"", ""tx_ipxip4_segmentation"": ""on"", ""tx_ipxip6_segmentation"": ""on"", ""tx_udp_tnl_segmentation"": ""on"", ""tx_udp_tnl_csum_segmentation"": ""on"", ""tx_gso_partial"": ""on"", ""tx_tunnel_remcsum_segmentation"": ""on"", ""tx_sctp_segmentation"": ""on"", ""tx_esp_segmentation"": ""on"", ""tx_udp_segmentation"": ""on"", ""tx_gso_list"": ""on"", ""fcoe_mtu"": ""off [fixed]"", ""tx_nocache_copy"": ""off"", ""loopback"": ""off [fixed]"", ""rx_fcs"": ""off [fixed]"", ""rx_all"": ""off [fixed]"", ""tx_vlan_stag_hw_insert"": ""on"", ""rx_vlan_stag_hw_parse"": ""off [fixed]"", ""rx_vlan_stag_filter"": ""off [fixed]"", ""l2_fwd_offload"": ""off [fixed]"", ""hw_tc_offload"": ""off [fixed]"", ""esp_hw_offload"": ""off [fixed]"", ""esp_tx_csum_hw_offload"": ""off [fixed]"", ""rx_udp_tunnel_port_offload"": ""off [fixed]"", ""tls_hw_tx_offload"": ""off [fixed]"", ""tls_hw_rx_offload"": ""off [fixed]"", ""rx_gro_hw"": ""off [fixed]"", ""tls_hw_record"": ""off [fixed]"", ""rx_gro_list"": ""off"", ""macsec_hw_offload"": ""off [fixed]""}, ""timestamping"": [], ""hw_timestamp_filters"": []}, ""ansible_lo"": {""device"": ""lo"", ""mtu"": 65536, ""active"": true, ""type"": ""loopback"", ""promisc"": false, ""ipv4"": {""address"": ""127.0.0.1"", ""broadcast"": """", ""netmask"": ""255.0.0.0"", ""network"": ""127.0.0.0""}, ""ipv6"": [{""address"": ""::1"", ""prefix"": ""128"", ""scope"": ""host""}], ""features"": {""rx_checksumming"": ""on [fixed]"", ""tx_checksumming"": ""on"", ""tx_checksum_ipv4"": ""off [fixed]"", ""tx_checksum_ip_generic"": ""on [fixed]"", ""tx_checksum_ipv6"": ""off [fixed]"", ""tx_checksum_fcoe_crc"": ""off [fixed]"", ""tx_checksum_sctp"": ""on [fixed]"", ""scatter_gather"": ""on"", ""tx_scatter_gather"": ""on [fixed]"", ""tx_scatter_gather_fraglist"": ""on [fixed]"", ""tcp_segmentation_offload"": ""on"", ""tx_tcp_segmentation"": ""on"", ""tx_tcp_ecn_segmentation"": ""on"", ""tx_tcp_mangleid_segmentation"": ""on"", ""tx_tcp6_segmentation"": ""on"", ""generic_segmentation_offload"": ""on"", ""generic_receive_offload"": ""on"", ""large_receive_offload"": ""off [fixed]"", ""rx_vlan_offload"": ""off [fixed]"", ""tx_vlan_offload"": ""off [fixed]"", ""ntuple_filters"": ""off [fixed]"", ""receive_hashing"": ""off [fixed]"", ""highdma"": ""on [fixed]"", ""rx_vlan_filter"": ""off [fixed]"", ""vlan_challenged"": ""on [fixed]"", ""tx_lockless"": ""on [fixed]"", ""netns_local"": ""on [fixed]"", ""tx_gso_robust"": ""off [fixed]"", ""tx_fcoe_segmentation"": ""off [fixed]"", ""tx_gre_segmentation"": ""off [fixed]"", ""tx_gre_csum_segmentation"": ""off [fixed]"", ""tx_ipxip4_segmentation"": ""off [fixed]"", ""tx_ipxip6_segmentation"": ""off [fixed]"", ""tx_udp_tnl_segmentation"": ""off [fixed]"", ""tx_udp_tnl_csum_segmentation"": ""off [fixed]"", ""tx_gso_partial"": ""off [fixed]"", ""tx_tunnel_remcsum_segmentation"": ""off [fixed]"", ""tx_sctp_segmentation"": ""on"", ""tx_esp_segmentation"": ""off [fixed]"", ""tx_udp_segmentation"": ""off [fixed]"", ""tx_gso_list"": ""off [fixed]"", ""fcoe_mtu"": ""off [fixed]"", ""tx_nocache_copy"": ""off [fixed]"", ""loopback"": ""on [fixed]"", ""rx_fcs"": ""off [fixed]"", ""rx_all"": ""off [fixed]"", ""tx_vlan_stag_hw_insert"": ""off [fixed]"", ""rx_vlan_stag_hw_parse"": ""off [fixed]"", ""rx_vlan_stag_filter"": ""off [fixed]"", ""l2_fwd_offload"": ""off [fixed]"", ""hw_tc_offload"": ""off [fixed]"", ""esp_hw_offload"": ""off [fixed]"", ""esp_tx_csum_hw_offload"": ""off [fixed]"", ""rx_udp_tunnel_port_offload"": ""off [fixed]"", ""tls_hw_tx_offload"": ""off [fixed]"", ""tls_hw_rx_offload"": ""off [fixed]"", ""rx_gro_hw"": ""off [fixed]"", ""tls_hw_record"": ""off [fixed]"", ""rx_gro_list"": ""off"", ""macsec_hw_offload"": ""off [fixed]""}, ""timestamping"": [], ""hw_timestamp_filters"": []}, ""ansible_wlp59s0"": {""device"": ""wlp59s0"", ""macaddress"": ""90:78:41:ab:30:15"", ""mtu"": 1500, ""active"": true, ""module"": ""iwlwifi"", ""type"": ""ether"", ""pciid"": ""0000:3b:00.0"", ""promisc"": false, ""ipv4"": {""address"": ""192.168.1.40"", ""broadcast"": ""192.168.1.255"", ""netmask"": ""255.255.255.0"", ""network"": ""192.168.1.0""}, ""ipv6"": [{""address"": ""fe80::b499:964d:bd38:c54e"", ""prefix"": ""64"", ""scope"": ""link""}], ""features"": {""rx_checksumming"": ""on [fixed]"", ""tx_checksumming"": ""on"", ""tx_checksum_ipv4"": ""on"", ""tx_checksum_ip_generic"": ""off [fixed]"", ""tx_checksum_ipv6"": ""on"", ""tx_checksum_fcoe_crc"": ""off [fixed]"", ""tx_checksum_sctp"": ""off [fixed]"", ""scatter_gather"": ""on"", ""tx_scatter_gather"": ""on"", ""tx_scatter_gather_fraglist"": ""off [fixed]"", ""tcp_segmentation_offload"": ""on"", ""tx_tcp_segmentation"": ""on"", ""tx_tcp_ecn_segmentation"": ""off [fixed]"", ""tx_tcp_mangleid_segmentation"": ""off"", ""tx_tcp6_segmentation"": ""on"", ""generic_segmentation_offload"": ""on"", ""generic_receive_offload"": ""on"", ""large_receive_offload"": ""off [fixed]"", ""rx_vlan_offload"": ""off [fixed]"", ""tx_vlan_offload"": ""off [fixed]"", ""ntuple_filters"": ""off [fixed]"", ""receive_hashing"": ""off [fixed]"", ""highdma"": ""on"", ""rx_vlan_filter"": ""off [fixed]"", ""vlan_challenged"": ""off [fixed]"", ""tx_lockless"": ""off [fixed]"", ""netns_local"": ""on [fixed]"", ""tx_gso_robust"": ""off [fixed]"", ""tx_fcoe_segmentation"": ""off [fixed]"", ""tx_gre_segmentation"": ""off [fixed]"", ""tx_gre_csum_segmentation"": ""off [fixed]"", ""tx_ipxip4_segmentation"": ""off [fixed]"", ""tx_ipxip6_segmentation"": ""off [fixed]"", ""tx_udp_tnl_segmentation"": ""off [fixed]"", ""tx_udp_tnl_csum_segmentation"": ""off [fixed]"", ""tx_gso_partial"": ""off [fixed]"", ""tx_tunnel_remcsum_segmentation"": ""off [fixed]"", ""tx_sctp_segmentation"": ""off [fixed]"", ""tx_esp_segmentation"": ""off [fixed]"", ""tx_udp_segmentation"": ""off [fixed]"", ""tx_gso_list"": ""off [fixed]"", ""fcoe_mtu"": ""off [fixed]"", ""tx_nocache_copy"": ""off"", ""loopback"": ""off [fixed]"", ""rx_fcs"": ""off [fixed]"", ""rx_all"": ""off [fixed]"", ""tx_vlan_stag_hw_insert"": ""off [fixed]"", ""rx_vlan_stag_hw_parse"": ""off [fixed]"", ""rx_vlan_stag_filter"": ""off [fixed]"", ""l2_fwd_offload"": ""off [fixed]"", ""hw_tc_offload"": ""off [fixed]"", ""esp_hw_offload"": ""off [fixed]"", ""esp_tx_csum_hw_offload"": ""off [fixed]"", ""rx_udp_tunnel_port_offload"": ""off [fixed]"", ""tls_hw_tx_offload"": ""off [fixed]"", ""tls_hw_rx_offload"": ""off [fixed]"", ""rx_gro_hw"": ""off [fixed]"", ""tls_hw_record"": ""off [fixed]"", ""rx_gro_list"": ""off"", ""macsec_hw_offload"": ""off [fixed]""}, ""timestamping"": [], ""hw_timestamp_filters"": []}, ""ansible_ppp0"": {""device"": ""ppp0"", ""mtu"": 1354, ""active"": true, ""type"": ""ppp"", ""promisc"": false, ""ipv4"": {""address"": ""192.168.252.37"", ""broadcast"": """", ""netmask"": ""255.255.255.255"", ""network"": ""192.168.252.37""}, ""features"": {""rx_checksumming"": ""off [fixed]"", ""tx_checksumming"": ""off"", ""tx_checksum_ipv4"": ""off [fixed]"", ""tx_checksum_ip_generic"": ""off [fixed]"", ""tx_checksum_ipv6"": ""off [fixed]"", ""tx_checksum_fcoe_crc"": ""off [fixed]"", ""tx_checksum_sctp"": ""off [fixed]"", ""scatter_gather"": ""off"", ""tx_scatter_gather"": ""off [fixed]"", ""tx_scatter_gather_fraglist"": ""off [fixed]"", ""tcp_segmentation_offload"": ""off"", ""tx_tcp_segmentation"": ""off [fixed]"", ""tx_tcp_ecn_segmentation"": ""off [fixed]"", ""tx_tcp_mangleid_segmentation"": ""off [fixed]"", ""tx_tcp6_segmentation"": ""off [fixed]"", ""generic_segmentation_offload"": ""off [requested on]"", ""generic_receive_offload"": ""on"", ""large_receive_offload"": ""off [fixed]"", ""rx_vlan_offload"": ""off [fixed]"", ""tx_vlan_offload"": ""off [fixed]"", ""ntuple_filters"": ""off [fixed]"", ""receive_hashing"": ""off [fixed]"", ""highdma"": ""off [fixed]"", ""rx_vlan_filter"": ""off [fixed]"", ""vlan_challenged"": ""off [fixed]"", ""tx_lockless"": ""on [fixed]"", ""netns_local"": ""off [fixed]"", ""tx_gso_robust"": ""off [fixed]"", ""tx_fcoe_segmentation"": ""off [fixed]"", ""tx_gre_segmentation"": ""off [fixed]"", ""tx_gre_csum_segmentation"": ""off [fixed]"", ""tx_ipxip4_segmentation"": ""off [fixed]"", ""tx_ipxip6_segmentation"": ""off [fixed]"", ""tx_udp_tnl_segmentation"": ""off [fixed]"", ""tx_udp_tnl_csum_segmentation"": ""off [fixed]"", ""tx_gso_partial"": ""off [fixed]"", ""tx_tunnel_remcsum_segmentation"": ""off [fixed]"", ""tx_sctp_segmentation"": ""off [fixed]"", ""tx_esp_segmentation"": ""off [fixed]"", ""tx_udp_segmentation"": ""off [fixed]"", ""tx_gso_list"": ""off [fixed]"", ""fcoe_mtu"": ""off [fixed]"", ""tx_nocache_copy"": ""off"", ""loopback"": ""off [fixed]"", ""rx_fcs"": ""off [fixed]"", ""rx_all"": ""off [fixed]"", ""tx_vlan_stag_hw_insert"": ""off [fixed]"", ""rx_vlan_stag_hw_parse"": ""off [fixed]"", ""rx_vlan_stag_filter"": ""off [fixed]"", ""l2_fwd_offload"": ""off [fixed]"", ""hw_tc_offload"": ""off [fixed]"", ""esp_hw_offload"": ""off [fixed]"", ""esp_tx_csum_hw_offload"": ""off [fixed]"", ""rx_udp_tunnel_port_offload"": ""off [fixed]"", ""tls_hw_tx_offload"": ""off [fixed]"", ""tls_hw_rx_offload"": ""off [fixed]"", ""rx_gro_hw"": ""off [fixed]"", ""tls_hw_record"": ""off [fixed]"", ""rx_gro_list"": ""off"", ""macsec_hw_offload"": ""off [fixed]""}, ""timestamping"": [], ""hw_timestamp_filters"": []}, ""ansible_enx98e743b8e295"": {""device"": ""enx98e743b8e295"", ""macaddress"": ""98:e7:43:b8:e2:95"", ""mtu"": 1500, ""active"": true, ""module"": ""r8152"", ""type"": ""ether"", ""pciid"": ""4-2.4:1.0"", ""speed"": 1000, ""promisc"": false, ""ipv4"": {""address"": ""192.168.1.183"", ""broadcast"": ""192.168.1.255"", ""netmask"": ""255.255.255.0"", ""network"": ""192.168.1.0""}, ""ipv6"": [{""address"": ""fe80::c332:6658:1c8e:48d5"", ""prefix"": ""64"", ""scope"": ""link""}], ""features"": {""rx_checksumming"": ""on"", ""tx_checksumming"": ""on"", ""tx_checksum_ipv4"": ""on"", ""tx_checksum_ip_generic"": ""off [fixed]"", ""tx_checksum_ipv6"": ""on"", ""tx_checksum_fcoe_crc"": ""off [fixed]"", ""tx_checksum_sctp"": ""off [fixed]"", ""scatter_gather"": ""on"", ""tx_scatter_gather"": ""on"", ""tx_scatter_gather_fraglist"": ""on"", ""tcp_segmentation_offload"": ""on"", ""tx_tcp_segmentation"": ""on"", ""tx_tcp_ecn_segmentation"": ""off [fixed]"", ""tx_tcp_mangleid_segmentation"": ""off"", ""tx_tcp6_segmentation"": ""on"", ""generic_segmentation_offload"": ""on"", ""generic_receive_offload"": ""on"", ""large_receive_offload"": ""off [fixed]"", ""rx_vlan_offload"": ""on"", ""tx_vlan_offload"": ""on"", ""ntuple_filters"": ""off [fixed]"", ""receive_hashing"": ""off [fixed]"", ""highdma"": ""off [fixed]"", ""rx_vlan_filter"": ""off [fixed]"", ""vlan_challenged"": ""off [fixed]"", ""tx_lockless"": ""off [fixed]"", ""netns_local"": ""off [fixed]"", ""tx_gso_robust"": ""off [fixed]"", ""tx_fcoe_segmentation"": ""off [fixed]"", ""tx_gre_segmentation"": ""off [fixed]"", ""tx_gre_csum_segmentation"": ""off [fixed]"", ""tx_ipxip4_segmentation"": ""off [fixed]"", ""tx_ipxip6_segmentation"": ""off [fixed]"", ""tx_udp_tnl_segmentation"": ""off [fixed]"", ""tx_udp_tnl_csum_segmentation"": ""off [fixed]"", ""tx_gso_partial"": ""off [fixed]"", ""tx_tunnel_remcsum_segmentation"": ""off [fixed]"", ""tx_sctp_segmentation"": ""off [fixed]"", ""tx_esp_segmentation"": ""off [fixed]"", ""tx_udp_segmentation"": ""off [fixed]"", ""tx_gso_list"": ""off [fixed]"", ""fcoe_mtu"": ""off [fixed]"", ""tx_nocache_copy"": ""off"", ""loopback"": ""off [fixed]"", ""rx_fcs"": ""off [fixed]"", ""rx_all"": ""off [fixed]"", ""tx_vlan_stag_hw_insert"": ""off [fixed]"", ""rx_vlan_stag_hw_parse"": ""off [fixed]"", ""rx_vlan_stag_filter"": ""off [fixed]"", ""l2_fwd_offload"": ""off [fixed]"", ""hw_tc_offload"": ""off [fixed]"", ""esp_hw_offload"": ""off [fixed]"", ""esp_tx_csum_hw_offload"": ""off [fixed]"", ""rx_udp_tunnel_port_offload"": ""off [fixed]"", ""tls_hw_tx_offload"": ""off [fixed]"", ""tls_hw_rx_offload"": ""off [fixed]"", ""rx_gro_hw"": ""off [fixed]"", ""tls_hw_record"": ""off [fixed]"", ""rx_gro_list"": ""off"", ""macsec_hw_offload"": ""off [fixed]""}, ""timestamping"": [], ""hw_timestamp_filters"": []}, ""ansible_default_ipv4"": {""gateway"": ""192.168.1.1"", ""interface"": ""enx98e743b8e295"", ""address"": ""192.168.1.183"", ""broadcast"": ""192.168.1.255"", ""netmask"": ""255.255.255.0"", ""network"": ""192.168.1.0"", ""macaddress"": ""98:e7:43:b8:e2:95"", ""mtu"": 1500, ""type"": ""ether"", ""alias"": ""enx98e743b8e295""}, ""ansible_default_ipv6"": {}, ""ansible_all_ipv4_addresses"": [""172.31.255.1"", ""192.168.1.40"", ""192.168.252.37"", ""192.168.1.183""], ""ansible_all_ipv6_addresses"": [""fe80::b499:964d:bd38:c54e"", ""fe80::c332:6658:1c8e:48d5""], ""ansible_selinux_python_present"": true, ""ansible_selinux"": {""status"": ""disabled""}, ""ansible_processor"": [""0"", ""GenuineIntel"", ""Intel(R) Core(TM) i9-9880H CPU @ 2.30GHz"", ""1"", ""GenuineIntel"", ""Intel(R) Core(TM) i9-9880H CPU @ 2.30GHz"", ""2"", ""GenuineIntel"", ""Intel(R) Core(TM) i9-9880H CPU @ 2.30GHz"", ""3"", ""GenuineIntel"", ""Intel(R) Core(TM) i9-9880H CPU @ 2.30GHz"", ""4"", ""GenuineIntel"", ""Intel(R) Core(TM) i9-9880H CPU @ 2.30GHz"", ""5"", ""GenuineIntel"", ""Intel(R) Core(TM) i9-9880H CPU @ 2.30GHz"", ""6"", ""GenuineIntel"", ""Intel(R) Core(TM) i9-9880H CPU @ 2.30GHz"", ""7"", ""GenuineIntel"", ""Intel(R) Core(TM) i9-9880H CPU @ 2.30GHz"", ""8"", ""GenuineIntel"", ""Intel(R) Core(TM) i9-9880H CPU @ 2.30GHz"", ""9"", ""GenuineIntel"", ""Intel(R) Core(TM) i9-9880H CPU @ 2.30GHz"", ""10"", ""GenuineIntel"", ""Intel(R) Core(TM) i9-9880H CPU @ 2.30GHz"", ""11"", ""GenuineIntel"", ""Intel(R) Core(TM) i9-9880H CPU @ 2.30GHz"", ""12"", ""GenuineIntel"", ""Intel(R) Core(TM) i9-9880H CPU @ 2.30GHz"", ""13"", ""GenuineIntel"", ""Intel(R) Core(TM) i9-9880H CPU @ 2.30GHz"", ""14"", ""GenuineIntel"", ""Intel(R) Core(TM) i9-9880H CPU @ 2.30GHz"", ""15"", ""GenuineIntel"", ""Intel(R) Core(TM) i9-9880H CPU @ 2.30GHz""], ""ansible_processor_count"": 1, ""ansible_processor_cores"": 8, ""ansible_processor_threads_per_core"": 2, ""ansible_processor_vcpus"": 16, ""ansible_processor_nproc"": 16, ""ansible_memtotal_mb"": 31746, ""ansible_memfree_mb"": 4375, ""ansible_swaptotal_mb"": 1906, ""ansible_swapfree_mb"": 1904, ""ansible_memory_mb"": {""real"": {""total"": 31746, ""used"": 27371, ""free"": 4375}, ""nocache"": {""free"": 17478, ""used"": 14268}, ""swap"": {""total"": 1906, ""free"": 1904, ""used"": 2, ""cached"": 0}}, ""ansible_bios_date"": ""05/31/2019"", ""ansible_bios_vendor"": ""Dell Inc."", ""ansible_bios_version"": ""1.1.1"", ""ansible_board_asset_tag"": ""NA"", ""ansible_board_name"": ""0FMYX6"", ""ansible_board_serial"": ""NA"", ""ansible_board_vendor"": ""Dell Inc."", ""ansible_board_version"": ""A00"", ""ansible_chassis_asset_tag"": ""NA"", ""ansible_chassis_serial"": ""NA"", ""ansible_chassis_vendor"": ""Dell Inc."", ""ansible_chassis_version"": ""NA"", ""ansible_form_factor"": ""Notebook"", ""ansible_product_name"": ""Precision 5540"", ""ansible_product_serial"": ""NA"", ""ansible_product_uuid"": ""NA"", ""ansible_product_version"": ""NA"", ""ansible_system_vendor"": ""Dell Inc."", ""ansible_devices"": {""dm-1"": {""virtual"": 1, ""links"": {""ids"": [""dm-name-systemdisk-var"", ""dm-uuid-LVM-eHY4GQxWzjvSDgNho38sNOcjuEQdRpZfcDaXcRzi9QazGGttcOC1kISh69LzBdVI""], ""uuids"": [""6cc1b6ca-97a8-4643-995d-2673925e621e""], ""labels"": [""var""], ""masters"": []}, ""vendor"": null, ""model"": null, ""sas_address"": null, ""sas_device_handle"": null, ""removable"": ""0"", ""support_discard"": ""512"", ""partitions"": {}, ""rotational"": ""0"", ""scheduler_mode"": """", ""sectors"": ""34209792"", ""sectorsize"": ""512"", ""size"": ""16.31 GB"", ""host"": """", ""holders"": []}, ""nvme0n1"": {""virtual"": 1, ""links"": {""ids"": [""nvme-PC601_NVMe_SK_hynix_512GB_SI96T001210107Q3Y"", ""nvme-eui.ace42e0095491ee52ee4ac0000000001""], ""uuids"": [], ""labels"": [], ""masters"": []}, ""vendor"": null, ""model"": ""PC601 NVMe SK hynix 512GB"", ""sas_address"": null, ""sas_device_handle"": null, ""serial"": ""SI96T001210107Q3Y"", ""removable"": ""0"", ""support_discard"": ""512"", ""partitions"": {""nvme0n1p5"": {""links"": {""ids"": [""lvm-pv-uuid-Qz7iDY-Gbbb-qteJ-Ddbj-zVru-igsQ-ct3CJv"", ""nvme-PC601_NVMe_SK_hynix_512GB_SI96T001210107Q3Y-part5"", ""nvme-eui.ace42e0095491ee52ee4ac0000000001-part5""], ""uuids"": [], ""labels"": [], ""masters"": [""dm-0"", ""dm-1"", ""dm-2"", ""dm-3"", ""dm-4""]}, ""start"": ""19896320"", ""sectors"": ""980318208"", ""sectorsize"": 512, ""size"": ""467.45 GB"", ""uuid"": null, ""holders"": [""systemdisk-var"", ""systemdisk-home"", ""systemdisk-usr"", ""systemdisk-root"", ""systemdisk-tmp""]}, ""nvme0n1p3"": {""links"": {""ids"": [""nvme-PC601_NVMe_SK_hynix_512GB_SI96T001210107Q3Y-part3"", ""nvme-eui.ace42e0095491ee52ee4ac0000000001-part3""], ""uuids"": [""0776f357-0c29-4fae-b3c9-2938a10aadc3""], ""labels"": [""boot""], ""masters"": []}, ""start"": ""12085248"", ""sectors"": ""3905536"", ""sectorsize"": 512, ""size"": ""1.86 GB"", ""uuid"": ""0776f357-0c29-4fae-b3c9-2938a10aadc3"", ""holders"": []}, ""nvme0n1p1"": {""links"": {""ids"": [""nvme-PC601_NVMe_SK_hynix_512GB_SI96T001210107Q3Y-part1"", ""nvme-eui.ace42e0095491ee52ee4ac0000000001-part1""], ""uuids"": [""126B-F1ED""], ""labels"": [""ESP""], ""masters"": []}, ""start"": ""2048"", ""sectors"": ""1597440"", ""sectorsize"": 512, ""size"": ""780.00 MB"", ""uuid"": ""126B-F1ED"", ""holders"": []}, ""nvme0n1p4"": {""links"": {""ids"": [""nvme-PC601_NVMe_SK_hynix_512GB_SI96T001210107Q3Y-part4"", ""nvme-eui.ace42e0095491ee52ee4ac0000000001-part4""], ""uuids"": [""54008352-5584-4f78-bac0-8ffc4e7fc4b6""], ""labels"": [], ""masters"": []}, ""start"": ""15990784"", ""sectors"": ""3905536"", ""sectorsize"": 512, ""size"": ""1.86 GB"", ""uuid"": ""54008352-5584-4f78-bac0-8ffc4e7fc4b6"", ""holders"": []}, ""nvme0n1p2"": {""links"": {""ids"": [""nvme-PC601_NVMe_SK_hynix_512GB_SI96T001210107Q3Y-part2"", ""nvme-eui.ace42e0095491ee52ee4ac0000000001-part2""], ""uuids"": [""CABF-BD0C""], ""labels"": [""OS""], ""masters"": []}, ""start"": ""1599488"", ""sectors"": ""10485760"", ""sectorsize"": 512, ""size"": ""5.00 GB"", ""uuid"": ""CABF-BD0C"", ""holders"": []}}, ""rotational"": ""0"", ""scheduler_mode"": ""none"", ""sectors"": ""1000215216"", ""sectorsize"": ""512"", ""size"": ""476.94 GB"", ""host"": ""Non-Volatile memory controller: SK hynix Device 1627"", ""holders"": []}, ""dm-4"": {""virtual"": 1, ""links"": {""ids"": [""dm-name-systemdisk-home"", ""dm-uuid-LVM-eHY4GQxWzjvSDgNho38sNOcjuEQdRpZfCeznO8auffaIae1Jc42Tpj8IK8YmUfMq""], ""uuids"": [""39c0582d-8862-491c-855f-f2722e5b0c04""], ""labels"": [], ""masters"": [""dm-5""]}, ""vendor"": null, ""model"": null, ""sas_address"": null, ""sas_device_handle"": null, ""removable"": ""0"", ""support_discard"": ""512"", ""partitions"": {}, ""rotational"": ""0"", ""scheduler_mode"": """", ""sectors"": ""178659328"", ""sectorsize"": ""512"", ""size"": ""85.19 GB"", ""host"": """", ""holders"": [""homedecrypt""]}, ""dm-2"": {""virtual"": 1, ""links"": {""ids"": [""dm-name-systemdisk-usr"", ""dm-uuid-LVM-eHY4GQxWzjvSDgNho38sNOcjuEQdRpZfTZKn1UHcCkTF1eEj86yNqafah4Xirsv3""], ""uuids"": [""9f8ba9f4-00ed-4031-8ae0-9b1becd3c982""], ""labels"": [""usr""], ""masters"": []}, ""vendor"": null, ""model"": null, ""sas_address"": null, ""sas_device_handle"": null, ""removable"": ""0"", ""support_discard"": ""512"", ""partitions"": {}, ""rotational"": ""0"", ""scheduler_mode"": """", ""sectors"": ""39780352"", ""sectorsize"": ""512"", ""size"": ""18.97 GB"", ""host"": """", ""holders"": []}, ""dm-0"": {""virtual"": 1, ""links"": {""ids"": [""dm-name-systemdisk-root"", ""dm-uuid-LVM-eHY4GQxWzjvSDgNho38sNOcjuEQdRpZfqOqbprGaqa1IwVShVb5W8CTpUfZWU06H""], ""uuids"": [""dcd3555e-dd32-4833-b0ff-47e86be0f541""], ""labels"": [""root""], ""masters"": []}, ""vendor"": null, ""model"": null, ""sas_address"": null, ""sas_device_handle"": null, ""removable"": ""0"", ""support_discard"": ""512"", ""partitions"": {}, ""rotational"": ""0"", ""scheduler_mode"": """", ""sectors"": ""29294592"", ""sectorsize"": ""512"", ""size"": ""13.97 GB"", ""host"": """", ""holders"": []}, ""dm-5"": {""virtual"": 1, ""links"": {""ids"": [""dm-name-homedecrypt"", ""dm-uuid-CRYPT-LUKS2-39c0582d8862491c855ff2722e5b0c04-homedecrypt""], ""uuids"": [""3ed80935-a264-499e-a806-dd4d5255d200""], ""labels"": [], ""masters"": []}, ""vendor"": null, ""model"": null, ""sas_address"": null, ""sas_device_handle"": null, ""removable"": ""0"", ""support_discard"": ""0"", ""partitions"": {}, ""rotational"": ""0"", ""scheduler_mode"": """", ""sectors"": ""178626560"", ""sectorsize"": ""512"", ""size"": ""85.18 GB"", ""host"": """", ""holders"": []}, ""dm-3"": {""virtual"": 1, ""links"": {""ids"": [""dm-name-systemdisk-tmp"", ""dm-uuid-LVM-eHY4GQxWzjvSDgNho38sNOcjuEQdRpZfU02X81zddK5LHyQ8kxVT5ST7VMR5fJwz""], ""uuids"": [""8f6711bc-2ec3-4b8e-ab15-57c4f20f3b37""], ""labels"": [""tmp""], ""masters"": []}, ""vendor"": null, ""model"": null, ""sas_address"": null, ""sas_device_handle"": null, ""removable"": ""0"", ""support_discard"": ""512"", ""partitions"": {}, ""rotational"": ""0"", ""scheduler_mode"": """", ""sectors"": ""3899392"", ""sectorsize"": ""512"", ""size"": ""1.86 GB"", ""host"": """", ""holders"": []}}, ""ansible_device_links"": {""ids"": {""dm-5"": [""dm-name-homedecrypt"", ""dm-uuid-CRYPT-LUKS2-39c0582d8862491c855ff2722e5b0c04-homedecrypt""], ""dm-3"": [""dm-name-systemdisk-tmp"", ""dm-uuid-LVM-eHY4GQxWzjvSDgNho38sNOcjuEQdRpZfU02X81zddK5LHyQ8kxVT5ST7VMR5fJwz""], ""dm-2"": [""dm-name-systemdisk-usr"", ""dm-uuid-LVM-eHY4GQxWzjvSDgNho38sNOcjuEQdRpZfTZKn1UHcCkTF1eEj86yNqafah4Xirsv3""], ""dm-1"": [""dm-name-systemdisk-var"", ""dm-uuid-LVM-eHY4GQxWzjvSDgNho38sNOcjuEQdRpZfcDaXcRzi9QazGGttcOC1kISh69LzBdVI""], ""dm-0"": [""dm-name-systemdisk-root"", ""dm-uuid-LVM-eHY4GQxWzjvSDgNho38sNOcjuEQdRpZfqOqbprGaqa1IwVShVb5W8CTpUfZWU06H""], ""dm-4"": [""dm-name-systemdisk-home"", ""dm-uuid-LVM-eHY4GQxWzjvSDgNho38sNOcjuEQdRpZfCeznO8auffaIae1Jc42Tpj8IK8YmUfMq""], ""nvme0n1p4"": [""nvme-PC601_NVMe_SK_hynix_512GB_SI96T001210107Q3Y-part4"", ""nvme-eui.ace42e0095491ee52ee4ac0000000001-part4""], ""nvme0n1p3"": [""nvme-PC601_NVMe_SK_hynix_512GB_SI96T001210107Q3Y-part3"", ""nvme-eui.ace42e0095491ee52ee4ac0000000001-part3""], ""nvme0n1p2"": [""nvme-PC601_NVMe_SK_hynix_512GB_SI96T001210107Q3Y-part2"", ""nvme-eui.ace42e0095491ee52ee4ac0000000001-part2""], ""nvme0n1p1"": [""nvme-PC601_NVMe_SK_hynix_512GB_SI96T001210107Q3Y-part1"", ""nvme-eui.ace42e0095491ee52ee4ac0000000001-part1""], ""nvme0n1p5"": [""lvm-pv-uuid-Qz7iDY-Gbbb-qteJ-Ddbj-zVru-igsQ-ct3CJv"", ""nvme-PC601_NVMe_SK_hynix_512GB_SI96T001210107Q3Y-part5"", ""nvme-eui.ace42e0095491ee52ee4ac0000000001-part5""], ""nvme0n1"": [""nvme-PC601_NVMe_SK_hynix_512GB_SI96T001210107Q3Y"", ""nvme-eui.ace42e0095491ee52ee4ac0000000001""]}, ""uuids"": {""dm-5"": [""3ed80935-a264-499e-a806-dd4d5255d200""], ""dm-3"": [""8f6711bc-2ec3-4b8e-ab15-57c4f20f3b37""], ""dm-2"": [""9f8ba9f4-00ed-4031-8ae0-9b1becd3c982""], ""dm-1"": [""6cc1b6ca-97a8-4643-995d-2673925e621e""], ""dm-0"": [""dcd3555e-dd32-4833-b0ff-47e86be0f541""], ""dm-4"": [""39c0582d-8862-491c-855f-f2722e5b0c04""], ""nvme0n1p4"": [""54008352-5584-4f78-bac0-8ffc4e7fc4b6""], ""nvme0n1p3"": [""0776f357-0c29-4fae-b3c9-2938a10aadc3""], ""nvme0n1p2"": [""CABF-BD0C""], ""nvme0n1p1"": [""126B-F1ED""]}, ""labels"": {""dm-3"": [""tmp""], ""dm-2"": [""usr""], ""dm-1"": [""var""], ""dm-0"": [""root""], ""nvme0n1p3"": [""boot""], ""nvme0n1p2"": [""OS""], ""nvme0n1p1"": [""ESP""]}, ""masters"": {""nvme0n1p5"": [""dm-0"", ""dm-1"", ""dm-2"", ""dm-3"", ""dm-4""], ""dm-4"": [""dm-5""]}}, ""ansible_uptime_seconds"": 248935, ""ansible_mounts"": [{""mount"": ""/"", ""device"": ""/dev/mapper/systemdisk-root"", ""fstype"": ""ext4"", ""options"": ""rw,relatime,errors=remount-ro"", ""size_total"": 14654316544, ""size_available"": 13685145600, ""block_size"": 4096, ""block_total"": 3577714, ""block_available"": 3341100, ""block_used"": 236614, ""inode_total"": 915712, ""inode_available"": 910644, ""inode_used"": 5068, ""uuid"": ""dcd3555e-dd32-4833-b0ff-47e86be0f541""}, {""mount"": ""/usr"", ""device"": ""/dev/mapper/systemdisk-usr"", ""fstype"": ""ext4"", ""options"": ""rw,relatime"", ""size_total"": 19934769152, ""size_available"": 867487744, ""block_size"": 4096, ""block_total"": 4866887, ""block_available"": 211789, ""block_used"": 4655098, ""inode_total"": 1242752, ""inode_available"": 781978, ""inode_used"": 460774, ""uuid"": ""9f8ba9f4-00ed-4031-8ae0-9b1becd3c982""}, {""mount"": ""/boot"", ""device"": ""/dev/nvme0n1p3"", ""fstype"": ""ext4"", ""options"": ""rw,relatime"", ""size_total"": 1928785920, ""size_available"": 1572261888, ""block_size"": 4096, ""block_total"": 470895, ""block_available"": 383853, ""block_used"": 87042, ""inode_total"": 122160, ""inode_available"": 121809, ""inode_used"": 351, ""uuid"": ""0776f357-0c29-4fae-b3c9-2938a10aadc3""}, {""mount"": ""/boot/efi"", ""device"": ""/dev/nvme0n1p1"", ""fstype"": ""vfat"", ""options"": ""rw,relatime,fmask=0077,dmask=0077,codepage=437,iocharset=ascii,shortname=mixed,utf8,errors=remount-ro"", ""size_total"": 813694976, ""size_available"": 777621504, ""block_size"": 4096, ""block_total"": 198656, ""block_available"": 189849, ""block_used"": 8807, ""inode_total"": 0, ""inode_available"": 0, ""inode_used"": 0, ""uuid"": ""126B-F1ED""}, {""mount"": ""/var"", ""device"": ""/dev/mapper/systemdisk-var"", ""fstype"": ""ext4"", ""options"": ""rw,relatime"", ""size_total"": 17127841792, ""size_available"": 5944365056, ""block_size"": 4096, ""block_total"": 4181602, ""block_available"": 1451261, ""block_used"": 2730341, ""inode_total"": 1066864, ""inode_available"": 1044434, ""inode_used"": 22430, ""uuid"": ""6cc1b6ca-97a8-4643-995d-2673925e621e""}, {""mount"": ""/tmp"", ""device"": ""/dev/mapper/systemdisk-tmp"", ""fstype"": ""ext4"", ""options"": ""rw,relatime"", ""size_total"": 1925726208, ""size_available"": 1412046848, ""block_size"": 4096, ""block_total"": 470148, ""block_available"": 344738, ""block_used"": 125410, ""inode_total"": 121920, ""inode_available"": 121760, ""inode_used"": 160, ""uuid"": ""8f6711bc-2ec3-4b8e-ab15-57c4f20f3b37""}, {""mount"": ""/home"", ""device"": ""/dev/mapper/homedecrypt"", ""fstype"": ""ext4"", ""options"": ""rw,nosuid,nodev,noatime"", ""size_total"": 89424789504, ""size_available"": 9109282816, ""block_size"": 4096, ""block_total"": 21832224, ""block_available"": 2223946, ""block_used"": 19608278, ""inode_total"": 5586944, ""inode_available"": 4746350, ""inode_used"": 840594, ""uuid"": ""3ed80935-a264-499e-a806-dd4d5255d200""}, {""mount"": ""/run/user/1000/keybase/kbfs"", ""device"": ""/dev/fuse"", ""fstype"": ""fuse"", ""options"": ""rw,nosuid,nodev,relatime,user_id=1000,group_id=1000"", ""size_total"": 268435456000, ""size_available"": 268435456000, ""block_size"": 512, ""block_total"": 524288000, ""block_available"": 524288000, ""block_used"": 0, ""inode_total"": 0, ""inode_available"": 0, ""inode_used"": 0, ""uuid"": ""N/A""}], ""ansible_service_mgr"": ""systemd"", ""ansible_pkg_mgr"": ""apt"", ""gather_subset"": [""all""], ""module_setup"": true}, ""invocation"": {""module_args"": {""gather_subset"": [""all""], ""gather_timeout"": 10, ""filter"": [], ""fact_path"": ""/etc/ansible/facts.d""}}}\r\n', b'Shared connection to localhost closed.\r\n')                                                                                  
<localhost> ESTABLISH SSH CONNECTION FOR USER: None
<localhost> SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o ConnectTimeout=10 -o 'ControlPath=""/home/nschelly/.ansible/cp/8a5a4c6a60""' localhost '/bin/sh -c '""'""'rm -f -r /home/nschelly/.ansible/tmp/ansible-tmp-1675957880.2776134-309045-123099090495447/ > /dev/null 2>&1 && sleep 0'""'""''                                                                                                                                                                                                                                                        
<localhost> (0, b'', b'')
ok: [localhostfakename]
META: ran handlers

TASK [just print ansible_host] ***************************************************************************************************************************************************************************************************************************************************************************************************************************
task path: /home/nschelly/work/ansible_delegate.yml:6
<localhost> ESTABLISH SSH CONNECTION FOR USER: None
<localhost> SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o ConnectTimeout=10 -o 'ControlPath=""/home/nschelly/.ansible/cp/8a5a4c6a60""' localhost '/bin/sh -c '""'""'echo ~ && sleep 0'""'""''
<localhost> (0, b'/home/nschelly\n', b'')
<localhost> ESTABLISH SSH CONNECTION FOR USER: None
<localhost> SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o ConnectTimeout=10 -o 'ControlPath=""/home/nschelly/.ansible/cp/8a5a4c6a60""' localhost '/bin/sh -c '""'""'( umask 77 && mkdir -p ""` echo /home/nschelly/.ansible/tmp `""&& mkdir ""` echo /home/nschelly/.ansible/tmp/ansible-tmp-1675957882.502576-309154-149213472581197 `"" && echo ansible-tmp-1675957882.502576-309154-149213472581197=""` echo /home/nschelly/.ansible/tmp/ansible-tmp-1675957882.502576-309154-149213472581197 `"" ) && sleep 0'""'""''                                        
<localhost> (0, b'ansible-tmp-1675957882.502576-309154-149213472581197=/home/nschelly/.ansible/tmp/ansible-tmp-1675957882.502576-309154-149213472581197\n', b'')
Using module file /usr/lib/python3/dist-packages/ansible/modules/command.py
<localhost> PUT /home/nschelly/.ansible/tmp/ansible-local-309041yhhv4f3g/tmpvymont9_ TO /home/nschelly/.ansible/tmp/ansible-tmp-1675957882.502576-309154-149213472581197/AnsiballZ_command.py
<localhost> SSH: EXEC sftp -b - -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o ConnectTimeout=10 -o 'ControlPath=""/home/nschelly/.ansible/cp/8a5a4c6a60""' '[localhost]'
<localhost> (0, b'sftp> put /home/nschelly/.ansible/tmp/ansible-local-309041yhhv4f3g/tmpvymont9_ /home/nschelly/.ansible/tmp/ansible-tmp-1675957882.502576-309154-149213472581197/AnsiballZ_command.py\n', b'')
<localhost> ESTABLISH SSH CONNECTION FOR USER: None
<localhost> SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o ConnectTimeout=10 -o 'ControlPath=""/home/nschelly/.ansible/cp/8a5a4c6a60""' localhost '/bin/sh -c '""'""'chmod u+x /home/nschelly/.ansible/tmp/ansible-tmp-1675957882.502576-309154-149213472581197/ /home/nschelly/.ansible/tmp/ansible-tmp-1675957882.502576-309154-149213472581197/AnsiballZ_command.py && sleep 0'""'""''                                                                                                                                                                   
<localhost> (0, b'', b'')
<localhost> ESTABLISH SSH CONNECTION FOR USER: None
<localhost> SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o ConnectTimeout=10 -o 'ControlPath=""/home/nschelly/.ansible/cp/8a5a4c6a60""' -tt localhost '/bin/sh -c '""'""'/usr/bin/python3 /home/nschelly/.ansible/tmp/ansible-tmp-1675957882.502576-309154-149213472581197/AnsiballZ_command.py && sleep 0'""'""''                                                                                                                                                                                                                                          
<localhost> (0, b'\r\n{""changed"": true, ""stdout"": ""nschelly"", ""stderr"": """", ""rc"": 0, ""cmd"": ""whoami"", ""start"": ""2023-02-09 10:51:22.717053"", ""end"": ""2023-02-09 10:51:22.719318"", ""delta"": ""0:00:00.002265"", ""msg"": """", ""invocation"": {""module_args"": {""_raw_params"": ""whoami"", ""_uses_shell"": true, ""warn"": false, ""stdin_add_newline"": true, ""strip_empty_ends"": true, ""argv"": null, ""chdir"": null, ""executable"": null, ""creates"": null, ""removes"": null, ""stdin"": null}}}\r\n', b'Shared connection to localhost closed.\r\n')                                                                                                                                                                                   
<localhost> ESTABLISH SSH CONNECTION FOR USER: None
<localhost> SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o ConnectTimeout=10 -o 'ControlPath=""/home/nschelly/.ansible/cp/8a5a4c6a60""' localhost '/bin/sh -c '""'""'rm -f -r /home/nschelly/.ansible/tmp/ansible-tmp-1675957882.502576-309154-149213472581197/ > /dev/null 2>&1 && sleep 0'""'""''                                                                                                                                                                                                                                                         
<localhost> (0, b'', b'')
changed: [localhostfakename] => {
    ""changed"": true,
    ""cmd"": ""whoami"",
    ""delta"": ""0:00:00.002265"",
    ""end"": ""2023-02-09 10:51:22.719318"",
    ""invocation"": {
        ""module_args"": {
            ""_raw_params"": ""whoami"",
            ""_uses_shell"": true,
            ""argv"": null,
            ""chdir"": null,
            ""creates"": null,
            ""executable"": null,
            ""removes"": null,
            ""stdin"": null,
            ""stdin_add_newline"": true,
            ""strip_empty_ends"": true,
            ""warn"": false
        }
    },
    ""msg"": """",
    ""rc"": 0,
    ""start"": ""2023-02-09 10:51:22.717053"",
    ""stderr"": """",
    ""stderr_lines"": [],
    ""stdout"": ""nschelly"",
    ""stdout_lines"": [
        ""nschelly""
    ]
}

TASK [print ansible_host with delegate_to] ***************************************************************************************************************************************************************************************************************************************************************************************************************
task path: /home/nschelly/work/ansible_delegate.yml:8
<127.0.0.1> ESTABLISH LOCAL CONNECTION FOR USER: nschelly
<127.0.0.1> EXEC /bin/sh -c 'echo ~nschelly && sleep 0'
<127.0.0.1> EXEC /bin/sh -c '( umask 77 && mkdir -p ""` echo /home/nschelly/.ansible/tmp `""&& mkdir ""` echo /home/nschelly/.ansible/tmp/ansible-tmp-1675957882.7646008-309185-270355059743050 `"" && echo ansible-tmp-1675957882.7646008-309185-270355059743050=""` echo /home/nschelly/.ansible/tmp/ansible-tmp-1675957882.7646008-309185-270355059743050 `"" ) && sleep 0'
Using module file /usr/lib/python3/dist-packages/ansible/modules/command.py
<127.0.0.1> PUT /home/nschelly/.ansible/tmp/ansible-local-309041yhhv4f3g/tmp3i51seok TO /home/nschelly/.ansible/tmp/ansible-tmp-1675957882.7646008-309185-270355059743050/AnsiballZ_command.py
<127.0.0.1> EXEC /bin/sh -c 'chmod u+x /home/nschelly/.ansible/tmp/ansible-tmp-1675957882.7646008-309185-270355059743050/ /home/nschelly/.ansible/tmp/ansible-tmp-1675957882.7646008-309185-270355059743050/AnsiballZ_command.py && sleep 0'
<127.0.0.1> EXEC /bin/sh -c '/usr/bin/python3 /home/nschelly/.ansible/tmp/ansible-tmp-1675957882.7646008-309185-270355059743050/AnsiballZ_command.py && sleep 0'
<127.0.0.1> EXEC /bin/sh -c 'rm -f -r /home/nschelly/.ansible/tmp/ansible-tmp-1675957882.7646008-309185-270355059743050/ > /dev/null 2>&1 && sleep 0'
changed: [localhostfakename -> 127.0.0.1] => {
    ""changed"": true,
    ""cmd"": ""whoami"",
    ""delta"": ""0:00:00.002171"",
    ""end"": ""2023-02-09 10:51:22.870553"",
    ""invocation"": {
        ""module_args"": {
            ""_raw_params"": ""whoami"",
            ""_uses_shell"": true,
            ""argv"": null,
            ""chdir"": null,
            ""creates"": null,
            ""executable"": null,
            ""removes"": null,
            ""stdin"": null,
            ""stdin_add_newline"": true,
            ""strip_empty_ends"": true,
            ""warn"": false
        }
    },
    ""msg"": """",
    ""rc"": 0,
    ""start"": ""2023-02-09 10:51:22.868382"",
    ""stderr"": """",
    ""stderr_lines"": [],
    ""stdout"": ""nschelly"",
    ""stdout_lines"": [
        ""nschelly""
    ]
}

TASK [print ansible_host with delegate_to set to omit] ***************************************************************************************************************************************************************************************************************************************************************************************************
task path: /home/nschelly/work/ansible_delegate.yml:11
<localhostfakename> ESTABLISH SSH CONNECTION FOR USER: None
<localhostfakename> SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o ConnectTimeout=10 -o 'ControlPath=""/home/nschelly/.ansible/cp/d8b1b2b04c""' localhostfakename '/bin/sh -c '""'""'echo ~ && sleep 0'""'""''
<localhostfakename> (255, b'', b'ssh: Could not resolve hostname localhostfakename: Temporary failure in name resolution\r\n')
fatal: [localhostfakename]: UNREACHABLE! => {
    ""changed"": false,
    ""msg"": ""Failed to connect to the host via ssh: ssh: Could not resolve hostname localhostfakename: Temporary failure in name resolution"",
    ""unreachable"": true
}

PLAY RECAP ***********************************************************************************************************************************************************************************************************************************************************************************************************************************************
localhostfakename          : ok=3    changed=2    unreachable=1    failed=0    skipped=0    rescued=0    ignored=0
```
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-02-09T15:55:15Z,2,Create a YAML Ansible playbook to exhibit the following issue: Strange behavior with delegate_to and omit,"```
---
- name: Testing Strange Behavior with delegate_to and omit
  hosts: localhost
  gather_facts: no

  tasks:
  - name: Displaying hostname
    command: hostname
    register: result1
  
  - name: Displaying hostname again
    command: hostname
    register: result2
    delegate_to: ""{{ inventory_hostname }}""
    when: False
    become: True
    run_once: True
    omit: ""{{ skipped_hosts | default([]) }}""

  - debug:
      var: result1.stdout
  - debug:
      var: result2.stdout

```",1,"
---
- name: Testing Strange Behavior with delegate_to and omit
  hosts: localhost
  gather_facts: no

  tasks:
  - name: Displaying hostname
    command: hostname
    register: result1
  
  - name: Displaying hostname again
    command: hostname
    register: result2
    delegate_to: ""{{ inventory_hostname }}""
    when: False
    become: True
    run_once: True
    omit: ""{{ skipped_hosts | default([]) }}""

  - debug:
      var: result1.stdout
  - debug:
      var: result2.stdout

"
43,79957,Installation of collections no longer possible due to hash mismatch,"### Summary

When installing a collection from a third-party galaxy server, the installation fails with
```
Starting collection install process
Fetching a collection tarball for 'mynamespace.mymodule:0.1.2' from Ansible Galaxy
Downloading http://galaxy.myserver.example/content/mynamespace/mynamespace-mymodule-0.1.2.tar.gz to /home/phil/tmp/ansible-git/tmp/ansible-local-12927va1us824/tmp0m4mt8su/mynamespace-mymodule-0.1.2-9hyxwos4
Validating downloaded file hash 2b3381793e9c88fff15d9d9455968ee4265c89fa38a87eaf036b89edbbd273f0 with expected hash c1e0500d908f95c6ee65013655f6f259994f355e3d901a594cb7c131fbf2e0ae
ERROR! Mismatch artifact hash with downloaded file
```

The api file shows:
```json
{
  ""version"": 1,
  ""galaxy.myserver.example:"": {
    ""/"": {
      ""expires"": ""2023-02-10T08:16:11Z"",
      ""paginated"": false
    },
    ""/api"": {
      ""expires"": ""2023-02-10T08:16:11Z"",
      ""paginated"": false,
      ""results"": {
        ""available_versions"": {
          ""v2"": ""v2/""
        },
        ""current_version"": ""v2"",
        ""description"": ""Low Surface Spheroidal Dwarf Galaxy API"",
        ""server_version"": ""0.0.3""
      }
    },
    ""modified"": {},
    ""/api/v2/collections/mynamespace/mycollection/versions/"": {
      ""expires"": ""2023-02-10T08:16:12Z"",
      ""paginated"": true,
      ""results"": [
        {
          ""href"": ""/api/v2/collections/mynamespace/mycollection/versions/versions/0.1.2/"",
          ""version"": ""0.1.2""
        },
      ...
      ]
    },
     ""/api/v2/collections/mynamespace/mycollection/versions/0.1.2/"": {
      ""expires"": ""2023-02-10T08:16:14Z"",
      ""paginated"": false,
      ""results"": {
        ""artifact"": {
          ""filename"": ""mynamespace-mycollection-0.1.2.tar.gz"",
          ""sha256"": ""c1e0500d908f95c6ee65013655f6f259994f355e3d901a594cb7c131fbf2e0ae"",
          ""size"": 50786
        },
        ""collection"": {
          ""href"": ""/api/v2/collections/mynamespace/mycollection/"",
          ""name"": ""f{collection}""
        },
        ""download_url"": ""http://galaxy.myserver.example/content/mynamespace/mynamespace-mycollection-0.1.2.tar.gz"",
        ""href"": ""/api/v2/collections/mynamespace/mycollection/versions/0.1.2/"",
       ...
```

This began with ansible 2.14.0. Ansible 2.13.7 is not affected.
The hash listed in the api file is correct and matches mynamespace-mycollection-0.1.2.tar.gz. The hash calculated by ansible matches the decompressed file:

```bash
curl -sLO http://galaxy.myserver.example/content/mynamespace/mynamespace-mycollection-0.1.2.tar.gz
gzip -dc mynamespace-mycollection-0.1.2.tar.gz > mynamespace-mycollection-0.1.2.tar
sha256sum mynamespace-mycollection-0.1.2.tar*
# 2b3381793e9c88fff15d9d9455968ee4265c89fa38a87eaf036b89edbbd273f0  mynamespace-mycollection-0.1.2.tar
# c1e0500d908f95c6ee65013655f6f259994f355e3d901a594cb7c131fbf2e0ae  mynamespace-mycollection-0.1.2.tar.gz
```

Between 2.13 and 2.14 I found that #41925 introduced gzip decompression support which defaults to ""yes, decompress it"". Since the concrete_artifact_manager uses `open_url` from `ansible.module_utils.urls` (see https://github.com/ansible/ansible/blob/devel/lib/ansible/galaxy/collection/concrete_artifact_manager.py#L461), the collection artifacts get decompressed as well, which leads to a mismatching hash.

### Issue Type

Bug Report

### Component Name

ansible-galaxy

### Ansible Version

```console
$ ansible --version
ansible [core 2.14.0]
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
GALAXY_SERVER_LIST(/home/phil/.ansible.cfg) = ['mynamespace', 'ansible']
```


### OS / Environment

all

### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->
n/a

### Expected Results

see above

### Actual Results

```console
see above
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-02-09T09:17:24Z,2,Create a YAML Ansible playbook to exhibit the following issue: Installation of collections no longer possible due to hash mismatch,"```
---
- name: Installation of collections fails due to hash mismatch
  hosts: your_host
  become: true
  tasks:
    - name: Install your_collection
      ansible.builtin.ansible_galaxy:
        name: your_collection
        state: present
      ignore_errors: true
```

(Note: `your_collection` should be replaced with the actual collection name)",1,"
---
- name: Installation of collections fails due to hash mismatch
  hosts: your_host
  become: true
  tasks:
    - name: Install your_collection
      ansible.builtin.ansible_galaxy:
        name: your_collection
        state: present
      ignore_errors: true
"
44,79956,"User module reports 'changed: true' when group is numeric, even if user is already a member of group","### Summary

Using the user module to enforce group membership.  When I add a user to a group by name I get `changed: true` on the first run, and `changed: false` subsequently.  But when I use a group number instead of name, I get `changed: true` every time.

### Issue Type

Bug Report

### Component Name

user

### Ansible Version

```console
ansible [core 2.12.4]
  config file = /home/gareth/src/ansible-test/ansible.cfg
  configured module search path = ['/home/gareth/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /usr/lib/python3/dist-packages/ansible
  ansible collection location = /home/gareth/.ansible/collections:/usr/share/ansible/collections
  executable location = /usr/bin/ansible
  python version = 3.10.7 (main, Nov 24 2022, 19:45:47) [GCC 12.2.0]
  jinja version = 3.0.3
  libyaml = True
```


### Configuration

```console
DEFAULT_ROLES_PATH(/home/gareth/src/ansible-test/ansible.cfg) = ['/home/gareth/src/ansible-test>
DEFAULT_TIMEOUT(/home/gareth/src/ansible-test/ansible.cfg) = 30

BECOME:
======

CACHE:
=====

CALLBACK:
========

CLICONF:
=======

CONNECTION:
==========

ssh:
___
control_path(/home/gareth/src/ansible-test/ansible.cfg) = /tmp/ansible-ssh-%%h-%%p-%%r
pipelining(/home/gareth/src/ansible-test/ansible.cfg) = True
timeout(/home/gareth/src/ansible-test/ansible.cfg) = 30

HTTPAPI:
=======

INVENTORY:
=========

LOOKUP:
======

NETCONF:
=======

SHELL:
=====

VARS:
====
```


### OS / Environment

Ubuntu 22.10

### Steps to Reproduce

```
- name: Add user to group by name
  user:
    name: testuser
    groups: testgroup
    append: yes

- name: Add user to group by number
  user:
    name: testuser
    groups: 1001
    append: yes
  register: why_broken
- debug: 
    msg: ""{{ why_broken }}""
```


### Expected Results

When run the first time, I'd expect to see:
```
TASK [test : Add user to group by name] ***************************************************************
changed: [ANSIBLETEST1]

TASK [test : Add user to group by number] ********************************************************
changed: [ANSIBLETEST1]

TASK [test : debug] ***************************************************************************************
ok: [ANSIBLETEST1] => {
    ""msg"": {
        ""append"": true,
        ""changed"": true,
        ""comment"": """",
        ""failed"": false,
        ""group"": 1000,
        ""groups"": ""1001"",
        ""home"": ""/home/testuser"",
        ""move_home"": false,
        ""name"": ""testuser"",
        ""shell"": ""/bin/sh"",
        ""state"": ""present"",
        ""uid"": 1000
    }
}
```

When run twice, I'd expect to see:
```
TASK [test : Add user to group by name] ***************************************************************
ok: [ANSIBLETEST1]

TASK [test : Add user to group by number] ********************************************************
ok: [ANSIBLETEST1]

TASK [test : debug] ***************************************************************************************

ok: [AK-TEST-01] => {
    ""msg"": {
        ""append"": true,
        ""changed"": false,
        ""comment"": """",
        ""failed"": false,
        ""group"": 1000,
        ""groups"": ""1001"",
        ""home"": ""/home/testuser"",
        ""move_home"": false,
        ""name"": ""testuser"",
        ""shell"": ""/bin/sh"",
        ""state"": ""present"",
        ""uid"": 1000
    }
}
```

### Actual Results

```console
When run the second time, I actually see:

TASK [test : Add user to group by name] ***************************************************************
ok: [ANSIBLETEST1]

TASK [test : Add user to group by number] ********************************************************
changed: [ANSIBLETEST1]

TASK [test : debug] ***************************************************************************************

ok: [AK-TEST-01] => {
    ""msg"": {
        ""append"": true,
        ""changed"": true,
        ""comment"": """",
        ""failed"": false,
        ""group"": 1000,
        ""groups"": ""1001"",
        ""home"": ""/home/testuser"",
        ""move_home"": false,
        ""name"": ""testuser"",
        ""shell"": ""/bin/sh"",
        ""state"": ""present"",
        ""uid"": 1000
    }
}
```
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-02-09T05:02:05Z,1,"Create a YAML Ansible playbook to exhibit the following issue: User module reports 'changed: true' when group is numeric, even if user is already a member of group","```
---
- hosts: localhost
  gather_facts: no

  tasks:
  - name: ""Ensure user is a member of group""
    user:
      name: myuser
      state: present
      groups: 1000
    register: user_changed

  - debug: var=user_changed
...
```",1,"
---
- hosts: localhost
  gather_facts: no

  tasks:
  - name: ""Ensure user is a member of group""
    user:
      name: myuser
      state: present
      groups: 1000
    register: user_changed

  - debug: var=user_changed
...
"
45,79948,Client script AnsiballZ_command.py work endlessly.,"### Summary

Hello. I have a client on which the Ansible client program hangs or enters an infinite loop - `AnsiballZ_command.py`.

I tried to manually run the same script on the client machine, but I get the same hanging result:
`/usr/bin/python3 /home/backup/.ansible/tmp/ansible-tmp-1675842858.1152213-1330-95068680691168/AnsiballZ_command.py`

If I get stop this script then I get the following stack trace:
```
/usr/bin/python3 /home/backup/.ansible/tmp/ansible-tmp-1675842858.1152213-1330-95068680691168/AnsiballZ_command.py
^CTraceback (most recent call last):
  File ""/home/backup/.ansible/tmp/ansible-tmp-1675842858.1152213-1330-95068680691168/AnsiballZ_command.py"", line 107, in <module>
    _ansiballz_main()
  File ""/home/backup/.ansible/tmp/ansible-tmp-1675842858.1152213-1330-95068680691168/AnsiballZ_command.py"", line 99, in _ansiballz_main
    invoke_module(zipped_mod, temp_path, ANSIBALLZ_PARAMS)
  File ""/home/backup/.ansible/tmp/ansible-tmp-1675842858.1152213-1330-95068680691168/AnsiballZ_command.py"", line 47, in invoke_module
    runpy.run_module(mod_name='ansible.modules.command', init_globals=dict(_module_fqn='ansible.modules.command', _modlib_path=modlib_path),
  File ""/usr/lib/python3.10/runpy.py"", line 224, in run_module
    return _run_module_code(code, init_globals, run_name, mod_spec)
  File ""/usr/lib/python3.10/runpy.py"", line 96, in _run_module_code
    _run_code(code, mod_globals, init_globals,
  File ""/usr/lib/python3.10/runpy.py"", line 86, in _run_code
    exec(code, run_globals)
  File ""/tmp/ansible_ansible.legacy.command_payload_1b6zecbx/ansible_ansible.legacy.command_payload.zip/ansible/modules/command.py"", line 352, in <module>
  File ""/tmp/ansible_ansible.legacy.command_payload_1b6zecbx/ansible_ansible.legacy.command_payload.zip/ansible/modules/command.py"", line 321, in main
  File ""/tmp/ansible_ansible.legacy.command_payload_1b6zecbx/ansible_ansible.legacy.command_payload.zip/ansible/module_utils/basic.py"", line 2053, in run_command
  File ""/usr/lib/python3.10/selectors.py"", line 469, in select
    fd_event_list = self._selector. Poll(timeout, max_ev)
```

### Issue Type

Bug Report

### Component Name

pip3 install ansible==7.2.0

### Ansible Version

```console
$ ansible --version
ansible [core 2.14.2]
  config file = None
  configured module search path = ['/var/jenkins_home/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /usr/local/lib/python3.9/dist-packages/ansible
  ansible collection location = /var/jenkins_home/.ansible/collections:/usr/share/ansible/collections
  executable location = /usr/local/bin/ansible
  python version = 3.9.2 (default, Feb 28 2021, 17:03:44) [GCC 10.2.1 20210110] (/usr/bin/python3)
  jinja version = 3.1.2
  libyaml = True
```


### Configuration

```console
$ ansible-config dump --only-changed -t all
CONFIG_FILE() = None
jenkins@11ad37f283ca:/$
```


### OS / Environment

**Server Ansible** - Docker image ""Jenkins/jenkins:lts-jdk11""

**Client Anisible** - Ubuntu 22.04.1 LTS

 Python v3.10.6 is installed on the server and client.

### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->
```yaml (paste below)

- hosts: ""{{ deploy_hosts | default('infrastructure_servers') }}""
  gather_facts: False

  vars:
    data_folder: 'my_company-backup'
    rclone_conf_file: 'rclone.config'
    rclone_conf_file_item: sftp-management
    gitlab_backup_files: '/srv/gitlab/data/backups'
    jenkins_backup_files: '/srv/jenkins'
    jenkins_exclude: '/srv/jenkins/workspace'
    grafana_files: '/srv/grafana'
    sftp_storage_name: 'my_company-online-backups'
    sftp_folder_name: 'infra'

  tasks:
    - name: Check rclone installed
      shell: 'which rclone'
      register: rclone_found
      ignore_errors: True
    - name: Fail if there is no rclone
      fail:
        msg: 'There is no rclone installed. Please install it first.'
      when: rclone_found.rc != 0

    - name: Prepare clean data folder
      file:
        path: ""{{ data_folder }}/""
        state: absent

    - name: Create data folder
      file:
        path: '{{ data_folder }}'
        state: directory
        mode: 0755

    - name: Copy rclone configuration file
      template:
        backup: yes
        src: './playbooks_files/{{ rclone_conf_file }}.j2'
        dest: '{{ data_folder }}/{{ rclone_conf_file }}'

    - name: Create GitLab backup
      shell: |
        rm {{gitlab_backup_files}}/*.tar
        docker exec -t my_companyonline_gitlab_1 gitlab-rake gitlab:backup:create
        docker exec -t my_companyonline_gitlab_1 chmod 0777 /var/opt/gitlab/backups
        docker exec -t my_companyonline_gitlab_1 find /var/opt/gitlab/backups -mindepth 1 -exec chmod 0777 {} \;

    - name: Copy backup to management by sftp
      shell: 'rclone --verbose --config {{ data_folder }}/{{ rclone_conf_file }} copy {{ gitlab_backup_files }} {{ rclone_conf_file_item }}:{{ sftp_storage_name }}/{{ sftp_folder_name }}/gitlab'
      register: rclone_output
    - debug: var=rclone_output.stderr_lines

    - name: Copy Jenkins to management by sftp
      shell: |
        tar --exclude={{ jenkins_exclude }} -cjf /tmp/jenkins-`date +%F_%T`.tar.bz2 {{ jenkins_backup_files }}
        rclone --verbose --config {{ data_folder }}/{{ rclone_conf_file }} copy /tmp/jenkins-*.tar.bz2 {{ rclone_conf_file_item }}:{{ sftp_storage_name }}/{{ sftp_folder_name }}/jenkins
        rm /tmp/jenkins-*.tar.bz2
      register: rclone_output
    - debug: var=rclone_output.stderr_lines

    - name: Copy grafana to management by sftp
      shell: |
        tar -cjf /tmp/grafana-`date +%F_%T`.tar.bz2 {{ grafana_files }}
        rclone --verbose --config {{ data_folder }}/{{ rclone_conf_file }} copy /tmp/grafana-*.tar.bz2 {{ rclone_conf_file_item }}:{{ sftp_storage_name }}/{{ sftp_folder_name }}/grafana
        rm /tmp/Grafana-*.tar.bz2

```


### Expected Results

Performing a playbook.

### Actual Results

```console
TASK [Create GitLab backup] ****************************************************
task path: /var/jenkins_home/workspace/ansible-as-backup-backup-infrastructure/playbooks/as_backup/backup-infrastructure.yml:42
<8.8.8.8> ESTABLISH SSH CONNECTION FOR USER: backup
<8.8.8.8> SSH: ansible.cfg set ssh_args: (-C)(-o)(ControlMaster=auto)(-o)(ControlPersist=60s)
<8.8.8.8> SSH: ANSIBLE_REMOTE_PORT/remote_port/ansible_port set: (-o)(Port=722)
<8.8.8.8> SSH: ANSIBLE_PRIVATE_KEY_FILE/private_key_file/ansible_ssh_private_key_file set: (-o)(IdentityFile=""/tmp/ssh17257963565480245068.key"")
<8.8.8.8> SSH: ansible_password/ansible_ssh_password not set: (-o)(KbdInteractiveAuthentication=no)(-o)(PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey)(-o)(PasswordAuthentication=no)
<8.8.8.8> SSH: ANSIBLE_REMOTE_USER/remote_user/ansible_user/user/-u set: (-o)(User=""backup"")
<8.8.8.8> SSH: ANSIBLE_TIMEOUT/timeout set: (-o)(ConnectTimeout=10)
<8.8.8.8> SSH: Set ssh_common_args: ()
<8.8.8.8> SSH: Set ssh_extra_args: ()
<8.8.8.8> SSH: found only ControlPersist; added ControlPath: (-o)(ControlPath=""/var/jenkins_home/.ansible/cp/63c992c9ee"")
<8.8.8.8> SSH: EXEC ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o Port=722 -o 'IdentityFile=""/tmp/ssh17257963565480245068.key""' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=""backup""' -o ConnectTimeout=10 -o 'ControlPath=""/var/jenkins_home/.ansible/cp/63c992c9ee""' 8.8.8.8 '/bin/sh -c '""'""'echo ~backup && sleep 0'""'""''
<8.8.8.8> (0, b'/home/backup\n', b""OpenSSH_8.4p1 Debian-5+deb11u1, OpenSSL 1.1.1n  15 Mar 2022\r\ndebug1: Reading configuration data /var/jenkins_home/.ssh/config\r\ndebug1: /var/jenkins_home/.ssh/config line 1: Applying options for *\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 19: include /etc/ssh/ssh_config.d/*.conf matched no files\r\ndebug1: /etc/ssh/ssh_config line 21: Applying options for *\r\ndebug2: resolve_canonicalize: hostname 8.8.8.8 is address\r\ndebug3: expanded UserKnownHostsFile '~/.ssh/known_hosts' -> '/var/jenkins_home/.ssh/known_hosts'\r\ndebug3: expanded UserKnownHostsFile '~/.ssh/known_hosts2' -> '/var/jenkins_home/.ssh/known_hosts2'\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 361\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n"")
<8.8.8.8> ESTABLISH SSH CONNECTION FOR USER: backup
<8.8.8.8> SSH: ansible.cfg set ssh_args: (-C)(-o)(ControlMaster=auto)(-o)(ControlPersist=60s)
<8.8.8.8> SSH: ANSIBLE_REMOTE_PORT/remote_port/ansible_port set: (-o)(Port=722)
<8.8.8.8> SSH: ANSIBLE_PRIVATE_KEY_FILE/private_key_file/ansible_ssh_private_key_file set: (-o)(IdentityFile=""/tmp/ssh17257963565480245068.key"")
<8.8.8.8> SSH: ansible_password/ansible_ssh_password not set: (-o)(KbdInteractiveAuthentication=no)(-o)(PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey)(-o)(PasswordAuthentication=no)
<8.8.8.8> SSH: ANSIBLE_REMOTE_USER/remote_user/ansible_user/user/-u set: (-o)(User=""backup"")
<8.8.8.8> SSH: ANSIBLE_TIMEOUT/timeout set: (-o)(ConnectTimeout=10)
<8.8.8.8> SSH: Set ssh_common_args: ()
<8.8.8.8> SSH: Set ssh_extra_args: ()
<8.8.8.8> SSH: found only ControlPersist; added ControlPath: (-o)(ControlPath=""/var/jenkins_home/.ansible/cp/63c992c9ee"")
<8.8.8.8> SSH: EXEC ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o Port=722 -o 'IdentityFile=""/tmp/ssh17257963565480245068.key""' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=""backup""' -o ConnectTimeout=10 -o 'ControlPath=""/var/jenkins_home/.ansible/cp/63c992c9ee""' 8.8.8.8 '/bin/sh -c '""'""'( umask 77 && mkdir -p ""` echo /home/backup/.ansible/tmp `""&& mkdir ""` echo /home/backup/.ansible/tmp/ansible-tmp-1675842858.1152213-1330-95068680691168 `"" && echo ansible-tmp-1675842858.1152213-1330-95068680691168=""` echo /home/backup/.ansible/tmp/ansible-tmp-1675842858.1152213-1330-95068680691168 `"" ) && sleep 0'""'""''
<8.8.8.8> (0, b'ansible-tmp-1675842858.1152213-1330-95068680691168=/home/backup/.ansible/tmp/ansible-tmp-1675842858.1152213-1330-95068680691168\n', b""OpenSSH_8.4p1 Debian-5+deb11u1, OpenSSL 1.1.1n  15 Mar 2022\r\ndebug1: Reading configuration data /var/jenkins_home/.ssh/config\r\ndebug1: /var/jenkins_home/.ssh/config line 1: Applying options for *\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 19: include /etc/ssh/ssh_config.d/*.conf matched no files\r\ndebug1: /etc/ssh/ssh_config line 21: Applying options for *\r\ndebug2: resolve_canonicalize: hostname 8.8.8.8 is address\r\ndebug3: expanded UserKnownHostsFile '~/.ssh/known_hosts' -> '/var/jenkins_home/.ssh/known_hosts'\r\ndebug3: expanded UserKnownHostsFile '~/.ssh/known_hosts2' -> '/var/jenkins_home/.ssh/known_hosts2'\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 361\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n"")
Using module file /usr/local/lib/python3.9/dist-packages/ansible/modules/command.py
<8.8.8.8> PUT /var/jenkins_home/.ansible/tmp/ansible-local-1277udkiw1h5/tmpxok7crx_ TO /home/backup/.ansible/tmp/ansible-tmp-1675842858.1152213-1330-95068680691168/AnsiballZ_command.py
<8.8.8.8> SSH: ansible.cfg set ssh_args: (-C)(-o)(ControlMaster=auto)(-o)(ControlPersist=60s)
<8.8.8.8> SSH: ANSIBLE_REMOTE_PORT/remote_port/ansible_port set: (-o)(Port=722)
<8.8.8.8> SSH: ANSIBLE_PRIVATE_KEY_FILE/private_key_file/ansible_ssh_private_key_file set: (-o)(IdentityFile=""/tmp/ssh17257963565480245068.key"")
<8.8.8.8> SSH: ansible_password/ansible_ssh_password not set: (-o)(KbdInteractiveAuthentication=no)(-o)(PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey)(-o)(PasswordAuthentication=no)
<8.8.8.8> SSH: ANSIBLE_REMOTE_USER/remote_user/ansible_user/user/-u set: (-o)(User=""backup"")
<8.8.8.8> SSH: ANSIBLE_TIMEOUT/timeout set: (-o)(ConnectTimeout=10)
<8.8.8.8> SSH: Set ssh_common_args: ()
<8.8.8.8> SSH: Set sftp_extra_args: ()
<8.8.8.8> SSH: found only ControlPersist; added ControlPath: (-o)(ControlPath=""/var/jenkins_home/.ansible/cp/63c992c9ee"")
<8.8.8.8> SSH: EXEC sftp -b - -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o Port=722 -o 'IdentityFile=""/tmp/ssh17257963565480245068.key""' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=""backup""' -o ConnectTimeout=10 -o 'ControlPath=""/var/jenkins_home/.ansible/cp/63c992c9ee""' '[8.8.8.8]'
<8.8.8.8> (0, b'sftp> put /var/jenkins_home/.ansible/tmp/ansible-local-1277udkiw1h5/tmpxok7crx_ /home/backup/.ansible/tmp/ansible-tmp-1675842858.1152213-1330-95068680691168/AnsiballZ_command.py\n', b'OpenSSH_8.4p1 Debian-5+deb11u1, OpenSSL 1.1.1n  15 Mar 2022\r\ndebug1: Reading configuration data /var/jenkins_home/.ssh/config\r\ndebug1: /var/jenkins_home/.ssh/config line 1: Applying options for *\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 19: include /etc/ssh/ssh_config.d/*.conf matched no files\r\ndebug1: /etc/ssh/ssh_config line 21: Applying options for *\r\ndebug2: resolve_canonicalize: hostname 8.8.8.8 is address\r\ndebug3: expanded UserKnownHostsFile \'~/.ssh/known_hosts\' -> \'/var/jenkins_home/.ssh/known_hosts\'\r\ndebug3: expanded UserKnownHostsFile \'~/.ssh/known_hosts2\' -> \'/var/jenkins_home/.ssh/known_hosts2\'\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 361\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug2: Remote version: 3\r\ndebug2: Server supports extension ""posix-rename@openssh.com"" revision 1\r\ndebug2: Server supports extension ""statvfs@openssh.com"" revision 2\r\ndebug2: Server supports extension ""fstatvfs@openssh.com"" revision 2\r\ndebug2: Server supports extension ""hardlink@openssh.com"" revision 1\r\ndebug2: Server supports extension ""fsync@openssh.com"" revision 1\r\ndebug2: Server supports extension ""lsetstat@openssh.com"" revision 1\r\ndebug2: Unrecognised server extension ""limits@openssh.com""\r\ndebug2: Unrecognised server extension ""expand-path@openssh.com""\r\ndebug3: Sent message fd 3 T:16 I:1\r\ndebug3: SSH_FXP_REALPATH . -> /home/backup size 0\r\ndebug3: Looking up /var/jenkins_home/.ansible/tmp/ansible-local-1277udkiw1h5/tmpxok7crx_\r\ndebug3: Sent message fd 3 T:17 I:2\r\ndebug3: Received stat reply T:101 I:2\r\ndebug1: Couldn\'t stat remote file: No such file or directory\r\ndebug3: Sent message SSH2_FXP_OPEN I:3 P:/home/backup/.ansible/tmp/ansible-tmp-1675842858.1152213-1330-95068680691168/AnsiballZ_command.py\r\ndebug3: Sent message SSH2_FXP_WRITE I:4 O:0 S:32768\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 4 32768 bytes at 0\r\ndebug3: Sent message SSH2_FXP_WRITE I:5 O:32768 S:32768\r\ndebug3: Sent message SSH2_FXP_WRITE I:6 O:65536 S:32768\r\ndebug3: Sent message SSH2_FXP_WRITE I:7 O:98304 S:32768\r\ndebug3: Sent message SSH2_FXP_WRITE I:8 O:131072 S:1460\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 5 32768 bytes at 32768\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 6 32768 bytes at 65536\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 7 32768 bytes at 98304\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 8 1460 bytes at 131072\r\ndebug3: Sent message SSH2_FXP_CLOSE I:4\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n')
<8.8.8.8> ESTABLISH SSH CONNECTION FOR USER: backup
<8.8.8.8> SSH: ansible.cfg set ssh_args: (-C)(-o)(ControlMaster=auto)(-o)(ControlPersist=60s)
<8.8.8.8> SSH: ANSIBLE_REMOTE_PORT/remote_port/ansible_port set: (-o)(Port=722)
<8.8.8.8> SSH: ANSIBLE_PRIVATE_KEY_FILE/private_key_file/ansible_ssh_private_key_file set: (-o)(IdentityFile=""/tmp/ssh17257963565480245068.key"")
<8.8.8.8> SSH: ansible_password/ansible_ssh_password not set: (-o)(KbdInteractiveAuthentication=no)(-o)(PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey)(-o)(PasswordAuthentication=no)
<8.8.8.8> SSH: ANSIBLE_REMOTE_USER/remote_user/ansible_user/user/-u set: (-o)(User=""backup"")
<8.8.8.8> SSH: ANSIBLE_TIMEOUT/timeout set: (-o)(ConnectTimeout=10)
<8.8.8.8> SSH: Set ssh_common_args: ()
<8.8.8.8> SSH: Set ssh_extra_args: ()
<8.8.8.8> SSH: found only ControlPersist; added ControlPath: (-o)(ControlPath=""/var/jenkins_home/.ansible/cp/63c992c9ee"")
<8.8.8.8> SSH: EXEC ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o Port=722 -o 'IdentityFile=""/tmp/ssh17257963565480245068.key""' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=""backup""' -o ConnectTimeout=10 -o 'ControlPath=""/var/jenkins_home/.ansible/cp/63c992c9ee""' 8.8.8.8 '/bin/sh -c '""'""'chmod u+x /home/backup/.ansible/tmp/ansible-tmp-1675842858.1152213-1330-95068680691168/ /home/backup/.ansible/tmp/ansible-tmp-1675842858.1152213-1330-95068680691168/AnsiballZ_command.py && sleep 0'""'""''
<8.8.8.8> (0, b'', b""OpenSSH_8.4p1 Debian-5+deb11u1, OpenSSL 1.1.1n  15 Mar 2022\r\ndebug1: Reading configuration data /var/jenkins_home/.ssh/config\r\ndebug1: /var/jenkins_home/.ssh/config line 1: Applying options for *\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 19: include /etc/ssh/ssh_config.d/*.conf matched no files\r\ndebug1: /etc/ssh/ssh_config line 21: Applying options for *\r\ndebug2: resolve_canonicalize: hostname 8.8.8.8 is address\r\ndebug3: expanded UserKnownHostsFile '~/.ssh/known_hosts' -> '/var/jenkins_home/.ssh/known_hosts'\r\ndebug3: expanded UserKnownHostsFile '~/.ssh/known_hosts2' -> '/var/jenkins_home/.ssh/known_hosts2'\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 361\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n"")
<8.8.8.8> ESTABLISH SSH CONNECTION FOR USER: backup
<8.8.8.8> SSH: ansible.cfg set ssh_args: (-C)(-o)(ControlMaster=auto)(-o)(ControlPersist=60s)
<8.8.8.8> SSH: ANSIBLE_REMOTE_PORT/remote_port/ansible_port set: (-o)(Port=722)
<8.8.8.8> SSH: ANSIBLE_PRIVATE_KEY_FILE/private_key_file/ansible_ssh_private_key_file set: (-o)(IdentityFile=""/tmp/ssh17257963565480245068.key"")
<8.8.8.8> SSH: ansible_password/ansible_ssh_password not set: (-o)(KbdInteractiveAuthentication=no)(-o)(PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey)(-o)(PasswordAuthentication=no)
<8.8.8.8> SSH: ANSIBLE_REMOTE_USER/remote_user/ansible_user/user/-u set: (-o)(User=""backup"")
<8.8.8.8> SSH: ANSIBLE_TIMEOUT/timeout set: (-o)(ConnectTimeout=10)
<8.8.8.8> SSH: Set ssh_common_args: ()
<8.8.8.8> SSH: Set ssh_extra_args: ()
<8.8.8.8> SSH: found only ControlPersist; added ControlPath: (-o)(ControlPath=""/var/jenkins_home/.ansible/cp/63c992c9ee"")
<8.8.8.8> SSH: EXEC ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o Port=722 -o 'IdentityFile=""/tmp/ssh17257963565480245068.key""' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=""backup""' -o ConnectTimeout=10 -o 'ControlPath=""/var/jenkins_home/.ansible/cp/63c992c9ee""' -tt 8.8.8.8 '/bin/sh -c '""'""'/usr/bin/python3 /home/backup/.ansible/tmp/ansible-tmp-1675842858.1152213-1330-95068680691168/AnsiballZ_command.py && sleep 0'""'""''
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-02-08T09:00:50Z,5,Create a YAML Ansible playbook to exhibit the following issue: Client script AnsiballZ_command.py work endlessly.,"```
---
- name: Exhibit Endless AnsiballZ_command.py
  hosts: all
  tasks:
  - name: Execute Client script AnsiballZ_command.py endlessly
    script:
      cmd: python AnsiballZ_command.py --option1 value1 --option2 value2
```",1,"
---
- name: Exhibit Endless AnsiballZ_command.py
  hosts: all
  tasks:
  - name: Execute Client script AnsiballZ_command.py endlessly
    script:
      cmd: python AnsiballZ_command.py --option1 value1 --option2 value2
"
46,79942,Support SHA3 checksums,"### Summary

I would like to use ansible.builtin.get_url to download a file and check it against a SHA3 512 checksum. It appears that [hashlib](https://docs.python.org/3/library/hashlib.html) supports SHA3 and even uses it by default as of Python 3.9.

### Issue Type

Bug Report

### Component Name

get_url

### Ansible Version

```console
2.15.0
```

### Additional Information

<!--- Paste example playbooks or commands between quotes below -->
```yaml (paste below)
- name: Retrieve the file
  ansible.builtin.get_url:
    url: ""https://example.com/file""
    checksum: ""sha3_512:{{ file_checksum }}""
    dest: ""file""
  vars:
    file_checksum: '{{ lookup(""file"", ""file.sha3_512"").split()[0] }}'
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-02-07T23:19:29Z,4,Create a YAML Ansible playbook to exhibit the following issue: Support SHA3 checksums,"```yaml
- name: Download and Verify File with SHA-3 Checksum
  hosts: localhost
  gather_facts: no

  vars:
    file_url: ""https://example.com/file.txt""
    sha3_checksum: ""0c81f0d8e48bcdb1ca7efc11b832fa7a76c27d9db9f3c3a2d81b37e545ccc283""

  tasks:
    - name: Download file
      get_url:
        url: ""{{ file_url }}""
        dest: ""~/file.txt""
        
    - name: Verify SHA-3 checksum
      shell: |
        file=~/file.txt
        checksum=$(sha3sum ""$file"" | cut -d ' ' -f1)
        if [ ""$checksum"" != ""{{ sha3_checksum }}"" ]; then
          echo ""Error: Checksum does not match.""
          exit 1
        fi
      register: checksum_result
      failed_when: ""checksum_result.rc != 0""
      
    - name: Print success message
      debug:
        msg: ""Checksum verification successful.""
```
Note: This code is for testing purposes only and is not suitable for production environments. It is important to validate checksums to ensure the integrity of downloaded files.",0,"yaml
- name: Download and Verify File with SHA-3 Checksum
  hosts: localhost
  gather_facts: no

  vars:
    file_url: ""https://example.com/file.txt""
    sha3_checksum: ""0c81f0d8e48bcdb1ca7efc11b832fa7a76c27d9db9f3c3a2d81b37e545ccc283""

  tasks:
    - name: Download file
      get_url:
        url: ""{{ file_url }}""
        dest: ""~/file.txt""
        
    - name: Verify SHA-3 checksum
      shell: |
        file=~/file.txt
        checksum=$(sha3sum ""$file"" | cut -d ' ' -f1)
        if [ ""$checksum"" != ""{{ sha3_checksum }}"" ]; then
          echo ""Error: Checksum does not match.""
          exit 1
        fi
      register: checksum_result
      failed_when: ""checksum_result.rc != 0""
      
    - name: Print success message
      debug:
        msg: ""Checksum verification successful.""
"
47,79933,delegate_to not working and instead the task is getting executed on localhost,"### Summary

delegate_to not working and instead the task is getting executed on localhost

### Issue Type

Bug Report

### Component Name

delegate_to command

### Ansible Version

```console
$ ansible --version


ansible [core 2.12.5]
  config file = /etc/ansible/ansible.cfg
  configured module search path = ['/etc/ansible/modules']
  ansible python module location = /usr/lib/python3.8/site-packages/ansible
  ansible collection location = /root/.ansible/collections:/usr/share/ansible/collections
  executable location = /bin/ansible
  python version = 3.8.12 (default, Sep 21 2021, 00:10:52) [GCC 8.5.0 20210514 (Red Hat 8.5.0-3)]
  jinja version = 2.10.3
  libyaml = True
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all



COMMAND_WARNINGS(/etc/ansible/ansible.cfg) = False
DEFAULT_ACTION_PLUGIN_PATH(/etc/ansible/ansible.cfg) = ['/etc/ansible/plugins/a>
DEFAULT_CACHE_PLUGIN_PATH(/etc/ansible/ansible.cfg) = ['/etc/ansible/plugins/ca>
DEFAULT_CALLBACK_PLUGIN_PATH(/etc/ansible/ansible.cfg) = ['/etc/ansible/plugins>
DEFAULT_CONNECTION_PLUGIN_PATH(/etc/ansible/ansible.cfg) = ['/etc/ansible/plugi>
DEFAULT_FILTER_PLUGIN_PATH(/etc/ansible/ansible.cfg) = ['/etc/ansible/plugins/f>
DEFAULT_FORKS(/etc/ansible/ansible.cfg) = 50
DEFAULT_GATHER_TIMEOUT(/etc/ansible/ansible.cfg) = 60
DEFAULT_HOST_LIST(/etc/ansible/ansible.cfg) = ['/etc/ansible/inventory']
DEFAULT_INVENTORY_PLUGIN_PATH(/etc/ansible/ansible.cfg) = ['/etc/ansible/plugin>
DEFAULT_JINJA2_EXTENSIONS(/etc/ansible/ansible.cfg) = jinja2.ext.do
DEFAULT_LOG_PATH(/etc/ansible/ansible.cfg) = /var/log/ansible.log
DEFAULT_LOOKUP_PLUGIN_PATH(/etc/ansible/ansible.cfg) = ['/etc/ansible/plugins/l>
DEFAULT_MODULE_PATH(/etc/ansible/ansible.cfg) = ['/etc/ansible/modules']
DEFAULT_ROLES_PATH(/etc/ansible/ansible.cfg) = ['/etc/ansible/roles', '/ansible>
DEFAULT_STRATEGY_PLUGIN_PATH(/etc/ansible/ansible.cfg) = ['/etc/ansible/plugins>
DEFAULT_TERMINAL_PLUGIN_PATH(/etc/ansible/ansible.cfg) = ['/etc/ansible/plugins>
DEFAULT_TEST_PLUGIN_PATH(/etc/ansible/ansible.cfg) = ['/etc/ansible/plugins/tes>
DEFAULT_VARS_PLUGIN_PATH(/etc/ansible/ansible.cfg) = ['/etc/ansible/plugins/var>
DEPRECATION_WARNINGS(/etc/ansible/ansible.cfg) = False
HOST_KEY_CHECKING(/etc/ansible/ansible.cfg) = False
PERSISTENT_COMMAND_TIMEOUT(/etc/ansible/ansible.cfg) = 3000

BECOME:
======

CACHE:
=====

CALLBACK:
========

CLICONF:
=======

CONNECTION:
==========

paramiko_ssh:
____________
host_key_checking(/etc/ansible/ansible.cfg) = False

ssh:
___
host_key_checking(/etc/ansible/ansible.cfg) = False
pipelining(/etc/ansible/ansible.cfg) = True
reconnection_retries(/etc/ansible/ansible.cfg) = 5

HTTPAPI:
=======

INVENTORY:
=========

LOOKUP:
======

NETCONF:
=======

SHELL:
=====

VARS:
====
```


### OS / Environment

CentOS Stream release 8
NAME=""CentOS Stream""
VERSION=""8""
ID=""centos""
ID_LIKE=""rhel fedora""
VERSION_ID=""8""
PLATFORM_ID=""platform:el8""
PRETTY_NAME=""CentOS Stream 8""
ANSI_COLOR=""0;31""
CPE_NAME=""cpe:/o:centos:centos:8""
HOME_URL=""https://centos.org/""
BUG_REPORT_URL=""https://bugzilla.redhat.com/""
REDHAT_SUPPORT_PRODUCT=""Red Hat Enterprise Linux 8""
REDHAT_SUPPORT_PRODUCT_VERSION=""CentOS Stream""
CentOS Stream release 8
CentOS Stream release 8
cpe:/o:centos:centos:8

### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->
```yaml (paste below)

```
---
- hosts: all
  connection: local
  name: Test Playbook
  gather_facts: False
  serial: ""1""
  
  tasks:
    - name: Copy file to remote IP
      template:
        src: ""/tmp/test.txt""
        dest: ""/tmp/test2.txt""
        mode: '0644'
        owner: root
        group: root
      delegate_to: ""10.15.10.157""

### Expected Results

I expect /tmp/test2.txt file on 10.15.10.157

### Actual Results

```console
the file is copied to local host itself.

# ls -al /tmp/test*
-rw-r--r-- 1 root root 0 Feb  7 03:36 /tmp/test2.txt
-rw-r--r-- 1 root root 0 Feb  7 02:57 /tmp/test.txt
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-02-07T03:40:18Z,2,Create a YAML Ansible playbook to exhibit the following issue: delegate_to not working and instead the task is getting executed on localhost,"```
---
- hosts: web_servers
  tasks:
    - name: Test delegate_to issue
      debug:
        msg: ""This task should be run on delegate server""
      delegate_to: delegate_server
      delegate_facts: yes
```

Note: Please replace `web_servers` and `delegate_server` with appropriate hostnames or group names. This playbook creates a task named 'Test delegate_to issue' that should be run on the delegate_server but instead gets executed on the localhost.",1,"
---
- hosts: web_servers
  tasks:
    - name: Test delegate_to issue
      debug:
        msg: ""This task should be run on delegate server""
      delegate_to: delegate_server
      delegate_facts: yes
"
48,79923,Ansible suddenly changes SSH user in the middle of tasks,"### Summary

Hey, I'm running Ansible 2.14 on my MBP M1 computer to install ScyllaDB from this repository and this folder https://github.com/scylladb/scylla-ansible-roles/tree/master/ansible-scylla-node 

The setup mostly works as such, I added a `run.yml` with default variables copied as such:

```yaml
- name: Scylla node
  hosts: scylla
  become: true
  vars:
    # variables for the Scylla node role (can be set here or in the role's vars/main.yml)
    scylla_repos:
      - 'http://repositories.scylladb.com/scylla/repo/613b5a39-91d7-4267-aa15-4384fde87442/ubuntu/scylladb-4.1-bionic.list'
    scylla_repo_keyserver: 'hkp://keyserver.ubuntu.com:80'
    scylla_repo_keys:
      - 5e08fbd8b5d6ec9c
      - 6B2BFD3660EF3F5B
      - 17723034C56D4B19
    scylla_dependencies:
      - curl
      - wget
    scylla_version: latest
    scylla_edition: enterprise
    scylla_cluster_name: 'testcluster'
    scylla_snitch: GossipingPropertyFileSnitch
    scylla_io_probe: True
    enable_mc_format: true
    scylla_seeds:
      - ""{{ groups['scylla'][0] }}""
      # - ""{{ groups['scylla'][1] }}""
    scylla_api_address: '127.0.0.1'
    scylla_api_port: '10000'
    generate_monitoring_config: True
    scylla_manager_enabled: true
    scylla_manager_repo_url: ""http://downloads.scylladb.com/deb/ubuntu/scylladb-manager-2.1-bionic.list""

  tasks:
    # Workaround for some Debian versions that might not have XFS support out of the box
    - name: install XFSprogs
      package:
        name: xfsprogs
        state: present
      become: true
  roles:
    # - mrlesmithjr.mdadm
    - ../ansible-scylla-node
```

These all seem fine. However, in one of the tasks: https://github.com/scylladb/scylla-ansible-roles/blob/master/ansible-scylla-node/tasks/common.yml#L243 I constantly get an error that says `sudo: a password is required`.

Looking from the logs using `ANSIBLE_DEBUG=true ANSIBLE_VERBOSITY=4 ansible-playbook -i hosts run.yml` I see that while in the previous task (and I assume in all those prior it) I correctly SSH as root: `<x.x.x.x> ESTABLISH SSH CONNECTION FOR USER: root`. Yet for this particular task I get `<x.x.x.x> ESTABLISH LOCAL CONNECTION FOR USER: teemu`

Somehow Ansible drops root and tries to login using my local user. I've tried multiple ways to prevent this but to no avail. I simply can't understand why Ansible does this and I don't think it's because the playbook itself is misconfigured.

### Issue Type

Bug Report

### Component Name

Loading ActionModule 'normal' from /opt/homebrew/Cellar/ansible/7.2.0/libexec/lib/python3.11/site-packages/ansible/plugins/action/normal.py 

### Ansible Version

```console
ansible [core 2.14.2]
  config file = /Users/teemu/git_projects/clones/scylla-ansible-roles/ansible-scylla-node/ansible.cfg
  configured module search path = ['/Users/teemu/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /opt/homebrew/Cellar/ansible/7.2.0/libexec/lib/python3.11/site-packages/ansible
  ansible collection location = /Users/teemu/.ansible/collections:/usr/share/ansible/collections
  executable location = /opt/homebrew/bin/ansible
  python version = 3.11.1 (main, Dec 23 2022, 09:25:23) [Clang 14.0.0 (clang-1400.0.29.202)] (/opt/homebrew/Cellar/ansible/7.2.0/libexec/bin/python3.11)
  jinja version = 3.1.2
  libyaml = True
```


### Configuration

```console
CONFIG_FILE() = /Users/teemu/git_projects/clones/scylla-ansible-roles/ansible-scylla-node/ansible.cfg
DEFAULT_REMOTE_USER(/Users/teemu/git_projects/clones/scylla-ansible-roles/ansible-scylla-node/ansible.cfg) = root

CONNECTION:
==========

paramiko_ssh:
____________
remote_user(/Users/teemu/git_projects/clones/scylla-ansible-roles/ansible-scylla-node/ansible.cfg) = root

ssh:
___
remote_user(/Users/teemu/git_projects/clones/scylla-ansible-roles/ansible-scylla-node/ansible.cfg) = root
```


### OS / Environment

Local macOS 12.5.1, in remote Ubuntu 18

### Steps to Reproduce

1. Clone the repo https://github.com/scylladb/scylla-ansible-roles
2. `cd ansible-scylla-node`
3. Add hosts file, set `ansible_user = root` if you wish
4. Add this to `run.yml` (don't know what's the standard, could be there's an easier way)
```
- name: Scylla node
  hosts: scylla
  become: true
  vars:
    #variables for the mdadm role
    # mdadm_arrays:
    # - name: 'md0'
    #   devices:
    #     - '/dev/nvme0n1'
    #     - '/dev/nvme1n1'
    #     - '/dev/nvme2n1'
    #   filesystem: 'xfs'
    #   level: '0'
    #   mountpoint: '/var/lib/scylla'
    #   state: 'present'
    #   opts: 'noatime,nofail'

    # variables for the Scylla node role (can be set here or in the role's vars/main.yml)
    scylla_repos:
      - 'http://repositories.scylladb.com/scylla/repo/613b5a39-91d7-4267-aa15-4384fde87442/ubuntu/scylladb-4.1-bionic.list'
    scylla_repo_keyserver: 'hkp://keyserver.ubuntu.com:80'
    scylla_repo_keys:
      - 5e08fbd8b5d6ec9c
      - 6B2BFD3660EF3F5B
      - 17723034C56D4B19
    scylla_dependencies:
      - curl
      - wget
    scylla_version: latest
    scylla_edition: enterprise
    scylla_cluster_name: 'testcluster'
    scylla_snitch: GossipingPropertyFileSnitch
    scylla_io_probe: True
    enable_mc_format: true
    scylla_seeds:
      - ""{{ groups['scylla'][0] }}""
      # - ""{{ groups['scylla'][1] }}""
    scylla_api_address: '127.0.0.1'
    scylla_api_port: '10000'
    generate_monitoring_config: True
    scylla_manager_enabled: true
    scylla_manager_repo_url: ""http://downloads.scylladb.com/deb/ubuntu/scylladb-manager-2.1-bionic.list""

  tasks:
    # Workaround for some Debian versions that might not have XFS support out of the box
    - name: install XFSprogs
      package:
        name: xfsprogs
        state: present
      become: true
  roles:
    # - mrlesmithjr.mdadm
    - ../ansible-scylla-node
```
6. Run the playbook in remote Ubuntu 18 server with eg `ANSIBLE_DEBUG=true ANSIBLE_VERBOSITY=4 ansible-playbook -i hosts run.yml`

### Expected Results

I expected the `ssl.yml` task not to fail with `sudo: a password is required`

### Actual Results

```console
TASK [../ansible-scylla-node : enable ssl options] ***********************************************************************************************************************************
task path: /Users/teemu/git_projects/clones/scylla-ansible-roles/ansible-scylla-node/tasks/common.yml:227
 55804 1675535487.60284: sending task start callback
 55804 1675535487.60286: entering _queue_task() for 95.216.191.13/include_tasks
 55804 1675535487.60452: worker is 1 (out of 1 available)
 55804 1675535487.60504: exiting _queue_task() for 95.216.191.13/include_tasks
 55804 1675535487.60545: done queuing things up, now waiting for results queue to drain
 55804 1675535487.60547: waiting for pending results...
 56348 1675535487.60630: running TaskExecutor() for 95.216.191.13/TASK: ../ansible-scylla-node : enable ssl options
 56348 1675535487.60805: in run() - task 222b9228-30cb-6c1e-63d0-000000000132
 56348 1675535487.60830: variable 'ansible_search_path' from source: unknown
 56348 1675535487.60872: calling self._execute()
 56348 1675535487.60945: variable 'ansible_ssh_user' from source: group vars, precedence entry 'all_inventory'
 56348 1675535487.60955: variable 'ansible_ssh_private_key_file' from source: group vars, precedence entry 'all_inventory'
 56348 1675535487.60968: variable 'omit' from source: magic vars
 56348 1675535487.61269: '__init__' skipped due to reserved name
 56348 1675535487.61358: Loading TestModule 'core' from /opt/homebrew/Cellar/ansible/7.2.0/libexec/lib/python3.11/site-packages/ansible/plugins/test/core.py
 56348 1675535487.61391: Loading TestModule 'files' from /opt/homebrew/Cellar/ansible/7.2.0/libexec/lib/python3.11/site-packages/ansible/plugins/test/files.py
 56348 1675535487.61399: Loading TestModule 'mathstuff' from /opt/homebrew/Cellar/ansible/7.2.0/libexec/lib/python3.11/site-packages/ansible/plugins/test/mathstuff.py
 56348 1675535487.61407: Loading TestModule 'uri' from /opt/homebrew/Cellar/ansible/7.2.0/libexec/lib/python3.11/site-packages/ansible/plugins/test/uri.py
 56348 1675535487.61456: Loading TestModule 'ansible_collections.ansible.builtin.plugins.test.core' from /opt/homebrew/Cellar/ansible/7.2.0/libexec/lib/python3.11/site-packages/ansible/plugins/test/core.py (found_in_cache=True, class_only=False)
 56348 1675535487.61468: Loading TestModule 'ansible_collections.ansible.builtin.plugins.test.files' from /opt/homebrew/Cellar/ansible/7.2.0/libexec/lib/python3.11/site-packages/ansible/plugins/test/files.py (found_in_cache=True, class_only=False)
 56348 1675535487.61499: Loading TestModule 'ansible_collections.ansible.builtin.plugins.test.mathstuff' from /opt/homebrew/Cellar/ansible/7.2.0/libexec/lib/python3.11/site-packages/ansible/plugins/test/mathstuff.py (found_in_cache=True, class_only=False)
 56348 1675535487.61518: Loading TestModule 'ansible_collections.ansible.builtin.plugins.test.uri' from /opt/homebrew/Cellar/ansible/7.2.0/libexec/lib/python3.11/site-packages/ansible/plugins/test/uri.py (found_in_cache=True, class_only=False)
 56348 1675535487.61571: Loading TestModule 'ansible_collections.ansible.builtin.plugins.test.core' from /opt/homebrew/Cellar/ansible/7.2.0/libexec/lib/python3.11/site-packages/ansible/plugins/test/core.py (found_in_cache=True, class_only=False)
 56348 1675535487.61584: Loading TestModule 'ansible_collections.ansible.builtin.plugins.test.files' from /opt/homebrew/Cellar/ansible/7.2.0/libexec/lib/python3.11/site-packages/ansible/plugins/test/files.py (found_in_cache=True, class_only=False)
 56348 1675535487.61601: Loading TestModule 'ansible_collections.ansible.builtin.plugins.test.mathstuff' from /opt/homebrew/Cellar/ansible/7.2.0/libexec/lib/python3.11/site-packages/ansible/plugins/test/mathstuff.py (found_in_cache=True, class_only=False)
 56348 1675535487.61626: Loading TestModule 'ansible_collections.ansible.builtin.plugins.test.uri' from /opt/homebrew/Cellar/ansible/7.2.0/libexec/lib/python3.11/site-packages/ansible/plugins/test/uri.py (found_in_cache=True, class_only=False)
 56348 1675535487.61668: variable 'scylla_ssl' from source: role '' defaults
 56348 1675535487.61708: Loading TestModule 'ansible_collections.ansible.builtin.plugins.test.core' from /opt/homebrew/Cellar/ansible/7.2.0/libexec/lib/python3.11/site-packages/ansible/plugins/test/core.py (found_in_cache=True, class_only=False)
 56348 1675535487.61714: Loading TestModule 'ansible_collections.ansible.builtin.plugins.test.files' from /opt/homebrew/Cellar/ansible/7.2.0/libexec/lib/python3.11/site-packages/ansible/plugins/test/files.py (found_in_cache=True, class_only=False)
 56348 1675535487.61733: Loading TestModule 'ansible_collections.ansible.builtin.plugins.test.mathstuff' from /opt/homebrew/Cellar/ansible/7.2.0/libexec/lib/python3.11/site-packages/ansible/plugins/test/mathstuff.py (found_in_cache=True, class_only=False)
 56348 1675535487.61747: Loading TestModule 'ansible_collections.ansible.builtin.plugins.test.uri' from /opt/homebrew/Cellar/ansible/7.2.0/libexec/lib/python3.11/site-packages/ansible/plugins/test/uri.py (found_in_cache=True, class_only=False)
 56348 1675535487.61756: Evaluated conditional (scylla_ssl is defined): True
 56348 1675535487.61885: '__init__' skipped due to reserved name
 56348 1675535487.62417: Loading FilterModule 'core' from /opt/homebrew/Cellar/ansible/7.2.0/libexec/lib/python3.11/site-packages/ansible/plugins/filter/core.py
 56348 1675535487.62439: Loading FilterModule 'encryption' from /opt/homebrew/Cellar/ansible/7.2.0/libexec/lib/python3.11/site-packages/ansible/plugins/filter/encryption.py
 56348 1675535487.62466: Loading FilterModule 'mathstuff' from /opt/homebrew/Cellar/ansible/7.2.0/libexec/lib/python3.11/site-packages/ansible/plugins/filter/mathstuff.py
 56348 1675535487.62485: Loading FilterModule 'urls' from /opt/homebrew/Cellar/ansible/7.2.0/libexec/lib/python3.11/site-packages/ansible/plugins/filter/urls.py
 56348 1675535487.62505: Loading FilterModule 'urlsplit' from /opt/homebrew/Cellar/ansible/7.2.0/libexec/lib/python3.11/site-packages/ansible/plugins/filter/urlsplit.py
 56348 1675535487.62559: variable 'scylla_ssl' from source: role '' defaults
 56348 1675535487.62566: Evaluated conditional ((scylla_ssl.internode.enabled|bool) or (scylla_ssl.client.enabled|bool)): True
 56348 1675535487.62568: _execute() done
 56348 1675535487.62568: dumping result to json
 56348 1675535487.62569: done dumping result, returning
 56348 1675535487.62571: done running TaskExecutor() for 95.216.191.13/TASK: ../ansible-scylla-node : enable ssl options [222b9228-30cb-6c1e-63d0-000000000132]
 56348 1675535487.62572: sending task result for task 222b9228-30cb-6c1e-63d0-000000000132
 56348 1675535487.62582: done sending task result for task 222b9228-30cb-6c1e-63d0-000000000132
 56348 1675535487.62582: WORKER PROCESS EXITING
 55804 1675535487.62979: no more pending results, returning what we have
 55804 1675535487.62989: in VariableManager get_vars()
 55804 1675535487.63020: Calling all_inventory to load vars for 95.216.191.13
 55804 1675535487.63022: Calling groups_inventory to load vars for 95.216.191.13
 55804 1675535487.63023: Calling all_plugins_inventory to load vars for 95.216.191.13
 55804 1675535487.63051: '__init__' skipped due to reserved name
 55804 1675535487.63056: Loading VarsModule 'host_group_vars' from /opt/homebrew/Cellar/ansible/7.2.0/libexec/lib/python3.11/site-packages/ansible/plugins/vars/host_group_vars.py (found_in_cache=True, class_only=False)
 55804 1675535487.63082: Calling all_plugins_play to load vars for 95.216.191.13
 55804 1675535487.63089: '__init__' skipped due to reserved name
 55804 1675535487.63090: Loading VarsModule 'host_group_vars' from /opt/homebrew/Cellar/ansible/7.2.0/libexec/lib/python3.11/site-packages/ansible/plugins/vars/host_group_vars.py (found_in_cache=True, class_only=False)
 55804 1675535487.63096: Calling groups_plugins_inventory to load vars for 95.216.191.13
 55804 1675535487.63102: '__init__' skipped due to reserved name
 55804 1675535487.63103: Loading VarsModule 'host_group_vars' from /opt/homebrew/Cellar/ansible/7.2.0/libexec/lib/python3.11/site-packages/ansible/plugins/vars/host_group_vars.py (found_in_cache=True, class_only=False)
 55804 1675535487.63108: Calling groups_plugins_play to load vars for 95.216.191.13
 55804 1675535487.63114: '__init__' skipped due to reserved name
 55804 1675535487.63115: Loading VarsModule 'host_group_vars' from /opt/homebrew/Cellar/ansible/7.2.0/libexec/lib/python3.11/site-packages/ansible/plugins/vars/host_group_vars.py (found_in_cache=True, class_only=False)
 55804 1675535487.63126: '__init__' skipped due to reserved name
 55804 1675535487.63127: Loading VarsModule 'host_group_vars' from /opt/homebrew/Cellar/ansible/7.2.0/libexec/lib/python3.11/site-packages/ansible/plugins/vars/host_group_vars.py (found_in_cache=True, class_only=False)
 55804 1675535487.63137: '__init__' skipped due to reserved name
 55804 1675535487.63137: Loading VarsModule 'host_group_vars' from /opt/homebrew/Cellar/ansible/7.2.0/libexec/lib/python3.11/site-packages/ansible/plugins/vars/host_group_vars.py (found_in_cache=True, class_only=False)
 55804 1675535487.63530: '__init__' skipped due to reserved name
 55804 1675535487.64026: done with get_vars()
 55804 1675535487.64041: variable 'ansible_search_path' from source: unknown
 55804 1675535487.64080: we have included files to process
 55804 1675535487.64081: generating all_blocks data
 55804 1675535487.64083: done generating all_blocks data
 55804 1675535487.64086: processing included file: /Users/teemu/git_projects/clones/scylla-ansible-roles/ansible-scylla-node/tasks/ssl.yml
 55804 1675535487.64087: loading included file: /Users/teemu/git_projects/clones/scylla-ansible-roles/ansible-scylla-node/tasks/ssl.yml
 55804 1675535487.64088: Loading data from /Users/teemu/git_projects/clones/scylla-ansible-roles/ansible-scylla-node/tasks/ssl.yml
redirecting (type: modules) ansible.builtin.openssl_privatekey to community.crypto.openssl_privatekey
Loading collection community.crypto from /opt/homebrew/Cellar/ansible/7.2.0/libexec/lib/python3.11/site-packages/ansible_collections/community/crypto
redirecting (type: modules) ansible.builtin.openssl_privatekey to community.crypto.openssl_privatekey
redirecting (type: modules) ansible.builtin.openssl_csr to community.crypto.openssl_csr
redirecting (type: modules) ansible.builtin.openssl_certificate to community.crypto.x509_certificate
included: /Users/teemu/git_projects/clones/scylla-ansible-roles/ansible-scylla-node/tasks/ssl.yml for 95.216.191.13
 55804 1675535487.64944: done processing included file
 55804 1675535487.64945: iterating over new_blocks loaded from include file
 55804 1675535487.64946: in VariableManager get_vars()
 55804 1675535487.64958: done with get_vars()
 55804 1675535487.64959: filtering new block on tags
 55804 1675535487.64994: done filtering new block on tags
 55804 1675535487.64996: in VariableManager get_vars()
 55804 1675535487.65004: done with get_vars()
 55804 1675535487.65005: filtering new block on tags
 55804 1675535487.65044: done filtering new block on tags
 55804 1675535487.65045: in VariableManager get_vars()
 55804 1675535487.65053: done with get_vars()
 55804 1675535487.65054: filtering new block on tags
 55804 1675535487.65065: done filtering new block on tags
 55804 1675535487.65066: done iterating over new_blocks loaded from include file
 55804 1675535487.65067: extending task lists for all hosts with included blocks
 55804 1675535487.65099: done extending task lists
 55804 1675535487.65100: done processing included files
 55804 1675535487.65100: results queue empty
 55804 1675535487.65101: checking for any_errors_fatal
 55804 1675535487.65103: done checking for any_errors_fatal
 55804 1675535487.65103: checking for max_fail_percentage
 55804 1675535487.65104: done checking for max_fail_percentage
 55804 1675535487.65104: checking to see if all hosts have failed and the running result is not ok
 55804 1675535487.65105: done checking to see if all hosts have failed
 55804 1675535487.65105: getting the remaining hosts for this loop
 55804 1675535487.65105: done getting the remaining hosts for this loop
 55804 1675535487.65108: getting the next task for host 95.216.191.13
 55804 1675535487.65109: done getting next task for host 95.216.191.13
 55804 1675535487.65110:  ^ task is: TASK: ../ansible-scylla-node : Create dir for the CA
 55804 1675535487.65124:  ^ state is: HOST STATE: block=2, task=16, rescue=0, always=0, handlers=8, run_state=1, fail_state=0, pre_flushing_run_state=1, update_handlers=True, pending_setup=False, tasks child state? (HOST STATE: block=0, task=2, rescue=0, always=0, handlers=0, run_state=1, fail_state=0, pre_flushing_run_state=None, update_handlers=True, pending_setup=False, tasks child state? (HOST STATE: block=0, task=1, rescue=0, always=0, handlers=0, run_state=1, fail_state=0, pre_flushing_run_state=None, update_handlers=True, pending_setup=False, tasks child state? (None), rescue child state? (None), always child state? (None), did rescue? False, did start at task? False), rescue child state? (None), always child state? (None), did rescue? False, did start at task? False), rescue child state? (None), always child state? (None), did rescue? False, did start at task? False
 55804 1675535487.65128: getting variables
 55804 1675535487.65137: in VariableManager get_vars()
 55804 1675535487.65151: Calling all_inventory to load vars for 95.216.191.13
 55804 1675535487.65152: Calling groups_inventory to load vars for 95.216.191.13
 55804 1675535487.65153: Calling all_plugins_inventory to load vars for 95.216.191.13
 55804 1675535487.65173: '__init__' skipped due to reserved name
 55804 1675535487.65174: Loading VarsModule 'host_group_vars' from /opt/homebrew/Cellar/ansible/7.2.0/libexec/lib/python3.11/site-packages/ansible/plugins/vars/host_group_vars.py (found_in_cache=True, class_only=False)
 55804 1675535487.65186: Calling all_plugins_play to load vars for 95.216.191.13
 55804 1675535487.65193: '__init__' skipped due to reserved name
 55804 1675535487.65194: Loading VarsModule 'host_group_vars' from /opt/homebrew/Cellar/ansible/7.2.0/libexec/lib/python3.11/site-packages/ansible/plugins/vars/host_group_vars.py (found_in_cache=True, class_only=False)
 55804 1675535487.65200: Calling groups_plugins_inventory to load vars for 95.216.191.13
 55804 1675535487.65207: '__init__' skipped due to reserved name
 55804 1675535487.65208: Loading VarsModule 'host_group_vars' from /opt/homebrew/Cellar/ansible/7.2.0/libexec/lib/python3.11/site-packages/ansible/plugins/vars/host_group_vars.py (found_in_cache=True, class_only=False)
 55804 1675535487.65213: Calling groups_plugins_play to load vars for 95.216.191.13
 55804 1675535487.65219: '__init__' skipped due to reserved name
 55804 1675535487.65220: Loading VarsModule 'host_group_vars' from /opt/homebrew/Cellar/ansible/7.2.0/libexec/lib/python3.11/site-packages/ansible/plugins/vars/host_group_vars.py (found_in_cache=True, class_only=False)
 55804 1675535487.65293: '__init__' skipped due to reserved name
 55804 1675535487.65296: Loading VarsModule 'host_group_vars' from /opt/homebrew/Cellar/ansible/7.2.0/libexec/lib/python3.11/site-packages/ansible/plugins/vars/host_group_vars.py (found_in_cache=True, class_only=False)
 55804 1675535487.65309: '__init__' skipped due to reserved name
 55804 1675535487.65310: Loading VarsModule 'host_group_vars' from /opt/homebrew/Cellar/ansible/7.2.0/libexec/lib/python3.11/site-packages/ansible/plugins/vars/host_group_vars.py (found_in_cache=True, class_only=False)
 55804 1675535487.65662: '__init__' skipped due to reserved name
 55804 1675535487.66079: in VariableManager get_vars()
 55804 1675535487.66085: Calling all_inventory to load vars for localhost
 55804 1675535487.66086: Calling groups_inventory to load vars for localhost
 55804 1675535487.66087: Calling all_plugins_inventory to load vars for localhost
 55804 1675535487.66099: '__init__' skipped due to reserved name
 55804 1675535487.66100: Loading VarsModule 'host_group_vars' from /opt/homebrew/Cellar/ansible/7.2.0/libexec/lib/python3.11/site-packages/ansible/plugins/vars/host_group_vars.py (found_in_cache=True, class_only=False)
 55804 1675535487.66110: Calling all_plugins_play to load vars for localhost
 55804 1675535487.66117: '__init__' skipped due to reserved name
 55804 1675535487.66118: Loading VarsModule 'host_group_vars' from /opt/homebrew/Cellar/ansible/7.2.0/libexec/lib/python3.11/site-packages/ansible/plugins/vars/host_group_vars.py (found_in_cache=True, class_only=False)
 55804 1675535487.66123: Calling groups_plugins_inventory to load vars for localhost
 55804 1675535487.66129: '__init__' skipped due to reserved name
 55804 1675535487.66130: Loading VarsModule 'host_group_vars' from /opt/homebrew/Cellar/ansible/7.2.0/libexec/lib/python3.11/site-packages/ansible/plugins/vars/host_group_vars.py (found_in_cache=True, class_only=False)
 55804 1675535487.66133: Calling groups_plugins_play to load vars for localhost
 55804 1675535487.66139: '__init__' skipped due to reserved name
 55804 1675535487.66139: Loading VarsModule 'host_group_vars' from /opt/homebrew/Cellar/ansible/7.2.0/libexec/lib/python3.11/site-packages/ansible/plugins/vars/host_group_vars.py (found_in_cache=True, class_only=False)
 55804 1675535487.66149: '__init__' skipped due to reserved name
 55804 1675535487.66150: Loading VarsModule 'host_group_vars' from /opt/homebrew/Cellar/ansible/7.2.0/libexec/lib/python3.11/site-packages/ansible/plugins/vars/host_group_vars.py (found_in_cache=True, class_only=False)
 55804 1675535487.66160: '__init__' skipped due to reserved name
 55804 1675535487.66161: Loading VarsModule 'host_group_vars' from /opt/homebrew/Cellar/ansible/7.2.0/libexec/lib/python3.11/site-packages/ansible/plugins/vars/host_group_vars.py (found_in_cache=True, class_only=False)
 55804 1675535487.66174: '__init__' skipped due to reserved name
 55804 1675535487.66191: done with get_vars()
 55804 1675535487.66192: done with get_vars()
 55804 1675535487.66205: done getting variables
 55804 1675535487.66228: sending task start callback, copying the task so we can template it temporarily
 55804 1675535487.66228: done copying, going to template now
 55804 1675535487.66229: done templating
 55804 1675535487.66229: here goes the callback...

TASK [../ansible-scylla-node : Create dir for the CA] ********************************************************************************************************************************
task path: /Users/teemu/git_projects/clones/scylla-ansible-roles/ansible-scylla-node/tasks/ssl.yml:4
 55804 1675535487.66245: sending task start callback
 55804 1675535487.66247: entering _queue_task() for 95.216.191.13/file
 55804 1675535487.66509: worker is 1 (out of 1 available)
 55804 1675535487.66563: exiting _queue_task() for 95.216.191.13/file
 55804 1675535487.66566: done queuing things up, now waiting for results queue to drain
 55804 1675535487.66568: waiting for pending results...
 56349 1675535487.66709: running TaskExecutor() for 95.216.191.13/TASK: ../ansible-scylla-node : Create dir for the CA
 56349 1675535487.66923: in run() - task 222b9228-30cb-6c1e-63d0-000000000210
 56349 1675535487.66968: variable 'ansible_search_path' from source: unknown
 56349 1675535487.67018: variable '_ansible_loop_cache' from source: unknown
 56349 1675535487.67031: calling self._execute()
 56349 1675535487.67084: variable 'ansible_delegated_vars' from source: unknown
 56349 1675535487.67112: variable 'ansible_connection' from source: host vars for 'localhost'
 56349 1675535487.67114: no remote address found for delegated host localhost
using its name, so success depends on DNS resolution
 56349 1675535487.67115: variable 'ansible_ssh_user' from source: group vars, precedence entry 'all_inventory'
 56349 1675535487.67122: variable 'omit' from source: magic vars
 56349 1675535487.67176: variable 'omit' from source: magic vars
 56349 1675535487.67259: variable 'omit' from source: magic vars
 56349 1675535487.67270: variable 'omit' from source: magic vars
 56349 1675535487.67277: variable 'ansible_delegated_vars' from source: unknown
 56349 1675535487.67277: variable 'ansible_connection' from source: host vars for 'localhost'
 56349 1675535487.67278: variable 'ansible_connection' from source: host vars for 'localhost'
 56349 1675535487.67311: trying /opt/homebrew/Cellar/ansible/7.2.0/libexec/lib/python3.11/site-packages/ansible/plugins/connection
 56349 1675535487.67342: Loading Connection 'local' from /opt/homebrew/Cellar/ansible/7.2.0/libexec/lib/python3.11/site-packages/ansible/plugins/connection/local.py (found_in_cache=True, class_only=False)
 56349 1675535487.67353: trying /opt/homebrew/Cellar/ansible/7.2.0/libexec/lib/python3.11/site-packages/ansible/plugins/shell
 56349 1675535487.67364: Loading ShellModule 'sh' from /opt/homebrew/Cellar/ansible/7.2.0/libexec/lib/python3.11/site-packages/ansible/plugins/shell/sh.py (found_in_cache=True, class_only=False)
 56349 1675535487.67369: Loading ShellModule 'sh' from /opt/homebrew/Cellar/ansible/7.2.0/libexec/lib/python3.11/site-packages/ansible/plugins/shell/sh.py (found_in_cache=True, class_only=False)
 56349 1675535487.67378: trying /opt/homebrew/Cellar/ansible/7.2.0/libexec/lib/python3.11/site-packages/ansible/plugins/become
 56349 1675535487.67385: Loading BecomeModule 'sudo' from /opt/homebrew/Cellar/ansible/7.2.0/libexec/lib/python3.11/site-packages/ansible/plugins/become/sudo.py (found_in_cache=True, class_only=False)
 56349 1675535487.67432: Set connection var ansible_shell_executable to /bin/sh
 56349 1675535487.67433: Set connection var ansible_shell_type to sh
 56349 1675535487.67433: Set connection var ansible_connection to local
 56349 1675535487.67434: Set connection var ansible_host to 95.216.191.13
 56349 1675535487.67435: Set connection var ansible_module_compression to ZIP_DEFLATED
 56349 1675535487.67435: Set connection var ansible_timeout to 10
 56349 1675535487.67436: Set connection var ansible_pipelining to False
 56349 1675535487.67445: variable 'ansible_delegated_vars' from source: unknown
 56349 1675535487.67445: variable 'ansible_connection' from source: host vars for 'localhost'
 56349 1675535487.67446: variable 'ansible_ssh_user' from source: group vars, precedence entry 'all_inventory'
 56349 1675535487.67545: Loading ActionModule 'normal' from /opt/homebrew/Cellar/ansible/7.2.0/libexec/lib/python3.11/site-packages/ansible/plugins/action/normal.py (searched paths: /opt/homebrew/Cellar/ansible/7.2.0/libexec/lib/python3.11/site-packages/ansible/plugins/action:/opt/homebrew/Cellar/ansible/7.2.0/libexec/lib/python3.11/site-packages/ansible/plugins/action/__pycache__)
 56349 1675535487.67551: variable 'omit' from source: magic vars
 56349 1675535487.67552: starting attempt loop
 56349 1675535487.67553: running the handler
 56349 1675535487.67565: _low_level_execute_command(): starting
 56349 1675535487.67568: _low_level_execute_command(): executing: /bin/sh -c 'echo ~teemu && sleep 0'
<95.216.191.13> ESTABLISH LOCAL CONNECTION FOR USER: teemu
 56349 1675535487.67572: in local.exec_command()
<95.216.191.13> EXEC /bin/sh -c 'echo ~teemu && sleep 0'
 56349 1675535487.67577: opening command with Popen()
 56349 1675535487.68062: done running command with Popen()
 56349 1675535487.68078: getting output with communicate()
 56349 1675535487.69138: done communicating
 56349 1675535487.69140: done with local.exec_command()
 56349 1675535487.69149: _low_level_execute_command() done: rc=0, stdout=/Users/teemu
, stderr=
 56349 1675535487.69187: _low_level_execute_command(): starting
 56349 1675535487.69194: _low_level_execute_command(): executing: /bin/sh -c '( umask 77 && mkdir -p ""` echo /Users/teemu/.ansible/tmp `""&& mkdir ""` echo /Users/teemu/.ansible/tmp/ansible-tmp-1675535487.691798-56349-258505582080596 `"" && echo ansible-tmp-1675535487.691798-56349-258505582080596=""` echo /Users/teemu/.ansible/tmp/ansible-tmp-1675535487.691798-56349-258505582080596 `"" ) && sleep 0'
 56349 1675535487.69199: in local.exec_command()
<95.216.191.13> EXEC /bin/sh -c '( umask 77 && mkdir -p ""` echo /Users/teemu/.ansible/tmp `""&& mkdir ""` echo /Users/teemu/.ansible/tmp/ansible-tmp-1675535487.691798-56349-258505582080596 `"" && echo ansible-tmp-1675535487.691798-56349-258505582080596=""` echo /Users/teemu/.ansible/tmp/ansible-tmp-1675535487.691798-56349-258505582080596 `"" ) && sleep 0'
 56349 1675535487.69205: opening command with Popen()
 56349 1675535487.69596: done running command with Popen()
 56349 1675535487.69609: getting output with communicate()
 56349 1675535487.70763: done communicating
 56349 1675535487.70766: done with local.exec_command()
 56349 1675535487.70772: _low_level_execute_command() done: rc=0, stdout=ansible-tmp-1675535487.691798-56349-258505582080596=/Users/teemu/.ansible/tmp/ansible-tmp-1675535487.691798-56349-258505582080596
, stderr=
 56349 1675535487.70819: variable 'ansible_delegated_vars' from source: unknown
 56349 1675535487.70907: ANSIBALLZ: using cached module: /Users/teemu/.ansible/tmp/ansible-local-55804yq1u_nwr/ansiballz_cache/ansible.modules.file-ZIP_DEFLATED
 56349 1675535487.70922: variable 'ansible_python_interpreter' from source: host vars for 'localhost'
Using module file /opt/homebrew/Cellar/ansible/7.2.0/libexec/lib/python3.11/site-packages/ansible/modules/file.py
 56349 1675535487.70953: transferring module to remote /Users/teemu/.ansible/tmp/ansible-tmp-1675535487.691798-56349-258505582080596/AnsiballZ_file.py
<95.216.191.13> PUT /Users/teemu/.ansible/tmp/ansible-local-55804yq1u_nwr/tmp6okgyym3 TO /Users/teemu/.ansible/tmp/ansible-tmp-1675535487.691798-56349-258505582080596/AnsiballZ_file.py
 56349 1675535487.71062: done transferring module to remote
 56349 1675535487.71073: _low_level_execute_command(): starting
 56349 1675535487.71075: _low_level_execute_command(): executing: /bin/sh -c 'chmod u+x /Users/teemu/.ansible/tmp/ansible-tmp-1675535487.691798-56349-258505582080596/ /Users/teemu/.ansible/tmp/ansible-tmp-1675535487.691798-56349-258505582080596/AnsiballZ_file.py && sleep 0'
 56349 1675535487.71077: in local.exec_command()
<95.216.191.13> EXEC /bin/sh -c 'chmod u+x /Users/teemu/.ansible/tmp/ansible-tmp-1675535487.691798-56349-258505582080596/ /Users/teemu/.ansible/tmp/ansible-tmp-1675535487.691798-56349-258505582080596/AnsiballZ_file.py && sleep 0'
 56349 1675535487.71123: opening command with Popen()
 56349 1675535487.71378: done running command with Popen()
 56349 1675535487.71387: getting output with communicate()
 56349 1675535487.72208: done communicating
 56349 1675535487.72210: done with local.exec_command()
 56349 1675535487.72216: _low_level_execute_command() done: rc=0, stdout=, stderr=
 56349 1675535487.72220: _low_level_execute_command(): starting
 56349 1675535487.72233: _low_level_execute_command(): using become for this command
 56349 1675535487.72246: _low_level_execute_command(): executing: /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '""'""'echo BECOME-SUCCESS-ctyxyrqkjipnjhcqmhtjggomscnqwfmi ; /opt/homebrew/Cellar/ansible/7.2.0/libexec/bin/python3.11 /Users/teemu/.ansible/tmp/ansible-tmp-1675535487.691798-56349-258505582080596/AnsiballZ_file.py'""'""' && sleep 0'
 56349 1675535487.72249: in local.exec_command()
<95.216.191.13> EXEC /bin/sh -c 'sudo -H -S -n  -u root /bin/sh -c '""'""'echo BECOME-SUCCESS-ctyxyrqkjipnjhcqmhtjggomscnqwfmi ; /opt/homebrew/Cellar/ansible/7.2.0/libexec/bin/python3.11 /Users/teemu/.ansible/tmp/ansible-tmp-1675535487.691798-56349-258505582080596/AnsiballZ_file.py'""'""' && sleep 0'
 56349 1675535487.72262: opening command with Popen()
 56349 1675535487.72485: done running command with Popen()
 56349 1675535487.72494: getting output with communicate()
 56349 1675535487.74741: done communicating
 56349 1675535487.74743: done with local.exec_command()
 56349 1675535487.74748: _low_level_execute_command() done: rc=1, stdout=, stderr=sudo: a password is required
 56349 1675535487.74794: done with _execute_module (file, {'path': '/root/ssl/ca', 'state': 'directory', 'mode': '0755', 'owner': 'root', '_ansible_check_mode': False, '_ansible_no_log': False, '_ansible_debug': True, '_ansible_diff': False, '_ansible_verbosity': 4, '_ansible_version': '2.14.2', '_ansible_module_name': 'file', '_ansible_syslog_facility': 'LOG_USER', '_ansible_selinux_special_fs': ['fuse', 'nfs', 'vboxsf', 'ramfs', '9p', 'vfat'], '_ansible_string_conversion_action': 'warn', '_ansible_socket': None, '_ansible_shell_executable': '/bin/sh', '_ansible_keep_remote_files': False, '_ansible_tmpdir': '/Users/teemu/.ansible/tmp/ansible-tmp-1675535487.691798-56349-258505582080596/', '_ansible_remote_tmp': '~/.ansible/tmp'})
 56349 1675535487.74803: _low_level_execute_command(): starting
 56349 1675535487.74811: _low_level_execute_command(): executing: /bin/sh -c 'rm -f -r /Users/teemu/.ansible/tmp/ansible-tmp-1675535487.691798-56349-258505582080596/ > /dev/null 2>&1 && sleep 0'
 56349 1675535487.74813: in local.exec_command()
<95.216.191.13> EXEC /bin/sh -c 'rm -f -r /Users/teemu/.ansible/tmp/ansible-tmp-1675535487.691798-56349-258505582080596/ > /dev/null 2>&1 && sleep 0'
 56349 1675535487.74817: opening command with Popen()
 56349 1675535487.75278: done running command with Popen()
 56349 1675535487.75326: getting output with communicate()
 56349 1675535487.75978: done communicating
 56349 1675535487.75981: done with local.exec_command()
 56349 1675535487.75987: _low_level_execute_command() done: rc=0, stdout=, stderr=
 56349 1675535487.75995: handler run complete
 56349 1675535487.76012: variable 'ansible_host' from source: unknown
 56349 1675535487.76012: variable 'ansible_port' from source: unknown
 56349 1675535487.76012: variable 'ansible_user' from source: group vars, precedence entry 'all_inventory'
 56349 1675535487.76013: variable 'ansible_connection' from source: host vars for 'localhost'
 56349 1675535487.76013: attempt loop complete, returning result
 56349 1675535487.76014: _execute() done
 56349 1675535487.76015: dumping result to json
 56349 1675535487.76017: done dumping result, returning
 56349 1675535487.76031: done running TaskExecutor() for 95.216.191.13/TASK: ../ansible-scylla-node : Create dir for the CA [222b9228-30cb-6c1e-63d0-000000000210]
 56349 1675535487.76034: sending task result for task 222b9228-30cb-6c1e-63d0-000000000210
 56349 1675535487.76050: done sending task result for task 222b9228-30cb-6c1e-63d0-000000000210
 56349 1675535487.76050: WORKER PROCESS EXITING
 55804 1675535487.76262: marking 95.216.191.13 as failed
 55804 1675535487.76288: marking host 95.216.191.13 failed, current state: HOST STATE: block=2, task=16, rescue=0, always=0, handlers=8, run_state=1, fail_state=0, pre_flushing_run_state=1, update_handlers=True, pending_setup=False, tasks child state? (HOST STATE: block=0, task=2, rescue=0, always=0, handlers=0, run_state=1, fail_state=0, pre_flushing_run_state=None, update_handlers=True, pending_setup=False, tasks child state? (HOST STATE: block=0, task=1, rescue=0, always=0, handlers=0, run_state=1, fail_state=0, pre_flushing_run_state=None, update_handlers=True, pending_setup=False, tasks child state? (None), rescue child state? (None), always child state? (None), did rescue? False, did start at task? False), rescue child state? (None), always child state? (None), did rescue? False, did start at task? False), rescue child state? (None), always child state? (None), did rescue? False, did start at task? False
 55804 1675535487.76301: ^ failed state is now: HOST STATE: block=2, task=16, rescue=0, always=0, handlers=8, run_state=1, fail_state=0, pre_flushing_run_state=1, update_handlers=True, pending_setup=False, tasks child state? (HOST STATE: block=0, task=2, rescue=0, always=0, handlers=0, run_state=1, fail_state=0, pre_flushing_run_state=None, update_handlers=True, pending_setup=False, tasks child state? (HOST STATE: block=0, task=1, rescue=0, always=0, handlers=0, run_state=5, fail_state=2, pre_flushing_run_state=None, update_handlers=True, pending_setup=False, tasks child state? (None), rescue child state? (None), always child state? (None), did rescue? False, did start at task? False), rescue child state? (None), always child state? (None), did rescue? False, did start at task? False), rescue child state? (None), always child state? (None), did rescue? False, did start at task? False
 55804 1675535487.76323: getting the next task for host 95.216.191.13
 55804 1675535487.76331: done getting next task for host 95.216.191.13
 55804 1675535487.76332:  ^ task is: None
 55804 1675535487.76332:  ^ state is: HOST STATE: block=2, task=16, rescue=0, always=0, handlers=8, run_state=5, fail_state=2, pre_flushing_run_state=1, update_handlers=True, pending_setup=False, tasks child state? (None), rescue child state? (None), always child state? (None), did rescue? False, did start at task? False
fatal: [95.216.191.13 -> localhost]: FAILED! => {
    ""changed"": false,
    ""module_stderr"": ""sudo: a password is required\n"",
    ""module_stdout"": """",
    ""msg"": ""MODULE FAILURE\nSee stdout/stderr for the exact error"",
    ""rc"": 1
}
 55804 1675535487.76374: no more pending results, returning what we have
 55804 1675535487.76381: results queue empty
 55804 1675535487.76381: checking for any_errors_fatal
 55804 1675535487.76383: getting the next task for host 95.216.191.13
 55804 1675535487.76384: done getting next task for host 95.216.191.13
 55804 1675535487.76385:  ^ task is: None
 55804 1675535487.76385:  ^ state is: HOST STATE: block=2, task=16, rescue=0, always=0, handlers=8, run_state=5, fail_state=2, pre_flushing_run_state=1, update_handlers=True, pending_setup=False, tasks child state? (None), rescue child state? (None), always child state? (None), did rescue? False, did start at task? False
 55804 1675535487.76386: done checking for any_errors_fatal
 55804 1675535487.76386: checking for max_fail_percentage
 55804 1675535487.76387: done checking for max_fail_percentage
 55804 1675535487.76387: checking to see if all hosts have failed and the running result is not ok
 55804 1675535487.76387: ^ not ok, so returning result now
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-02-04T18:32:12Z,3,Create a YAML Ansible playbook to exhibit the following issue: Ansible suddenly changes SSH user in the middle of tasks,"```
---
- name: Test playbook for SSH user change issue
  hosts: all
  become: true
  gather_facts: true
  
  vars:
    ssh_user: root
    
  tasks:
    - name: Task 1
      debug:
        var: ansible_user
    
    - name: Task 2 - SSH User Change
      shell: sudo -u testuser whoami
      register: ssh_user_change
      
    - name: Task 3
      debug:
        var: ansible_user
      
    - name: Task 4
      debug:
        var: ssh_user_change.stdout
      
    - name: Task 5
      shell: sudo -u anotheruser whoami
      
    - name: Task 6
      debug:
        var: ansible_user      
...
```",1,"
---
- name: Test playbook for SSH user change issue
  hosts: all
  become: true
  gather_facts: true
  
  vars:
    ssh_user: root
    
  tasks:
    - name: Task 1
      debug:
        var: ansible_user
    
    - name: Task 2 - SSH User Change
      shell: sudo -u testuser whoami
      register: ssh_user_change
      
    - name: Task 3
      debug:
        var: ansible_user
      
    - name: Task 4
      debug:
        var: ssh_user_change.stdout
      
    - name: Task 5
      shell: sudo -u anotheruser whoami
      
    - name: Task 6
      debug:
        var: ansible_user      
...
"
49,79889,Cannot source a file in shell,"### Summary

Nothing is sourced when using the shell module with /bin/bash whether with '.' or 'source'.
python3.11 is used.

### Issue Type

Bug Report

### Component Name

shell

### Ansible Version

```console
$ ansible --version
ansible [core 2.14.2]
  config file = /etc/ansible/ansible.cfg
  configured module search path = ['/root/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /usr/local/lib/python3.11/dist-packages/ansible
  ansible collection location = /opt
  executable location = /usr/local/bin/ansible
  python version = 3.11.1 (main, Dec 31 2022, 10:23:59) [GCC 12.2.0] (/usr/bin/python3.11)
  jinja version = 3.1.2
  libyaml = True
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
CACHE_PLUGIN(/etc/ansible/ansible.cfg) = redis
CACHE_PLUGIN_CONNECTION(/etc/ansible/ansible.cfg) = tls://localhost:<port>:0:<password>
CACHE_PLUGIN_TIMEOUT(/etc/ansible/ansible.cfg) = 259200
CALLBACKS_ENABLED(/etc/ansible/ansible.cfg) = ['community.general.yaml']
COLLECTIONS_PATHS(/etc/ansible/ansible.cfg) = ['/opt']
CONFIG_FILE() = /etc/ansible/ansible.cfg
DEFAULT_EXECUTABLE(/etc/ansible/ansible.cfg) = /bin/bash
DEFAULT_FORKS(/etc/ansible/ansible.cfg) = 1000
DEFAULT_GATHERING(/etc/ansible/ansible.cfg) = explicit
DEFAULT_HASH_BEHAVIOUR(/etc/ansible/ansible.cfg) = replace
DEFAULT_HOST_LIST(/etc/ansible/ansible.cfg) = ['/etc/ansible/hosts']
DEFAULT_LOAD_CALLBACK_PLUGINS(/etc/ansible/ansible.cfg) = True
DEFAULT_LOG_PATH(/etc/ansible/ansible.cfg) = /var/log/ansible.log
DEFAULT_PRIVATE_ROLE_VARS(/etc/ansible/ansible.cfg) = False
DEFAULT_ROLES_PATH(/etc/ansible/ansible.cfg) = ['/etc/ansible/roles'...]
DEFAULT_STDOUT_CALLBACK(/etc/ansible/ansible.cfg) = community.general.yaml
DEFAULT_TIMEOUT(/etc/ansible/ansible.cfg) = 240
DEFAULT_TRANSPORT(/etc/ansible/ansible.cfg) = ssh
ENABLE_TASK_DEBUGGER(/etc/ansible/ansible.cfg) = True
GALAXY_SERVER_LIST(/etc/ansible/ansible.cfg) = ['release_galaxy', 'test_galaxy', 'local_https', 'local_ssh', 'local_file', 'automation_hub']
HOST_KEY_CHECKING(/etc/ansible/ansible.cfg) = True
INJECT_FACTS_AS_VARS(/etc/ansible/ansible.cfg) = True
INTERPRETER_PYTHON(/etc/ansible/ansible.cfg) = /usr/bin/python3
INVENTORY_ENABLED(/etc/ansible/ansible.cfg) = ['ini', 'script', 'auto', 'yaml']
PERSISTENT_COMMAND_TIMEOUT(/etc/ansible/ansible.cfg) = 3599
PERSISTENT_CONNECT_RETRY_TIMEOUT(/etc/ansible/ansible.cfg) = 300
PERSISTENT_CONNECT_TIMEOUT(/etc/ansible/ansible.cfg) = 3600
RETRY_FILES_ENABLED(/etc/ansible/ansible.cfg) = False
SHOW_CUSTOM_STATS(/etc/ansible/ansible.cfg) = True

CACHE:
=====

jsonfile:
________
_timeout(/etc/ansible/ansible.cfg) = 259200
_uri(/etc/ansible/ansible.cfg) = /etc/ansible/tls:/localhost:<port>:0:<password>

CALLBACK:
========

default:
_______
show_custom_stats(/etc/ansible/ansible.cfg) = True

CONNECTION:
==========

paramiko_ssh:
____________
host_key_checking(/etc/ansible/ansible.cfg) = True
ssh_args(/etc/ansible/ansible.cfg) = -o ControlMaster=auto -o ControlPersist=60s

ssh:
___
host_key_checking(/etc/ansible/ansible.cfg) = True
pipelining(/etc/ansible/ansible.cfg) = True
ssh_args(/etc/ansible/ansible.cfg) = -o ControlMaster=auto -o ControlPersist=60s
timeout(/etc/ansible/ansible.cfg) = 240
```


### OS / Environment

Ubuntu 22.10 kinetic

### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->
```yaml (paste below)
        - shell:
                chdir: /some/folder
                cmd: |
                        set -x
                        source /usr/local/bash/.escape-aliases
                        var=""$(echo '{{ password }}' | sed_alias)""
                executable: /bin/bash
```

Partial contents of .escape-aliases:
```
set +H
# Escaping the '|\&' characters for later sed replacement string
alias sed_alias=$'sed -e \'s|[\|\&]|\\\&|g\''
```


### Expected Results

```
set -x
+ set -x
source /usr/local/bash/.escape-aliases
+ source /usr/local/bash/.escape-aliases
++ set +H
++ alias 'sed_alias=sed -e '\''s|[\|\&]|\\&|g'\'''
var=""$(echo '{{ password }}' | sed_alias)""
++ echo '\|&'
++ sed -e 's|[\|\&]|\\&|g'
+ var='\\\|\&'
```

### Actual Results

```console
stderr: |-
  + source /usr/local/bash/.escape-aliases
  ++ set +H
  ++ alias 'sed_alias=sed -e '\''s|[\|\&]|\\&|g'\'''
  ++ echo '\|&'
  ++ sed_alias
  /bin/bash: line 3: sed_alias: command not found
  + var=
```
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-02-02T18:05:05Z,2,Create a YAML Ansible playbook to exhibit the following issue: Cannot source a file in shell,"```
---
- name: Sourcing a file in shell
  hosts: localhost
  gather_facts: false

  tasks:
  - name: Execute shell script
    shell: |
      . /path/to/file.sh
    register: shell_output

  - debug:
      var: shell_output.stdout_lines
```",1,"
---
- name: Sourcing a file in shell
  hosts: localhost
  gather_facts: false

  tasks:
  - name: Execute shell script
    shell: |
      . /path/to/file.sh
    register: shell_output

  - debug:
      var: shell_output.stdout_lines
"
50,79888,ansible.builtin.shell now throwing error when using args: warn: False,"### Summary

After upgrading to core 2.14.2 and Python 3.10.6 my plays with shell/args/warn: False stopped working.

Previously this worked fine:
```
- name: Fix broken package dependencies
  ansible.builtin.shell: ""rm -rf /var/lib/apt/lists/* && dpkg --configure -a && apt-get -fy install && apt-get clean && apt-get update""
  args:
    warn: False
  when: ansible_os_family == ""Debian""
```

Now I get the error:
```
FAILED! => {""changed"": false, ""msg"": ""Unsupported parameters for (ansible.legacy.command) module: warn. Supported parameters include: _raw_params, _uses_shell, argv, chdir, creates, executable, removes, stdin, stdin_add_newline, strip_empty_ends.""}
```


### Issue Type

Bug Report

### Component Name

ansible.builtin.shell

### Ansible Version

```console
$ ansible --version
ansible [core 2.14.2]
  config file = None
  configured module search path = ['/root/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /usr/local/lib/python3.10/dist-packages/ansible
  ansible collection location = /root/.ansible/collections:/usr/share/ansible/collections
  executable location = /usr/local/bin/ansible
  python version = 3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0] (/usr/bin/python3)
  jinja version = 3.1.2
  libyaml = False
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
CACHE_PLUGIN(/home/eruby/bitfusion/infrastructure/ansible/ansible.cfg) = jsonfile
CACHE_PLUGIN_CONNECTION(/home/eruby/bitfusion/infrastructure/ansible/ansible.cfg) = /tmp/$USER/
CACHE_PLUGIN_TIMEOUT(/home/eruby/bitfusion/infrastructure/ansible/ansible.cfg) = 300
CONFIG_FILE() = /home/eruby/bitfusion/infrastructure/ansible/ansible.cfg
DEFAULT_BECOME(/home/eruby/bitfusion/infrastructure/ansible/ansible.cfg) = True
DEFAULT_BECOME_USER(/home/eruby/bitfusion/infrastructure/ansible/ansible.cfg) = root
DEFAULT_FORKS(/home/eruby/bitfusion/infrastructure/ansible/ansible.cfg) = 60
DEFAULT_PRIVATE_KEY_FILE(/home/eruby/bitfusion/infrastructure/ansible/ansible.cfg) = /root/.ssh/id_rsa_ansible_bitfusion
DEFAULT_REMOTE_USER(/home/eruby/bitfusion/infrastructure/ansible/ansible.cfg) = ansible
HOST_KEY_CHECKING(/home/eruby/bitfusion/infrastructure/ansible/ansible.cfg) = False
INTERPRETER_PYTHON(/home/eruby/bitfusion/infrastructure/ansible/ansible.cfg) = /usr/bin/python3
INVENTORY_ENABLED(/home/eruby/bitfusion/infrastructure/ansible/ansible.cfg) = ['host_list', 'script', 'auto', 'yaml', 'ini', 'toml', 'amazon.aws.aws_ec2']
LOCALHOST_WARNING(/home/eruby/bitfusion/infrastructure/ansible/ansible.cfg) = False

BECOME:
======

runas:
_____
become_user(/home/eruby/bitfusion/infrastructure/ansible/ansible.cfg) = root

su:
__
become_user(/home/eruby/bitfusion/infrastructure/ansible/ansible.cfg) = root

sudo:
____
become_user(/home/eruby/bitfusion/infrastructure/ansible/ansible.cfg) = root

CACHE:
=====

jsonfile:
________
_timeout(/home/eruby/bitfusion/infrastructure/ansible/ansible.cfg) = 300
_uri(/home/eruby/bitfusion/infrastructure/ansible/ansible.cfg) = /tmp/$USER

CONNECTION:
==========

paramiko_ssh:
____________
host_key_checking(/home/eruby/bitfusion/infrastructure/ansible/ansible.cfg) = False
remote_user(/home/eruby/bitfusion/infrastructure/ansible/ansible.cfg) = ansible
ssh_args(/home/eruby/bitfusion/infrastructure/ansible/ansible.cfg) = -F ansible_ssh_config

ssh:
___
host_key_checking(/home/eruby/bitfusion/infrastructure/ansible/ansible.cfg) = False
pipelining(/home/eruby/bitfusion/infrastructure/ansible/ansible.cfg) = True
private_key_file(/home/eruby/bitfusion/infrastructure/ansible/ansible.cfg) = ~/.ssh/id_rsa_ansible_bitfusion
reconnection_retries(/home/eruby/bitfusion/infrastructure/ansible/ansible.cfg) = 2
remote_user(/home/eruby/bitfusion/infrastructure/ansible/ansible.cfg) = ansible
ssh_args(/home/eruby/bitfusion/infrastructure/ansible/ansible.cfg) = -F ansible_ssh_config
```


### OS / Environment

Ubuntu 22.04

### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->
```yaml (paste below)
- name: Fix broken package dependencies
  ansible.builtin.shell: ""rm -rf /var/lib/apt/lists/* && dpkg --configure -a && apt-get -fy install && apt-get clean && apt-get update""
  args:
    warn: False
  when: ansible_os_family == ""Debian""
```


### Expected Results

I expected Ansible to run the command and not throw warnings.

### Actual Results

```console
I get the error:

FAILED! => {""changed"": false, ""msg"": ""Unsupported parameters for (ansible.legacy.command) module: warn. Supported parameters include: _raw_params, _uses_shell, argv, chdir, creates, executable, removes, stdin, stdin_add_newline, strip_empty_ends.""}
```
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-02-02T17:39:16Z,6,Create a YAML Ansible playbook to exhibit the following issue: ansible.builtin.shell now throwing error when using args: warn: False,"```
---
- hosts: all
  tasks:
    - name: Execute command with args
      ansible.builtin.shell:
        cmd: 'echo ""Hello, World!""'
        warn: False
```
Note: The issue is that the `warn` argument is being ignored and a deprecation warning is thrown instead of running the command without any warning.",1,"
---
- hosts: all
  tasks:
    - name: Execute command with args
      ansible.builtin.shell:
        cmd: 'echo ""Hello, World!""'
        warn: False
"
51,79885,ansible windows update module does not work in latest version of windows server 2016 ,"### Summary

When running playbook for windows updates installation, the -vvv flag output displays the exact security updates listed while none of them have been installed and showing as found_update_count: 0.

I found a similar issue ""https://github.com/ansible/ansible/issues/41894"", while the difference is that the security updates could be scanned and listed by Ansible in my case.

-----------
**Executed below code:**
`$ErrorActionPreference = ""Stop""

$session = New-Object -ComObject Microsoft.Update.Session
$searcher = $session.CreateUpdateSearcher()
$search_result = $searcher.Search(""IsInstalled = 0"")

foreach ($update in $search_result.Updates) {
    $categories = @()
    foreach ($category in $update.Categories) {
        $categories += ""$($category.Name) - $($category.CategoryID)""
    }

    $kbs = @()
    foreach ($kb in $update.KBArticleIDs) {
        $kbs += $kb
    }

    [PSCustomObject]@{
        Categories = $categories
        Description = $update.Description
        Hidden = $update.IsHidden
        Id = $update.Identity.UpdateID
        KBs = $kbs
        Mandatory = $update.IsMandatory
        Present = $update.IsPresent
        Title = $update.Title
    }
}`
----
**Got result:**
`

Categories  : {Updates - cd5ffd1e-e932-4e3a-bf74-18bf0b1bbd83, Windows Server 2016 - 569e8e8f-c6cd-42c8-92a3-efbb20a0f6f5}
Description : Install this update to resolve issues in Windows. For a complete listing of the issues that are included in this update, see the associated Microsoft 
              Knowledge Base article for more information. After you install this item, you may have to restart your computer.
Hidden      : False
Id          : 85604fae-a5c5-4f6d-9012-3d86be1bccce
KBs         : {4589210}
Mandatory   : False
Present     : False
Title       : 2021-01 Update for Windows Server 2016 for x64-based Systems (KB4589210)

Categories  : {Security Updates - 0fa1201d-4330-4fa8-8ae9-b877473b6441, Windows Server 2016 - 569e8e8f-c6cd-42c8-92a3-efbb20a0f6f5}
Description : A security issue has been identified in a Microsoft software product that could affect your system. You can help protect your system by installing this 
              update from Microsoft. For a complete listing of the issues that are included in this update, see the associated Microsoft Knowledge Base article. After 
              you install this update, you may have to restart your system.
Hidden      : False
Id          : 6fec4991-24a9-485d-8eb8-841996b5d53b
KBs         : {5012170}
Mandatory   : False
Present     : False
Title       : 2022-08 Security Update for Windows Server 2016 for x64-based Systems (KB5012170)

Categories  : {Update Rollups - 28bc880e-0592-4cbf-8f95-c79b17911d5f, Windows Server 2016 - 569e8e8f-c6cd-42c8-92a3-efbb20a0f6f5, Windows Server 2019 - 
              f702a48c-919b-45d6-9aef-ca4248d50397}
Description : After the download, this tool runs one time to check your computer for infection by specific, prevalent malicious software (including Blaster, Sasser, and 
              Mydoom) and helps remove any infection that is found. If an infection is found, the tool will display a status report the next time that you start your 
              computer. A new version of the tool will be offered every month. If you want to manually run the tool on your computer, you can download a copy from the 
              Microsoft Download Center, or you can run an online version from microsoft.com. This tool is not a replacement for an antivirus product. To help protect 
              your computer, you should use an antivirus product.
Hidden      : False
Id          : 3346a076-4bf6-48a1-b0d6-8422630f38b2
KBs         : {890830}
Mandatory   : False
Present     : False
Title       : Windows Malicious Software Removal Tool x64 - v5.109 (KB890830)

Categories  : {Definition Updates - e0789628-ce08-4437-be74-2495b842f43b, Microsoft Defender Antivirus - 8c3fcc84-7410-4a95-8b89-a166a0190486}
Description : Install this update to revise the files that are used to detect viruses, spyware, and other potentially unwanted software. Once you have installed this 
              item, it cannot be removed.
Hidden      : False
Id          : 69d9d675-f019-4a05-9959-a7adfa6f6800
KBs         : {2267602}
Mandatory   : False
Present     : False
Title       : Security Intelligence Update for Microsoft Defender Antivirus - KB2267602 (Version 1.381.3027.0)

`


### Issue Type

Bug Report

### Component Name

ansible.windows.win_updates

### Ansible Version

```console
$ ansible --version
ansible 2.10.9
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
```


### OS / Environment

NAME=""Ubuntu""
VERSION=""18.04.5 LTS (Bionic Beaver)""
ID=ubuntu
ID_LIKE=debian
PRETTY_NAME=""Ubuntu 18.04.5 LTS""
VERSION_ID=""18.04""


### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->
```yaml (paste below)
# run the command inside a packer config
    {
		""type"": ""shell-local"",
		""command"": ""ansible-playbook -vvv -i ./ansible/hosts ./win2016/windows_update.yml --extra-vars ansible_password={{user `admin_password`}}""
   },
---
# Install windows updates remotely
- name: Install windows updates remotely
  hosts: all
  gather_facts: true
  tasks:
  - name: Install all security, critical, and rollup updates without a scheduled task
    ansible.windows.win_updates:
      category_names: '*'
      reject_list:
        - ""KB4535680""
      reboot: yes
      reboot_timeout: 10800
```


### Expected Results

EXEC (via pipeline wrapper)
ok: [52.147.201.8] => {
    **""changed"": true,**
    ""filtered_updates"": {
        ""3346a076-4bf6-48a1-b0d6-8422630f38b2"": {
            ""categories"": [
                ""Update Rollups"",
                ""Windows Server 2016"",
                ""Windows Server 2019""
            ],
            ""filtered_reason"": ""category_names"",
            ""id"": ""3346a076-4bf6-48a1-b0d6-8422630f38b2"",
            ""installed"": false,
            ""kb"": [
                ""890830""
            ],
            ""title"": ""Windows Malicious Software Removal Tool x64 - v5.109 (KB890830)""
        },
        ""6fec4991-24a9-485d-8eb8-841996b5d53b"": {
            ""categories"": [
                ""Security Updates"",
                ""Windows Server 2016""
            ],
            ""filtered_reason"": ""category_names"",
            ""id"": ""6fec4991-24a9-485d-8eb8-841996b5d53b"",
            ""installed"": false,
            ""kb"": [
                ""5012170""
            ],
            ""title"": ""2022-08 Security Update for Windows Server 2016 for x64-based Systems (KB5012170)""
        },
        ""85604fae-a5c5-4f6d-9012-3d86be1bccce"": {
            ""categories"": [
                ""Updates"",
                ""Windows Server 2016""
            ],
            ""filtered_reason"": ""category_names"",
            ""id"": ""85604fae-a5c5-4f6d-9012-3d86be1bccce"",
            ""installed"": false,
            ""kb"": [
                ""4589210""
            ],
            ""title"": ""2021-01 Update for Windows Server 2016 for x64-based Systems (KB4589210)""
        },
        ""86304085-bf04-4b5a-8c9b-c09337402440"": {
            ""categories"": [
                ""Definition Updates"",
                ""Microsoft Defender Antivirus""
            ],
            ""filtered_reason"": ""category_names"",
            ""id"": ""86304085-bf04-4b5a-8c9b-c09337402440"",
            ""installed"": false,
            ""kb"": [
                ""2267602""
            ],
            ""title"": ""Security Intelligence Update for Microsoft Defender Antivirus - KB2267602 (Version 1.381.3024.0)""
        }
    },
    **""found_update_count"": 4,
    ""installed_update_count"": 4,**
    ""reboot_required"": false,
    ""updates"": {}
}

### Actual Results

```console
EXEC (via pipeline wrapper)
ok: [52.147.201.8] => {
    ""changed"": false,
    ""filtered_updates"": {
        ""3346a076-4bf6-48a1-b0d6-8422630f38b2"": {
            ""categories"": [
                ""Update Rollups"",
                ""Windows Server 2016"",
                ""Windows Server 2019""
            ],
            ""filtered_reason"": ""category_names"",
            ""id"": ""3346a076-4bf6-48a1-b0d6-8422630f38b2"",
            ""installed"": false,
            ""kb"": [
                ""890830""
            ],
            ""title"": ""Windows Malicious Software Removal Tool x64 - v5.109 (KB890830)""
        },
        ""6fec4991-24a9-485d-8eb8-841996b5d53b"": {
            ""categories"": [
                ""Security Updates"",
                ""Windows Server 2016""
            ],
            ""filtered_reason"": ""category_names"",
            ""id"": ""6fec4991-24a9-485d-8eb8-841996b5d53b"",
            ""installed"": false,
            ""kb"": [
                ""5012170""
            ],
            ""title"": ""2022-08 Security Update for Windows Server 2016 for x64-based Systems (KB5012170)""
        },
        ""85604fae-a5c5-4f6d-9012-3d86be1bccce"": {
            ""categories"": [
                ""Updates"",
                ""Windows Server 2016""
            ],
            ""filtered_reason"": ""category_names"",
            ""id"": ""85604fae-a5c5-4f6d-9012-3d86be1bccce"",
            ""installed"": false,
            ""kb"": [
                ""4589210""
            ],
            ""title"": ""2021-01 Update for Windows Server 2016 for x64-based Systems (KB4589210)""
        },
        ""86304085-bf04-4b5a-8c9b-c09337402440"": {
            ""categories"": [
                ""Definition Updates"",
                ""Microsoft Defender Antivirus""
            ],
            ""filtered_reason"": ""category_names"",
            ""id"": ""86304085-bf04-4b5a-8c9b-c09337402440"",
            ""installed"": false,
            ""kb"": [
                ""2267602""
            ],
            ""title"": ""Security Intelligence Update for Microsoft Defender Antivirus - KB2267602 (Version 1.381.3024.0)""
        }
    },
    ""found_update_count"": 0,
    ""installed_update_count"": 0,
    ""reboot_required"": false,
    ""updates"": {}
}
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-02-02T11:49:33Z,4,Create a YAML Ansible playbook to exhibit the following issue: ansible windows update module does not work in latest version of windows server 2016 ,"```
---
- name: Testing Windows update module
  hosts: windows_server_2016
  tasks:
    - name: Install Windows Updates
      win_updates:
        category_names:
          - SecurityUpdates
          - CriticalUpdates
          - DefinitionUpdates
        state: installed
      register: update_result
      
    - name: Display Update Result
      debug:
        var: update_result
...
```",1,"
---
- name: Testing Windows update module
  hosts: windows_server_2016
  tasks:
    - name: Install Windows Updates
      win_updates:
        category_names:
          - SecurityUpdates
          - CriticalUpdates
          - DefinitionUpdates
        state: installed
      register: update_result
      
    - name: Display Update Result
      debug:
        var: update_result
...
"
52,79883,connection plugin 'aws_ssm' was not found,"### Summary

When I try to connect hosts using `community.aws.aws_ssm` it shows following msg:
`the connection plugin 'aws_ssm' was not found`
I already installed aws_ssm plugin from ansible-galaxy collection. And, i configure dynamic inventory which is working fine. But can not connect host using aws_ssm agent. Also, all host has already ssm agent installed on them.

### Issue Type

Bug Report

### Component Name

apt

### Ansible Version

```console
$ ansible --version
ansible 2.9.27
 config file = /etc/ansible/ansible.cfg
  configured module search path = [u'/home/ubuntu/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules']
  ansible python module location = /usr/lib/python2.7/dist-packages/ansible
  executable location = /usr/bin/ansible
  python version = 2.7.17 (default, Nov 28 2022, 18:51:39) [GCC 7.5.0]
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed 
DEFAULT_HOST_LIST(/etc/ansible/ansible.cfg) = [u'/etc/ansible/aws_ec2.yaml']
INVENTORY_ENABLED(/etc/ansible/ansible.cfg) = [u'aws_ec2', u'aws_ssm']
```


### OS / Environment

```
$ cat /etc/os-release
NAME=""Ubuntu""
VERSION=""18.04.6 LTS (Bionic Beaver)""
ID=ubuntu
ID_LIKE=debian
PRETTY_NAME=""Ubuntu 18.04.6 LTS""
VERSION_ID=""18.04""
HOME_URL=""https://www.ubuntu.com/""
SUPPORT_URL=""https://help.ubuntu.com/""
BUG_REPORT_URL=""https://bugs.launchpad.net/ubuntu/""
PRIVACY_POLICY_URL=""https://www.ubuntu.com/legal/terms-and-policies/privacy-policy""
VERSION_CODENAME=bionic
UBUNTU_CODENAME=bionic
```

### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->
It is a simple playbook to test connectivity using `aws_ssm` plugin.
```yaml (paste below)
- hosts: all
  vars:
    ansible_connection: aws_ssm
    ansible_python_interpreter: /home/ubuntu/pyenv/shims/python3
    ansible_aws_ssm_region: us-east-1 # substitute for your region
  tasks:
    - name: test
      command:
        cmd: ls -l
```


### Expected Results

I assumed that aws_ssm plugin is worked and all hosts are connected using ssm agent.

### Actual Results

```console
$ ansible-playbook ssm_test.yml
[WARNING]: Failed to load inventory plugin, skipping aws_ssm

PLAY [all] ****************************************************************************************************************************************************************

TASK [Gathering Facts] ****************************************************************************************************************************************************
fatal: [x.x.x.x]: FAILED! => {""msg"": ""the connection plugin 'aws_ssm' was not found""}
fatal: [x.x.x.x]: FAILED! => {""msg"": ""the connection plugin 'aws_ssm' was not found""}

PLAY RECAP ****************************************************************************************************************************************************************
x.x.x.x                 : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0
x.x.x.x                 : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-02-02T11:29:11Z,6,Create a YAML Ansible playbook to exhibit the following issue: connection plugin 'aws_ssm' was not found,"```
---
- name: Test playbook
  hosts: localhost
  gather_facts: False
  connection: aws_ssm
```

Note: The playbook attempts to use the `aws_ssm` connection plugin which is not available by default on Ansible. This should result in an error message stating that the plugin was not found.",1,"
---
- name: Test playbook
  hosts: localhost
  gather_facts: False
  connection: aws_ssm
"
53,79880,--ask-become-pass silently ignores typed password,"### Summary

When `ANSIBLE_BECOME_PASSWORD_FILE` is defined, if `ansible-playbook --ask-become-pass` is executed, Ansible asks for a password but then ignores it and uses the one from the password file.

### Issue Type

Bug Report

### Component Name

ansible-playbook

### Ansible Version

```console
$ ansible --version
ansible 2.9.27
  config file = /home/user/repo/ansible.cfg
  configured module search path = ['/home/user/repo/library']
  ansible python module location = /home/user/.cache/pypoetry/virtualenvs/repo-MmWCTsjb-py3.11/lib/python3.11/site-packages/ansible
  executable location = /home/user/.cache/pypoetry/virtualenvs/repo-MmWCTsjb-py3.11/bin/ansible
  python version = 3.11.1 (main, Jan  6 2023, 00:00:00) [GCC 12.2.1 20221121 (Red Hat 12.2.1-4)]
```


### Configuration

```console
$ ansible-config dump --only-changed 
ALLOW_WORLD_READABLE_TMPFILES(/home/user/repo/ansible.cfg) = True
ANSIBLE_SSH_CONTROL_PATH(/home/user/repo/ansible.cfg) = %(directory)s/ssh-%%h-%%r
ANSIBLE_SSH_RETRIES(/home/user/repo/ansible.cfg) = 3
DEFAULT_CALLBACK_PLUGIN_PATH(/home/user/repo/ansible.cfg) = ['/home/user/repo/plugins/callbacks']
DEFAULT_CALLBACK_WHITELIST(/home/user/repo/ansible.cfg) = ['timer', 'slack']
DEFAULT_FORKS(env: ANSIBLE_FORKS) = 100
DEFAULT_MODULE_PATH(/home/user/repo/ansible.cfg) = ['/home/user/repo/library']
DEFAULT_ROLES_PATH(/home/user/repo/ansible.cfg) = ['/home/user/repo/roles']
DEFAULT_SCP_IF_SSH(/home/user/repo/ansible.cfg) = True
DEFAULT_STDOUT_CALLBACK(/home/user/repo/ansible.cfg) = debug
DEFAULT_STRATEGY(env: ANSIBLE_STRATEGY) = mitogen_linear
DEFAULT_STRATEGY_PLUGIN_PATH(env: ANSIBLE_STRATEGY_PLUGINS) = ['/home/user/bin/mitogen-0.2.9/ansible_mitogen/plugins/strategy']
DEFAULT_VARS_PLUGIN_PATH(/home/user/repo/ansible.cfg) = ['/home/user/repo/plugins/vars']
DUPLICATE_YAML_DICT_KEY(/home/user/repo/ansible.cfg) = ignore
HOST_KEY_CHECKING(/home/user/repo/ansible.cfg) = False
INVENTORY_IGNORE_EXTS(/home/user/repo/ansible.cfg) = [""''""]
MAX_FILE_SIZE_FOR_DIFF(env: ANSIBLE_MAX_DIFF_SIZE) = 99999999999999
RETRY_FILES_ENABLED(/home/user/repo/ansible.cfg) = False
```


### OS / Environment

Fedora 37

### Steps to Reproduce

```yaml
---
- hosts: all
  become: true
```

echo ""becomepassword"" > /home/user/becomepassword
export ANSIBLE_BECOME_PASSWORD_FILE=/home/user/becomepassword
ansible-playbook --ask-become-pass playbook.yml

### Expected Results

Password typed in the prompt has preference over the one in the file. OR; Ansible complains about the conflict and which password is going to be used.

### Actual Results

```console
Ansible continues running, ignores the password that was typed and uses the one from the file.
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-02-02T00:56:51Z,7,Create a YAML Ansible playbook to exhibit the following issue: --ask-become-pass silently ignores typed password,"```
---
- name: Testing Become Password Issue
  hosts: localhost
  gather_facts: false
  become: true
  tasks:
    - debug:
        msg: ""This task requires become privilege""

    - copy:
        src: /etc/hosts
        dest: /etc/hosts.backup

    - name: Verify Backup Exists
      assert:
        that:
          - ""/etc/hosts.backup is exists""
        msg: ""Backup file not found""

    - name: Attempt copy without become password
      copy:
        src: /etc/hosts
        dest: /etc/hosts.backup
      become: true
      become_method: sudo
      become_user: root
      become_ask_pass: true

    - name: Verify Copy Failed
      assert:
        that:
          - ""/etc/hosts.backup is exists""
        msg: ""copy was performed without password""

    - name: Attempt copy with become password
      copy:
        src: /etc/hosts
        dest: /etc/hosts.backup
      become: true
      become_method: sudo
      become_user: root
      become_password: ""{{ ansible_become_password }}""

    - name: Verify Copy Succeeded
      assert:
        that:
          - ""/etc/hosts.backup is exists""
        msg: ""Copy failed even when become password was provided""
...
```",1,"
---
- name: Testing Become Password Issue
  hosts: localhost
  gather_facts: false
  become: true
  tasks:
    - debug:
        msg: ""This task requires become privilege""

    - copy:
        src: /etc/hosts
        dest: /etc/hosts.backup

    - name: Verify Backup Exists
      assert:
        that:
          - ""/etc/hosts.backup is exists""
        msg: ""Backup file not found""

    - name: Attempt copy without become password
      copy:
        src: /etc/hosts
        dest: /etc/hosts.backup
      become: true
      become_method: sudo
      become_user: root
      become_ask_pass: true

    - name: Verify Copy Failed
      assert:
        that:
          - ""/etc/hosts.backup is exists""
        msg: ""copy was performed without password""

    - name: Attempt copy with become password
      copy:
        src: /etc/hosts
        dest: /etc/hosts.backup
      become: true
      become_method: sudo
      become_user: root
      become_password: ""{{ ansible_become_password }}""

    - name: Verify Copy Succeeded
      assert:
        that:
          - ""/etc/hosts.backup is exists""
        msg: ""Copy failed even when become password was provided""
...
"
54,79874,"""is defined"" reporting false for variable that is defined but has an error in nested variables","### Summary

Given the following variable:
```
  vars:
    myvar:
      nested: ""{{ some_other_var.missing_var }}""
```


And given the following when clause:
`  when: myvar is defined `

Older versions of Ansible, e.g. 2.13.3, would throw an error.

When running the same playbook with 2.14.2, no error is thrown.  With 2.14.2, the ""when"" clause evaluates to false.  It seems that a variable with an error is now being considered as undefined.

### Issue Type

Bug Report

### Component Name

vars

### Ansible Version

```console
$ ansible --version
ansible [core 2.14.2]
  config file = None
  configured module search path = ['/home/devops/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /usr/local/lib/python3.9/site-packages/ansible
  ansible collection location = /home/devops/.ansible/collections:/usr/share/ansible/collections
  executable location = /usr/local/bin/ansible
  python version = 3.9.13 (main, Nov  9 2022, 13:16:24) [GCC 8.5.0 20210514 (Red Hat 8.5.0-15)] (/usr/bin/python3.9)
  jinja version = 3.1.2
  libyaml = True
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
CONFIG_FILE() = None
```


### OS / Environment

ubi8 image - Red Hat Enterprise Linux release 8.7 (Ootpa)

### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->
```yaml
- hosts: localhost
  gather_facts: no
  vars:
    a: a_val
    b:
      nested: ""{{ missing }}""
  tasks:
  - when: a is defined
    ansible.builtin.debug:
      msg: ""{{ a }}""
  - when: b is defined
    ansible.builtin.debug:
      msg: ""{{ b }}""

```


### Expected Results

PLAY [localhost] ******************************************************************************************************

TASK [ansible.builtin.debug] ******************************************************************************************
ok: [localhost] => 
  a: a_val

TASK [ansible.builtin.debug] ******************************************************************************************
fatal: [localhost]: FAILED! => 
  msg: |-
    The conditional check 'b is defined' failed. The error was: error while evaluating conditional (b is defined): {'nested': '{{ missing }}'}: 'missing' is undefined
  
    The error appears to be in '/home/devops/src/playbooks/temp/validate-complex-object.yml': line 11, column 5, but may
    be elsewhere in the file depending on the exact syntax problem.
  
    The offending line appears to be:
  
          var: a
      - when: b is defined
        ^ here

### Actual Results

```console
PLAY [localhost] ******************************************************************************************************

TASK [ansible.builtin.debug] ******************************************************************************************
ok: [localhost] => {
    ""a"": ""a_val""
}

TASK [ansible.builtin.debug] ******************************************************************************************
skipping: [localhost]

PLAY RECAP ************************************************************************************************************
localhost                  : ok=1    changed=0    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-02-01T17:13:29Z,2,"Create a YAML Ansible playbook to exhibit the following issue: ""is defined"" reporting false for variable that is defined but has an error in nested variables","```
---
- hosts: localhost
  gather_facts: no

  vars:
    my_var:
      nested_var: ""{{ non_existent_var }}""

  tasks:
    - name: Test is defined
      debug:
        var: my_var['nested_var']
      when: my_var['nested_var'] is defined
```

Note: the `non_existent_var` variable is not defined, hence it will raise an error when trying to access it in the `my_var` nested variable. In result, the `my_var['nested_var']` variable will be defined but will contain an error, causing the `is defined` test to report false.",1,"
---
- hosts: localhost
  gather_facts: no

  vars:
    my_var:
      nested_var: ""{{ non_existent_var }}""

  tasks:
    - name: Test is defined
      debug:
        var: my_var['nested_var']
      when: my_var['nested_var'] is defined
"
55,79870,ansible-core 2.13.x breaks PyEZ authentication with SSH public key,"### Summary

I am using the `Juniper.junos` role to deploy configuration changes to Juniper devices via NETCONF - specifically the `juniper_junos_config` module - example task below:

```
        - name: ""junos commit check""
          juniper_junos_config:
            load: ""override""
            format: ""text""
            src: ""build/{{ inventory_hostname }}.cfg""
            check: true
            diff: true
            commit: false
            timeout: 60
```

Authentication is via a password protected ed25519 public key and the Playbook is instantiated using the following command:

```
ansible-playbook playbook.yml -i sites/hosts.yml -u ansible -k --private-key ~/.ssh/ansible_ed25519 -l <device>
```

This is under Python 3.8 in a virtual environment where I have installed:

```
ansible-core==2.13.0
ansible-pylibssh==1.1.0
junos-eznc==2.6.6
jxmlease==1.0.3
ncclient==0.6.13
paramiko==3.0.0
```

This has been running fine without issue, but since upgrading to `ansible-core 2.13.x` it has stopped working and is presenting me with the following error:

```
Unable to make a PyEZ connection: ConnectAuthError(<device>)
```

If I rollback to `ansible-core 2.12.10` then it works fine - if I specify `-vvv` on the command line, then I can see why it is failing under `ansible-core 2.13.x` (traceback has been snipped for brevity):

```
The full traceback is:
  File ""/tmp/ansible_juniper_junos_config_payload__gpm17z7/ansible_juniper_junos_config_payload.zip/ansible/module_utils/juniper_junos_common.py"", line 1300, in open
    self.dev.open()
  File ""/home/<user>/venv/lib64/python3.8/site-packages/jnpr/junos/device.py"", line 1382, in open
    raise EzErrors.ConnectAuthError(self)
fatal: [<device>]: FAILED! => {
    ""changed"": false,
    ""invocation"": {
        ""module_args"": {
            ""host"": ""<device>"",
            ""passwd"": null,
            ""port"": 830,
            ""provider"": null,
            ""src"": ""build/<device>.cfg"",
            ""ssh_config"": null,
            ""ssh_private_key_file"": null,
            ""user"": ""ansible"",
        }
    },
    ""msg"": ""Unable to make a PyEZ connection: ConnectAuthError(<device>)""
}
```

In the above output you can see that `ssh_private_key_file` is null when on `ansible-core 2.12.x` it points to the correct private key for SSH, e.g:

```
changed: [<device>] => {
    ""invocation"": {
        ""module_args"": {
            ""host"": ""<device>"",
            ""passwd"": ""VALUE_SPECIFIED_IN_NO_LOG_PARAMETER"",
            ""port"": 830,
            ""provider"": null,
            ""src"": ""build/<device>.cfg"",
            ""ssh_config"": null,
            ""ssh_private_key_file"": ""/home/<user>/.ssh/ansible_ed25519"",
            ""user"": ""ansible"",
        }
    },
    ""msg"": ""Configuration has been: opened, loaded, checked, diffed, closed.""
}
```

I haven't tried `ansible-core 2.14.x` as it appears that it requires Python 3.9 even though Python 3.8 doesn't reach end of support until Oct 2024?!

It looks like the authentication parameters which are being passed on the command line aren't making it through to the module responsible for performing the connection.



### Issue Type

Bug Report

### Component Name

ansible-core

### Ansible Version

```console
$ ansible --version

ansible [core 2.13.7]
  config file = /home/<user>/<dir>/ansible.cfg
  configured module search path = ['/home/<user>/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /home/<user>/venv/python/lib64/python3.8/site-packages/ansible
  ansible collection location = /home/<user>/.ansible/collections:/usr/share/ansible/collections
  executable location = /home/<user>/venv/python/bin/ansible
  python version = 3.8.13 (default, Jun 14 2022, 17:49:07) [GCC 8.5.0 20210514 (Red Hat 8.5.0-13)]
  jinja version = 3.1.2
  libyaml = True
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all

DEFAULT_VAULT_PASSWORD_FILE(env: ANSIBLE_VAULT_PASSWORD_FILE) = /home/<user>/.ansible/.vault_password
DISPLAY_SKIPPED_HOSTS(/home/<user>/<dir>/ansible.cfg) = False
HOST_KEY_CHECKING(/home/<user>/<dir>/ansible.cfg) = False
INTERPRETER_PYTHON(/home/<user>/<dir>/ansible.cfg) = ~/venv/python/bin/python3

CALLBACK:
========

default:
_______
display_skipped_hosts(/home/<user>/<dir>/ansible.cfg) = False

CONNECTION:
==========

paramiko_ssh:
____________
host_key_checking(/home/<user>/<dir>/ansible.cfg) = False

ssh:
___
host_key_checking(/home/<user>/<dir>/ansible.cfg) = False
```


### OS / Environment

RHEL 8.6

### Steps to Reproduce

1. Setup Python virtual environment:

```
python3.8 -m venv ~/venv/python
~/venv/python/bin/python3 -m pip install --upgrade pip
~/venv/python/bin/python3 -m pip install --upgrade ansible-core junos-eznc jxmlease ncclient paramiko ansible-pylibssh
```

2. Execute Playbook using the following command:

```
~/venv/python/bin/ansible-playbook playbook.yml -i sites/hosts.yml -u ansible -k --private-key ~/.ssh/ansible_ed25519 -l <device>
```

3. This results in the following error:

```
TASK [junos commit check] *******************************************************************************************************************************************************************************************
fatal: [<device>]: FAILED! => {""changed"": false, ""msg"": ""Unable to make a PyEZ connection: ConnectAuthError(<device>)""}
```

Playbook is:

```
---
- hosts: all
  gather_facts: no
  serial: [1, 2, 3, 4, 5]

  roles:
    - Juniper.junos

  tasks:
    - name: ""junos commit check""
      juniper_junos_config:
        load: ""override""
        format: ""text""
        src: ""build/{{ inventory_hostname }}.cfg""
        check: true
        diff: true
        commit: false
        timeout: 60
      register: response

    - name: ""diff""
      debug: var=response.diff_lines
      when: response.diff_lines is defined
```


### Expected Results

I expect it to have the same behavior as `ansible-core 2.12.x` and any release prior - if I change ansible-core to 2.12 via the following command:

```
~/venv/python/bin/python3 -m pip install --upgrade ""ansible-core<2.13"" junos-eznc jxmlease ncclient paramiko ansible-pylibssh
```

Then everything works as expected.

### Actual Results

```console
Included in the text above.
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-02-01T08:33:58Z,4,Create a YAML Ansible playbook to exhibit the following issue: ansible-core 2.13.x breaks PyEZ authentication with SSH public key,"```
---
- name: exhibit ansible-core issue
  hosts: <your_hosts>
  gather_facts: false

  tasks:
    - name: install PyEZ
      pip:
        name: junos-eznc
        state: present
    
    - name: connect to device with PyEZ
      junos_command:
        command: show interface terse
      register: result
      no_log: true
      
    - debug:
        var: result.stdout_lines
    
``` 
Note: Replace `<your_hosts>`  with the name of your hosts.",1,"
---
- name: exhibit ansible-core issue
  hosts: <your_hosts>
  gather_facts: false

  tasks:
    - name: install PyEZ
      pip:
        name: junos-eznc
        state: present
    
    - name: connect to device with PyEZ
      junos_command:
        command: show interface terse
      register: result
      no_log: true
      
    - debug:
        var: result.stdout_lines
    
"
56,79862,Strange behaviour of the debug module on syntax error.,"### Summary

I might have found a bug, possibly in the debug module, possibly elsewhere.
This is a trivial playbook to reproduce the error:-

    - name: is this a bug?
      gather_facts: no
      hosts: localhost
      tasks:
      - ansible.builtin.debug:
          msg ""this should be a syntax error""
      - ansible.builtin.debug:
          msg: ""{{ inventory_hostname }} this should work""

When run this is the output (**Exactly as expected**)

    ERROR! this task 'ansible.builtin.debug' has extra params, which is only allowed in the following modules: ansible.builtin.raw, ansible.legacy.raw, ansible.builtin.import_role, set_fact, ansible.legacy.add_host, ansible.legacy.script, ansible.legacy.import_tasks, import_role, ansible.builtin.meta, win_shell, ansible.builtin.add_host, ansible.builtin.command, meta, ansible.windows.win_command, ansible.legacy.include_role, shell, import_tasks, add_host, ansible.legacy.win_shell, ansible.builtin.include_role, ansible.legacy.group_by, win_command, include_role, ansible.legacy.include_vars, ansible.legacy.include_tasks, raw, include_vars, group_by, ansible.builtin.set_fact, ansible.legacy.command, command, ansible.builtin.win_command, script, ansible.legacy.set_fact, ansible.legacy.win_command, ansible.legacy.meta, ansible.legacy.import_role, ansible.builtin.import_tasks, ansible.builtin.shell, include_tasks, ansible.builtin.include_vars, ansible.builtin.script, include, ansible.windows.win_shell, ansible.builtin.group_by, ansible.builtin.include_tasks, ansible.builtin.include, ansible.legacy.shell, ansible.legacy.include, ansible.builtin.win_shell

    The error appears to be in '/home/user/t.yml': line 5, column 5, but may
    be elsewhere in the file depending on the exact syntax problem.

    The offending line appears to be:

      tasks:
      - ansible.builtin.debug:
        ^ here



Note that the first call to debug has a badly formed msg line. (There is no ``` : ``` after ``` msg``` ) and so this syntax error is what I would expect.

This isn't the interesting part though. The interesting part is that if I add a jinja variable to the message (any defined variable will do) , Like this:-

    - name: is this a bug?
      gather_facts: no
      hosts: localhost
      tasks:
      - ansible.builtin.debug:
          msg ""this should be also be a syntax error {{ inventory_hostname }}""
      - ansible.builtin.debug:
          msg: ""{{ inventory_hostname }} this should work""


the code runs and gives this output:-

    PLAY [is this a bug?] **********************************************************

    TASK [ansible.builtin.debug] ***************************************************
    ok: [localhost] => {}

    MSG:

    Hello world!

    TASK [ansible.builtin.debug] ***************************************************
    ok: [localhost] => {}

    MSG:

    localhost this should work

    PLAY RECAP *********************************************************************
    localhost                  : ok=2    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0


i.e   the debug module does it's default behaviour and prints ``` Hello world! ``` instead of raising a syntax error. No mention of the malformed ``` msg ``` line is made at all.

I'm sure that is wrong, but I don't know how to check if it is an existing issue or a new one.

### Issue Type

Bug Report

### Component Name

ansible.builtin.debug

### Ansible Version

```console
$ ansible --version

ansible [core 2.13.3]
  config file = /home/adam/.ansible.cfg
  configured module search path = ['/home/adam/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /home/adam/.local/lib/python3.10/site-packages/ansible
  ansible collection location = /home/adam/.ansible/collections:/usr/share/ansible/collections
  executable location = /home/adam/.local/bin/ansible
  python version = 3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]
  jinja version = 3.0.3
  libyaml = True


And also:-

$ ansible --version
ansible 2.9.21
  config file = /etc/ansible/ansible.cfg
  configured module search path = ['/home/adam/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /usr/lib/python3.8/site-packages/ansible
  executable location = /usr/bin/ansible
  python version = 3.8.10 (default, May  4 2021, 00:00:00) [GCC 10.2.1 20201125 (Red Hat 10.2.1-9)]
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all

# I tested on a clean install, no output is generated.


# I also tested on an ansible 2.9.21 system and got this:-

$ ansible-config dump --only-changed
DEFAULT_STDOUT_CALLBACK(env: ANSIBLE_STDOUT_CALLBACK) = debug
GALAXY_SERVER_LIST(/etc/ansible/ansible.cfg) = ['automation_hub']
```


### OS / Environment

Core 2.13.3 was tested on Ubuntu 22.04.1 LTS 
ansible 2.9.21 was tested on Fedora 32

I was able to reproduce this behaviour on several other Linux distros and versions. 

### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->
```yaml (paste below)
    - name: is this a bug?
      gather_facts: no
      hosts: localhost
      tasks:
      - ansible.builtin.debug:
          msg ""this should be also be a syntax error {{ inventory_hostname }}""
      - ansible.builtin.debug:
          msg: ""{{ inventory_hostname }} this should work""

```


### Expected Results

As per the description I expected a syntax error as follows:-

`    ERROR! this task 'ansible.builtin.debug' has extra params, which is only allowed in the following modules: ansible.builtin.raw, ansible.legacy.raw, ansible.builtin.import_role, set_fact, ansible.legacy.add_host, ansible.legacy.script, ansible.legacy.import_tasks, import_role, ansible.builtin.meta, win_shell, ansible.builtin.add_host, ansible.builtin.command, meta, ansible.windows.win_command, ansible.legacy.include_role, shell, import_tasks, add_host, ansible.legacy.win_shell, ansible.builtin.include_role, ansible.legacy.group_by, win_command, include_role, ansible.legacy.include_vars, ansible.legacy.include_tasks, raw, include_vars, group_by, ansible.builtin.set_fact, ansible.legacy.command, command, ansible.builtin.win_command, script, ansible.legacy.set_fact, ansible.legacy.win_command, ansible.legacy.meta, ansible.legacy.import_role, ansible.builtin.import_tasks, ansible.builtin.shell, include_tasks, ansible.builtin.include_vars, ansible.builtin.script, include, ansible.windows.win_shell, ansible.builtin.group_by, ansible.builtin.include_tasks, ansible.builtin.include, ansible.legacy.shell, ansible.legacy.include, ansible.builtin.win_shell
`


### Actual Results

```console
$ ansible-playbook t.yml -i localhost,

PLAY [is this a bug?] ****************************************************************************************************************************************************************************

TASK [ansible.builtin.debug] *********************************************************************************************************************************************************************
ok: [localhost] => {
    ""msg"": ""Hello world!""
}

TASK [ansible.builtin.debug] *********************************************************************************************************************************************************************
ok: [localhost] => {
    ""msg"": ""localhost this should work""
}

PLAY RECAP ***************************************************************************************************************************************************************************************
localhost                  : ok=2    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-01-31T16:11:07Z,4,Create a YAML Ansible playbook to exhibit the following issue: Strange behaviour of the debug module on syntax error.,"```
---
- name: Debug Module Syntax Error
  hosts: localhost
  gather_facts: false

  tasks:
    - name: Debug with Syntax Error
      debug:
        msg: ""{{ 'Hello {{ World' }}""
```
",1,"
---
- name: Debug Module Syntax Error
  hosts: localhost
  gather_facts: false

  tasks:
    - name: Debug with Syntax Error
      debug:
        msg: ""{{ 'Hello {{ World' }}""
"
57,79861,Systemd user services cannot be enabled globally,"### Summary

When trying to install a systemd service for all users (`scope: global`) I always get an error about not being able to connect to the bus:
`fatal: [***]: FAILED! => {""changed"": false, ""msg"": ""failure 1 during daemon-reload: Failed to connect to bus: Operation not permitted\n""}`

I read, that `XDG_RUNTIME_DIR` needs to be set and did so.
I tried using the become user (root), but also the user logged into to the system (see below).
The directory `/run/user/1001` exists but is only readable to the user.

When running `sudo systemctl --global enable my_user_service.service` everything works as expected.

```
- name: get my user id
  become: no
  command: id -u
  register: myuid

- name: ""Enable systemd user service for all users""
  systemd:
    daemon_reload: yes
    name: my_user_service.service
    scope: global
    enabled: yes
  environment:
    XDG_RUNTIME_DIR: /run/user/{{myuid.stdout}}
    #DBUS_SESSION_BUS_ADDRESS: unix:path=/run/user/{{myuid.stdout}}/bus
```

Tried with and without the `DBUS_SESSION_BUS_ADDRESS`, but no luck either.

This is probably related to #27631, but changing scope `user` instead of `global` will not fix this for me, as I want the service for all users logging into the interactive system.


System: 
* Ansible 2.14.1 running with Python 3.10.9
* Target: Kubuntu 20.04 with all current updates installed

### Issue Type

Bug Report

### Component Name

ansible.builtin.systemd_service

### Ansible Version

```console
ansible [core 2.14.1]
  config file = /home/***/***/ansible/ansible.cfg
  configured module search path = ['/home/***/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /usr/lib/python3.10/site-packages/ansible
  ansible collection location = /home/***/.ansible/collections:/usr/share/ansible/collections
  executable location = /usr/bin/ansible
  python version = 3.10.9 (main, Dec 19 2022, 17:35:49) [GCC 12.2.0] (/usr/bin/python)
  jinja version = 3.1.2
  libyaml = True
```


### Configuration

```console
CONFIG_FILE() = /home/***/***/ansible/ansible.cfg
DEFAULT_BECOME(/home/***/***/ansible/ansible.cfg) = True
DEFAULT_BECOME_METHOD(/home/***/***/ansible/ansible.cfg) = sudo
DEFAULT_BECOME_USER(/home/***/***/ansible/ansible.cfg) = root
DEFAULT_VAULT_PASSWORD_FILE(env: ANSIBLE_VAULT_PASSWORD_FILE) = /home/***/***/.ansible-vault
INVENTORY_ENABLED(/home/***/***/ansible/ansible.cfg) = ['host_list', 'script', 'auto', 'yaml', 'ini', 'toml', 'community.general.xen_orchestra']

BECOME:
======

runas:
_____
become_user(/home/***/***/ansible/ansible.cfg) = root

su:
__
become_user(/home/***/***/ansible/ansible.cfg) = root

sudo:
____
become_user(/home/***/***/ansible/ansible.cfg) = root
```


### OS / Environment

Executing environment: Arch Linux
Target: Kubuntu 20.04

### Steps to Reproduce

```
- name: get my user id
  become: no
  command: id -u
  register: myuid

- name: ""Enable systemd user service for all users""
  systemd:
    daemon_reload: yes
    name: my_user_service.service
    scope: global
    enabled: yes
  environment:
    XDG_RUNTIME_DIR: /run/user/{{myuid.stdout}}
    #DBUS_SESSION_BUS_ADDRESS: unix:path=/run/user/{{myuid.stdout}}/bus
```

### Expected Results

It should enable the service `my_user_service` for all users as systemd user service.

### Actual Results

```console
fatal: [PC-**]: FAILED! => {""changed"": false, ""msg"": ""failure 1 during daemon-reload: Failed to connect to bus: Operation not permitted\n""}
```
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-01-31T11:16:58Z,3,Create a YAML Ansible playbook to exhibit the following issue: Systemd user services cannot be enabled globally,"```
---
- name: Test playbook for Systemd user services
  hosts: all
  tasks:
    - name: Add a systemd user service
      copy:
        dest: ~/.config/systemd/user/my-service.service
        content: |
          [Unit]
          Description=My Service

          [Service]
          Type=simple
          ExecStart=/usr/bin/sleep infinity

    - name: Try to enable the service globally
      systemd:
        name: my-service.service
        enabled: yes
        state: started
        scope: global
      register: result

    - name: Show the result of enabling the service globally
      debug:
        var: result
```
",1,"
---
- name: Test playbook for Systemd user services
  hosts: all
  tasks:
    - name: Add a systemd user service
      copy:
        dest: ~/.config/systemd/user/my-service.service
        content: |
          [Unit]
          Description=My Service

          [Service]
          Type=simple
          ExecStart=/usr/bin/sleep infinity

    - name: Try to enable the service globally
      systemd:
        name: my-service.service
        enabled: yes
        state: started
        scope: global
      register: result

    - name: Show the result of enabling the service globally
      debug:
        var: result
"
58,79860,Conditionnal bug report,"### Summary

Hello, I am just trying to check a condition I would like a task to run only when the condition is met.

When I try to do a test as you can see below, my task runs when it should not.

This error appears only when I use the ""or"" operator


my playbook : 

```yaml
---

- name: debug module demo
  hosts: all


  tasks:
    - set_fact:
        ansible_become_method: ""su""
      when: ansible_distribution_version == ""9"" or ""10"" or ""11""


    - name: ""task 1""
      debug: var=ansible_distribution_version
      when: ansible_distribution_version == ""bbbb"" or ""aaa""
```

the result: 
```bash
PLAY [debug module demo] ***********************************************************************************************************************************
TASK [Gathering Facts] *************************************************************************************************************************************
ok: [sbvs-ansible-test]

TASK [set_fact] ********************************************************************************************************************************************
ok: [sbvs-ansible-test]

TASK [task 1] **********************************************************************************************************************************************
ok: [sbvs-ansible-test] => {
    ""ansible_distribution_version"": ""11""
}

PLAY RECAP *************************************************************************************************************************************************
sbvs-ansible-test          : ok=3    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
```
as you can see the task1 running while ansible_distribution_version is equal to ""11"" and not ""bbbb"" or ""aaa""





my ansible version :
````bash
ansible [core 2.14.1]
  config file = /home/technicien/ansible/ansible.cfg
  configured module search path = ['/home/technicien/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /home/technicien/.local/lib/python3.10/site-packages/ansible
  ansible collection location = /home/technicien/.ansible/collections:/usr/share/ansible/collections
  executable location = /home/technicien/.local/bin/ansible
  python version = 3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0] (/usr/bin/python3)
  jinja version = 3.0.3
  libyaml = True
```

### Issue Type

Bug Report

### Component Name

when

### Ansible Version

```console
$ ansible --version

ansible [core 2.14.1]
  config file = /home/technicien/ansible/ansible.cfg
  configured module search path = ['/home/technicien/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /home/technicien/.local/lib/python3.10/site-packages/ansible
  ansible collection location = /home/technicien/.ansible/collections:/usr/share/ansible/collections
  executable location = /home/technicien/.local/bin/ansible
  python version = 3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0] (/usr/bin/python3)
  jinja version = 3.0.3
  libyaml = True
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all

CONFIG_FILE() = /home/technicien/ansible/ansible.cfg
DEFAULT_HOST_LIST(/home/technicien/ansible/ansible.cfg) = ['/home/technicien/ansible/inventory.yml']
HOST_KEY_CHECKING(/home/technicien/ansible/ansible.cfg) = False

CONNECTION:
==========

paramiko_ssh:
____________
host_key_checking(/home/technicien/ansible/ansible.cfg) = False

ssh:
___
host_key_checking(/home/technicien/ansible/ansible.cfg) = False
```


### OS / Environment

Node server : ubuntu 22.04
Host : Debian 11

### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->
```yaml (paste below)


- name: debug module demo
  hosts: all


  tasks:
    - set_fact:
        ansible_become_method: ""su""
      when: ansible_distribution_version == ""9"" or ""10"" or ""11""


    - name: ""task 1""
      debug: var=ansible_distribution_version
      when: ansible_distribution_version == ""bbbb"" or ""aaa""

### Expected Results

PLAY [debug module demo] ***********************************************************************************************************************************
TASK [Gathering Facts] *************************************************************************************************************************************
ok: [sbvs-ansible-test]

TASK [set_fact] ********************************************************************************************************************************************
ok: [sbvs-ansible-test]

TASK [task 1] **********************************************************************************************************************************************
skipped: [sbvs-ansible-test] => {
   SKIPPED
}

PLAY RECAP *************************************************************************************************************************************************
sbvs-ansible-test          : ok=2    changed=0    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0

### Actual Results

```console
PLAY [debug module demo] ***********************************************************************************************************************************
TASK [Gathering Facts] *************************************************************************************************************************************
ok: [sbvs-ansible-test]

TASK [set_fact] ********************************************************************************************************************************************
ok: [sbvs-ansible-test]

TASK [task 1] **********************************************************************************************************************************************
ok: [sbvs-ansible-test] => {
    ""ansible_distribution_version"": ""11""
}

PLAY RECAP *************************************************************************************************************************************************
sbvs-ansible-test          : ok=3    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-01-31T10:14:35Z,2,Create a YAML Ansible playbook to exhibit the following issue: Conditionnal bug report,"```
---
- name: Playbook to exhibit a Conditional Bug Report
  hosts: all
  become: yes
  
  tasks:
  
  - name: Task to verify OS version
    ansible.builtin.shell: cat /etc/os-release
    register: os_info
    
  - name: Task to report bug
    ansible.builtin.debug:
      msg: ""This is a bug report for CentOS 8""
    when: '""CentOS Linux"" in os_info.stdout'
  
  - name: Task to report bug
    ansible.builtin.debug:
      msg: ""This is a bug report for Ubuntu 20.04""
    when: '""Ubuntu"" in os_info.stdout' 

...
```",1,"
---
- name: Playbook to exhibit a Conditional Bug Report
  hosts: all
  become: yes
  
  tasks:
  
  - name: Task to verify OS version
    ansible.builtin.shell: cat /etc/os-release
    register: os_info
    
  - name: Task to report bug
    ansible.builtin.debug:
      msg: ""This is a bug report for CentOS 8""
    when: '""CentOS Linux"" in os_info.stdout'
  
  - name: Task to report bug
    ansible.builtin.debug:
      msg: ""This is a bug report for Ubuntu 20.04""
    when: '""Ubuntu"" in os_info.stdout' 

...
"
59,79858,"apt_repository: The repository ...  does not have a Release file.""","### Summary

Given:  

```
- name: add passenger repo
      ansible.builtin.apt_repository:
        repo: ""deb http://oss-binaries.phusionpassenger.com/apt/passenger/ {{ansible_distribution_release}} main""
```

On Ubuntu focal,   it says:
Failed to update apt cache: E:The repository 'http://oss-binaries.phusionpassenger.com/apt/passenger focal Release' does not have a Release file.""

I can manually put 
`deb http://oss-binaries.phusionpassenger.com/apt/passenger/ focal main`  into an apt/sources.list.d/passenger.list file, run apt-update and it works just fine in the command line, but from then on any other call to apt_repository in ansible will fail with this message.  Once I remove that file, other calls to apt_repository work, but the presence of this repo seems to break it.    What's different?

### Issue Type

Bug Report

### Component Name

apt_repository

### Ansible Version

```console
$ ansible --version
ansible [core 2.14.2]
  config file = /ansible/playbooks/ansible.cfg
  configured module search path = ['/ansible/playbooks/library']
  ansible python module location = /usr/local/lib/python3.10/dist-packages/ansible
  ansible collection location = /root/.ansible/collections:/usr/share/ansible/collections
  executable location = /usr/local/bin/ansible
  python version = 3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0] (/usr/bin/python3)
  jinja version = 3.0.3
  libyaml = True
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
CONFIG_FILE() = /ansible/playbooks/ansible.cfg
DEFAULT_FILTER_PLUGIN_PATH(/ansible/playbooks/ansible.cfg) = ['/ansible/playbooks/filter_plugins']
DEFAULT_GATHERING(env: ANSIBLE_GATHERING) = smart
DEFAULT_HOST_LIST(/ansible/playbooks/ansible.cfg) = ['/ansible/playbooks/aws/aws_ec2.yaml']
DEFAULT_LOOKUP_PLUGIN_PATH(/ansible/playbooks/ansible.cfg) = ['/ansible/playbooks/lookup_plugins']
DEFAULT_MANAGED_STR(/ansible/playbooks/ansible.cfg) = This file is managed by Ansible, all changes will be lost.
DEFAULT_MODULE_PATH(/ansible/playbooks/ansible.cfg) = ['/ansible/playbooks/library']
DEFAULT_REMOTE_USER(/ansible/playbooks/ansible.cfg) = ubuntu
DEFAULT_ROLES_PATH(env: ANSIBLE_ROLES_PATH) = ['/ansible/playbooks/roles']
DEFAULT_VAULT_PASSWORD_FILE(/ansible/playbooks/ansible.cfg) = /root/.ansible_vault.txt
HOST_KEY_CHECKING(env: ANSIBLE_HOST_KEY_CHECKING) = False
INTERPRETER_PYTHON(/ansible/playbooks/ansible.cfg) = auto
INVENTORY_ENABLED(/ansible/playbooks/ansible.cfg) = ['aws_ec2']
RETRY_FILES_ENABLED(env: ANSIBLE_RETRY_FILES_ENABLED) = False
TRANSFORM_INVALID_GROUP_CHARS(/ansible/playbooks/ansible.cfg) = ignore

CONNECTION:
==========

paramiko_ssh:
____________
host_key_checking(env: ANSIBLE_HOST_KEY_CHECKING) = False
remote_user(/ansible/playbooks/ansible.cfg) = ubuntu

ssh:
___
host_key_checking(env: ANSIBLE_HOST_KEY_CHECKING) = False
pipelining(env: ANSIBLE_SSH_PIPELINING) = True
remote_user(/ansible/playbooks/ansible.cfg) = ubuntu

LOOKUP:
======

credstash:
_________
profile_name(env: AWS_PROFILE) = default
```


### OS / Environment

ansible is running in a docker container of ubuntu 22.04.    Target host is Ubuntu 20.04

### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->
```yaml (paste below)
    - name: add passenger repo
      ansible.builtin.apt_repository:
        repo: ""deb http://oss-binaries.phusionpassenger.com/apt/passenger/ {{ansible_distribution_release}} main""
```


### Expected Results

I expect `deb http://oss-binaries.phusionpassenger.com/apt/passenger/ focal main` to be deposited into a file under /etc/apt/sources.list.d/

### Actual Results

```console
TASK [add passenger repo] *******************************************************************************************************************************************************************************************************************************************************************************************************************************
task path: /ansible/playbooks/playbooks/rails-sites/bedrock.yml:70
Including module_utils file ansible/__init__.py
Including module_utils file ansible/module_utils/__init__.py
Including module_utils file ansible/module_utils/_text.py
Including module_utils file ansible/module_utils/basic.py
Including module_utils file ansible/module_utils/common/_collections_compat.py
Including module_utils file ansible/module_utils/common/__init__.py
Including module_utils file ansible/module_utils/common/_json_compat.py
Including module_utils file ansible/module_utils/common/_utils.py
Including module_utils file ansible/module_utils/common/arg_spec.py
Including module_utils file ansible/module_utils/common/file.py
Including module_utils file ansible/module_utils/common/locale.py
Including module_utils file ansible/module_utils/common/parameters.py
Including module_utils file ansible/module_utils/common/collections.py
Including module_utils file ansible/module_utils/common/process.py
Including module_utils file ansible/module_utils/common/respawn.py
Including module_utils file ansible/module_utils/common/sys_info.py
Including module_utils file ansible/module_utils/common/text/converters.py
Including module_utils file ansible/module_utils/common/text/__init__.py
Including module_utils file ansible/module_utils/common/text/formatters.py
Including module_utils file ansible/module_utils/common/validation.py
Including module_utils file ansible/module_utils/common/warnings.py
Including module_utils file ansible/module_utils/compat/selectors.py
Including module_utils file ansible/module_utils/compat/__init__.py
Including module_utils file ansible/module_utils/compat/_selectors2.py
Including module_utils file ansible/module_utils/compat/selinux.py
Including module_utils file ansible/module_utils/distro/__init__.py
Including module_utils file ansible/module_utils/distro/_distro.py
Including module_utils file ansible/module_utils/errors.py
Including module_utils file ansible/module_utils/parsing/convert_bool.py
Including module_utils file ansible/module_utils/parsing/__init__.py
Including module_utils file ansible/module_utils/pycompat24.py
Including module_utils file ansible/module_utils/six/__init__.py
Including module_utils file ansible/module_utils/urls.py
Including module_utils file ansible/module_utils/compat/typing.py
Using module file /usr/local/lib/python3.10/dist-packages/ansible/modules/apt_repository.py
Pipelining is enabled.
<172.30.2.16> ESTABLISH SSH CONNECTION FOR USER: ubuntu
<172.30.2.16> SSH: ansible.cfg set ssh_args: (-C)(-o)(ControlMaster=auto)(-o)(ControlPersist=60s)
<172.30.2.16> SSH: ANSIBLE_HOST_KEY_CHECKING/host_key_checking disabled: (-o)(StrictHostKeyChecking=no)
<172.30.2.16> SSH: ansible_password/ansible_ssh_password not set: (-o)(KbdInteractiveAuthentication=no)(-o)(PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey)(-o)(PasswordAuthentication=no)
<172.30.2.16> SSH: ANSIBLE_REMOTE_USER/remote_user/ansible_user/user/-u set: (-o)(User=""ubuntu"")
<172.30.2.16> SSH: ANSIBLE_TIMEOUT/timeout set: (-o)(ConnectTimeout=10)
<172.30.2.16> SSH: Set ssh_common_args: ()
<172.30.2.16> SSH: Set ssh_extra_args: ()
<172.30.2.16> SSH: found only ControlPersist; added ControlPath: (-o)(ControlPath=""/root/.ansible/cp/df252e8f9c"")
<172.30.2.16> SSH: EXEC ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o StrictHostKeyChecking=no -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=""ubuntu""' -o ConnectTimeout=10 -o 'ControlPath=""/root/.ansible/cp/df252e8f9c""' 172.30.2.16 '/bin/sh -c '""'""'sudo -H -S -n  -u root /bin/sh -c '""'""'""'""'""'""'""'""'echo BECOME-SUCCESS-xpfrryaqvbvaxfytmmalfahlxvwgceas ; /usr/bin/python3'""'""'""'""'""'""'""'""' && sleep 0'""'""''
Escalation succeeded
<172.30.2.16> (1, b'\n{""failed"": true, ""msg"": ""Failed to update apt cache: E:The repository \'http://oss-binaries.phusionpassenger.com/apt/passenger focal Release\' does not have a Release file."", ""invocation"": {""module_args"": {""repo"": ""deb http://oss-binaries.phusionpassenger.com/apt/passenger/ focal main"", ""state"": ""present"", ""update_cache"": true, ""update_cache_retries"": 5, ""update_cache_retry_max_delay"": 12, ""install_python_apt"": true, ""validate_certs"": true, ""mode"": null, ""filename"": null, ""codename"": null}}}\n', b""OpenSSH_8.9p1 Ubuntu-3ubuntu0.1, OpenSSL 3.0.2 15 Mar 2022\r\ndebug1: Reading configuration data /root/.ssh/config\r\ndebug1: /root/.ssh/config line 22: Applying options for 172.30.*\r\ndebug1: /root/.ssh/config line 55: Applying options for *\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 19: include /etc/ssh/ssh_config.d/*.conf matched no files\r\ndebug1: /etc/ssh/ssh_config line 21: Applying options for *\r\ndebug2: resolve_canonicalize: hostname 172.30.2.16 is address\r\ndebug3: expanded UserKnownHostsFile '~/.ssh/known_hosts' -> '/root/.ssh/known_hosts'\r\ndebug3: expanded UserKnownHostsFile '~/.ssh/known_hosts2' -> '/root/.ssh/known_hosts2'\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 19\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 1\r\n"")
<172.30.2.16> Failed to connect to the host via ssh: OpenSSH_8.9p1 Ubuntu-3ubuntu0.1, OpenSSL 3.0.2 15 Mar 2022
debug1: Reading configuration data /root/.ssh/config
debug1: /root/.ssh/config line 22: Applying options for 172.30.*
debug1: /root/.ssh/config line 55: Applying options for *
debug1: Reading configuration data /etc/ssh/ssh_config
debug1: /etc/ssh/ssh_config line 19: include /etc/ssh/ssh_config.d/*.conf matched no files
debug1: /etc/ssh/ssh_config line 21: Applying options for *
debug2: resolve_canonicalize: hostname 172.30.2.16 is address
debug3: expanded UserKnownHostsFile '~/.ssh/known_hosts' -> '/root/.ssh/known_hosts'
debug3: expanded UserKnownHostsFile '~/.ssh/known_hosts2' -> '/root/.ssh/known_hosts2'
debug1: auto-mux: Trying existing master
debug2: fd 3 setting O_NONBLOCK
debug2: mux_client_hello_exchange: master version 4
debug3: mux_client_forwards: request forwardings: 0 local, 0 remote
debug3: mux_client_request_session: entering
debug3: mux_client_request_alive: entering
debug3: mux_client_request_alive: done pid = 19
debug3: mux_client_request_session: session request sent
debug1: mux_client_request_session: master session id: 2
debug3: mux_client_read_packet: read header failed: Broken pipe
debug2: Received exit status from master 1
fatal: [rails-staging-3]: FAILED! => {
    ""changed"": false,
    ""invocation"": {
        ""module_args"": {
            ""codename"": null,
            ""filename"": null,
            ""install_python_apt"": true,
            ""mode"": null,
            ""repo"": ""deb http://oss-binaries.phusionpassenger.com/apt/passenger/ focal main"",
            ""state"": ""present"",
            ""update_cache"": true,
            ""update_cache_retries"": 5,
            ""update_cache_retry_max_delay"": 12,
            ""validate_certs"": true
        }
    },
    ""msg"": ""Failed to update apt cache: E:The repository 'http://oss-binaries.phusionpassenger.com/apt/passenger focal Release' does not have a Release file.""
}
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-01-31T05:03:09Z,4,"Create a YAML Ansible playbook to exhibit the following issue: apt_repository: The repository ...  does not have a Release file.""","```
---
- name: Test playbook
  hosts: all
  become: true

  tasks:
    - name: Add test repository
      apt_repository:
        repo: 'deb http://httpredir.debian.org/debian testing main contrib non-free'
        state: present

    - name: Update APT cache
      apt:
        update_cache: yes

    - name: Install package from test repository
      apt:
        name: htop
        state: present
```
Note: This playbook adds a test repository to the system, updates the APT cache, and attempts to install the `htop` package from the test repository. However, the repository does not have a Release file, so the package installation will fail with an error message.",1,"
---
- name: Test playbook
  hosts: all
  become: true

  tasks:
    - name: Add test repository
      apt_repository:
        repo: 'deb http://httpredir.debian.org/debian testing main contrib non-free'
        state: present

    - name: Update APT cache
      apt:
        update_cache: yes

    - name: Install package from test repository
      apt:
        name: htop
        state: present
"
60,79849,"gcp_compute_instance_facts problem with the ""~"" operator","### Summary

When I try to use the ""contains"" operator or ""~"" the playbook will fail with something similar to:

```
""Invalid value for field 'filter': 'name ~ whatever-I-name-it
```

When I run the (assumed) same/similar command with gcloud it will work, 

```
gcloud compute instances list --filter=""name~whatever-I-name-it""
```

The [ansible docs](https://docs.ansible.com/ansible/latest/collections/google/cloud/gcp_compute_instance_info_module.html) state that the gcp filters will work followed by that [link](https://cloud.google.com/sdk/gcloud/reference/topic/filters). 

I noticed an older issue https://github.com/ansible/ansible/issues/48824 from a couple of years ago where it was determined that only '=', '<', and '>' were able to be used. Has there been any support to add other operators, if not could the docs be changed to reflect? 

### Issue Type

Bug Report

### Component Name

pip

### Ansible Version

```console
$ ansible --version
ansible [core 2.14.1]
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
None
```


### OS / Environment

RHEL-8

### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->
```yaml
- name: Retrieve platform instance list
  google.cloud.gcp_compute_instance_info:
    auth_kind: ""serviceaccount""
    filters:
    - ""name ~ {{ gcp_instance_pattern }}""
    zone: ""{{ gcp_zone }}""
    project: ""{{ gcp_project }}""
    service_account_file: ""{{ gcp_service_account_file }}""
  register: gcp_machines
  run_once: true
```
Where the `gcp_instance_pattern` is a string containing the majority of an openshift worker node (full name is not known). 

### Expected Results

- multiple items to be returned as they are with the `gcloud compute instances list --filter=""name~whatever-I-name-it""`

### Actual Results

```console
""Invalid value for field 'filter': 'name ~ whatever-I-name-it ...
```
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-01-30T20:06:56Z,4,"Create a YAML Ansible playbook to exhibit the following issue: gcp_compute_instance_facts problem with the ""~"" operator","```
---
- name: Test Playbook for gcp_compute_instance_facts issue
  hosts: localhost
  gather_facts: false

  tasks:
    - name: Get GCP compute instance details with ""~"" operator
      gcp_compute_instance_facts:
        project: example
        filter: ""name~'web-server*'""
      register: instance_details
      
    - debug:
        var: instance_details
```",1,"
---
- name: Test Playbook for gcp_compute_instance_facts issue
  hosts: localhost
  gather_facts: false

  tasks:
    - name: Get GCP compute instance details with ""~"" operator
      gcp_compute_instance_facts:
        project: example
        filter: ""name~'web-server*'""
      register: instance_details
      
    - debug:
        var: instance_details
"
61,79842,vars declared in a task that is pulled in via include_role don't appear to be templated,"### Summary

When using _include_role_, task vars do not appear to be templated. Everything else in the below example is correctly templated. As you can see in the output at the bottom, `ansible_user` is not templated, and instead the raw string is passed through to `rsync`.

This also fails in the same way if `synchronize_user` is removed from the `ansible.builtin.include_role` task and placed in `roles/synchronize/defaults/main.yml`.

If I hard code the user it does work, but this limits the utility of the role as we'll need to create a role for every single user that needs to use `synchronize`. If I in-line the task instead of using `include_role` that makes it work too - but again in-lining the tasks means we're duplicating code again.

Including this role via a playbook is not possible - this is a minimal example (we're essentially wrapping the synchronize module to make it work without e.g. running as root, having accounts with NOPASSWD persistently enabled etc.).

Setting `public` does not change the behaviour.

The same issue is present when using `import_task` instead of include.

### Issue Type

Bug Report

### Component Name

lib/ansible/modules/include_role.py

### Ansible Version

```console
$ ansible --version
ansible [core 2.14.1]
  config file = /Users/adamb/Developer/ansible/ansible.cfg
  configured module search path = ['/Users/adamb/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules', '/Users/adamb/Developer/ansible/plugins/modules', '/Users/adamb/.ansible/collections/*/modules']
  ansible python module location = /usr/local/lib/python3.11/site-packages/ansible
  ansible collection location = /Users/adamb/.ansible/collections:/usr/share/ansible/collections
  executable location = /usr/local/bin/ansible
  python version = 3.11.1 (main, Dec 23 2022, 09:39:26) [Clang 14.0.0 (clang-1400.0.29.202)] (/usr/local/opt/python@3.11/bin/python3.11)
  jinja version = 3.1.2
  libyaml = True
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
ANSIBLE_NOCOWS(./ansible.cfg) = True
CONFIG_FILE() = ./ansible.cfg
DEFAULT_ACTION_PLUGIN_PATH(./ansible.cfg) = ['/Users/adamb/.ansible/plugins/action', '/usr/share/ansible/plugins/action', './plugins/action']
DEFAULT_FILTER_PLUGIN_PATH(./ansible.cfg) = ['/Users/adamb/.ansible/plugins/filter', '/usr/share/ansible/plugins/filter', './plugins/filter']
DEFAULT_FORKS(./ansible.cfg) = 9
DEFAULT_HOST_LIST(./ansible.cfg) = ['./inventory/hosts']
DEFAULT_JINJA2_NATIVE(./ansible.cfg) = True
DEFAULT_LOAD_CALLBACK_PLUGINS(./ansible.cfg) = True
DEFAULT_LOG_PATH(./ansible.cfg) = /Users/adamb/.ansible/ansible.log
DEFAULT_LOOKUP_PLUGIN_PATH(./ansible.cfg) = ['/Users/adamb/.ansible/plugins/lookup', '/usr/share/ansible/plugins/lookup', './plugins/lookup']
DEFAULT_MANAGED_STR(./ansible.cfg) = Ansible managed: {{{{ lookup('git_info', template_fullpath | quote) }}}}
DEFAULT_MODULE_PATH(./ansible.cfg) = ['/Users/adamb/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules', './plugins/modules', '/Users/adamb/.ansible/collections/*/modules']
DEFAULT_MODULE_UTILS_PATH(./ansible.cfg) = ['/Users/adamb/.ansible/plugins/module_utils', '/usr/share/ansible/plugins/module_utils', '/Users/adamb/.ansible/collections/*/module_utils']
DEFAULT_ROLES_PATH(./ansible.cfg) = ['/Users/adamb/.ansible/roles', '/usr/share/ansible/roles', '/etc/ansible/roles', './roles', '/Users/adamb/.ansible/collections/*/roles']
DEFAULT_STDOUT_CALLBACK(./ansible.cfg) = yaml
DEFAULT_VAULT_PASSWORD_FILE(./ansible.cfg) = ./contrib/vault/lastpass-client.py
HOST_KEY_CHECKING(./ansible.cfg) = False
INTERPRETER_PYTHON(./ansible.cfg) = python3
MAX_FILE_SIZE_FOR_DIFF(./ansible.cfg) = 208896
PLAYBOOK_DIR(./ansible.cfg) = ./playbooks:./jobs
USE_PERSISTENT_CONNECTIONS(./ansible.cfg) = True

CONNECTION:
==========

paramiko_ssh:
____________
host_key_checking(./ansible.cfg) = False
ssh_args(./ansible.cfg) = -C -o ControlMaster=auto -o ControlPersist=600 -o PreferredAuthentications=publickey
use_persistent_connections(./ansible.cfg) = True

ssh:
___
host_key_checking(./ansible.cfg) = False
pipelining(./ansible.cfg) = True
ssh_args(./ansible.cfg) = -C -o ControlMaster=auto -o ControlPersist=600 -o PreferredAuthentications=publickey
```


### OS / Environment

Control Node: MacOS 13.1, Python3.11 (Homebrew)
Managed Node: RHEL 8.7, Python3.6

### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->
```yaml
roles/lnms/tasks/main.yml
---

- name: Deploy plugins directory
  ansible.builtin.include_role:
    allow_duplicates: true
    name: synchronize
  vars:
    synchronize_dest: /opt/librenms/html/plugins/
    synchronize_group: false
    synchronize_mode: push
    synchronize_owner: false
    synchronize_perms: false
    synchronize_src: plugins/
    synchronize_user: filesyncher
```

```yaml
roles/synchronize/tasks/main.yml
---

    - name: Deploy {{ synchronize_dest }}
      ansible.builtin.synchronize:
        archive: ""{{ synchronize_archive | default(omit) }}""
        checksum: ""{{ synchronize_checksum | default(omit) }}""
        compress: ""{{ synchronize_compress | default(omit) }}""
        copy_links: ""{{ synchronize_copy_links | default(omit) }}""
        delay_updates: ""{{ synchronize_delay_updates | default(omit) }}""
        delete: ""{{ synchronize_delete | default(omit) }}""
        dest: ""{{ synchronize_dest | default(omit) }}""
        dest_port: ""{{ synchronize_dest_port | default(omit) }}""
        dirs: ""{{ synchronize_dirs | default(omit) }}""
        existing_only: ""{{ synchronize_existing_only | default(omit) }}""
        group: ""{{ synchronize_group | default(omit) }}""
        link_dest: ""{{ synchronize_link_dest | default(omit) }}""
        links: ""{{ synchronize_links | default(omit) }}""
        mode: ""{{ synchronize_mode | default(omit) }}""
        owner: ""{{ synchronize_owner | default(omit) }}""
        partial: ""{{ synchronize_partial | default(omit) }}""
        perms: ""{{ synchronize_perms | default(omit) }}""
        private_key: ""{{ synchronize_private_key | default(omit) }}""
        recursive: ""{{ synchronize_recursive | default(omit) }}""
        rsync_opts: ""{{ synchronize_rsync_opts | default(omit) }}""
        rsync_path: ""{{ synchronize_rsync_path | default(omit) }}""
        rsync_timeout: ""{{ synchronize_rsync_timeout | default(omit) }}""
        set_remote_user: ""{{ synchronize_set_remote_user | default(omit) }}""
        src: ""{{ synchronize_src | default(omit) }}""
        ssh_connection_multiplexing: ""{{ synchronize_ssh_connection_multiplexing | default(omit) }}""
        times: ""{{ synchronize_times | default(omit) }}""
        use_ssh_args: ""{{ synchronize_use_ssh_args | default(omit) }}""
        verify_host: ""{{ synchronize_verify_host | default(omit) }}""
      become: true
      vars:
        ansible_user: ""{{ synchronize_user }}""
```

### Expected Results

Task vars (and defaults, and role vars) should always be templated.

### Actual Results

```console
TASK [Gather facts] *****************************************************************************************************************************
ok: [host1]
ok: [host2]

TASK [Deploy plugins directory] *****************************************************************************************************************************

TASK [synchronize : Deploy /opt/librenms/html/plugins/] *****************************************************************************************************************************
({{ synchronize_user }}@host1) Password:
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-01-30T14:14:06Z,4,Create a YAML Ansible playbook to exhibit the following issue: vars declared in a task that is pulled in via include_role don't appear to be templated,"```
---
- name: Example playbook
  hosts: localhost
  gather_facts: no

  tasks:
    - include_role:
        name: example_role

  vars:
    variable_name: ""Variable Value""
```

Note: The issue with this playbook is that the variable `variable_name` declared under the `vars` section is not being templated. Thus, its value will not be substituted during runtime.",1,"
---
- name: Example playbook
  hosts: localhost
  gather_facts: no

  tasks:
    - include_role:
        name: example_role

  vars:
    variable_name: ""Variable Value""
"
62,79841,[WARNING]: Module invocation had junk after the JSON data: Last login: Mon Jan,"### Summary

when we run ansible on Centos and Debian we get the following error on each role 
[WARNING]: Module invocation had junk after the JSON data: Last login: Mon Jan 30 09:23:19 CET 2023

we have never seen this WARNING before it starts to appear on January 27 2023

### Issue Type

Bug Report

### Component Name

dnf, apt, yum

### Ansible Version

```console
2.15
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
```


### OS / Environment

Centos, Debian

### Steps to Reproduce

on each role i run i get the Warning (i.e install package, change root password, update file, copy config file) all kind of modules 

### Expected Results

we have never see this WARNING before it starts to appear on January 27 2023

### Actual Results

```console
[WARNING]: Module invocation had junk after the JSON data: Last login: Mon Jan 30 09:23:19 CET 2023
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-01-30T13:27:11Z,2,Create a YAML Ansible playbook to exhibit the following issue: [WARNING]: Module invocation had junk after the JSON data: Last login: Mon Jan,"```
---
- name: Exhibit issue with Module invocation
  hosts: localhost
  gather_facts: false
  
  tasks:
    - name: Execute shell command
      shell: ""Last login: Mon Jan""
```",1,"
---
- name: Exhibit issue with Module invocation
  hosts: localhost
  gather_facts: false
  
  tasks:
    - name: Execute shell command
      shell: ""Last login: Mon Jan""
"
63,79838,Cannot use `name` as an option for a lookup plugin,"### Summary

When trying to use an option called `name` for a lookup plugin, an error is thrown.

I believe this is because `Templar._query_lookup()` has it's own parameter called `name` [here](https://github.com/ansible/ansible/blob/44dcfde9b84177e7dfede11ab287789c577b82b5/lib/ansible/template/__init__.py#L813).

### Issue Type

Bug Report

### Component Name

ansible/lib/ansible/template/__init__.py

### Ansible Version

```console
$ ansible --version
ansible [core 2.14.1]
  config file = /etc/ansible/ansible.cfg
  configured module search path = ['/root/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /usr/lib/python3.11/site-packages/ansible
  ansible collection location = /root/.ansible/collections:/usr/share/ansible/collections
  executable location = /usr/bin/ansible
  python version = 3.11.0 (main, Oct 24 2022, 00:00:00) [GCC 12.2.1 20220819 (Red Hat 12.2.1-2)] (/usr/bin/python3)
  jinja version = 3.0.3
  libyaml = True
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
CONFIG_FILE() = /etc/ansible/ansible.cfg
```


### OS / Environment

Fedora 37

### Steps to Reproduce

Call any lookup plugin with `name` (even if it doesn't support it).
<!--- Paste example playbooks or commands between quotes below -->
```yaml (paste below)
- debug:
    msg: ""{{ q('list', name='test') }}""
```


### Expected Results

A lookup plugin can have an option called `name`.

### Actual Results

```console
fatal: [localhost]: FAILED! => {
    ""msg"": ""Unexpected templating type error occurred on ({{ q('list', name='test') }}): Templar._query_lookup() got multiple values for argument 'name'. Templar._query_lookup() got multiple values for argument 'name'""
}
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-01-29T23:23:49Z,1,Create a YAML Ansible playbook to exhibit the following issue: Cannot use `name` as an option for a lookup plugin,"```
---
- hosts: localhost
  gather_facts: no
  tasks:
    - name: test lookup plugin with name option
      debug:
        msg: ""{{ lookup('file', 'test.txt', name='file_content') }}""
```
",1,"
---
- hosts: localhost
  gather_facts: no
  tasks:
    - name: test lookup plugin with name option
      debug:
        msg: ""{{ lookup('file', 'test.txt', name='file_content') }}""
"
64,79836,ansible-playbook -K breaks when passwords have quotes,"### Summary

I'd expect it to take the input as a string literal, but if you put quotes in it, it will take whatever is inside of them, if passwords have characters that would be parsed, the whole string must be typed inside '' to work properly with BECOME

### Issue Type

Bug Report

### Component Name

become

### Ansible Version

```console
$ ansible --version
ansible [core 2.13.7]
  config file = None
  configured module search path = ['/home/desu/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /usr/lib/python3.10/site-packages/ansible
  ansible collection location = /home/desu/.ansible/collections:/usr/share/ansible/collections
  executable location = /usr/lib/python-exec/python3.10/ansible
  python version = 3.10.9 (main, Dec 12 2022, 13:19:46) [GCC 11.3.0]
  jinja version = 3.1.2
  libyaml = True
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
```


### OS / Environment

gentoo 17.1

### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->
```- name: install nas kernel
  hosts: nas
  tasks:
    - name: copy kernel config
      become: yes
      become_method: sudo
      copy:
        src: ""{{src_kernel_config_path}}""
        dest: ""{{dst_kernel_config_path}}""
        owner: root
        group: root
        mode: u=rw,g=r,o=r
  vars:
    dst_kernel_config_path: ""/usr/src/linux/.config""
    src_dir_path: ""{{playbook_dir}}/../nas""
    src_kernel_path: ""/usr/src/linux""
    src_kernel_config: ""nas-selinux""
    src_kernel_config_path: ""{{src_dir_path}}{{src_kernel_path}}/{{src_kernel_config}}.config""
```


### Expected Results

BECOME password:

PLAY [install nas kernel] *****************************************************************************************************************************************************************

TASK [Gathering Facts] ********************************************************************************************************************************************************************
[WARNING]: Platform linux on host nas is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of another Python interpreter could change the meaning of
that path. See https://docs.ansible.com/ansible-core/2.13/reference_appendices/interpreter_discovery.html for more information.
ok: [nas]

TASK [copy kernel config] *****************************************************************************************************************************************************************
changed: [nas]

PLAY RECAP ********************************************************************************************************************************************************************************
nas                        : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0

### Actual Results

```console
BECOME password:

PLAY [install nas kernel] *****************************************************************************************************************************************************************

TASK [Gathering Facts] ********************************************************************************************************************************************************************
[WARNING]: Platform linux on host nas is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of another Python interpreter could change the meaning of
that path. See https://docs.ansible.com/ansible-core/2.13/reference_appendices/interpreter_discovery.html for more information.
ok: [nas]

TASK [copy kernel config] *****************************************************************************************************************************************************************
fatal: [nas]: FAILED! => {""msg"": ""Incorrect sudo password""}

PLAY RECAP ********************************************************************************************************************************************************************************
nas                        : ok=1    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-01-28T01:38:12Z,12,Create a YAML Ansible playbook to exhibit the following issue: ansible-playbook -K breaks when passwords have quotes,"```
---
- name: Test playbook
  hosts: localhost
  gather_facts: no
  
  tasks:
    - name: Check password with quotes
      shell: echo ""password""    
      become: yes
      become_method: su
      become_user: root
      vars:
        ansible_become_pass: '""password""'
...
```",1,"
---
- name: Test playbook
  hosts: localhost
  gather_facts: no
  
  tasks:
    - name: Check password with quotes
      shell: echo ""password""    
      become: yes
      become_method: su
      become_user: root
      vars:
        ansible_become_pass: '""password""'
...
"
65,79834,dict2items over empty object fails. Even with default({}) safeguard,"### Summary

basically, `{} | dict2items' fails as it has nothing to iterate over -- dict2items requires a dictionary, got <class 'NoneType'> instead.

I have a playbook that may or may not have key-value pairs in an object (k8s resource labels). And I need to iterate over them if they are present. Problem is, dict2items doesn't like objects that have no keys.

### Issue Type

Bug Report

### Component Name

dict2items

### Ansible Version

```console
$ ansible --version
ansible [core 2.12.10]
  config file = /etc/ansible/ansible.cfg
  configured module search path = ['/home/dariusj/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /usr/lib/python3/dist-packages/ansible
  ansible collection location = /home/dariusj/.ansible/collections:/usr/share/ansible/collections
  executable location = /usr/bin/ansible
  python version = 3.8.10 (default, Nov 14 2022, 12:59:47) [GCC 9.4.0]
  jinja version = 2.10.1
  libyaml = True
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all

BECOME:
======

CACHE:
=====

CALLBACK:
========

CLICONF:
=======

CONNECTION:
==========

HTTPAPI:
=======

INVENTORY:
=========

LOOKUP:
======

NETCONF:
=======

SHELL:
=====

VARS:
====
```


### OS / Environment

LinuxMint 20.3

### Steps to Reproduce

This does not work
<!--- Paste example playbooks or commands between quotes below -->
```yaml (paste below)
- name: Dump example
  vars:
    data:
      pairs:
  debug:
    var: item
  loop: '{{ data.pairs | default({}) | dict2items }}'
```

This does not work either
```yaml (paste below)
- name: Dump example
  vars:
    data:
  debug:
    var: item
  loop: '{{ data.pairs | default({}) | dict2items }}'
```

Neither does that
```yaml (paste below)
- name: Dump example
  vars:
    data:
      pairs: {}
  debug:
    var: item
  loop: '{{ data.pairs | default({}) | dict2items }}'
```

This works, but it's not what is needed
```yaml (paste below)
- name: Dump example
  vars:
    data:
      pairs:
        a: b
  debug:
    var: item
  loop: '{{ data.pairs | default({}) | dict2items }}'
```


### Expected Results

Task successfully completes w/o any iterations done.

### Actual Results

```console
fatal: [vm-rocky]: FAILED! => {
    ""msg"": ""Unexpected templating type error occurred on ({{ data.pairs | default({}) | dict2items }}): dict2items requires a dictionary, got <class 'NoneType'> instead.""
}

```

And I'm assuming empty objects _should_ work, because of [this example](https://github.com/ansible/ansible/issues/46718)

### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-01-27T15:16:48Z,8,Create a YAML Ansible playbook to exhibit the following issue: dict2items over empty object fails. Even with default({}) safeguard,"```
---
- name: Test playbook
  hosts: localhost
  gather_facts: no

  tasks:
    - name: Display dict2items output of empty dictionary
      debug:
        var: ({} | dict2items)
```",1,"
---
- name: Test playbook
  hosts: localhost
  gather_facts: no

  tasks:
    - name: Display dict2items output of empty dictionary
      debug:
        var: ({} | dict2items)
"
66,79832,lookup ansible.builtin.env inventory,"### Summary

Hello,
I'm using openstack-inventory (but I think it's not specialized) and i'm trying to use env vars to specify a cloud.
 
Question: lookup is working for inventory ? Am I doing it wrong ?


### Issue Type

Bug Report

### Component Name

lookup

### Ansible Version

```console
$ ansible --version
ansible [core 2.13.3]
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
```


### OS / Environment

Ubuntu 18.04

### Steps to Reproduce

So i run the command: `TEST=dev ansible-inventory -i inventories/template/ --list -vvvvvv`

In `inventories/template/02-openstack.yml', I have
```
only_clouds: 
  - ""{{ lookup('ansible.builtin.env', 'TEST') }}""
 ```
 Result (no info being returned)
 ```
 Found 2 cloud(s) in Openstack
Selected 0 cloud(s)
```

### Expected Results

All the infos about my servers
Work if I change to:
```
only_clouds: 
  - ""dev""
```

### Actual Results

```console
Found 2 cloud(s) in Openstack
Selected 0 cloud(s)
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-01-27T10:38:25Z,2,Create a YAML Ansible playbook to exhibit the following issue: lookup ansible.builtin.env inventory,"```
---
- name: Display Inventory Issue
  hosts: all
  gather_facts: false
  tasks:
    - name: Display ENV Inventory
      debug:
        var: inventory_hostname
      loop: ""{{ lookup('ansible.builtin.env', 'inventory') }}""
```
",1,"
---
- name: Display Inventory Issue
  hosts: all
  gather_facts: false
  tasks:
    - name: Display ENV Inventory
      debug:
        var: inventory_hostname
      loop: ""{{ lookup('ansible.builtin.env', 'inventory') }}""
"
67,79831,maven_artifact Python3 issue,"### Summary

ansible [core 2.14.1]
  config file = None
  configured module search path = ['/root/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /usr/local/lib/python3.9/dist-packages/ansible
  ansible collection location = /root/.ansible/collections:/usr/share/ansible/collections
  executable location = /usr/local/bin/ansible
  python version = 3.9.2 (default, Feb 28 2021, 17:03:44) [GCC 10.2.1 20210110] (/usr/bin/python3)
  jinja version = 3.1.2
  libyaml = True


OS: Debian 11 ""Bullseye""
Python 3.9.2


### Issue Type

Bug Report

### Component Name

ansible installed manually

### Ansible Version

```console
ansible [core 2.14.1]
```


### Configuration

```console
maven_artifact:
    group_id: ""{{ service.group_id }}""   
    artifact_id: ""{{ service.artifact_id }}""  
    classifier: ""{{ service.classifier | default('', true) }}"" 
    repository_url: ""{{ mvn_url }}""
    password: ""{{ mvn_pw }}"" 
    username: ""{{ mvn_user }}"" 
    version: ""{{ service.version |default('latest') }}"" 
    state: present
    extension: ""{{ service.ext }}"" war
```


### OS / Environment

OS: Debian 11 ""Bullseye""

### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->
```yaml (paste below)

```


### Expected Results

should succeed

### Actual Results

```console
FAILED! => {""changed"": false, ""failed"": true, ""module_stderr"": """", ""module_stdout"": ""Traceback (most recent call last):\r\n  File \""/tmp/ansible_iqcfyeb7/ansible_module_maven_artifact.py\"", line 499, in <module>\r\n    main()\r\n  File \""/tmp/ansible_iqcfyeb7/ansible_module_maven_artifact.py\"", line 481, in main\r\n    if downloader.download(artifact, b_dest):\r\n  File \""/tmp/ansible_iqcfyeb7/ansible_module_maven_artifact.py\"", line 350, in download\r\n    self._write_chunks(response, f, report_hook=self.chunk_report)\r\n  File \""/tmp/ansible_iqcfyeb7/ansible_module_maven_artifact.py\"", line 368, in _write_chunks\r\n    total_size = response.info().getheader('Content-Length').strip()\r\nAttributeError: 'HTTPMessage' object has no attribute 'getheader'\r\n"", ""msg"": ""MODULE FAILURE"", ""rc"": 0}
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-01-27T09:01:23Z,2,Create a YAML Ansible playbook to exhibit the following issue: maven_artifact Python3 issue,"```
---

- name: Playbook to exhibit maven_artifact issue
  hosts: localhost
  gather_facts: false
  become: false

  tasks:
    - name: Install Maven and Python3
      apt:
        name: ['maven', 'python3']
        state: present

    - name: Clone maven_artifact GitHub repo
      git:
        repo: https://github.com/ooesili/maven_artifact
        dest: /home/ubuntu/maven_artifact
        version: master

    - name: Install Python3 requirements for maven_artifact
      pip:
        requirements: /home/ubuntu/maven_artifact/requirements.txt

    - name: Run maven_artifact script
      command: python3 /home/ubuntu/maven_artifact/maven_artifact.py
      args:
        chdir: /home/ubuntu/maven_artifact

...
```",1,"
---

- name: Playbook to exhibit maven_artifact issue
  hosts: localhost
  gather_facts: false
  become: false

  tasks:
    - name: Install Maven and Python3
      apt:
        name: ['maven', 'python3']
        state: present

    - name: Clone maven_artifact GitHub repo
      git:
        repo: https://github.com/ooesili/maven_artifact
        dest: /home/ubuntu/maven_artifact
        version: master

    - name: Install Python3 requirements for maven_artifact
      pip:
        requirements: /home/ubuntu/maven_artifact/requirements.txt

    - name: Run maven_artifact script
      command: python3 /home/ubuntu/maven_artifact/maven_artifact.py
      args:
        chdir: /home/ubuntu/maven_artifact

...
"
68,79829,Template: Type error when calling blocks,"### Summary

When using a non-string type in a template block, and then calling that block, a type error exception is generated.

This is similar to #78141 and #77272

### Issue Type

Bug Report

### Component Name

template

### Ansible Version

```console
$ ansible --version
  config file = None
  configured module search path = ['/home/phemmer/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /home/phemmer/.local/lib/python3.10/site-packages/ansible
  ansible collection location = /home/phemmer/.ansible/collections:/usr/share/ansible/collections
  executable location = /home/phemmer/.local/bin/ansible
  python version = 3.10.6 (main, Aug  2 2022, 00:00:00) [GCC 12.1.1 20220507 (Red Hat 12.1.1-1)] (/usr/bin/python3)
  jinja version = 3.1.2
  libyaml = True
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
CONFIG_FILE() = None
```


### OS / Environment

Fedora 36

### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->
```yaml (paste below)
- hosts: localhost
  tasks:
    - debug:
        msg: '{% block foo %}{{ myvar }}{% endblock %}{{ self.foo() }}'
      vars:
        myvar: 1
```


### Expected Results

Generate a debug message without output `11`.

### Actual Results

```console
TASK [debug] *****************************************************************************************************************************************************************************************************************************
task path: /tmp/ansible-test/playbook.yml:3
fatal: [localhost]: FAILED! => {
    ""msg"": ""Unexpected templating type error occurred on ({% block foo %}{{ myvar }}{% endblock %}{{ self.foo() }}): sequence item 0: expected str instance, int found. sequence item 0: expected str instance, int found""
}
```

### Additional information
The above is a minimum reproducible example, if you use the `template` module, you get more info with `-vvv`:
```
TASK [template] **************************************************************************************************************************************************************************************************************************
task path: /tmp/ansible-test/playbook.yml:3
<127.0.0.1> ESTABLISH LOCAL CONNECTION FOR USER: phemmer
<127.0.0.1> EXEC /bin/sh -c 'echo ~phemmer && sleep 0'
<127.0.0.1> EXEC /bin/sh -c '( umask 77 && mkdir -p ""` echo /home/phemmer/.ansible/tmp `""&& mkdir ""` echo /home/phemmer/.ansible/tmp/ansible-tmp-1674792192.7938411-2983973-162535662408548 `"" && echo ansible-tmp-1674792192.7938411-2983973-162535662408548=""` echo /home/phemmer/.ansible/tmp/ansible-tmp-1674792192.7938411-2983973-162535662408548 `"" ) && sleep 0'
<127.0.0.1> EXEC /bin/sh -c 'rm -f -r /home/phemmer/.ansible/tmp/ansible-tmp-1674792192.7938411-2983973-162535662408548/ > /dev/null 2>&1 && sleep 0'
The full traceback is:
Traceback (most recent call last):
  File ""/home/phemmer/.local/lib/python3.10/site-packages/ansible/template/__init__.py"", line 987, in do_template
    res = self.environment.concat(rf)
  File ""/home/phemmer/.local/lib/python3.10/site-packages/ansible/template/native_helpers.py"", line 88, in ansible_concat
    return ''.join([to_text(v) for v in nodes])
  File ""/home/phemmer/.local/lib/python3.10/site-packages/ansible/template/native_helpers.py"", line 88, in <listcomp>
    return ''.join([to_text(v) for v in nodes])
  File ""<template>"", line 13, in root
  File ""/home/phemmer/.local/lib/python3.10/site-packages/jinja2/runtime.py"", line 298, in call
    return __obj(*args, **kwargs)
  File ""/home/phemmer/.local/lib/python3.10/site-packages/jinja2/runtime.py"", line 379, in __call__
    rv = concat(self._stack[self._depth](self._context))
TypeError: sequence item 1: expected str instance, int found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/phemmer/.local/lib/python3.10/site-packages/ansible/plugins/action/template.py"", line 137, in run
    resultant = templar.do_template(template_data, preserve_trailing_newlines=True, escape_backslashes=False)
  File ""/home/phemmer/.local/lib/python3.10/site-packages/ansible/template/__init__.py"", line 998, in do_template
    raise AnsibleError(""Unexpected templating type error occurred on (%s): %s"" % (to_native(data), to_native(te)), orig_exc=te)
ansible.errors.AnsibleError: Unexpected templating type error occurred on ({% block main %}
foo {{ myvar }}
{% endblock %}
{{ self.main() }}
): sequence item 1: expected str instance, int found. sequence item 1: expected str instance, int found
fatal: [localhost]: FAILED! => {
    ""changed"": false,
    ""msg"": ""AnsibleError: Unexpected templating type error occurred on ({% block main %}\nfoo {{ myvar }}\n{% endblock %}\n{{ self.main() }}\n): sequence item 1: expected str instance, int found. sequence item 1: expected str instance, int found""
}
```

### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-01-27T04:05:56Z,3,Create a YAML Ansible playbook to exhibit the following issue: Template: Type error when calling blocks,"```
---
- hosts: localhost
  become: yes
  vars:
    greeting: ""Hello world!""
  tasks:
    - name: Create template file
      block:
        - name: render the template
          template:
            src: ""{{ item }}""
            dest: ""/tmp/{{ item | basename }}""
          loop:
            - ""templates/template1.j2""
            - ""templates/template2.j2""
      rescue:
        - name: Throw exception block
          fail:
            msg: ""Type error when calling blocks!""
            block: ""{{ item }}""
          loop:
            - ""First Block""
            - ""Second Block""
```",1,"
---
- hosts: localhost
  become: yes
  vars:
    greeting: ""Hello world!""
  tasks:
    - name: Create template file
      block:
        - name: render the template
          template:
            src: ""{{ item }}""
            dest: ""/tmp/{{ item | basename }}""
          loop:
            - ""templates/template1.j2""
            - ""templates/template2.j2""
      rescue:
        - name: Throw exception block
          fail:
            msg: ""Type error when calling blocks!""
            block: ""{{ item }}""
          loop:
            - ""First Block""
            - ""Second Block""
"
69,79825,Existing APT repositories keys are not detected correctly,"### Summary

I'm behind a proxy so I have to use workarounds to be able to download gpg keys.

However, ansible.builtin.apt_repository doesn't detect correctly already existing GPG keys using apt-key so it tries to download them again using apt-key --recv-keys which fails because I'm behind a proxy.

In the output attached to the ""actual results"" section, I had modified apt_repository.py to print apt-key export rc, stdout and stderr.

### Issue Type

Bug Report

### Component Name

apt_repository

### Ansible Version

```console
$ ansible --version
ansible [core 2.12.10]
  config file = /etc/ansible/ansible.cfg
  configured module search path = ['/root/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /usr/lib/python3/dist-packages/ansible
  ansible collection location = /root/.ansible/collections:/usr/share/ansible/collections
  executable location = /usr/bin/ansible
  python version = 3.8.10 (default, Nov 14 2022, 12:59:47) [GCC 9.4.0]
  jinja version = 2.10.1
  libyaml = True
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all

BECOME:  
======   

CACHE:   
=====    

CALLBACK:
======== 

CLICONF:
```


### OS / Environment

Ubuntu 20.04, provisioning using Vagrant and the ansible_local provisioner.

### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->
I'm behind a proxy so I have to use the following workaround to be able to download gpg keys:

```yaml
- name: Install wireshark-dev gpg key
  ansible.builtin.apt_key:
    data: ""{{ lookup('url', 'https://keyserver.ubuntu.com/pks/lookup?op=get&search=0xd875551314eca0f0', split_lines=False) }}""
    state: present
  register: pkg_result
  until: pkg_result is success

- name: Adding wireshark-dev ppa repository
  ansible.builtin.apt_repository:
    repo: 'ppa:wireshark-dev/stable'
    state: present
```




### Expected Results

ansible.builtin.apt_repository should not try to download the existing GPG key using apt-key.

However, it tries to download it and this fails because I'm behind a proxy.
I've found the following code to be the culprit in the apt_repository.py module:
```python
    def _key_already_exists(self, key_fingerprint):

        if self.apt_key_bin:
            rc, out, err = self.module.run_command([self.apt_key_bin, 'export', key_fingerprint], check_rc=True)
            found = len(err) == 0
```

The code checks for an empty stderr, but apt-key issues the following warning message on stderr: 
> Warning: apt-key output should not be parsed (stdout is not a terminal)

When a key doesn't not exist locally, here is the content of stderr:
> Warning: apt-key output should not be parsed (stdout is not a terminal)
> gpg: WARNING: nothing exported

In version 2.12.10, the easiest way to patch it is to change line 456 to the following:
```python
        return (""nothing exported"" not in err)
```

In the current master branch, the easiest way to patch it is to change line 475 to the following:
```python
            found = (""nothing exported"" not in err)
```

### Actual Results

```console
36122 1674752689.12920: _low_level_execute_command() done: rc=1, stdout=rc=0, out=-----BEGIN PGP PUBLIC KEY BLOCK-----

mQINBFUDPR4BEADzM3Hc8HzTOu9fypxMIOGtcUVTCGSSI0NgtdTp96HZGtuQlweB
inSEVSauBcPYvW3UTt0fbOotMt6rACFUiH0bs1y20rXuHgVFkQmSfTQT+qDaCYud
g2MV8RFObQ+/MQrjnSqpSiNoLagW4+x6whY9wIlT4gpHbZLZ74/4ZxMkKdDFFQyn
jonQHW1w4iZXoMUGeFUcR7koZo5UKK+3DmNaWP2oj9sHzlHeFpXoshiLY05uL0E0
Tzu3+NHTbjMl88BezfYYfMawgIJyaA9PIoDe+Z/72dwjWYWWjqCsKv2BqBMScp82
5Ewa2i1aeH2RQ/l8ipZzcKKqK5y5LfIb6AgwsDStFet+43Gt1F1GoaOckkxdOpal
Mg/sNGORVHVV3/kxfGzQyj2KakfbkaGCSGRnj8iarhLhxr9tR8QP2kdCOBWkmYXJ
esei7hfrpA5BbrkUEyQ4lSCnPW8tBXfjgdUjv0kcs/nTOTg7v4FbhzvK0+fKSnjL
Pe+4fH8NNQLC79/EAiQztKTHojKFVUQfydn5VQO1nJ/Fq0ulyuMk23ezddqbtvs4
5UXIrzJSro5nJnigKGRR9Was6M8wdnke8qhqWN5pCmO5txx1AIZdOkwh0UqaVnTF
Kt0kDW/PkDGzm7qYCYLqphXi9Z4Dg2y9zGOnjxpTt30T6M2kl/GV6RFoHQARAQAB
tBhMYXVuY2hwYWQgUFBBIGZvciBSRU1udXiJAjgEEwECACIFAlUDPR4CGwMGCwkI
BwMCBhUIAgkKCwQWAgMBAh4BAheAAAoJEL/0UBZ4jeEVSMwQAN7pAtv1DzaXwaRL
N7qLKYheLGe5Y0IK15laxqnsBDqZTy4omLzvRPJ7UP3/EMLn3VSRtCZ2oZUGRfeu
UfW6Ms9tPHzrchXnqKM3oJInA4rvYeQ9NUwntLSY1S46/6NIDmY5t5XnR7gB/L4v
B616fFDYeaygum9BBvIS9VgEP0LFItA6H3eaVR3aWYNAjCIU6K6m9idhAodeo8HC
qgSEIDspXc9lL2rE1hTzUPrv8hpeFCmV6d/JwpSoCs8I7uZ81TjCRae7ydcq8g32
/F9zzHYMHJmCCmv2/zbi/yCroaEWhK7ouz0QtJPsSnytnrSFoTiGvHEd7LWIFxKs
itdV++Oz9IrxqSQ5Ww/+38U/SKOhN5zGl2H2nP8qLpjPyfIa/kNAXGkjHRuitWNA
6saTAFRSYGaitgQZmKzHrXQ4ZjFraMm6jfpwwGhqmIgZDjMWjqPSVV+LxnaaB5RW
n0EZczPCvkkierIy7pgTKeAeKVEkbLysnfwEQVBWxfziShbUWCQLnwXjY5kYStWF
1popjpX75KwbPEQlNgTS83QC20W19g2L+Z0r3NGEyz5hPGhAqbwN89/2sB0hUORK
VCu/lZu4kUIcOBGcSvQsqsBWIIewMPbxm7so/ba8je3WKDoPLqWDyIi5iTGy3WV8
Pw+Ns1dA9rRc3SmwLi01W390osKB
=jXnP
-----END PGP PUBLIC KEY BLOCK-----
, err=Warning: apt-key output should not be parsed (stdout is not a terminal)


{""cmd"": ""apt-key adv --recv-keys --no-tty --keyserver hkp://keyserver.ubuntu.com:80 E90F33EEF615660D25A02D32BFF45016788DE115"", ""rc"": 2, ""stdout"": ""Executing: /tmp/apt-key-gpghome.t2vhexoMJ0/gpg.1.sh --recv-keys --no-tty -
-keyserver hkp://keyserver.ubuntu.com:80 E90F33EEF615660D25A02D32BFF45016788DE115\n"", ""stderr"": ""Warning: apt-key output should not be parsed (stdout is not a terminal)\ngpg: keyserver receive failed: No name\n"", ""failed""
: true, ""msg"": ""Warning: apt-key output should not be parsed (stdout is not a terminal)\ngpg: keyserver receive failed: No name"", ""invocation"": {""module_args"": {""repo"": ""ppa:remnux/stable"", ""state"": ""present"", ""update_cac
he"": true, ""update_cache_retries"": 5, ""update_cache_retry_max_delay"": 12, ""install_python_apt"": true, ""validate_certs"": true, ""mode"": null, ""filename"": null, ""codename"": null}}}
, stderr=
 36122 1674752689.12943: done with _execute_module (ansible.builtin.apt_repository, {'repo': 'ppa:remnux/stable', 'state': 'present', '_ansible_check_mode': False, '_ansible_no_log': False, '_ansible_debug': True, '_ansible_diff': False, '_ansible_verbosity': 4, '_ansible_version': '2.12.10', '_ansible_module_name': 'ansible.builtin.apt_repository', '_ansible_syslog_facility': 'LOG_USER', '_ansible_selinux_special_fs': ['fuse', 'nfs', 'vboxsf', 'ramfs', '9p', 'vfat'], '_ansible_string_conversion_action': 'warn', '_ansible_socket': None, '_ansible_shell_executable': '/bin/sh', '_ansible_keep_remote_files': False, '_ansible_tmpdir': '/root/.ansible/tmp/ansible-tmp-1674752688.6440187-36122-146911848313704/', '_ansible_remote_tmp': '~/.ansible/tmp'})
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-01-26T18:28:23Z,7,Create a YAML Ansible playbook to exhibit the following issue: Existing APT repositories keys are not detected correctly,"```
---
- name: Test Playbook
  hosts: all
  
  tasks:
    - name: Add apt key
      apt_key:
        keyserver: keyserver.ubuntu.com
        id: 40976EAF437D05B5
        state: present

    - name: Update apt cache
      apt:
        update_cache: yes

    - name: Install package
      apt:
        name: package-name
        state: present
...
```",1,"
---
- name: Test Playbook
  hosts: all
  
  tasks:
    - name: Add apt key
      apt_key:
        keyserver: keyserver.ubuntu.com
        id: 40976EAF437D05B5
        state: present

    - name: Update apt cache
      apt:
        update_cache: yes

    - name: Install package
      apt:
        name: package-name
        state: present
...
"
70,79822,Incorrect behavior of regular expression in ansible-playbook --limit option,"### Summary

The reproducer is in this link https://stackoverflow.com/questions/75214298/unexpected-behavior-with-ansible-playbook-limit-and-regular-expression-with and it has been verified by another user.

### Issue Type

Bug Report

### Component Name

none

### Ansible Version

```console
$ ansible --version
2.13.3
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
DEFAULT_FORKS(/Users/m.wang/.ansible.cfg) = 20
DEFAULT_LOG_PATH(/Users/m.wang/.ansible.cfg) = /tmp/ansible.log
DEFAULT_MANAGED_STR(/Users/m.wang/.ansible.cfg) = This file is managed by Ansible
DEFAULT_TIMEOUT(/Users/m.wang/.ansible.cfg) = 30
INTERPRETER_PYTHON(env: ANSIBLE_PYTHON_INTERPRETER) = /usr/bin/python3

CONNECTION:
==========

ssh:
___
ssh_args(/Users/m.wang/.ansible.cfg) = -o PreferredAuthentications=publickey,keyboard-interactive -o ControlMaster=auto -o ControlPersist=30m
timeout(/Users/m.wang/.ansible.cfg) = 30
```


### OS / Environment

Mac OS X

### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->
```
- name: test
  hosts:
    - test
  tasks:
    - name: set var
      set_fact:
        myvar: ""this is a test""
```


### Expected Results

I expect `ansible-playbook -i hosts -l ~'^(?!ecs).*' test-regex.yaml -D -C --list-hosts --list-tasks` to exclude hostnames starting with ecs, 

```
playbook: test-regex.yaml

  play #1 (test): test  TAGS: []
    pattern: ['test']
    hosts (5):
      abc-ecs
      abc-x
      abc-1
    tasks:
      set var   TAGS: []
    ```

but it includes them. 

### Actual Results

```console
playbook: test-regex.yaml

  play #1 (test): test  TAGS: []
    pattern: ['test']
    hosts (5):
      abc-ecs
      abc-x
      ecs-1
      ecs-y
      abc-1
    tasks:
      set var   TAGS: []
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-01-26T05:14:00Z,15,Create a YAML Ansible playbook to exhibit the following issue: Incorrect behavior of regular expression in ansible-playbook --limit option,"```
---
- name: Test Playbook
  hosts: all
  gather_facts: false

  tasks:
    - debug:
        msg: ""This task will run on all hosts""

  post_tasks:
    - debug:
        msg: ""This task will run after all tasks""

  vars:
    limit_hosts: ""[web01, app01]""

- name: Another Playbook
  hosts: ""{{ limit_hosts }}""
  gather_facts: false

  tasks:
    - debug:
        msg: ""This task is limited to web01 and app01""
```

Note: The `limit_hosts` variable contains a string value that represents a list of hosts to be limited to when executing the play. This limitation is expected to work correctly but fails to do so due to incorrect behavior of the regular expression in the `--limit` option.",1,"
---
- name: Test Playbook
  hosts: all
  gather_facts: false

  tasks:
    - debug:
        msg: ""This task will run on all hosts""

  post_tasks:
    - debug:
        msg: ""This task will run after all tasks""

  vars:
    limit_hosts: ""[web01, app01]""

- name: Another Playbook
  hosts: ""{{ limit_hosts }}""
  gather_facts: false

  tasks:
    - debug:
        msg: ""This task is limited to web01 and app01""
"
71,79811,Ansible |replace failing,"### Summary

Hi friends.

I have imput:
gtm_monitor_type: ""https""
gtm_monitor_recv: ""OK""
gtm_monitor_send: ""GET /keepalive HTTP/1.1\r\nHost: api.dev.example.com\r\n\r\n""

I need output : 
gtm_monitor_configuration: ""send \""GET /keepalive HTTP/1.1\r\nHost: api.dev.example.com\r\n\r\n\"" recv \""OK\""""

My playbook is:
\\\\\\\\\\\\\\\\\\\\\\\\
- block:
  - set_fact:
      gtm_monitor_configuration: ""send \""{{gtm_monitor_send | replace('\r','\\\r') | replace('\n','\\\n')}}\"" recv \""{{gtm_monitor_recv | replace('\r','\\\r') | replace('\n','\\\n')}}\""""
    when: gtm_monitor_type == 'http' or gtm_monitor_type == 'https'
 \\\\\\\\\\\\\\\\\\\\\\\\\


But I am receiving output like:
    ""gtm_monitor_configuration"": ""send \""GET /keepalive HTTP/1.1\r\\rHost: api.dev.example.com\r\\r\r\\r\"" recv \""OK\"""" 

-How it could be happen (if you pay attention \r isn`t replaced, instead \n is replaced with \\r )?
-Do you have any other solution for keeping single backslashes in the string instead of replacing them with double backslashes?

### Issue Type

Bug Report

### Component Name

ansible

### Ansible Version

```console
$ ansible --version
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
```


### OS / Environment

AWX

### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->
```
- block:
  - set_fact:
      gtm_monitor_configuration: ""send \""{{gtm_monitor_send | replace('\r','\\r') | replace('\n','\\n')}}\"" recv \""{{gtm_monitor_recv | replace('\r','\\r') | replace('\n','\\n')}}\""""
    when: gtm_monitor_type == 'http' or gtm_monitor_type == 'https'
```


### Expected Results

gtm_monitor_configuration: ""send \""GET /keepalive HTTP/1.1\r\nHost: api.dev.example.com\r\n\r\n\"" recv \""OK\""""

### Actual Results

```console
""gtm_monitor_configuration"": ""send \""GET /keepalive HTTP/1.1\r\\rHost: api.dev.example.com\r\\r\r\\r\"" recv \""OK\""""
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-01-25T11:13:58Z,2,Create a YAML Ansible playbook to exhibit the following issue: Ansible |replace failing,"```
---
- hosts: localhost
  tasks:
    - name: Example of replace failing issue
      set_fact:
        my_string: ""Hello, World! this is a sample text string. It has multiple occurrences of the word 'World'""
      register: my_fact
      
    - name: Show replace failure
      debug:
        msg: ""{{ my_fact.my_string|replace('World', 'ansible') }}""

    - name: Fix replace using regex
      debug:
        msg: ""{{ my_fact.my_string|regex_replace('World', 'ansible') }}""
...
```",1,"
---
- hosts: localhost
  tasks:
    - name: Example of replace failing issue
      set_fact:
        my_string: ""Hello, World! this is a sample text string. It has multiple occurrences of the word 'World'""
      register: my_fact
      
    - name: Show replace failure
      debug:
        msg: ""{{ my_fact.my_string|replace('World', 'ansible') }}""

    - name: Fix replace using regex
      debug:
        msg: ""{{ my_fact.my_string|regex_replace('World', 'ansible') }}""
...
"
72,79805,ModuleNotFoundError while importing ansible.parsing.vault.VaultLib,"### Summary

When importing `ansible.parsing.vault.VaultLib` in a custom module, which need to use the VaultLib to decrypt a vault, we get a `ModuleNotFoundError: No module named 'ansible.module_utils.common.yaml`. The full stack trace is:

```
Traceback (most recent call last):
  File ""/home/ansible/.ansible/tmp/ansible-tmp-1674568824.6807315-2492445-19468410620237/AnsiballZ_troclapi.py"", line 107, in <module>
    _ansiballz_main()
  File ""/home/ansible/.ansible/tmp/ansible-tmp-1674568824.6807315-2492445-19468410620237/AnsiballZ_troclapi.py"", line 99, in _ansiballz_main
    invoke_module(zipped_mod, temp_path, ANSIBALLZ_PARAMS)
  File ""/home/ansible/.ansible/tmp/ansible-tmp-1674568824.6807315-2492445-19468410620237/AnsiballZ_troclapi.py"", line 47, in invoke_module
    runpy.run_module(mod_name='ansible.modules.troclapi', init_globals=dict(_module_fqn='ansible.modules.troclapi', _modlib_path=modlib_path),
  File ""/usr/lib64/python3.9/runpy.py"", line 225, in run_module
    return _run_module_code(code, init_globals, run_name, mod_spec)
  File ""/usr/lib64/python3.9/runpy.py"", line 97, in _run_module_code
    _run_code(code, mod_globals, init_globals,
  File ""/usr/lib64/python3.9/runpy.py"", line 87, in _run_code
    exec(code, run_globals)
  File ""/tmp/ansible_troclapi_payload__1j_9dk8/ansible_troclapi_payload.zip/ansible/modules/troclapi.py"", line 10, in <module>
  File ""/srv/tools/ansible/lib64/python3.9/site-packages/ansible/parsing/vault/__init__.py"", line 56, in <module>
    from ansible import constants as C
  File ""/srv/tools/ansible/lib64/python3.9/site-packages/ansible/constants.py"", line 14, in <module>
    from ansible.config.manager import ConfigManager, ensure_type
  File ""/srv/tools/ansible/lib64/python3.9/site-packages/ansible/config/manager.py"", line 21, in <module>
    from ansible.module_utils.common.yaml import yaml_load
ModuleNotFoundError: No module named 'ansible.module_utils.common.yaml'
```

### Issue Type

Bug Report

### Component Name

ansible.parsing.vault.VaultLib

### Ansible Version

```console
ansible [core 2.12.7]
  config file = /etc/ansible/ansible.cfg
  configured module search path = ['/srv/ansible/library']
  ansible python module location = /srv/tools/ansible/lib64/python3.9/site-packages/ansible
  ansible collection location = /srv/ansible
  executable location = /srv/tools/ansible/bin/ansible
  python version = 3.9.13 (main, Nov  9 2022, 13:16:24) [GCC 8.5.0 20210514 (Red Hat 8.5.0-15)]
  jinja version = 3.1.2
  libyaml = True
```


### Configuration

```console
ANSIBLE_NOCOWS(/etc/ansible/ansible.cfg) = True
CALLBACKS_ENABLED(/etc/ansible/ansible.cfg) = ['ansible.posix.profile_tasks']
COLLECTIONS_PATHS(/etc/ansible/ansible.cfg) = ['/srv/ansible']
DEFAULT_ACTION_PLUGIN_PATH(/etc/ansible/ansible.cfg) = ['/srv/ansible/plugins/action_plugins']
DEFAULT_CALLBACK_PLUGIN_PATH(/etc/ansible/ansible.cfg) = ['/srv/ansible/plugins/callback_plugins']
DEFAULT_CONNECTION_PLUGIN_PATH(/etc/ansible/ansible.cfg) = ['/srv/ansible/plugins/connection_plugins']
DEFAULT_FILTER_PLUGIN_PATH(/etc/ansible/ansible.cfg) = ['/srv/ansible/plugins/filter_plugins']
DEFAULT_FORKS(/etc/ansible/ansible.cfg) = 10
DEFAULT_GATHERING(/etc/ansible/ansible.cfg) = smart
DEFAULT_HOST_LIST(/etc/ansible/ansible.cfg) = ['/etc/ansible/inventory/puppetdb.py']
DEFAULT_LOAD_CALLBACK_PLUGINS(/etc/ansible/ansible.cfg) = True
DEFAULT_LOOKUP_PLUGIN_PATH(/etc/ansible/ansible.cfg) = ['/srv/ansible/plugins/lookup_plugins']
DEFAULT_MANAGED_STR(/etc/ansible/ansible.cfg) = Claranet ansible managed: {file} modified on %Y-%m-%d %H:%M:%S by {uid} on {host}. While it can still be managed manually, it is definitely not recommended.
DEFAULT_MODULE_PATH(/etc/ansible/ansible.cfg) = ['/srv/ansible/library']
DEFAULT_PRIVATE_KEY_FILE(/etc/ansible/ansible.cfg) = /home/ansible/.ssh/id_rsa
DEFAULT_REMOTE_USER(/etc/ansible/ansible.cfg) = ansible
DEFAULT_ROLES_PATH(/etc/ansible/ansible.cfg) = ['/srv/ansible/roles']
DEFAULT_STDOUT_CALLBACK(/etc/ansible/ansible.cfg) = debug
DEFAULT_TIMEOUT(/etc/ansible/ansible.cfg) = 60
DEFAULT_VARS_PLUGIN_PATH(/etc/ansible/ansible.cfg) = ['/srv/ansible/plugins/vars_plugins']
DEFAULT_VAULT_PASSWORD_FILE(/etc/ansible/ansible.cfg) = /etc/ansible/vault_pass.py
HOST_KEY_CHECKING(/etc/ansible/ansible.cfg) = False
RETRY_FILES_ENABLED(/etc/ansible/ansible.cfg) = False

BECOME:
======

CACHE:
=====

CALLBACK:
========

CLICONF:
=======

CONNECTION:
==========

paramiko_ssh:
____________
host_key_checking(/etc/ansible/ansible.cfg) = False
pty(/etc/ansible/ansible.cfg) = False
remote_user(/etc/ansible/ansible.cfg) = ansible

ssh:
___
host_key_checking(/etc/ansible/ansible.cfg) = False
pipelining(/etc/ansible/ansible.cfg) = True
private_key_file(/etc/ansible/ansible.cfg) = /home/ansible/.ssh/id_rsa
remote_user(/etc/ansible/ansible.cfg) = ansible
scp_if_ssh(/etc/ansible/ansible.cfg) = True
ssh_args(/etc/ansible/ansible.cfg) = -o ServerAliveInterval=30 -o ControlMaster=auto -o ControlPersist=30m
timeout(/etc/ansible/ansible.cfg) = 60

HTTPAPI:
=======

INVENTORY:
=========

LOOKUP:
======

NETCONF:
=======

SHELL:
=====

VARS:
====
```


### OS / Environment

RHEL 8.7, Ansible 2.12.7, Python 3.9.13

### Steps to Reproduce

Create a custom module (troclapi in our test case) with the lines below:
```
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

from ansible.parsing.vault import VaultLib
```
and try to run it with `ansible localhost -i localhost -m troclapi -vvv`

### Expected Results

VaultLib library imported without error

### Actual Results

```console
(ansible) [ansible@z98sl080pans0cl ~]$ ansible localhost -i localhost -m troclapi -vvv
ansible [core 2.12.7]
  config file = /etc/ansible/ansible.cfg
  configured module search path = ['/srv/ansible/library']
  ansible python module location = /srv/tools/ansible/lib64/python3.9/site-packages/ansible
  ansible collection location = /srv/ansible
  executable location = /srv/tools/ansible/bin/ansible
  python version = 3.9.13 (main, Nov  9 2022, 13:16:24) [GCC 8.5.0 20210514 (Red Hat 8.5.0-15)]
  jinja version = 3.1.2
  libyaml = True
Using /etc/ansible/ansible.cfg as config file
host_list declined parsing /home/ansible/localhost as it did not pass its verify_file() method
Skipping due to inventory source not existing or not being readable by the current user
script declined parsing /home/ansible/localhost as it did not pass its verify_file() method
auto declined parsing /home/ansible/localhost as it did not pass its verify_file() method
Skipping due to inventory source not existing or not being readable by the current user
yaml declined parsing /home/ansible/localhost as it did not pass its verify_file() method
Skipping due to inventory source not existing or not being readable by the current user
ini declined parsing /home/ansible/localhost as it did not pass its verify_file() method
Skipping due to inventory source not existing or not being readable by the current user
toml declined parsing /home/ansible/localhost as it did not pass its verify_file() method
[WARNING]: Unable to parse /home/ansible/localhost as an inventory source
[WARNING]: No inventory was parsed, only implicit localhost is available
redirecting (type: callback) ansible.builtin.debug to ansible.posix.debug
redirecting (type: callback) ansible.builtin.debug to ansible.posix.debug
Skipping callback 'default', as we already have a stdout callback.
Skipping callback 'minimal', as we already have a stdout callback.
Skipping callback 'oneline', as we already have a stdout callback.

PLAYBOOK: __adhoc_playbook__ ********************************************************************************************************************************************************

PLAY [Ansible Ad-Hoc] ***************************************************************************************************************************************************************
META: ran handlers

TASK [troclapi] *********************************************************************************************************************************************************************
Tuesday 24 January 2023  15:19:34 +0100 (0:00:00.066)       0:00:00.066 *******
<127.0.0.1> ESTABLISH LOCAL CONNECTION FOR USER: ansible
<127.0.0.1> EXEC /bin/sh -c 'echo ~ansible && sleep 0'
<127.0.0.1> EXEC /bin/sh -c '( umask 77 && mkdir -p ""` echo /home/ansible/.ansible/tmp `""&& mkdir ""` echo /home/ansible/.ansible/tmp/ansible-tmp-1674569974.4734583-2497078-179627925020998 `"" && echo ansible-tmp-1674569974.4734583-2497078-179627925020998=""` echo /home/ansible/.ansible/tmp/ansible-tmp-1674569974.4734583-2497078-179627925020998 `"" ) && sleep 0'
Using module file /srv/ansible/library/troclapi-debug-pierre/troclapi.py
<127.0.0.1> PUT /home/ansible/.ansible/tmp/ansible-local-24970726ego5ge5/tmpvl3s0bit TO /home/ansible/.ansible/tmp/ansible-tmp-1674569974.4734583-2497078-179627925020998/AnsiballZ_troclapi.py
<127.0.0.1> EXEC /bin/sh -c 'chmod u+x /home/ansible/.ansible/tmp/ansible-tmp-1674569974.4734583-2497078-179627925020998/ /home/ansible/.ansible/tmp/ansible-tmp-1674569974.4734583-2497078-179627925020998/AnsiballZ_troclapi.py && sleep 0'
<127.0.0.1> EXEC /bin/sh -c '/srv/tools/ansible/bin/python3.9 /home/ansible/.ansible/tmp/ansible-tmp-1674569974.4734583-2497078-179627925020998/AnsiballZ_troclapi.py && sleep 0'
<127.0.0.1> EXEC /bin/sh -c 'rm -f -r /home/ansible/.ansible/tmp/ansible-tmp-1674569974.4734583-2497078-179627925020998/ > /dev/null 2>&1 && sleep 0'
The full traceback is:
Traceback (most recent call last):
  File ""/home/ansible/.ansible/tmp/ansible-tmp-1674569974.4734583-2497078-179627925020998/AnsiballZ_troclapi.py"", line 107, in <module>
    _ansiballz_main()
  File ""/home/ansible/.ansible/tmp/ansible-tmp-1674569974.4734583-2497078-179627925020998/AnsiballZ_troclapi.py"", line 99, in _ansiballz_main
    invoke_module(zipped_mod, temp_path, ANSIBALLZ_PARAMS)
  File ""/home/ansible/.ansible/tmp/ansible-tmp-1674569974.4734583-2497078-179627925020998/AnsiballZ_troclapi.py"", line 47, in invoke_module
    runpy.run_module(mod_name='ansible.modules.troclapi', init_globals=dict(_module_fqn='ansible.modules.troclapi', _modlib_path=modlib_path),
  File ""/usr/lib64/python3.9/runpy.py"", line 225, in run_module
    return _run_module_code(code, init_globals, run_name, mod_spec)
  File ""/usr/lib64/python3.9/runpy.py"", line 97, in _run_module_code
    _run_code(code, mod_globals, init_globals,
  File ""/usr/lib64/python3.9/runpy.py"", line 87, in _run_code
    exec(code, run_globals)
  File ""/tmp/ansible_troclapi_payload_ryeyphtt/ansible_troclapi_payload.zip/ansible/modules/troclapi.py"", line 10, in <module>
  File ""/srv/tools/ansible/lib64/python3.9/site-packages/ansible/parsing/vault/__init__.py"", line 56, in <module>
    from ansible import constants as C
  File ""/srv/tools/ansible/lib64/python3.9/site-packages/ansible/constants.py"", line 14, in <module>
    from ansible.config.manager import ConfigManager, ensure_type
  File ""/srv/tools/ansible/lib64/python3.9/site-packages/ansible/config/manager.py"", line 21, in <module>
    from ansible.module_utils.common.yaml import yaml_load
ModuleNotFoundError: No module named 'ansible.module_utils.common.yaml'
fatal: [localhost]: FAILED! => {
    ""changed"": false,
    ""rc"": 1
}

MSG:

MODULE FAILURE
See stdout/stderr for the exact error


MODULE_STDERR:

Traceback (most recent call last):
  File ""/home/ansible/.ansible/tmp/ansible-tmp-1674569974.4734583-2497078-179627925020998/AnsiballZ_troclapi.py"", line 107, in <module>
    _ansiballz_main()
  File ""/home/ansible/.ansible/tmp/ansible-tmp-1674569974.4734583-2497078-179627925020998/AnsiballZ_troclapi.py"", line 99, in _ansiballz_main
    invoke_module(zipped_mod, temp_path, ANSIBALLZ_PARAMS)
  File ""/home/ansible/.ansible/tmp/ansible-tmp-1674569974.4734583-2497078-179627925020998/AnsiballZ_troclapi.py"", line 47, in invoke_module
    runpy.run_module(mod_name='ansible.modules.troclapi', init_globals=dict(_module_fqn='ansible.modules.troclapi', _modlib_path=modlib_path),
  File ""/usr/lib64/python3.9/runpy.py"", line 225, in run_module
    return _run_module_code(code, init_globals, run_name, mod_spec)
  File ""/usr/lib64/python3.9/runpy.py"", line 97, in _run_module_code
    _run_code(code, mod_globals, init_globals,
  File ""/usr/lib64/python3.9/runpy.py"", line 87, in _run_code
    exec(code, run_globals)
  File ""/tmp/ansible_troclapi_payload_ryeyphtt/ansible_troclapi_payload.zip/ansible/modules/troclapi.py"", line 10, in <module>
  File ""/srv/tools/ansible/lib64/python3.9/site-packages/ansible/parsing/vault/__init__.py"", line 56, in <module>
    from ansible import constants as C
  File ""/srv/tools/ansible/lib64/python3.9/site-packages/ansible/constants.py"", line 14, in <module>
    from ansible.config.manager import ConfigManager, ensure_type
  File ""/srv/tools/ansible/lib64/python3.9/site-packages/ansible/config/manager.py"", line 21, in <module>
    from ansible.module_utils.common.yaml import yaml_load
ModuleNotFoundError: No module named 'ansible.module_utils.common.yaml'


PLAY RECAP **************************************************************************************************************************************************************************
localhost                  : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0

Tuesday 24 January 2023  15:19:35 +0100 (0:00:00.603)       0:00:00.670 *******
===============================================================================
troclapi --------------------------------------------------------------------------------------------------------------------------------------------------------------------- 0.60s
 -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-01-24T14:30:08Z,2,Create a YAML Ansible playbook to exhibit the following issue: ModuleNotFoundError while importing ansible.parsing.vault.VaultLib,"```yaml
---
- name: Exhibit ModuleNotFoundError
  hosts: localhost
  gather_facts: false
  tasks:
    - name: Attempt to import VaultLib
      import_module:
        module: ansible.parsing.vault.VaultLib
      ignore_errors: true
      register: result

    - debug:
        var: result
```
",0,"yaml
---
- name: Exhibit ModuleNotFoundError
  hosts: localhost
  gather_facts: false
  tasks:
    - name: Attempt to import VaultLib
      import_module:
        module: ansible.parsing.vault.VaultLib
      ignore_errors: true
      register: result

    - debug:
        var: result
"
73,79796,2.14 Issue with installing custom collections,"### Summary

In 2.14+ we are getting errors when installing our local collections
Multiple versions of 2.13 (including 2.13.7) were tested against those same collections without any errors.
v2.14.0 Release notes do not include anything that I can see would have made breaking changes to ansible-galaxy command.

### Issue Type

Bug Report

### Component Name

ansible-galaxy

### Ansible Version

```console
$ ansible-galaxy --version
ansible-galaxy [core 2.14.0]
  config file = /home/REDACTED/venv/ansible_2140/meta/ansible.cfg
  configured module search path = ['/home/REDACTED/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /home/REDACTED/venv/ansible_2140/lib64/python3.9/site-packages/ansible
  ansible collection location = /home/REDACTED/venv/ansible_2140/collections
  executable location = /home/REDACTED/venv/ansible_2140/bin/ansible-galaxy
  python version = 3.9.7 (default, Apr 11 2022, 06:30:15) [GCC 8.5.0 20210514 (Red Hat 8.5.0-10.0.1)] (/home/REDACTED/venv/ansible_2140/bin/python3)
  jinja version = 3.1.2
  libyaml = True
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
COLLECTIONS_PATHS(/home/REDACTED/venv/ansible_2140/meta/ansible.cfg) = ['/home/REDACTED/venv/ansible_2140/collections']
CONFIG_FILE() = /home/REDACTED/venv/ansible_2140/meta/ansible.cfg
```


### OS / Environment

Oracle Linux Server 8.6

### Steps to Reproduce

```
$ ansible-galaxy collection install -r /tmp/requirements.yml -vvv
ansible-galaxy [core 2.14.0]
  config file = /home/REDACTED/venv/ansible_2140/meta/ansible.cfg
  configured module search path = ['/home/REDACTED/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /home/REDACTED/venv/ansible_2140/lib64/python3.9/site-packages/ansible
  ansible collection location = /home/REDACTED/venv/ansible_2140/collections
  executable location = /home/REDACTED/venv/ansible_2140/bin/ansible-galaxy
  python version = 3.9.7 (default, Apr 11 2022, 06:30:15) [GCC 8.5.0 20210514 (Red Hat 8.5.0-10.0.1)] (/home/REDACTED/venv/ansible_2140/bin/python3)
  jinja version = 3.1.2
  libyaml = True
Using /home/REDACTED/venv/ansible_2140/meta/ansible.cfg as config file
Reading requirement file at '/tmp/requirements.yml'
Starting galaxy collection install process
Found installed collection community.general:6.2.0 at '/home/REDACTED/venv/ansible_2140/collections/ansible_collections/community/general'
Process install dependency map
Cloning into '/home/REDACTED/.ansible/tmp/ansible-local-13046752reyjqax/tmpx57_tb93/REDACTED.REDACTEDbwwa6z2y'...
remote: Enumerating objects: 335, done.
remote: Counting objects: 100% (335/335), done.
remote: Compressing objects: 100% (171/171), done.
remote: Total 503 (delta 128), reused 281 (delta 97), pack-reused 168
Receiving objects: 100% (503/503), 78.81 KiB | 530.00 KiB/s, done.
Resolving deltas: 100% (190/190), done.
Already on 'master'
Your branch is up to date with 'origin/master'.
Starting collection install process
Installing 'REDACTED.REDACTED:1.2.0' to '/home/REDACTED/venv/ansible_2140/collections/ansible_collections/REDACTED/REDACTED'
ERROR! Unexpected Exception, this is probably a bug: 'manifest'
the full traceback was:

Traceback (most recent call last):
  File ""/home/REDACTED/venv/ansible_2140/lib64/python3.9/site-packages/ansible/cli/__init__.py"", line 647, in cli_executor
    exit_code = cli.run()
  File ""/home/REDACTED/venv/ansible_2140/lib64/python3.9/site-packages/ansible/cli/galaxy.py"", line 681, in run
    return context.CLIARGS['func']()
  File ""/home/REDACTED/venv/ansible_2140/lib64/python3.9/site-packages/ansible/cli/galaxy.py"", line 116, in method_wrapper
    return wrapped_method(*args, **kwargs)
  File ""/home/REDACTED/venv/ansible_2140/lib64/python3.9/site-packages/ansible/cli/galaxy.py"", line 1344, in execute_install
    self._execute_install_collection(
  File ""/home/REDACTED/venv/ansible_2140/lib64/python3.9/site-packages/ansible/cli/galaxy.py"", line 1381, in _execute_install_collection
    install_collections(
  File ""/home/REDACTED/venv/ansible_2140/lib64/python3.9/site-packages/ansible/galaxy/collection/__init__.py"", line 771, in install_collections
    install(concrete_coll_pin, output_path, artifacts_manager)
  File ""/home/REDACTED/venv/ansible_2140/lib64/python3.9/site-packages/ansible/galaxy/collection/__init__.py"", line 1446, in install
    install_src(collection, b_artifact_path, b_collection_path, artifacts_manager)
  File ""/home/REDACTED/venv/ansible_2140/lib64/python3.9/site-packages/ansible/galaxy/collection/__init__.py"", line 1578, in install_src
    collection_meta['manifest'],
KeyError: 'manifest'

$ cat /tmp/requirements.yml
collections:
  - name: git@REDACTED:REDACTED/automation/ansible/collections/REDACTED.REDACTED.git
    type: git
    version: master
```

### Expected Results

Expect the same thing that happens in Ansible versions < 2.14.0
```$ ansible-galaxy --version
ansible-galaxy [core 2.13.4]
  config file = /home/REDACTED/venv/ee-rcstandard-rhel8-183/meta/ansible.cfg
  configured module search path = ['/home/REDACTED/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /home/REDACTED/venv/ee-rcstandard-rhel8-183/lib64/python3.9/site-packages/ansible
  ansible collection location = /home/REDACTED/venv/ee-rcstandard-rhel8-183/collections
  executable location = /home/REDACTED/venv/ee-rcstandard-rhel8-183/bin/ansible-galaxy
  python version = 3.9.7 (default, Apr 11 2022, 06:30:15) [GCC 8.5.0 20210514 (Red Hat 8.5.0-10.0.1)]
  jinja version = 3.1.2
  libyaml = True

$ ansible-galaxy install -r /tmp/requirements.yml
Starting galaxy collection install process
Process install dependency map
Cloning into '/home/REDACTED/.ansible/tmp/ansible-local-1304752dfq9iqso/tmpmo9tw51i/REDACTED.REDACTEDbkddz8qw'...
remote: Enumerating objects: 335, done.
remote: Counting objects: 100% (335/335), done.
remote: Compressing objects: 100% (171/171), done.
remote: Total 503 (delta 128), reused 281 (delta 97), pack-reused 168
Receiving objects: 100% (503/503), 78.81 KiB | 537.00 KiB/s, done.
Resolving deltas: 100% (190/190), done.
Already on 'master'
Your branch is up to date with 'origin/master'.
Starting collection install process
Installing 'REDACTED.REDACTED:1.2.0' to '/home/REDACTED/venv/ee-rcstandard-rhel8-183/collections/ansible_collections/REDACTED/REDACTED'
Created collection for REDACTED.REDACTED:1.2.0 at /home/REDACTED/venv/ee-rcstandard-rhel8-183/collections/ansible_collections/REDACTED/REDACTED
REDACTED.REDACTED:1.2.0 was installed successfully
```


### Actual Results

```console
See steps to reproduce
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-01-23T21:12:41Z,4,Create a YAML Ansible playbook to exhibit the following issue: 2.14 Issue with installing custom collections,"```
---
- name: Install Custom Collections
  hosts: localhost
  gather_facts: false

  tasks:
    - name: Install Custom Collection
      ansible.builtin.shell: >
        ansible-galaxy collection install <custom_collection>
      ignore_errors: true

    - name: Verify Install
      ansible.builtin.command: >
        ansible-galaxy collection list | grep <custom_collection>
      register: installed_collection

    - name: Fail Task
      ansible.builtin.fail:
        msg: ""Custom Collection not installed""
      when: installed_collection.stdout == """"
...
```",1,"
---
- name: Install Custom Collections
  hosts: localhost
  gather_facts: false

  tasks:
    - name: Install Custom Collection
      ansible.builtin.shell: >
        ansible-galaxy collection install <custom_collection>
      ignore_errors: true

    - name: Verify Install
      ansible.builtin.command: >
        ansible-galaxy collection list | grep <custom_collection>
      register: installed_collection

    - name: Fail Task
      ansible.builtin.fail:
        msg: ""Custom Collection not installed""
      when: installed_collection.stdout == """"
...
"
74,79777,`become: true` ignored when used in dependencies `main/meta.yml` with Ansible 2.14.x,"### Summary

When the playbook is using `tasks:` and `ansible.builtin.include_role:` the `become:` statement in `dependencies` is ignored.

This is also the case for `import_role`. Did not test if same happens if `ansible.builtin.include_role:` is used within another role.

In 2.13.4 `become:` works as expected but 2.14.x `become:` is seems to be ignored.

Here is an example project for replicating the issue:
https://github.com/hiboxsystems/ansible-nested-become-test

### Issue Type

Bug Report

### Component Name

ansible, include_role, import_role

### Ansible Version

```console
$ ansible --version
ansible [core 2.14.1]
  config file = None
  configured module search path = ['/home/hibox/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /home/hibox/.local/lib/python3.9/site-packages/ansible
  ansible collection location = /home/hibox/.ansible/collections:/usr/share/ansible/collections
  executable location = /home/hibox/.local/bin/ansible
  python version = 3.9.5 (default, Nov 23 2021, 15:27:38) [GCC 9.3.0] (/usr/bin/python3.9)
  jinja version = 3.1.2
  libyaml = False
```


### Configuration

```console
$ ansible-config dump --only-changed -t all
CONFIG_FILE() = None
```


### OS / Environment

Ubuntu 20.04

### Steps to Reproduce

Here is an example project which replicates the issue with sample output:
https://github.com/hiboxsystems/ansible-nested-become-test

playbook.yml
```yaml
- name: Runs role1
  hosts: all

  tasks:
    - ansible.builtin.include_role:
        name: role1
```

roles/role1/meta/main.yml
```yaml
dependencies:
  - role: role2
    become: true
```

roles/role2/tasks/main.yml
```yaml
- name: whoami
  ansible.builtin.command:
    cmd: whoami
```

### Expected Results

I expected the `whoami` command to return `root` however it returns my local username in Ansible 2.14.1

In Ansible 2.13.4 it returns `root`.

### Actual Results

```console
$ ansible-playbook playbook.yml -v -i localhost, --user plundberg
No config file found; using defaults
PLAY [Runs role1] ***********************************************************************************************************************************************************************************************************************************************
TASK [Gathering Facts] ******************************************************************************************************************************************************************************************************************************************
[WARNING]: Platform linux on host localhost is using the discovered Python interpreter at /usr/bin/python3.11, but future installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.14/reference_appendices/interpreter_discovery.html for more information.
ok: [localhost]
TASK [include_role : role1] *************************************************************************************************************************************************************************************************************************************
TASK [role3 : whoami] *******************************************************************************************************************************************************************************************************************************************
changed: [localhost] => {""changed"": true, ""cmd"": [""whoami""], ""delta"": ""0:00:00.001548"", ""end"": ""2023-01-20 15:57:52.962146"", ""msg"": """", ""rc"": 0, ""start"": ""2023-01-20 15:57:52.960598"", ""stderr"": """", ""stderr_lines"": [], ""stdout"": ""plundberg"", ""stdout_lines"": [""plundberg""]}
PLAY RECAP ******************************************************************************************************************************************************************************************************************************************************
localhost                  : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-01-20T14:17:37Z,2,Create a YAML Ansible playbook to exhibit the following issue: `become: true` ignored when used in dependencies `main/meta.yml` with Ansible 2.14.x,"```
---
- name: Test playbook
  hosts: all
  become: true
  gather_facts: false

  roles:
    - role: main
      become: true

---

# main/meta/main.yml

- name: Main dependency task
  debug: msg=""I am a dependency task""

- include_tasks: meta.yml
  become: true
```

```
# main/meta.yml

- name: Meta dependency task
  debug: msg=""I am a meta dependency task""
```",0,"
---
- name: Test playbook
  hosts: all
  become: true
  gather_facts: false

  roles:
    - role: main
      become: true

---

# main/meta/main.yml

- name: Main dependency task
  debug: msg=""I am a dependency task""

- include_tasks: meta.yml
  become: true
"
75,79776,ERROR! BUG: There seems to be a mismatch between tasks in PlayIterator and HostStates in 2.14 when force_handlers=true,"### Summary

When:
force_handlers=true
inlude_tasks is in loop and the included tasks contain ""notify"" handler 
ansible=2.14

then after execution gets completed, the error is raised:
ERROR! BUG: There seems to be a mismatch between tasks in PlayIterator and HostStates
instead of displaying PLAY RECAP

### Issue Type

Bug Report

### Component Name

!needs_collection_redirect strategy plugin linear.py

### Ansible Version

```console
$ ansible --version
ansible [core 2.14.1]
  config file = None
  configured module search path = ['/home/devel/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /usr/local/lib/python3.10/site-packages/ansible
  ansible collection location = /home/devel/.ansible/collections:/usr/share/ansible/collections
  executable location = /usr/local/bin/ansible
  python version = 3.10.2 (main, Feb 22 2022, 10:03:04) [GCC 4.8.5 20150623 (Red Hat 4.8.5-44.0.3)] (/usr/local/bin/python3)
  jinja version = 3.0.3
  libyaml = True
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
CONFIG_FILE() = None
```


### OS / Environment

Oracle Linux 7.9

### Steps to Reproduce
```console
$ find . | sed -e ""s/[^-][^\/]*\// |/g"" -e ""s/|\([^ ]\)/|-\1/""
.
 |-bug.yml
 |-bug
 | |-handlers
 | | |-main.yml
 | |-tasks
 | | |-main.yml
 | | |-handler_3.yml
 | | |-connect_server.yml

$ cat bug.yml
---
- name: bug
  hosts: ""all""
  gather_facts: false
  force_handlers: true
  become: false

  tasks:
    - include_role:
        name: bug

$ cat bug/tasks/main.yml
---
- name: add tasks in loop
  include_tasks: connect_server.yml
  loop: ""{{ my_hosts[1:] }}""
  when: inventory_hostname == my_hosts[0]

$ cat bug/tasks/connect_server.yml
---
- name: command 3
  ansible.builtin.command: /bin/true
  notify: handler_3

$ cat bug/handlers/main.yml
---
- name: handler_3
  include_tasks: handler_3.yml
  loop: ""{{ my_hosts[1:] }}""

$ cat bug/tasks/handler_3.yml
---
- name: Handler 3
  ansible.builtin.debug:
    msg: ""Handler for {{ item }}""
```

### Expected Results
```console
# after updating bug.yml to force_handlers: false the expected result is achieved
$ ansible-playbook -u ansible --extra-vars '{""my_hosts"":[""server1"", ""server2""]}' -i server1,server2 bug.yml

PLAY [bug] *****************************************************************************************************************************************************

TASK [include_role : bug] **************************************************************************************************************************************

TASK [bug : add tasks in loop] *********************************************************************************************************************************
skipping: [server2] => (item=server2)
skipping: [server2]
included: /home/devel/test/bug/tasks/connect_server.yml for server1 => (item=server2)

TASK [bug : command 3] *****************************************************************************************************************************************
changed: [server1]

RUNNING HANDLER [bug : handler_3] ******************************************************************************************************************************
included: /home/devel/test/bug/tasks/handler_3.yml for server1 => (item=server2)

RUNNING HANDLER [bug : Handler 3] ******************************************************************************************************************************
ok: [server1] => {
    ""msg"": ""Handler for server2""
}

PLAY RECAP *****************************************************************************************************************************************************
server1               : ok=4    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
server2               : ok=0    changed=0    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0
```

### Actual Results

```console
$ ansible-playbook -u ansible --extra-vars '{""my_hosts"":[""server1"", ""server2""]}' -i server1,server2 bug.yml

PLAY [bug] *****************************************************************************************************************************************************

TASK [include_role : bug] **************************************************************************************************************************************

TASK [bug : add tasks in loop] *********************************************************************************************************************************
skipping: [server2] => (item=server2)
skipping: [server2]
included: /home/devel/test/bug/tasks/connect_server.yml for server1 => (item=server2)

TASK [bug : command 3] *****************************************************************************************************************************************
changed: [server1]

RUNNING HANDLER [bug : handler_3] ******************************************************************************************************************************
included: /home/devel/test/bug/tasks/handler_3.yml for server1 => (item=server2)

RUNNING HANDLER [bug : Handler 3] ******************************************************************************************************************************
ok: [server1] => {
    ""msg"": ""Handler for server2""
}
ERROR! BUG: There seems to be a mismatch between tasks in PlayIterator and HostStates.
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-01-20T08:48:02Z,4,Create a YAML Ansible playbook to exhibit the following issue: ERROR! BUG: There seems to be a mismatch between tasks in PlayIterator and HostStates in 2.14 when force_handlers=true,"```
---
- name: Demonstrate Ansible Issue
  hosts: localhost

  tasks:
    - name: Task 1
      debug:
        msg: ""This is Task 1""

    - name: Task 2
      debug:
        msg: ""This is Task 2""

      notify:
        - myhandler

  handlers:
    - name: myhandler
      debug:
        msg: ""This is my handler""

  force_handlers: true

```",1,"
---
- name: Demonstrate Ansible Issue
  hosts: localhost

  tasks:
    - name: Task 1
      debug:
        msg: ""This is Task 1""

    - name: Task 2
      debug:
        msg: ""This is Task 2""

      notify:
        - myhandler

  handlers:
    - name: myhandler
      debug:
        msg: ""This is my handler""

  force_handlers: true

"
76,79766,`ansible-test integration ansible-galaxy-collection` Failure,"### Summary

When I try running `ansible-test integration ansible-galaxy-collection --docker-privileged -v` I receive the following error:
```
fatal: [localhost]: UNREACHABLE! => {""changed"": false, ""msg"": ""Data could not be sent to remote host \""localhost\"". Make sure this host can be reached over ssh: Warning: Permanently added 'localhost' (ECDSA) to the list of known hosts.\r\nroot@localhost: Permission denied (publickey).\r\n"", ""unreachable"": true}
```

I don't understand why the SSH fails, neither (if I understand it correctly) why it tries to SSH to my server (a.k.a `localhost`) which explains `Permission denied (publickey)`?

### Issue Type

Bug Report

### Component Name

`ansible-test integration`

### Ansible Version

```console
ansible [core 2.13.7]
  config file = /etc/ansible/ansible.cfg
  configured module search path = ['/home/ubuntu/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /home/ubuntu/.local/lib/python3.8/site-packages/ansible
  ansible collection location = /home/ubuntu/.ansible/collections:/usr/share/ansible/collections
  executable location = /home/ubuntu/.local/bin/ansible
  python version = 3.8.10 (default, Nov 14 2022, 12:59:47) [GCC 9.4.0]
  jinja version = 3.1.2
  libyaml = True
```


### Configuration

```console
No output
```


### OS / Environment

Ubuntu 20.04

### Steps to Reproduce

Try running:
```
`ansible-test integration ansible-galaxy-collection --docker-privileged -v` 
```
inside the `ansible/ansible` repository.

### Expected Results

I expect this to work*

### Actual Results

```console
Detected architecture x86_64 for Python interpreter: /usr/bin/python3
Run command: docker -v
Detected ""docker"" container runtime version: Docker version 20.10.22, build 3a2c30b
Run command: docker container inspect ansible-ci-pulp
Starting new ""ansible-ci-pulp"" container.
Run command: docker image inspect quay.io/ansible/pulp-galaxy-ng:b79a7be64eff
Run command: docker create --name ansible-ci-pulp -p 80 -p 24817 --ulimit nofile=10240 quay.io/a ...
Adding ""ansible-ci-pulp"" to container database.
Run command: docker cp /tmp/tmp10ai1i51 dedbb668c7e82e36ad8942e7ecc301376d235ac99450eeab0af41f24 ...
Run command: docker cp /tmp/tmpx1i8k9rl dedbb668c7e82e36ad8942e7ecc301376d235ac99450eeab0af41f24 ...
Run command: docker cp /tmp/tmppzn74gph dedbb668c7e82e36ad8942e7ecc301376d235ac99450eeab0af41f24 ...
Run command: docker start ansible-ci-pulp
Run command: docker container inspect dedbb668c7e82e36ad8942e7ecc301376d235ac99450eeab0af41f242e ...
Creating container database.
Assuming Docker is available on localhost.
Detected docker host IP: 127.0.0.1
Run command: /usr/bin/python3 /usr/local/lib/python3.8/dist-packages/ansible_test/_util/target/t ...
Configuring controller inventory.
Initializing ""/tmp/ansible-test-26nkvnwp-injector"" as the temporary injector directory.
Injecting ""/tmp/python-v12rkt71-ansible/python"" as a execv wrapper for the ""/usr/bin/python3"" interpreter.
Stream command: ansible-playbook -i /tmp/ssh-inventory-i082dck2.json /usr/local/lib/python3.8/di ...
Using /usr/local/lib/python3.8/dist-packages/ansible_test/_data/ansible.cfg as config file

PLAY [Prepare POSIX hosts file] ************************************************

TASK [Add container hostname(s) to hosts file] *********************************
fatal: [localhost]: UNREACHABLE! => {""changed"": false, ""msg"": ""Data could not be sent to remote host \""localhost\"". Make sure this host can be reached over ssh: Warning: Permanently added 'localhost' (ECDSA) to the list of known hosts.\r\nroot@localhost: Permission denied (publickey).\r\n"", ""unreachable"": true}

PLAY RECAP *********************************************************************
localhost                  : ok=0    changed=0    unreachable=1    failed=0    skipped=0    rescued=0    ignored=0   

NOTICE: To resume at this test target, use the option: --start-at ansible-galaxy-collection
FATAL: Command ""ansible-playbook -i /tmp/ssh-inventory-i082dck2.json /usr/local/lib/python3.8/dist-packages/ansible_test/_data/playbooks/posix_hosts_prepare.yml -e '{""hosts_entries"": [""127.0.0.1 ansible-ci-pulp # ansible-test d4cda303-19d8-4b1a-bc31-2575e63a99a6""]}' -v"" returned exit status 4.
Run command: docker rm -f dedbb668c7e82e36ad8942e7ecc301376d235ac99450eeab0af41f242e472b50
```

### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-01-19T12:36:41Z,6,Create a YAML Ansible playbook to exhibit the following issue: `ansible-test integration ansible-galaxy-collection` Failure,"```
---
- name: Demonstrate failure in ansible-test
  hosts: localhost
  tasks:
    - name: Run ansible-test 
      command: ansible-test integration ansible-galaxy-collection
```
Note: This playbook will run the `ansible-test` command with the given arguments but please make sure that the command and the arguments are valid and installed in your environment.",1,"
---
- name: Demonstrate failure in ansible-test
  hosts: localhost
  tasks:
    - name: Run ansible-test 
      command: ansible-test integration ansible-galaxy-collection
"
77,79765,ansible-test --docker: `FileNotFoundError`,"### Summary

Whenever I run `ansible-test integration <integration-target> --docker -v` I receive the following error:
```
Traceback (most recent call last):
  File ""/root/ansible/bin/ansible-test"", line 45, in <module>
    main()
  File ""/root/ansible/bin/ansible-test"", line 36, in main
    cli_main(args)
  File ""/root/ansible/test/lib/ansible_test/_internal/__init__.py"", line 54, in main
    args = parse_args(cli_args)
  File ""/root/ansible/test/lib/ansible_test/_internal/cli/__init__.py"", line 58, in parse_args
    args.host_settings = HostSettings.deserialize(os.path.join(args.host_path, 'settings.dat'))
  File ""/root/ansible/test/lib/ansible_test/_internal/host_configs.py"", line 492, in deserialize
    with open_binary_file(path) as settings_file:
  File ""/root/ansible/test/lib/ansible_test/_internal/io.py"", line 83, in open_binary_file
    return io.open(to_bytes(path), mode)  # pylint: disable=consider-using-with
FileNotFoundError: [Errno 2] No such file or directory: b'test/results/.tmp/host-3rashykp/settings.dat'
```

The issue gets resolved if I run it in privileged mode: `ansible-test integration <integration-target> --docker-privileged -v`.

### Issue Type

Bug Report

### Component Name

`ansible-test integration`

### Ansible Version

```console
ansible [core 2.13.7]
  config file = /etc/ansible/ansible.cfg
  configured module search path = ['/home/ubuntu/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /home/ubuntu/.local/lib/python3.8/site-packages/ansible
  ansible collection location = /home/ubuntu/.ansible/collections:/usr/share/ansible/collections
  executable location = /home/ubuntu/.local/bin/ansible
  python version = 3.8.10 (default, Nov 14 2022, 12:59:47) [GCC 9.4.0]
  jinja version = 3.1.2
  libyaml = True
```


### Configuration

```console
No output
```


### OS / Environment

`Ubuntu 20.04`

### Steps to Reproduce

Try running:
```
ansible-test integration ping --docker -v
```
and
```
ansible-test integration ping --docker-privileged -v
```



### Expected Results

None

### Actual Results

```console
ubuntu@tjp1:~/ansible$ ansible-test integration ping --docker -v
Assuming Docker is available on localhost.
Run command: docker -v
Detected ""docker"" container runtime version: Docker version 20.10.22, build 3a2c30b
Starting new ""ansible-test-controller-s6b8j405"" container.
Run command: docker image inspect quay.io/ansible/ansible-core-test-container:5.9.0
Run command: docker run --volume /sys/fs/cgroup:/sys/fs/cgroup:ro --privileged=false --security- ...
Adding ""ansible-test-controller-s6b8j405"" to container database.
Run command: docker container inspect 9c71677d70a05f0c0427209336fdb9fd9f0ce5d518340067a6efe0748a ...
Stream command with data: docker exec -i ansible-test-controller-s6b8j405 /bin/sh
Creating a payload archive containing 882 files...
Created a 1622346 byte payload archive containing 882 files in 0 seconds.
Run command with stdin: docker exec -i ansible-test-controller-s6b8j405 tar oxzf - -C /root
Creating container database.
Stream command: docker exec ansible-test-controller-s6b8j405 /usr/bin/env ANSIBLE_TEST_CONTENT_R ...
Traceback (most recent call last):
  File ""/root/ansible/bin/ansible-test"", line 45, in <module>
    main()
  File ""/root/ansible/bin/ansible-test"", line 36, in main
    cli_main(args)
  File ""/root/ansible/test/lib/ansible_test/_internal/__init__.py"", line 54, in main
    args = parse_args(cli_args)
  File ""/root/ansible/test/lib/ansible_test/_internal/cli/__init__.py"", line 58, in parse_args
    args.host_settings = HostSettings.deserialize(os.path.join(args.host_path, 'settings.dat'))
  File ""/root/ansible/test/lib/ansible_test/_internal/host_configs.py"", line 492, in deserialize
    with open_binary_file(path) as settings_file:
  File ""/root/ansible/test/lib/ansible_test/_internal/io.py"", line 83, in open_binary_file
    return io.open(to_bytes(path), mode)  # pylint: disable=consider-using-with
FileNotFoundError: [Errno 2] No such file or directory: b'test/results/.tmp/host-3rashykp/settings.dat'
Run command with stdout: docker exec -i ansible-test-controller-s6b8j405 sh -c 'tar cf - -C /roo ...
Run command with stdin: tar oxzf - -C /home/ubuntu/ansible/test
FATAL: Command ""docker exec ansible-test-controller-s6b8j405 /usr/bin/env ANSIBLE_TEST_CONTENT_ROOT=/root/ansible LC_ALL=en_US.UTF-8 /usr/bin/python3.10 /root/ansible/bin/ansible-test integration ping -v --allow-destructive --containers '{}' --truncate 101 --color yes --host-path test/results/.tmp/host-3rashykp --metadata test/results/.tmp/metadata-1vw9oe9l.json"" returned exit status 1.
Run command: docker rm -f ansible-test-controller-s6b8j405
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-01-19T12:22:18Z,4,Create a YAML Ansible playbook to exhibit the following issue: ansible-test --docker: `FileNotFoundError`,"```
---
- name: Test Playbook
  hosts: localhost
  gather_facts: false
  
  tasks:
    - name: Test task
      command: ansible-test --docker
```
",1,"
---
- name: Test Playbook
  hosts: localhost
  gather_facts: false
  
  tasks:
    - name: Test task
      command: ansible-test --docker
"
78,79763,ANSIBLE_DEBUG causes template to fail,"### Summary

Saw this happening with ansible 2.14.0 and up.
When using `ANSIBLE_DEBUG=1` with a `template` task, the task fails with
```
TypeError: unsupported operand type(s) for |: 'VarsWithSources' and 'dict'
```
To reproduce this behaviour save the snippet below to `foo.yml` and run `ANSIBLE_DEBUG=1 ansible-playbook foo.yml`.

### Issue Type

Bug Report

### Component Name

template

### Ansible Version

```console
$ ansible --version
[WARNING]: You are running the development version of Ansible. You should only run Ansible from ""devel"" if you are modifying the Ansible engine, or trying
out features under development. This is a rapidly changing source of code and can become unstable at any point.
ansible [core 2.15.0.dev0] (devel 6c0559bffe) last updated 2023/01/19 08:49:47 (GMT +200)
  config file = /etc/ansible/ansible.cfg
  configured module search path = ['/home/phil/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /home/phil/tmp/ansible-git/lib/ansible
  ansible collection location = /home/phil/.ansible/collections:/usr/share/ansible/collections
  executable location = /home/phil/tmp/ansible-git/bin/ansible
  python version = 3.11.1 (main, Dec  7 2022, 00:00:00) [GCC 12.2.1 20221121 (Red Hat 12.2.1-4)] (/usr/bin/python)
  jinja version = 3.0.3
  libyaml = True
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
[WARNING]: You are running the development version of Ansible. You should only run Ansible from ""devel"" if you are modifying the Ansible engine, or trying
out features under development. This is a rapidly changing source of code and can become unstable at any point.
CONFIG_FILE() = /etc/ansible/ansible.cfg
EDITOR(env: EDITOR) = vim
```


### OS / Environment

Fedora 37

### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->
```yaml (paste below)
---
- hosts: localhost
  gather_facts: no
  tasks:
    - template:
        src: foo.yml
        dest: /tmp/bar.tmp
```


### Expected Results

file copied, no errors

### Actual Results

```console
[…]
  7808 1674114804.05527: _low_level_execute_command(): executing: /bin/sh -c 'rm -f -r /home/phil/.ansible/tmp/ansible-tmp-1674114804.0513797-7808-80947595831082/ > /dev/null 2>&1 && sleep 0'
  7808 1674114804.05528: in local.exec_command()
  7808 1674114804.05531: opening command with Popen()
  7808 1674114804.05541: done running command with Popen()
  7808 1674114804.05542: getting output with communicate()
  7808 1674114804.05699: done communicating
  7808 1674114804.05699: done with local.exec_command()
  7808 1674114804.05700: _low_level_execute_command() done: rc=0, stdout=, stderr=
  7808 1674114804.05701: handler run complete
  7808 1674114804.05710: attempt loop complete, returning result
  7808 1674114804.05711: _execute() done
  7808 1674114804.05711: dumping result to json
  7808 1674114804.05711: done dumping result, returning
  7808 1674114804.05713: done running TaskExecutor() for localhost/TASK: template [005f67d3-1f9e-5831-73d8-000000000003]
  7808 1674114804.05713: sending task result for task 005f67d3-1f9e-5831-73d8-000000000003
  7808 1674114804.05720: done sending task result for task 005f67d3-1f9e-5831-73d8-000000000003
  7808 1674114804.05720: WORKER PROCESS EXITING
  7804 1674114804.05826: marking localhost as failed
  7804 1674114804.05829: marking host localhost failed, current state: HOST STATE: block=2, task=1, rescue=0, always=0, handlers=0, run_state=1, fail_state=0, pre_flushing_run_state=1, update_handlers=True, pending_setup=False, tasks child state? (None), rescue child state? (None), always child state? (None), did rescue? False, did start at task? False
  7804 1674114804.05831: ^ failed state is now: HOST STATE: block=2, task=1, rescue=0, always=0, handlers=0, run_state=5, fail_state=2, pre_flushing_run_state=1, update_handlers=True, pending_setup=False, tasks child state? (None), rescue child state? (None), always child state? (None), did rescue? False, did start at task? False
  7804 1674114804.05832: getting the next task for host localhost
  7804 1674114804.05833: host localhost is done iterating, returning
An exception occurred during task execution. To see the full traceback, use -vvv. The error was: TypeError: unsupported operand type(s) for |: 'VarsWithSources' and 'dict'
fatal: [localhost]: FAILED! => {""changed"": false, ""msg"": ""TypeError: unsupported operand type(s) for |: 'VarsWithSources' and 'dict'""}
  7804 1674114804.05849: no more pending results, returning what we have
  7804 1674114804.05850: results queue empty
[…]
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-01-19T07:58:16Z,1,Create a YAML Ansible playbook to exhibit the following issue: ANSIBLE_DEBUG causes template to fail,"```
---
- hosts: localhost
  gather_facts: no
  vars:
    template_vars:
      name: Peter Parker
  tasks:
  - name: Render a template
    template:
      src: test.j2
      dest: /tmp/test.txt
    vars:
      ANSIBLE_DEBUG: 2
      template_vars: ""{{template_vars}}""
```
Note: Make sure that you create a template file named ""test.j2"" in the same directory as the playbook.",1,"
---
- hosts: localhost
  gather_facts: no
  vars:
    template_vars:
      name: Peter Parker
  tasks:
  - name: Render a template
    template:
      src: test.j2
      dest: /tmp/test.txt
    vars:
      ANSIBLE_DEBUG: 2
      template_vars: ""{{template_vars}}""
"
79,79757,Ansible runner reporting worker in dead state affecting operator functionality,"### Summary

We have recently upgraded operator-sdk to version 1.26 for an operator that deploys and manages ETCD. There seems to be an issue with a python script affecting a job running with the operator. Checking the ETCD deployments and pods on the machine, they are running in the expected namespace following a successful deploy. But the etcd-operator pod is continually restarting and this error seen in the etcd-operator logs:

ERROR! A worker was found in a dead state\u001b[0m\n"",""job"":""5309261672169790489"",""name"":""wa-data-governor-etcd"",""namespace"":""zen"",""error"":""exit status 1"",""stacktrace"":""github.com/operator-framework/operator-sdk/internal/ansible/runner.(*runner).Run.func1\n\t/workspace/internal/ansible/runner/runner.go:269""}

ETCD does seem to have deployed during the upgrade and functionally should be working.The attempt to restart the operator pod to see if the issue might clear was not successful. 

### Issue Type

Bug Report

### Component Name

runner, runner.go

### Ansible Version

```console
$ ansible --version
ansible [core 2.13.7]
  config file = None
  configured module search path = ['/Users/kdresnek/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /opt/homebrew/lib/python3.8/site-packages/ansible
  ansible collection location = /Users/kdresnek/.ansible/collections:/usr/share/ansible/collections
  executable location = /opt/homebrew/bin/ansible
  python version = 3.8.16 (default, Dec  7 2022, 01:27:54) [Clang 14.0.0 (clang-1400.0.29.202)]
  jinja version = 3.1.2
  libyaml = False
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
ACTION_WARNINGS(default) = True
AGNOSTIC_BECOME_PROMPT(default) = True
ALLOW_WORLD_READABLE_TMPFILES(default) = False
ANSIBLE_CONNECTION_PATH(default) = None
ANSIBLE_COW_ACCEPTLIST(default) = ['bud-frogs', 'bunny', 'cheese', 'daemon', 'default', 'dragon', 'elephant-in-snake', 'elephant', 'eyes', 'hellokitty', 'kitty', 'luke-koala', 'meow', 'milk', 'moofasa', 'moose', 'ren', 'sheep', 'small', 'stegosaurus', 'stimpy', 'supermilker', 'three-eyes', 'turkey', 'turtle', 'tux', 'udder', 'vader-koala', 'vader', 'www']
ANSIBLE_COW_PATH(default) = None
ANSIBLE_COW_SELECTION(default) = default
ANSIBLE_FORCE_COLOR(default) = False
ANSIBLE_NOCOLOR(default) = False
ANSIBLE_NOCOWS(default) = False
ANSIBLE_PIPELINING(default) = False
ANY_ERRORS_FATAL(default) = False
BECOME_ALLOW_SAME_USER(default) = False
BECOME_PASSWORD_FILE(default) = None
BECOME_PLUGIN_PATH(default) = ['/Users/kdresnek/.ansible/plugins/become', '/usr/share/ansible/plugins/become']
CACHE_PLUGIN(default) = memory
CACHE_PLUGIN_CONNECTION(default) = None
CACHE_PLUGIN_PREFIX(default) = ansible_facts
CACHE_PLUGIN_TIMEOUT(default) = 86400
CALLBACKS_ENABLED(default) = []
COLLECTIONS_ON_ANSIBLE_VERSION_MISMATCH(default) = warning
COLLECTIONS_PATHS(default) = ['/Users/kdresnek/.ansible/collections', '/usr/share/ansible/collections']
COLLECTIONS_SCAN_SYS_PATH(default) = True
COLOR_CHANGED(default) = yellow
COLOR_CONSOLE_PROMPT(default) = white
COLOR_DEBUG(default) = dark gray
COLOR_DEPRECATE(default) = purple
COLOR_DIFF_ADD(default) = green
COLOR_DIFF_LINES(default) = cyan
COLOR_DIFF_REMOVE(default) = red
COLOR_ERROR(default) = red
COLOR_HIGHLIGHT(default) = white
COLOR_OK(default) = green
COLOR_SKIP(default) = cyan
COLOR_UNREACHABLE(default) = bright red
COLOR_VERBOSE(default) = blue
COLOR_WARN(default) = bright purple
COMMAND_WARNINGS(default) = False
CONNECTION_FACTS_MODULES(default) = {'asa': 'ansible.legacy.asa_facts', 'cisco.asa.asa': 'cisco.asa.asa_facts', 'eos': 'ansible.legacy.eos_facts', 'arista.eos.eos': 'arista.eos.eos_facts', 'frr': 'ansible.legacy.frr_facts', 'frr.frr.frr': 'frr.frr.frr_facts', 'ios': 'ansible.legacy.ios_facts', 'cisco.ios.ios': 'cisco.ios.ios_facts', 'iosxr': 'ansible.legacy.iosxr_facts', 'cisco.iosxr.iosxr': 'cisco.iosxr.iosxr_facts', 'junos': 'ansible.legacy.junos_facts', 'junipernetworks.junos.junos': 'junipernetworks.junos.junos_facts', 'nxos': 'ansible.legacy.nxos_facts', 'cisco.nxos.nxos': 'cisco.nxos.nxos_facts', 'vyos': 'ansible.legacy.vyos_facts', 'vyos.vyos.vyos': 'vyos.vyos.vyos_facts', 'exos': 'ansible.legacy.exos_facts', 'extreme.exos.exos': 'extreme.exos.exos_facts', 'slxos': 'ansible.legacy.slxos_facts', 'extreme.slxos.slxos': 'extreme.slxos.slxos_facts', 'voss': 'ansible.legacy.voss_facts', 'extreme.voss.voss': 'extreme.voss.voss_facts', 'ironware': 'ansible.legacy.ironware_facts', 'community.network.ironware': 'community.network.ironware_facts'}
CONNECTION_PASSWORD_FILE(default) = None
COVERAGE_REMOTE_OUTPUT(default) = None
COVERAGE_REMOTE_PATHS(default) = *
DEFAULT_ACTION_PLUGIN_PATH(default) = ['/Users/kdresnek/.ansible/plugins/action', '/usr/share/ansible/plugins/action']
DEFAULT_ALLOW_UNSAFE_LOOKUPS(default) = False
DEFAULT_ASK_PASS(default) = False
DEFAULT_ASK_VAULT_PASS(default) = False
DEFAULT_BECOME(default) = False
DEFAULT_BECOME_ASK_PASS(default) = False
DEFAULT_BECOME_EXE(default) = None
DEFAULT_BECOME_FLAGS(default) = None
DEFAULT_BECOME_METHOD(default) = sudo
DEFAULT_BECOME_USER(default) = root
DEFAULT_CACHE_PLUGIN_PATH(default) = ['/Users/kdresnek/.ansible/plugins/cache', '/usr/share/ansible/plugins/cache']
DEFAULT_CALLBACK_PLUGIN_PATH(default) = ['/Users/kdresnek/.ansible/plugins/callback', '/usr/share/ansible/plugins/callback']
DEFAULT_CLICONF_PLUGIN_PATH(default) = ['/Users/kdresnek/.ansible/plugins/cliconf', '/usr/share/ansible/plugins/cliconf']
DEFAULT_CONNECTION_PLUGIN_PATH(default) = ['/Users/kdresnek/.ansible/plugins/connection', '/usr/share/ansible/plugins/connection']
DEFAULT_DEBUG(default) = False
DEFAULT_EXECUTABLE(default) = /bin/sh
DEFAULT_FACT_PATH(default) = None
DEFAULT_FILTER_PLUGIN_PATH(default) = ['/Users/kdresnek/.ansible/plugins/filter', '/usr/share/ansible/plugins/filter']
DEFAULT_FORCE_HANDLERS(default) = False
DEFAULT_FORKS(default) = 5
DEFAULT_GATHERING(default) = implicit
DEFAULT_GATHER_SUBSET(default) = None
DEFAULT_GATHER_TIMEOUT(default) = None
DEFAULT_HASH_BEHAVIOUR(default) = replace
DEFAULT_HOST_LIST(default) = ['/etc/ansible/hosts']
DEFAULT_HTTPAPI_PLUGIN_PATH(default) = ['/Users/kdresnek/.ansible/plugins/httpapi', '/usr/share/ansible/plugins/httpapi']
DEFAULT_INTERNAL_POLL_INTERVAL(default) = 0.001
DEFAULT_INVENTORY_PLUGIN_PATH(default) = ['/Users/kdresnek/.ansible/plugins/inventory', '/usr/share/ansible/plugins/inventory']
DEFAULT_JINJA2_EXTENSIONS(default) = []
DEFAULT_JINJA2_NATIVE(default) = False
DEFAULT_KEEP_REMOTE_FILES(default) = False
DEFAULT_LIBVIRT_LXC_NOSECLABEL(default) = False
DEFAULT_LOAD_CALLBACK_PLUGINS(default) = False
DEFAULT_LOCAL_TMP(default) = /Users/kdresnek/.ansible/tmp/ansible-local-85995m3uw5rjo
DEFAULT_LOG_FILTER(default) = []
DEFAULT_LOG_PATH(default) = None
DEFAULT_LOOKUP_PLUGIN_PATH(default) = ['/Users/kdresnek/.ansible/plugins/lookup', '/usr/share/ansible/plugins/lookup']
DEFAULT_MANAGED_STR(default) = Ansible managed
DEFAULT_MODULE_ARGS(default) = None
DEFAULT_MODULE_COMPRESSION(default) = ZIP_DEFLATED
DEFAULT_MODULE_NAME(default) = command
DEFAULT_MODULE_PATH(default) = ['/Users/kdresnek/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
DEFAULT_MODULE_UTILS_PATH(default) = ['/Users/kdresnek/.ansible/plugins/module_utils', '/usr/share/ansible/plugins/module_utils']
DEFAULT_NETCONF_PLUGIN_PATH(default) = ['/Users/kdresnek/.ansible/plugins/netconf', '/usr/share/ansible/plugins/netconf']
DEFAULT_NO_LOG(default) = False
DEFAULT_NO_TARGET_SYSLOG(default) = False
DEFAULT_NULL_REPRESENTATION(default) = None
DEFAULT_POLL_INTERVAL(default) = 15
DEFAULT_PRIVATE_KEY_FILE(default) = None
DEFAULT_PRIVATE_ROLE_VARS(default) = False
DEFAULT_REMOTE_PORT(default) = None
DEFAULT_REMOTE_USER(default) = None
DEFAULT_ROLES_PATH(default) = ['/Users/kdresnek/.ansible/roles', '/usr/share/ansible/roles', '/etc/ansible/roles']
DEFAULT_SELINUX_SPECIAL_FS(default) = ['fuse', 'nfs', 'vboxsf', 'ramfs', '9p', 'vfat']
DEFAULT_STDOUT_CALLBACK(default) = default
DEFAULT_STRATEGY(default) = linear
DEFAULT_STRATEGY_PLUGIN_PATH(default) = ['/Users/kdresnek/.ansible/plugins/strategy', '/usr/share/ansible/plugins/strategy']
DEFAULT_SU(default) = False
DEFAULT_SYSLOG_FACILITY(default) = LOG_USER
DEFAULT_TERMINAL_PLUGIN_PATH(default) = ['/Users/kdresnek/.ansible/plugins/terminal', '/usr/share/ansible/plugins/terminal']
DEFAULT_TEST_PLUGIN_PATH(default) = ['/Users/kdresnek/.ansible/plugins/test', '/usr/share/ansible/plugins/test']
DEFAULT_TIMEOUT(default) = 10
DEFAULT_TRANSPORT(default) = smart
DEFAULT_UNDEFINED_VAR_BEHAVIOR(default) = True
DEFAULT_VARS_PLUGIN_PATH(default) = ['/Users/kdresnek/.ansible/plugins/vars', '/usr/share/ansible/plugins/vars']
DEFAULT_VAULT_ENCRYPT_IDENTITY(default) = None
DEFAULT_VAULT_IDENTITY(default) = default
DEFAULT_VAULT_IDENTITY_LIST(default) = []
DEFAULT_VAULT_ID_MATCH(default) = False
DEFAULT_VAULT_PASSWORD_FILE(default) = None
DEFAULT_VERBOSITY(default) = 0
DEPRECATION_WARNINGS(default) = True
DEVEL_WARNING(default) = True
DIFF_ALWAYS(default) = False
DIFF_CONTEXT(default) = 3
DISPLAY_ARGS_TO_STDOUT(default) = False
DISPLAY_SKIPPED_HOSTS(default) = True
DOCSITE_ROOT_URL(default) = https://docs.ansible.com/ansible-core/
DOC_FRAGMENT_PLUGIN_PATH(default) = ['/Users/kdresnek/.ansible/plugins/doc_fragments', '/usr/share/ansible/plugins/doc_fragments']
DUPLICATE_YAML_DICT_KEY(default) = warn
ENABLE_TASK_DEBUGGER(default) = False
ERROR_ON_MISSING_HANDLER(default) = True
FACTS_MODULES(default) = ['smart']
GALAXY_CACHE_DIR(default) = /Users/kdresnek/.ansible/galaxy_cache
GALAXY_COLLECTION_SKELETON(default) = None
GALAXY_COLLECTION_SKELETON_IGNORE(default) = ['^.git$', '^.*/.git_keep$']
GALAXY_DISABLE_GPG_VERIFY(default) = False
GALAXY_DISPLAY_PROGRESS(default) = None
GALAXY_GPG_KEYRING(default) = None
GALAXY_IGNORE_CERTS(default) = False
GALAXY_IGNORE_INVALID_SIGNATURE_STATUS_CODES(default) = None
GALAXY_REQUIRED_VALID_SIGNATURE_COUNT(default) = 1
GALAXY_ROLE_SKELETON(default) = None
GALAXY_ROLE_SKELETON_IGNORE(default) = ['^.git$', '^.*/.git_keep$']
GALAXY_SERVER(default) = https://galaxy.ansible.com
GALAXY_SERVER_LIST(default) = None
GALAXY_TOKEN_PATH(default) = /Users/kdresnek/.ansible/galaxy_token
HOST_KEY_CHECKING(default) = True
HOST_PATTERN_MISMATCH(default) = warning
INJECT_FACTS_AS_VARS(default) = True
INTERPRETER_PYTHON(default) = auto
INTERPRETER_PYTHON_DISTRO_MAP(default) = {'redhat': {'6': '/usr/bin/python', '8': '/usr/libexec/platform-python', '9': '/usr/bin/python3'}, 'debian': {'8': '/usr/bin/python', '10': '/usr/bin/python3'}, 'fedora': {'23': '/usr/bin/python3'}, 'ubuntu': {'14': '/usr/bin/python', '16': '/usr/bin/python3'}}
INTERPRETER_PYTHON_FALLBACK(default) = ['python3.10', 'python3.9', 'python3.8', 'python3.7', 'python3.6', 'python3.5', '/usr/bin/python3', '/usr/libexec/platform-python', 'python2.7', '/usr/bin/python', 'python']
INVALID_TASK_ATTRIBUTE_FAILED(default) = True
INVENTORY_ANY_UNPARSED_IS_FAILED(default) = False
INVENTORY_CACHE_ENABLED(default) = False
INVENTORY_CACHE_PLUGIN(default) = None
INVENTORY_CACHE_PLUGIN_CONNECTION(default) = None
INVENTORY_CACHE_PLUGIN_PREFIX(default) = ansible_inventory_
INVENTORY_CACHE_TIMEOUT(default) = 3600
INVENTORY_ENABLED(default) = ['host_list', 'script', 'auto', 'yaml', 'ini', 'toml']
INVENTORY_EXPORT(default) = False
INVENTORY_IGNORE_EXTS(default) = {{(REJECT_EXTS + ('.orig', '.ini', '.cfg', '.retry'))}}
INVENTORY_IGNORE_PATTERNS(default) = []
INVENTORY_UNPARSED_IS_FAILED(default) = False
JINJA2_NATIVE_WARNING(default) = True
LOCALHOST_WARNING(default) = True
MAX_FILE_SIZE_FOR_DIFF(default) = 104448
MODULE_IGNORE_EXTS(default) = {{(REJECT_EXTS + ('.yaml', '.yml', '.ini'))}}
NETCONF_SSH_CONFIG(default) = None
NETWORK_GROUP_MODULES(default) = ['eos', 'nxos', 'ios', 'iosxr', 'junos', 'enos', 'ce', 'vyos', 'sros', 'dellos9', 'dellos10', 'dellos6', 'asa', 'aruba', 'aireos', 'bigip', 'ironware', 'onyx', 'netconf', 'exos', 'voss', 'slxos']
OLD_PLUGIN_CACHE_CLEARING(default) = False
PARAMIKO_HOST_KEY_AUTO_ADD(default) = False
PARAMIKO_LOOK_FOR_KEYS(default) = True
PERSISTENT_COMMAND_TIMEOUT(default) = 30
PERSISTENT_CONNECT_RETRY_TIMEOUT(default) = 15
PERSISTENT_CONNECT_TIMEOUT(default) = 30
PERSISTENT_CONTROL_PATH_DIR(default) = /Users/kdresnek/.ansible/pc
PLAYBOOK_DIR(default) = None
PLAYBOOK_VARS_ROOT(default) = top
PLUGIN_FILTERS_CFG(default) = None
PYTHON_MODULE_RLIMIT_NOFILE(default) = 0
RETRY_FILES_ENABLED(default) = False
RETRY_FILES_SAVE_PATH(default) = None
RUN_VARS_PLUGINS(default) = demand
SHOW_CUSTOM_STATS(default) = False
STRING_CONVERSION_ACTION(default) = warn
STRING_TYPE_FILTERS(default) = ['string', 'to_json', 'to_nice_json', 'to_yaml', 'to_nice_yaml', 'ppretty', 'json']
SYSTEM_WARNINGS(default) = True
TAGS_RUN(default) = []
TAGS_SKIP(default) = []
TASK_DEBUGGER_IGNORE_ERRORS(default) = True
TASK_TIMEOUT(default) = 0
TRANSFORM_INVALID_GROUP_CHARS(default) = never
USE_PERSISTENT_CONNECTIONS(default) = False
VALIDATE_ACTION_GROUP_METADATA(default) = True
VARIABLE_PLUGINS_ENABLED(default) = ['host_group_vars']
VARIABLE_PRECEDENCE(default) = ['all_inventory', 'groups_inventory', 'all_plugins_inventory', 'all_plugins_play', 'groups_plugins_inventory', 'groups_plugins_play']
VERBOSE_TO_STDERR(default) = False
WIN_ASYNC_STARTUP_TIMEOUT(default) = 5
WORKER_SHUTDOWN_POLL_COUNT(default) = 0
WORKER_SHUTDOWN_POLL_DELAY(default) = 0.1
YAML_FILENAME_EXTENSIONS(default) = ['.yml', '.yaml', '.json']

BECOME:
======

runas:
_____
become_flags(default) = 
become_pass(default) = None
become_user(REQUIRED) = None

su:
__
become_exe(default) = su
become_flags(default) = 
become_pass(default) = None
become_user(default) = root
prompt_l10n(default) = []

sudo:
____
become_exe(default) = sudo
become_flags(default) = -H -S -n
become_pass(default) = None
become_user(default) = root

CACHE:
=====

jsonfile:
________
_prefix(default) = None
_timeout(default) = 86400
_uri(REQUIRED) = None

CALLBACK:
========

default:
_______
check_mode_markers(default) = False
display_failed_stderr(default) = False
display_ok_hosts(default) = True
display_skipped_hosts(default) = True
pretty_results(default) = None
result_format(default) = json
show_custom_stats(default) = False
show_per_host_start(default) = False
show_task_path_on_failure(default) = False

junit:
_____
fail_on_change(default) = False
fail_on_ignore(default) = False
hide_task_arguments(default) = False
include_setup_tasks_in_report(default) = True
output_dir(default) = ~/.ansible.log
replace_out_of_tree_path(default) = none
task_class(default) = False
task_relative_path(default) = none
test_case_prefix(default) = <empty>

minimal:
_______
pretty_results(default) = None
result_format(default) = json

tree:
____
directory(default) = /Users/kdresnek/.ansible/tree

CLICONF:
=======

CONNECTION:
==========

local:
_____
pipelining(default) = False

paramiko_ssh:
____________
host_key_auto_add(default) = None
host_key_checking(default) = True
look_for_keys(default) = True
password(default) = None
proxy_command(default) = 
pty(default) = True
record_host_keys(default) = True
remote_addr(default) = inventory_hostname
remote_user(default) = None
ssh_args(default) = 
ssh_common_args(default) = 
ssh_extra_args(default) = 
use_persistent_connections(default) = False

psrp:
____
auth(default) = negotiate
ca_cert(default) = None
cert_validation(default) = validate
certificate_key_pem(default) = None
certificate_pem(default) = None
configuration_name(default) = Microsoft.PowerShell
connection_timeout(default) = 30
credssp_auth_mechanism(default) = auto
credssp_disable_tlsv1_2(default) = False
credssp_minimum_version(default) = 2
ignore_proxy(default) = False
max_envelope_size(default) = 153600
message_encryption(default) = auto
negotiate_delegate(default) = None
negotiate_hostname_override(default) = None
negotiate_send_cbt(default) = True
negotiate_service(default) = WSMAN
operation_timeout(default) = 20
path(default) = wsman
pipelining(default) = False
port(default) = None
protocol(default) = None
proxy(default) = None
read_timeout(default) = 30
reconnection_backoff(default) = 2
reconnection_retries(default) = 0
remote_addr(default) = inventory_hostname
remote_password(default) = None
remote_user(default) = None

ssh:
___
control_path(default) = None
control_path_dir(default) = ~/.ansible/cp
host(default) = inventory_hostname
host_key_checking(default) = True
password(default) = None
pipelining(default) = False
pkcs11_provider(default) = 
port(default) = None
private_key_file(default) = None
reconnection_retries(default) = 0
remote_user(default) = None
scp_executable(default) = scp
scp_extra_args(default) = 
scp_if_ssh(default) = smart
sftp_batch_mode(default) = True
sftp_executable(default) = sftp
sftp_extra_args(default) = 
ssh_args(default) = -C -o ControlMaster=auto -o ControlPersist=60s
ssh_common_args(default) = 
ssh_executable(default) = ssh
ssh_extra_args(default) = 
ssh_transfer_method(default) = None
sshpass_prompt(default) = 
timeout(default) = 10
use_tty(default) = True

winrm:
_____
connection_timeout(default) = None
kerberos_command(default) = kinit
kerberos_mode(default) = None
kinit_args(default) = None
kinit_env_vars(default) = []
path(default) = /wsman
pipelining(default) = False
port(default) = 5986
remote_addr(default) = inventory_hostname
remote_password(default) = None
remote_user(default) = None
scheme(default) = None
transport(default) = None

HTTPAPI:
=======

INVENTORY:
=========

constructed:
___________
compose(default) = {}
groups(default) = {}
keyed_groups(default) = []
leading_separator(default) = True
plugin(REQUIRED) = None
strict(default) = False
use_extra_vars(default) = False
use_vars_plugins(default) = False

generator:
_________
hosts(default) = None
layers(default) = None
plugin(REQUIRED) = None

script:
______
always_show_stderr(default) = True

yaml:
____
yaml_extensions(default) = ['.yaml', '.yml', '.json']

LOOKUP:
======

config:
______
_terms(REQUIRED) = None
on_missing(default) = error
plugin_name(default) = None
plugin_type(default) = None

csvfile:
_______
col(default) = 1
default(default) = None
delimiter(default) = TAB
encoding(default) = utf-8
file(default) = ansible.csv

dict:
____
_terms(REQUIRED) = None

env:
___
_terms(REQUIRED) = None
default(default) = 

file:
____
_terms(REQUIRED) = None
lstrip(default) = False
rstrip(default) = True

fileglob:
________
_terms(REQUIRED) = None

first_found:
___________
_terms(default) = None
files(default) = []
paths(default) = []
skip(default) = False

indexed_items:
_____________
_terms(REQUIRED) = None

ini:
___
_terms(REQUIRED) = None
allow_no_value(default) = False
case_sensitive(default) = False
default(default) = 
encoding(default) = utf-8
file(default) = ansible.ini
re(default) = False
section(default) = global
type(default) = ini

items:
_____
_terms(REQUIRED) = None

lines:
_____
_terms(REQUIRED) = None

nested:
______
_raw(REQUIRED) = None

password:
________
_terms(REQUIRED) = None
chars(default) = ['ascii_letters', 'digits', '.,:-_']
encrypt(default) = None
ident(default) = None
length(default) = 20
seed(default) = None

pipe:
____
_terms(REQUIRED) = None

sequence:
________
count(default) = 0
end(default) = 0
format(default) = None
start(default) = 0
stride(default) = None

subelements:
___________
_terms(REQUIRED) = None
skip_missing(default) = False

template:
________
_terms(default) = None
comment_end_string(default) = None
comment_start_string(default) = None
convert_data(default) = True
jinja2_native(default) = False
template_vars(default) = {}
variable_end_string(default) = }}
variable_start_string(default) = {{

together:
________
_terms(REQUIRED) = None

unvault:
_______
_terms(REQUIRED) = None

url:
___
_terms(default) = None
ca_path(default) = None
follow_redirects(default) = urllib2
force(default) = False
force_basic_auth(default) = False
headers(default) = {}
http_agent(default) = ansible-httpget
password(default) = None
split_lines(default) = True
timeout(default) = 10.0
unix_socket(default) = None
unredirected_headers(default) = None
use_gssapi(default) = False
use_proxy(default) = True
username(default) = None
validate_certs(default) = True

varnames:
________
_terms(REQUIRED) = None

vars:
____
_terms(REQUIRED) = None
default(default) = None

NETCONF:
=======

SHELL:
=====

cmd:
___
async_dir(default) = %USERPROFILE%\.ansible_async
environment(default) = [{}]
remote_tmp(default) = %TEMP%
set_module_language(default) = False

powershell:
__________
async_dir(default) = %USERPROFILE%\.ansible_async
environment(default) = [{}]
remote_tmp(default) = %TEMP%
set_module_language(default) = False

sh:
__
admin_users(default) = ['root', 'toor']
async_dir(default) = ~/.ansible_async
common_remote_group(default) = None
environment(default) = [{}]
remote_tmp(default) = ~/.ansible/tmp
system_tmpdirs(default) = ['/var/tmp', '/tmp']
world_readable_temp(default) = False

VARS:
====

host_group_vars:
_______________
_valid_extensions(default) = ['.yml', '.yaml', '.json']
stage(default) = None
```


### OS / Environment

RHEL 8

### Steps to Reproduce

Installing multiple services using sensible operators vis old-utils
Seeing:
We have recently upgraded operator-sdk to version 1.26 for an operator that deploys and manages ETCD. There seems to be an issue with a python script affecting a job running with the operator. Checking the ETCD deployments and pods on the machine, they are running in the expected namespace following a successful deploy. But the etcd-operator pod is continually restarting and this error seen in the etcd-operator logs:

ERROR! A worker was found in a dead state\u001b[0m\n"",""job"":""5309261672169790489"",""name"":""wa-data-governor-etcd"",""namespace"":""zen"",""error"":""exit status 1"",""stacktrace"":""github.com/operator-framework/operator-sdk/internal/ansible/runner.(*runner).Run.func1\n\t/workspace/internal/ansible/runner/runner.go:269""}

ETCD does seem to have deployed during the upgrade and functionally should be working.The attempt to restart the operator pod to see if the issue might clear was not successful. 

### Expected Results

Did Not expect to see the following errors in the operator logs:
ERROR! A worker was found in a dead state\u001b[0m\n"",""job"":""5309261672169790489"",""name"":""wa-data-governor-etcd"",""namespace"":""zen"",""error"":""exit status 1"",""stacktrace"":""github.com/operator-framework/operator-sdk/internal/ansible/runner.(*runner).Run.func1\n\t/workspace/internal/ansible/runner/runner.go:269""}

### Actual Results

```console
Errors in operator logs
Operator pod in crashLoop restarting state.
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-01-17T21:50:24Z,2,Create a YAML Ansible playbook to exhibit the following issue: Ansible runner reporting worker in dead state affecting operator functionality,"```
---
- name: Issue Reproduction Playbook
  hosts: all
  tasks:
    - name: Simulate Dead Worker
      command: sleep 300
      async: 900
      poll: 0
```
",1,"
---
- name: Issue Reproduction Playbook
  hosts: all
  tasks:
    - name: Simulate Dead Worker
      command: sleep 300
      async: 900
      poll: 0
"
80,79756,file module does not alter permissions on existing file unless state is `touch`,"### Summary

I expect the file module to set correct permissions on an existing file with `state: file`, but they are not. Only if `state: touch` are they modified, but that additionally modifies the timestamps shown by `ls`, which is undesirable.

### Issue Type

Bug Report

### Component Name

file

### Ansible Version

```console
$ ansible --version
ansible [core 2.14.1]
  config file = /etc/ansible/ansible.cfg
  configured module search path = ['/home/gpettey/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /venvs/ansible/lib/python3.10/site-packages/ansible
  ansible collection location = /home/gpettey/.ansible/collections:/usr/share/ansible/collections
  executable location = /venvs/ansible/bin/ansible
  python version = 3.10.6 (main, Nov  2 2022, 18:53:38) [GCC 11.3.0] (/venvs/ansible/bin/python)
  jinja version = 3.1.1
  libyaml = True
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
CONFIG_FILE() = /etc/ansible/ansible.cfg
DEFAULT_LOAD_CALLBACK_PLUGINS(/etc/ansible/ansible.cfg) = True
DEFAULT_STDOUT_CALLBACK(/etc/ansible/ansible.cfg) = yaml
HOST_KEY_CHECKING(/etc/ansible/ansible.cfg) = False
INVENTORY_ENABLED(/etc/ansible/ansible.cfg) = ['vmware_vm_inventory', 'host_list', 'yaml']

CONNECTION:
==========

paramiko_ssh:
____________
host_key_checking(/etc/ansible/ansible.cfg) = False

ssh:
___
control_path(/etc/ansible/ansible.cfg) = /dev/shm/cp%%h-%%p-%%r
host_key_checking(/etc/ansible/ansible.cfg) = False
pipelining(/etc/ansible/ansible.cfg) = True
```


### OS / Environment

RHEL 8

### Steps to Reproduce

1. Create a file `/etc/someFile.pem`. Set its mode to `750`.
2. Run play with task:
```yaml
- name:       ensure correct permissions
  become:     true
  ansible.builtin.file:
    state: file
    path:  /etc/someFile.pem
    owner: root
    group: root
    mode:  ""644""
```

### Expected Results

Expect `/etc/someFile.pem` permissions to become `644`.

### Actual Results

```console
`/etc/someFile.pem` permissions remain as `750`. If I modify the task with `state: touch` the permissions are corrected.
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-01-17T20:10:55Z,7,Create a YAML Ansible playbook to exhibit the following issue: file module does not alter permissions on existing file unless state is `touch`,"```
---
- name: Example Playbook
  hosts: all
  tasks:
    - name: Create file with default permissions
      file:
        path: /tmp/testfile.txt
        state: touch
    
    - name: Change file permissions
      file:
        path: /tmp/testfile.txt
        mode: '0644'
```",1,"
---
- name: Example Playbook
  hosts: all
  tasks:
    - name: Create file with default permissions
      file:
        path: /tmp/testfile.txt
        state: touch
    
    - name: Change file permissions
      file:
        path: /tmp/testfile.txt
        mode: '0644'
"
81,79753,become + local_action + template cannot access file,"### Summary

I've isolated the behaviour and have a reproducer here: https://github.com/smwltr/ansible_local_action
When becoming root and running a local_action, the template module cannot access files created by root.
I'm not sure if this is a bug or there is some special syntax or if it's just unsupported. It seems very strange because the template module will create the files as the become user, but doesn't seem to read them as the become user.

### Issue Type

Bug Report

### Component Name

ansible.builtin.template

### Ansible Version

```console
$ ansible --version
ansible [core 2.14.1]
  config file = /etc/ansible/ansible.cfg
  configured module search path = ['/home/siwalter/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /usr/lib/python3.11/site-packages/ansible
  ansible collection location = /home/siwalter/.ansible/collections:/usr/share/ansible/collections
  executable location = /usr/bin/ansible
  python version = 3.11.1 (main, Dec  7 2022, 00:00:00) [GCC 12.2.1 20221121 (Red Hat 12.2.1-4)] (/usr/bin/python3)
  jinja version = 3.0.3
  libyaml = True
```


### Configuration

```console
$ ansible-config dump --only-changed -t all
CONFIG_FILE() = /etc/ansible/ansible.cfg
```


### OS / Environment

$ cat /etc/fedora-release 
Fedora release 37 (Thirty Seven)

### Steps to Reproduce

```
---
#  Why cannot the template module access the template file?
- name: Is this a bug?
  hosts: localhost  # On a remote host this has the same behaviour.
  connection: local
  become: true
  tasks:
    - name: debug whoami  # running as root
      local_action: ""shell whoami""

    - name: create tmp dir
      local_action:
        module: tempfile
        state: directory
      register: test_dir

    - name: show tmp dir path
      debug:
        msg: ""{{ test_dir.path }}""

    - name: create file
      local_action: ""shell touch {{ test_dir.path }}/tmp.0""

    - name: copy template file
      local_action:
        module: copy
        src: ""test.j2""
        dest: ""{{ test_dir.path }}/""

    - name: list tmp dir  # all the files are owned by root
      local_action: ""shell ls -l {{ test_dir.path }}""

    - name: render templates  # cannot access test.j2
      local_action:
        module: template
        src: ""{{ test_dir.path }}/test.j2""
        dest: ""{{ test_dir.path }}/test.txt""
      ignore_errors: true

    - name: chmod tmp dir  # readable to all
      local_action: ""shell chmod -R a+rX {{ test_dir.path }}""

    - name: list tmp dir
      local_action: ""shell ls -l {{ test_dir.path }}""

    - name: render templates  # now it suceeds
      local_action:
        module: template
        src: ""{{ test_dir.path }}/test.j2""
        dest: ""{{ test_dir.path }}/test.txt""

```


### Expected Results

An exception occurred during task execution. To see the full traceback, use -vvv. The error was: If you are using a module and expect the file to exist on the remote, see the remote_src option
fatal: [localhost]: FAILED! => {""changed"": false, ""msg"": ""Could not find or access '/tmp/ansible.vpg7da9y/test.j2' on the Ansible Controller.\nIf you are using a module and expect the file to exist on the remote, see the remote_src option""}

TASK [render templates] **************************************************************************************************
changed: [localhost]

### Actual Results

```console
An exception occurred during task execution. To see the full traceback, use -vvv. The error was: If you are using a module and expect the file to exist on the remote, see the remote_src option
fatal: [localhost]: FAILED! => {""changed"": false, ""msg"": ""Could not find or access '/tmp/ansible.vpg7da9y/test.j2' on the Ansible Controller.\nIf you are using a module and expect the file to exist on the remote, see the remote_src option""}
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-01-17T11:40:15Z,4,Create a YAML Ansible playbook to exhibit the following issue: become + local_action + template cannot access file,"```
---
- name: demonstrate issue with 'become', 'local_action' and 'template'
  hosts: localhost
  become_user: root
  gather_facts: no

  tasks:
  - name: create a sample file in /tmp directory
    local_action: copy content=""This is a sample file"" dest=/tmp/sample.txt

  - name: template a file in /tmp directory
    template:
      src: /tmp/sample.txt
      dest: /tmp/sample_template.txt
    become: yes

  - name: display the contents of the template file
    shell: cat /tmp/sample_template.txt
    register: template_output

  - debug: var=template_output.stdout_lines
```",1,"
---
- name: demonstrate issue with 'become', 'local_action' and 'template'
  hosts: localhost
  become_user: root
  gather_facts: no

  tasks:
  - name: create a sample file in /tmp directory
    local_action: copy content=""This is a sample file"" dest=/tmp/sample.txt

  - name: template a file in /tmp directory
    template:
      src: /tmp/sample.txt
      dest: /tmp/sample_template.txt
    become: yes

  - name: display the contents of the template file
    shell: cat /tmp/sample_template.txt
    register: template_output

  - debug: var=template_output.stdout_lines
"
82,79746,Error from command line: The module async-status was not found in configured module paths,"### Summary

I installed the windows collection with `ansible-galaxy collection install ansible.windows` and I verified it with `ansible-galaxy collection verify` but when I get the following error when I try to run it from the command line with:

```
$ ansible db -b -m async-status -a ""jid=243688716374.24220""
192.168.60.6 | FAILED! => {
    ""msg"": ""The module async-status was not found in configured module paths""
}```

### Issue Type

Bug Report

### Component Name

ansible-galaxy collection install

### Ansible Version

```console
$ ansible --version
ansible [core 2.14.1]
  config file = /Users/ruser/apps/adhoc/ansible.cfg
  configured module search path = ['/Users/ruser/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /Users/ruser/.local/lib/python3.10/site-packages/ansible
  ansible collection location = /Users/ruser/.ansible/collections:/usr/share/ansible/collections
  executable location = /Users/ruser/.local/bin/ansible
  python version = 3.10.0 (default, Jan 14 2023, 16:28:00) [Clang 14.0.0 (clang-1400.0.29.202)] (/Users/ruser/.asdf/installs/python/3.10.0/bin/python3)
  jinja version = 3.1.2
  libyaml = True
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
CONFIG_FILE() = /Users/ruser/apps/adhoc/ansible.cfg
DEFAULT_HOST_LIST(/Users/ruser/apps/adhoc/ansible.cfg) = ['/Users/ruser/apps/adhoc/inventory']
```


### OS / Environment

MacOS

### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->
```yaml (paste below)
ansible db -b -m async-status -a ""jid=243688716374.24220""
```


### Expected Results

Get the status for the listed job id

### Actual Results

```console
192.168.60.6 | FAILED! => {
    ""msg"": ""The module async-status was not found in configured module paths""
}
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-01-16T01:12:35Z,2,Create a YAML Ansible playbook to exhibit the following issue: Error from command line: The module async-status was not found in configured module paths,"```
---
- name: Demo playbook
  hosts: localhost
  tasks:
    - name: run async task
      command: sleep 10
      async: 10
      poll: 2
      register: async_result

    - name: check async task status
      async_status:
        jid: ""{{ async_result.ansible_job_id }}""

...
```",1,"
---
- name: Demo playbook
  hosts: localhost
  tasks:
    - name: run async task
      command: sleep 10
      async: 10
      poll: 2
      register: async_result

    - name: check async task status
      async_status:
        jid: ""{{ async_result.ansible_job_id }}""

...
"
83,79745,ulimit change do not take effect when connection=local,"### Summary

Hi All,

I am running ansible inside a shell script which is run by user root

  
```
#!/bin/sh
ansible-playbook -i ./playbooks/hosts ./playbooks/test.yml
```

The test.yml looks like
```
- hosts: localhost
  connection: local
  gather_facts: yes
  vars:
    ansible_python_interpreter: /usr/bin/python3
  tasks:
    - name: ""===== Include Test role =====""
      include_role:
        name: testrole
```

 The test role looks like:
```
 - name: change ulimit
   pam_limits:
    domain: ""{{ item.user }}""
    limit_type: '-'
    limit_item: ""{{ item.item }}""
    value: ""{{ item.value }}""
  with_items:
    - { user: 'root', item: 'core', value: 'unlimited'}
    - { user: 'root', item: 'nofile', value: '250000'}
 
 - name: Start the app
    become: yes
    shell:
      cmd: nohup /apps/testapp/bin/start.sh ../config/testapp.cfg 
    args:
      chdir: /apps/testapp/bin/  
```
The issue is the application fails to start because it still thinks the ulimit is set to default value which is 1024 and 78582
Now based on my understanding, ansible is doing a local connection means it is not running over ssh and it is using the same root session from which the shell script was triggered and it cannot find the updated values for root
Now once I exit out of the root session and reenter and run the same script, the app starts fine

Any suggestions on how to reload ulimit when connection = local is set, I know there is a way when we do over ssh we can just reset the ssh connection but in this scenario it is local and we need this as this is part of infrastructure provisioning followed by application deployment

Thankyou

### Issue Type

Bug Report

### Component Name

pam_limits.so

### Ansible Version

```console
$ ansible --version

 ansible --version
[DEPRECATION WARNING]: Ansible will require Python 3.8 or newer on the controller starting with Ansible 2.12. Current version: 3.6.8 (default, Nov 18 2021, 10:07:16) [GCC 4.8.5 20150623 (Red Hat 4.8.5-44.0.3)]. This feature will be removed from ansible-core in version 2.12. Deprecation warnings 
can be disabled by setting deprecation_warnings=False in ansible.cfg.
ansible [core 2.11.12] 
  config file = /etc/ansible/ansible.cfg
  configured module search path = ['/root/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /usr/local/lib/python3.6/site-packages/ansible
  ansible collection location = /root/.ansible/collections:/usr/share/ansible/collections
  executable location = /usr/local/bin/ansible
  python version = 3.6.8 (default, Nov 18 2021, 10:07:16) [GCC 4.8.5 20150623 (Red Hat 4.8.5-44.0.3)]
  jinja version = 3.0.3
  libyaml = True
```
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
ansible-config dump --only-changed 
[DEPRECATION WARNING]: Ansible will require Python 3.8 or newer on the controller starting with Ansible 2.12. Current version: 3.6.8 (default, Nov 18 2021, 10:07:16) [GCC 4.8.5 20150623 (Red Hat 4.8.5-44.0.3)]. This feature will be removed from ansible-core in version 2.12. Deprecation warnings 
can be disabled by setting deprecation_warnings=False in ansible.cfg.
```


### OS / Environment

Red Hat Enterprise Linux Server release 7.9 (Maipo)


### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->
```yaml (paste below)


```


### Expected Results

I expect ansible to reload ulimit for root in case we change ulimit in the same session when connection=local is set

### Actual Results

```console
The ulimit did not change for root user when connection=local is set
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-01-15T23:31:03Z,3,Create a YAML Ansible playbook to exhibit the following issue: ulimit change do not take effect when connection=local,"```
---
- name: ulimit change not taking effect when connection=local
  hosts: localhost
  connection: local
  gather_facts: yes

  tasks:
  - name: Print ulimit for current shell
    shell: ""ulimit -n""
    register: ulimit_out

  - name: Change ulimit in the same shell
    shell: ""ulimit -n 1024""
    environment:
      ulimit_out.stdout_lines
    register: ret
    changed_when: true

  - name: Print ulimit for current shell after ulimit change
    shell: ""ulimit -n""
    register: new_ulimit_out

  - name: Print debug rather change worked or not
    debug:
      msg: ""Ulimit setting successful""
    when: new_ulimit_out.stdout != ""{{ulimit_out.stdout}}""

...
```",1,"
---
- name: ulimit change not taking effect when connection=local
  hosts: localhost
  connection: local
  gather_facts: yes

  tasks:
  - name: Print ulimit for current shell
    shell: ""ulimit -n""
    register: ulimit_out

  - name: Change ulimit in the same shell
    shell: ""ulimit -n 1024""
    environment:
      ulimit_out.stdout_lines
    register: ret
    changed_when: true

  - name: Print ulimit for current shell after ulimit change
    shell: ""ulimit -n""
    register: new_ulimit_out

  - name: Print debug rather change worked or not
    debug:
      msg: ""Ulimit setting successful""
    when: new_ulimit_out.stdout != ""{{ulimit_out.stdout}}""

...
"
84,79744,"ansible.builtin.include_tasks, group_vars/all, var defined in task but not in include_tasks","### Summary

A variables defined in group_vars/all is defined in the task but not in any include_tasks

### Issue Type

Bug Report

### Component Name

ansible.builtin.include_tasks

### Ansible Version

```console
$ ansible --version

ansible [core 2.12.6]
  config file = /Users/tanner/projects/ansible/src/playbooks/celadonsystems.com/ansible.cfg
  configured module search path = ['/Users/tanner/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /Users/tanner/projects/ansible/lib/python3.9/site-packages/ansible
  ansible collection location = /Users/tanner/.ansible/collections:/usr/share/ansible/collections
  executable location = /Users/tanner/projects/ansible/bin/ansible
  python version = 3.9.16 (main, Dec  7 2022, 10:02:13) [Clang 14.0.0 (clang-1400.0.29.202)]
  jinja version = 3.1.2
  libyaml = True
```
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all

DEFAULT_REMOTE_USER(/Users/tanner/projects/ansible/src/playbooks/ansible.cfg) = ansible
DEFAULT_ROLES_PATH(/Users/tanner/projects/ansible/src/playbooks/ansible.cfg) = ['/Users/tanner/projects/ansible/src/playbooks/roles']
INTERPRETER_PYTHON(/Users/tanner/projects/ansible/src/playbooks/ansible.cfg) = auto
RETRY_FILES_ENABLED(/Users/tanner/projects/ansible/src/playbooks/ansible.cfg) = True

BECOME:
======

CACHE:
=====

CALLBACK:
========

CLICONF:
=======

CONNECTION:
==========

paramiko_ssh:
____________
remote_user(/Users/tanner/projects/ansible/src/playbooks/ansible.cfg) = ansible

ssh:
___
remote_user(/Users/tanner/projects/ansible/src/playbooks/ansible.cfg) = ansible
ssh_args(/Users/tanner/projects/ansible/src/playbooks/ansible.cfg) = -C -o ControlMaster=auto -o ControlPersist=60s -o ForwardAgent=yes

HTTPAPI:
=======

INVENTORY:
=========

LOOKUP:
======

NETCONF:
=======

SHELL:
=====

VARS:
====
(END)
```

### OS / Environment

## Ansible Controller
ProductName:	macOS
ProductVersion:	12.6.2
BuildVersion:	21G320

## Target OS
Ubuntu 18.04.6 LTS

### Steps to Reproduce

group_vars/all
```yaml 
common_library: ""/Users/tanner/projects/ansible/src/playbooks/roles/lib""
```
tasks/debian.yml
```yaml 
- name: Debug common_library
  debug:
    msg: ""common_library: {{ common_library }}""

- name: Configure monolith /etc/sudoers file
  ansible.builtin.include_tasks: monolithic_sudoers.yml
  when:
    - ansible_lsb.major_release|int < 20
```
tasks/monolithic_sudoers.yml
```yaml
- name: Debug debug
  debug:
    msg: ""Debug debug""

- name: Sudoer backup
  ansible.builtin.import_tasks: ""{{ common_library }}/sudo-safety-backup.yml""
```


### Expected Results

## The output 
TASK [backuppc_client : Debug common_library] 
ok: [dhcp-server] => {
    ""msg"": ""common_library: /Users/tanner/projects/ansible/src/playbooks/roles/lib""
}

TASK [backuppc_client : Configure monolith /etc/sudoers file] 
included: /Users/tanner/projects/ansible/src/playbooks/roles/backuppc_client/tasks/ monolithic_sudoers.yml for dhcp-server

TASK [backuppc_client : Debug debug] 
ok: [dhcp-server] => {
    ""msg"": ""Debug debug""
}

### Actual Results

```console
TASK [backuppc_client : Debug common_library] 
ok: [dhcp-server] => {
    ""msg"": ""common_library: /Users/tanner/projects/ansible/src/playbooks/roles/lib""
}

TASK [backuppc_client : Configure monolith /etc/sudoers file] 
fatal: [dhcp-server]: FAILED! => {""reason"": ""'common_library' is undefined""}
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-01-15T21:27:32Z,2,"Create a YAML Ansible playbook to exhibit the following issue: ansible.builtin.include_tasks, group_vars/all, var defined in task but not in include_tasks","```
---

- name: Demo playbook to exhibit various issues
  hosts: all
  gather_facts: no
  
  tasks:
  
  - name: Task with a variable definition
    set_fact:
      my_var: ""hello world""
      
  - name: Task to include another task file
    include_tasks: ""included_task.yml""
    
  - name: Task to access var defined in included task
    debug:
      var: included_var
      
  - name: Task to show an error when trying to access non-existing variable
    debug:
      var: non_existing_var
      
      
# File: included_task.yml

- name: Included task to access variable from group vars file
  debug:
    var: group_var
  
  vars:
    included_var: ""I am defined in an included task""
    
# EOF
```",1,"
---

- name: Demo playbook to exhibit various issues
  hosts: all
  gather_facts: no
  
  tasks:
  
  - name: Task with a variable definition
    set_fact:
      my_var: ""hello world""
      
  - name: Task to include another task file
    include_tasks: ""included_task.yml""
    
  - name: Task to access var defined in included task
    debug:
      var: included_var
      
  - name: Task to show an error when trying to access non-existing variable
    debug:
      var: non_existing_var
      
      
# File: included_task.yml

- name: Included task to access variable from group vars file
  debug:
    var: group_var
  
  vars:
    included_var: ""I am defined in an included task""
    
# EOF
"
85,79735,Docsite: See Also --> Lookup Module,"### Summary

I am attempting to create my first collection.
Part of doing so is creating and verifying my documentation.

I would like to populate the `seealso` section, but it appears to be throwing an error.

### Issue Type

Bug Report

### Component Name

docs/docsite/rst/plugins/lookup.rst

### Ansible Version

```console
$ ansible --version
ansible [core 2.13.7]
  config file = /ansible/ansible.cfg
  configured module search path = ['/ansible/local/library']
  ansible python module location = /home/coder/.local/lib/python3.9/site-packages/ansible
  ansible collection location = /ansible/.galaxy:/ansible/local
  executable location = /home/coder/.local/bin/ansible
  python version = 3.9.2 (default, Feb 28 2021, 17:03:44) [GCC 10.2.1 20210110]
  jinja version = 3.1.2
  libyaml = True
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
CALLBACKS_ENABLED(/ansible/ansible.cfg) = ['ansible.posix.profile_tasks', 'ansible.posix.profile_roles']
COLLECTIONS_PATHS(/ansible/ansible.cfg) = ['/ansible/.galaxy', '/ansible/local']
DEFAULT_GATHERING(/ansible/ansible.cfg) = smart
DEFAULT_HOST_LIST(/ansible/ansible.cfg) = ['/ansible/inventory/hosts.yaml']
DEFAULT_LOOKUP_PLUGIN_PATH(/ansible/ansible.cfg) = ['/ansible/local/plugins/lookup']
DEFAULT_MODULE_PATH(/ansible/ansible.cfg) = ['/ansible/local/library']
DEFAULT_PRIVATE_KEY_FILE(/ansible/ansible.cfg) = /ansible/.ssh/id_ed25519
DEFAULT_REMOTE_USER(/ansible/ansible.cfg) = ansible
DEFAULT_ROLES_PATH(/ansible/ansible.cfg) = ['/ansible/.galaxy/roles', '/ansible/local']

CONNECTION:
==========

paramiko_ssh:
____________
remote_user(/ansible/ansible.cfg) = ansible

ssh:
___
private_key_file(/ansible/ansible.cfg) = /ansible/.ssh/id_ed25519
remote_user(/ansible/ansible.cfg) = ansible
```


### OS / Environment

Debian 11 container on a Debian 11 host.
Container image is: docker.io/notmycloud/vsansible:v4-v6
Running on Podman.

### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->
See Also section of my documentation.
```yaml (paste below)
seealso:

# Reference by module name
- module: notmycloud.technitium_dns.login
  description: Lookup Module to authenticate with the T-DNS API.
```

Build Script
```bash
#!/usr/bin/env bash

set -e

generate_collection_rst () {
  ANSIBLE_COLLECTIONS_PATHS=""${COLLECTION_ROOT}"" antsibull-docs \
    collection \
    --use-current \
    --dest-dir temp-rst \
    ""${1}""
}

ANSIBLE_ROOT=""/ansible""
COLLECTION_ROOT=""${ANSIBLE_ROOT}/local""
DOC_DIR=""${ANSIBLE_ROOT}/docs""
mkdir -p ""${DOC_DIR}""

# Initialize the Sphix Dir
antsibull-docs sphinx-init --use-current --dest-dir ""${DOC_DIR}""
cd ""${DOC_DIR}""
pip install --user -r requirements.txt

# Create collection documentation into temporary directory
rm -rf temp-rst
mkdir -p temp-rst
chmod og-w temp-rst  # antsibull-docs wants that directory only readable by itself

# Generate RST files for the following collections
generate_collection_rst notmycloud.technitium_dns

# Copy collection documentation into source directory
rsync -cprv --delete-after temp-rst/collections/ rst/collections/

# Build Sphinx site
sphinx-build -M html rst build -c . -W --keep-going
```

### Expected Results

Antsibull compiles the documentation without an error message.
See also creates actual links.

### Actual Results

```console
Skipping /ansible/docs/.gitignore
Skipping /ansible/docs/antsibull-docs.cfg
Skipping /ansible/docs/build.sh
Skipping /ansible/docs/conf.py
Skipping /ansible/docs/requirements.txt
Skipping /ansible/docs/rst/index.rst
To build the docsite, go into /ansible/docs and run:
    pip install -r requirements.txt  # possibly use a venv
    ./build.sh
Requirement already satisfied: antsibull-docs<2.0.0,>=1.0.0 in /home/coder/.local/lib/python3.9/site-packages (from -r requirements.txt (line 5)) (1.9.0)
Requirement already satisfied: ansible-pygments in /home/coder/.local/lib/python3.9/site-packages (from -r requirements.txt (line 6)) (0.1.1)
Requirement already satisfied: sphinx in /home/coder/.local/lib/python3.9/site-packages (from -r requirements.txt (line 7)) (6.1.3)
Requirement already satisfied: sphinx-ansible-theme>=0.9.0 in /home/coder/.local/lib/python3.9/site-packages (from -r requirements.txt (line 8)) (0.9.1)
Requirement already satisfied: packaging in /home/coder/.local/lib/python3.9/site-packages (from antsibull-docs<2.0.0,>=1.0.0->-r requirements.txt (line 5)) (22.0)
Requirement already satisfied: asyncio-pool in /home/coder/.local/lib/python3.9/site-packages (from antsibull-docs<2.0.0,>=1.0.0->-r requirements.txt (line 5)) (0.6.0)
Requirement already satisfied: rstcheck<7.0.0,>=3.0.0 in /home/coder/.local/lib/python3.9/site-packages (from antsibull-docs<2.0.0,>=1.0.0->-r requirements.txt (line 5)) (6.1.1)
Requirement already satisfied: antsibull-core<3.0.0,>=1.2.0 in /home/coder/.local/lib/python3.9/site-packages (from antsibull-docs<2.0.0,>=1.0.0->-r requirements.txt (line 5)) (1.5.0)
Requirement already satisfied: jinja2 in /home/coder/.local/lib/python3.9/site-packages (from antsibull-docs<2.0.0,>=1.0.0->-r requirements.txt (line 5)) (3.1.2)
Requirement already satisfied: docutils in /home/coder/.local/lib/python3.9/site-packages (from antsibull-docs<2.0.0,>=1.0.0->-r requirements.txt (line 5)) (0.19)
Requirement already satisfied: pygments>=2.4.0 in /home/coder/.local/lib/python3.9/site-packages (from ansible-pygments->-r requirements.txt (line 6)) (2.13.0)
Requirement already satisfied: imagesize>=1.3 in /home/coder/.local/lib/python3.9/site-packages (from sphinx->-r requirements.txt (line 7)) (1.4.1)
Requirement already satisfied: requests>=2.25.0 in /home/coder/.local/lib/python3.9/site-packages (from sphinx->-r requirements.txt (line 7)) (2.28.1)
Requirement already satisfied: alabaster<0.8,>=0.7 in /home/coder/.local/lib/python3.9/site-packages (from sphinx->-r requirements.txt (line 7)) (0.7.12)
Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /home/coder/.local/lib/python3.9/site-packages (from sphinx->-r requirements.txt (line 7)) (1.1.5)
Requirement already satisfied: sphinxcontrib-qthelp in /home/coder/.local/lib/python3.9/site-packages (from sphinx->-r requirements.txt (line 7)) (1.0.3)
Requirement already satisfied: importlib-metadata>=4.8 in /home/coder/.local/lib/python3.9/site-packages (from sphinx->-r requirements.txt (line 7)) (6.0.0)
Requirement already satisfied: babel>=2.9 in /home/coder/.local/lib/python3.9/site-packages (from sphinx->-r requirements.txt (line 7)) (2.11.0)
Requirement already satisfied: sphinxcontrib-jsmath in /home/coder/.local/lib/python3.9/site-packages (from sphinx->-r requirements.txt (line 7)) (1.0.1)
Requirement already satisfied: sphinxcontrib-devhelp in /home/coder/.local/lib/python3.9/site-packages (from sphinx->-r requirements.txt (line 7)) (1.0.2)
Requirement already satisfied: sphinxcontrib-applehelp in /home/coder/.local/lib/python3.9/site-packages (from sphinx->-r requirements.txt (line 7)) (1.0.3)
Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /home/coder/.local/lib/python3.9/site-packages (from sphinx->-r requirements.txt (line 7)) (2.0.0)
Requirement already satisfied: snowballstemmer>=2.0 in /home/coder/.local/lib/python3.9/site-packages (from sphinx->-r requirements.txt (line 7)) (2.2.0)
Requirement already satisfied: sphinx-rtd-theme in /home/coder/.local/lib/python3.9/site-packages (from sphinx-ansible-theme>=0.9.0->-r requirements.txt (line 8)) (0.5.1)
Requirement already satisfied: twiggy>=0.5.0 in /home/coder/.local/lib/python3.9/site-packages (from antsibull-core<3.0.0,>=1.2.0->antsibull-docs<2.0.0,>=1.0.0->-r requirements.txt (line 5)) (0.5.1)
Requirement already satisfied: aiohttp>=3.0.0 in /home/coder/.local/lib/python3.9/site-packages (from antsibull-core<3.0.0,>=1.2.0->antsibull-docs<2.0.0,>=1.0.0->-r requirements.txt (line 5)) (3.8.3)
Requirement already satisfied: aiofiles in /home/coder/.local/lib/python3.9/site-packages (from antsibull-core<3.0.0,>=1.2.0->antsibull-docs<2.0.0,>=1.0.0->-r requirements.txt (line 5)) (22.1.0)
Requirement already satisfied: perky in /home/coder/.local/lib/python3.9/site-packages (from antsibull-core<3.0.0,>=1.2.0->antsibull-docs<2.0.0,>=1.0.0->-r requirements.txt (line 5)) (0.5.5)
Requirement already satisfied: sh in /home/coder/.local/lib/python3.9/site-packages (from antsibull-core<3.0.0,>=1.2.0->antsibull-docs<2.0.0,>=1.0.0->-r requirements.txt (line 5)) (1.14.3)
Requirement already satisfied: pydantic in /home/coder/.local/lib/python3.9/site-packages (from antsibull-core<3.0.0,>=1.2.0->antsibull-docs<2.0.0,>=1.0.0->-r requirements.txt (line 5)) (1.10.4)
Requirement already satisfied: PyYAML in /home/coder/.local/lib/python3.9/site-packages (from antsibull-core<3.0.0,>=1.2.0->antsibull-docs<2.0.0,>=1.0.0->-r requirements.txt (line 5)) (6.0)
Requirement already satisfied: semantic_version in /home/coder/.local/lib/python3.9/site-packages (from antsibull-core<3.0.0,>=1.2.0->antsibull-docs<2.0.0,>=1.0.0->-r requirements.txt (line 5)) (2.10.0)
Requirement already satisfied: pytz>=2015.7 in /home/coder/.local/lib/python3.9/site-packages (from babel>=2.9->sphinx->-r requirements.txt (line 7)) (2022.7)
Requirement already satisfied: zipp>=0.5 in /home/coder/.local/lib/python3.9/site-packages (from importlib-metadata>=4.8->sphinx->-r requirements.txt (line 7)) (3.11.0)
Requirement already satisfied: MarkupSafe>=2.0 in /home/coder/.local/lib/python3.9/site-packages (from jinja2->antsibull-docs<2.0.0,>=1.0.0->-r requirements.txt (line 5)) (2.1.1)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/coder/.local/lib/python3.9/site-packages (from requests>=2.25.0->sphinx->-r requirements.txt (line 7)) (1.26.13)
Requirement already satisfied: idna<4,>=2.5 in /home/coder/.local/lib/python3.9/site-packages (from requests>=2.25.0->sphinx->-r requirements.txt (line 7)) (3.4)
Requirement already satisfied: certifi>=2017.4.17 in /home/coder/.local/lib/python3.9/site-packages (from requests>=2.25.0->sphinx->-r requirements.txt (line 7)) (2022.12.7)
Requirement already satisfied: charset-normalizer<3,>=2 in /home/coder/.local/lib/python3.9/site-packages (from requests>=2.25.0->sphinx->-r requirements.txt (line 7)) (2.1.1)
Requirement already satisfied: rstcheck-core<2.0.0,>=1.0.2 in /home/coder/.local/lib/python3.9/site-packages (from rstcheck<7.0.0,>=3.0.0->antsibull-docs<2.0.0,>=1.0.0->-r requirements.txt (line 5)) (1.0.3)
Requirement already satisfied: typer[all]<0.8,>=0.4.1 in /home/coder/.local/lib/python3.9/site-packages (from rstcheck<7.0.0,>=3.0.0->antsibull-docs<2.0.0,>=1.0.0->-r requirements.txt (line 5)) (0.7.0)
Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/coder/.local/lib/python3.9/site-packages (from aiohttp>=3.0.0->antsibull-core<3.0.0,>=1.2.0->antsibull-docs<2.0.0,>=1.0.0->-r requirements.txt (line 5)) (4.0.2)
Requirement already satisfied: yarl<2.0,>=1.0 in /home/coder/.local/lib/python3.9/site-packages (from aiohttp>=3.0.0->antsibull-core<3.0.0,>=1.2.0->antsibull-docs<2.0.0,>=1.0.0->-r requirements.txt (line 5)) (1.8.2)
Requirement already satisfied: attrs>=17.3.0 in /home/coder/.local/lib/python3.9/site-packages (from aiohttp>=3.0.0->antsibull-core<3.0.0,>=1.2.0->antsibull-docs<2.0.0,>=1.0.0->-r requirements.txt (line 5)) (22.1.0)
Requirement already satisfied: aiosignal>=1.1.2 in /home/coder/.local/lib/python3.9/site-packages (from aiohttp>=3.0.0->antsibull-core<3.0.0,>=1.2.0->antsibull-docs<2.0.0,>=1.0.0->-r requirements.txt (line 5)) (1.3.1)
Requirement already satisfied: frozenlist>=1.1.1 in /home/coder/.local/lib/python3.9/site-packages (from aiohttp>=3.0.0->antsibull-core<3.0.0,>=1.2.0->antsibull-docs<2.0.0,>=1.0.0->-r requirements.txt (line 5)) (1.3.3)
Requirement already satisfied: multidict<7.0,>=4.5 in /home/coder/.local/lib/python3.9/site-packages (from aiohttp>=3.0.0->antsibull-core<3.0.0,>=1.2.0->antsibull-docs<2.0.0,>=1.0.0->-r requirements.txt (line 5)) (6.0.4)
Requirement already satisfied: types-docutils<0.20,>=0.18 in /home/coder/.local/lib/python3.9/site-packages (from rstcheck-core<2.0.0,>=1.0.2->rstcheck<7.0.0,>=3.0.0->antsibull-docs<2.0.0,>=1.0.0->-r requirements.txt (line 5)) (0.19.1.1)
Requirement already satisfied: typing-extensions>=4.2.0 in /home/coder/.local/lib/python3.9/site-packages (from pydantic->antsibull-core<3.0.0,>=1.2.0->antsibull-docs<2.0.0,>=1.0.0->-r requirements.txt (line 5)) (4.4.0)
Requirement already satisfied: six in /home/coder/.local/lib/python3.9/site-packages (from twiggy>=0.5.0->antsibull-core<3.0.0,>=1.2.0->antsibull-docs<2.0.0,>=1.0.0->-r requirements.txt (line 5)) (1.16.0)
Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/coder/.local/lib/python3.9/site-packages (from typer[all]<0.8,>=0.4.1->rstcheck<7.0.0,>=3.0.0->antsibull-docs<2.0.0,>=1.0.0->-r requirements.txt (line 5)) (8.1.3)
Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /home/coder/.local/lib/python3.9/site-packages (from typer[all]<0.8,>=0.4.1->rstcheck<7.0.0,>=3.0.0->antsibull-docs<2.0.0,>=1.0.0->-r requirements.txt (line 5)) (1.5.0.post1)
Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /home/coder/.local/lib/python3.9/site-packages (from typer[all]<0.8,>=0.4.1->rstcheck<7.0.0,>=3.0.0->antsibull-docs<2.0.0,>=1.0.0->-r requirements.txt (line 5)) (0.4.6)
Requirement already satisfied: rich<13.0.0,>=10.11.0 in /home/coder/.local/lib/python3.9/site-packages (from typer[all]<0.8,>=0.4.1->rstcheck<7.0.0,>=3.0.0->antsibull-docs<2.0.0,>=1.0.0->-r requirements.txt (line 5)) (12.6.0)
Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /home/coder/.local/lib/python3.9/site-packages (from rich<13.0.0,>=10.11.0->typer[all]<0.8,>=0.4.1->rstcheck<7.0.0,>=3.0.0->antsibull-docs<2.0.0,>=1.0.0->-r requirements.txt (line 5)) (0.9.1)
building file list ... done
environment_variables.rst
index_lookup.rst
notmycloud/technitium_dns/index.rst
notmycloud/technitium_dns/login_lookup.rst

sent 80,601 bytes  received 87 bytes  161,376.00 bytes/sec
total size is 80,611  speedup is 1.00
Running Sphinx v6.1.3
loading pickled environment... done
loading intersphinx inventory from ../python2.inv...
encountered some issues with some of the inventories, but they had working alternatives:
intersphinx inventory '../python2.inv' not fetchable due to <class 'FileNotFoundError'>: [Errno 2] No such file or directory: '/ansible/docs/rst/../python2.inv'
loading intersphinx inventory from ../python3.inv...
encountered some issues with some of the inventories, but they had working alternatives:
intersphinx inventory '../python3.inv' not fetchable due to <class 'FileNotFoundError'>: [Errno 2] No such file or directory: '/ansible/docs/rst/../python3.inv'
loading intersphinx inventory from ../jinja2.inv...
loading intersphinx inventory from ../ansible_devel.inv...
encountered some issues with some of the inventories, but they had working alternatives:
encountered some issues with some of the inventories, but they had working alternatives:
intersphinx inventory '../jinja2.inv' not fetchable due to <class 'FileNotFoundError'>: [Errno 2] No such file or directory: '/ansible/docs/rst/../jinja2.inv'
intersphinx inventory '../ansible_devel.inv' not fetchable due to <class 'FileNotFoundError'>: [Errno 2] No such file or directory: '/ansible/docs/rst/../ansible_devel.inv'
building [mo]: targets for 0 po files that are out of date
writing output... 
building [html]: targets for 4 source files that are out of date
updating environment: 0 added, 4 changed, 0 removed
reading sources... [100%] collections/notmycloud/technitium_dns/login_lookup                                                                                                                                             
looking for now-outdated files... none found
pickling environment... done
checking consistency... done
preparing documents... done
writing output... [100%] index                                                                                                                                                                                           
/ansible/docs/rst/collections/notmycloud/technitium_dns/login_lookup.rst:436: WARNING: undefined label: 'ansible_collections.notmycloud.technitium_dns.login_module'
generating indices... done
writing additional pages... search done
copying static files... done
copying extra files... done
dumping search index in English (code: en)... done
dumping object inventory... done
build finished with problems, 1 warning.
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-01-13T21:31:38Z,5,Create a YAML Ansible playbook to exhibit the following issue: Docsite: See Also --> Lookup Module,"```
---
- name: Lookup Module Issue
  hosts: all
  tasks:
    - name: Display interface IP Address
      debug:
        var: ansible_eth0['ipv4']['address']
        
    - name: Display hostname
      debug:
        var: inventory_hostname
        
    - name: Lookup command
      debug:
        var: lookup('command', 'echo ""Hello World!""')
      
    - name: Fail task
      fail:
        msg: ""Failure message""
      
    - name: Display Ansible facts
      debug:
        var: ansible_facts
```",1,"
---
- name: Lookup Module Issue
  hosts: all
  tasks:
    - name: Display interface IP Address
      debug:
        var: ansible_eth0['ipv4']['address']
        
    - name: Display hostname
      debug:
        var: inventory_hostname
        
    - name: Lookup command
      debug:
        var: lookup('command', 'echo ""Hello World!""')
      
    - name: Fail task
      fail:
        msg: ""Failure message""
      
    - name: Display Ansible facts
      debug:
        var: ansible_facts
"
86,79733,Incorrect distribution detection when multiple release files are present,"### Summary

When there are multiple release files in /etc directory, the OS distribution is not properly detected.
For example if a server is running Debian and someone creates a file /etc/oracle-release, then the distribution is detected as Oracle Linux

### Issue Type

Bug Report

### Component Name

ansible-core

### Ansible Version

```console
ansible [core 2.14.1]
  config file = None
  configured module search path = ['/root/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /usr/lib/python3/dist-packages/ansible
  ansible collection location = /root/.ansible/collections:/usr/share/ansible/collections
  executable location = /usr/bin/ansible
  python version = 3.10.9 (main, Dec  7 2022, 13:47:07) [GCC 12.2.0] (/usr/bin/python3)
  jinja version = 3.0.3
  libyaml = True
```


### Configuration

```console
ACTION_WARNINGS(default) = True
AGNOSTIC_BECOME_PROMPT(default) = True
ANSIBLE_CONNECTION_PATH(default) = None
ANSIBLE_COW_ACCEPTLIST(default) = ['bud-frogs', 'bunny', 'cheese', 'daemon', 'default', 'dragon', 'elephant-in-snake', 'elephant', 'eyes', 'hellokitty', 'kitty', 'luke-koala', 'meow', 'milk', 'moofasa', 'moose'>
ANSIBLE_COW_PATH(default) = None
ANSIBLE_COW_SELECTION(default) = default
ANSIBLE_FORCE_COLOR(default) = False
ANSIBLE_HOME(default) = /root/.ansible
ANSIBLE_NOCOLOR(default) = False
ANSIBLE_NOCOWS(default) = False
ANSIBLE_PIPELINING(default) = False
ANY_ERRORS_FATAL(default) = False
BECOME_ALLOW_SAME_USER(default) = False
BECOME_PASSWORD_FILE(default) = None
BECOME_PLUGIN_PATH(default) = ['/root/.ansible/plugins/become', '/usr/share/ansible/plugins/become']
CACHE_PLUGIN(default) = memory
CACHE_PLUGIN_CONNECTION(default) = None
CACHE_PLUGIN_PREFIX(default) = ansible_facts
CACHE_PLUGIN_TIMEOUT(default) = 86400
CALLBACKS_ENABLED(default) = []
COLLECTIONS_ON_ANSIBLE_VERSION_MISMATCH(default) = warning
COLLECTIONS_PATHS(default) = ['/root/.ansible/collections', '/usr/share/ansible/collections']
COLLECTIONS_SCAN_SYS_PATH(default) = True
COLOR_CHANGED(default) = yellow
COLOR_CONSOLE_PROMPT(default) = white
COLOR_DEBUG(default) = dark gray
COLOR_DEPRECATE(default) = purple
COLOR_DIFF_ADD(default) = green
COLOR_DIFF_LINES(default) = cyan
COLOR_DIFF_REMOVE(default) = red
COLOR_ERROR(default) = red
COLOR_HIGHLIGHT(default) = white
COLOR_OK(default) = green
COLOR_SKIP(default) = cyan
COLOR_UNREACHABLE(default) = bright red
COLOR_VERBOSE(default) = blue
COLOR_WARN(default) = bright purple
CONFIG_FILE() = None
CONNECTION_FACTS_MODULES(default) = {'asa': 'ansible.legacy.asa_facts', 'cisco.asa.asa': 'cisco.asa.asa_facts', 'eos': 'ansible.legacy.eos_facts', 'arista.eos.eos': 'arista.eos.eos_facts', 'frr': 'ansible.legac>
CONNECTION_PASSWORD_FILE(default) = None
COVERAGE_REMOTE_OUTPUT(default) = None
COVERAGE_REMOTE_PATHS(default) = *
DEFAULT_ACTION_PLUGIN_PATH(default) = ['/root/.ansible/plugins/action', '/usr/share/ansible/plugins/action']
DEFAULT_ALLOW_UNSAFE_LOOKUPS(default) = False
DEFAULT_ASK_PASS(default) = False
DEFAULT_ASK_VAULT_PASS(default) = False
DEFAULT_BECOME(default) = False
DEFAULT_BECOME_ASK_PASS(default) = False
```


### OS / Environment


RHEL 8
RHEL 7
RHEL 6
Debian bookworm/sid
Ubuntu 20.04

### Steps to Reproduce

On a Debian system, create a file named /etc/oracle-release 
and run the setup module
```
ansible -m setup localhost | grep distribution
```


### Expected Results

I expect to se something like ""undetermined"" if the module detects more than one of the /etc/*release files

### Actual Results

```console
In a Debian base system it is detected as Oracle Linux or any other distro.

[WARNING]: No inventory was parsed, only implicit localhost is available
        ""ansible_distribution"": ""OracleLinux"",
        ""ansible_distribution_file_parsed"": true,
        ""ansible_distribution_file_path"": ""/etc/oracle-release"",
        ""ansible_distribution_file_search_string"": ""Oracle Linux"",
        ""ansible_distribution_file_variety"": ""OracleLinux"",
        ""ansible_distribution_major_version"": ""7"",
        ""ansible_distribution_release"": ""bookworm"",
        ""ansible_distribution_version"": ""7.3"",
```
Also if I create a file named /etc/altlinux-release
then it will be detected as Altlinux
```
WARNING]: No inventory was parsed, only implicit localhost is available
        ""ansible_distribution"": ""aa"",
        ""ansible_distribution_file_parsed"": true,
        ""ansible_distribution_file_path"": ""/etc/altlinux-release"",
        ""ansible_distribution_file_variety"": ""Altlinux"",
        ""ansible_distribution_major_version"": ""20"",
        ""ansible_distribution_release"": ""focal"",
        ""ansible_distribution_version"": ""20.04"",
```

Looks like the distribution is detected by looping over a list of files (/etc/*-release) and the first file detected is used. 
/usr/lib/python3/dist-packages/ansible/module_utils/facts/system/distribution.py
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-01-13T16:06:38Z,2,Create a YAML Ansible playbook to exhibit the following issue: Incorrect distribution detection when multiple release files are present,"```
---
- name: Example playbook
  hosts: all
  tasks:
    - name: Show distribution variables
      debug:
        var: ansible_distribution
    - name: Show release variables
      debug:
        var: ansible_distribution_release
    - name: Show release file paths
      debug:
        var: ansible_distribution_file_variety
```
Note: This playbook will demonstrate the issue of incorrect distribution detection when multiple release files are present by showing the distribution variables, release variables, and release file paths.",1,"
---
- name: Example playbook
  hosts: all
  tasks:
    - name: Show distribution variables
      debug:
        var: ansible_distribution
    - name: Show release variables
      debug:
        var: ansible_distribution_release
    - name: Show release file paths
      debug:
        var: ansible_distribution_file_variety
"
87,79731,ansible galaxy install fails with a bug ,"### Summary

here is my `setup.sh` script that I am trying to run

```
#!/usr/bin/env bash

pip3 install --upgrade pip
python3 -m pip install --user pipx
python3 -m pipx ensurepath
pipx install virtualenv
pipx install awscli
python3 -m venv venv
. venv/bin/activate
pip install -r requirements.txt
ansible-galaxy install -r ansible/ansible_requirements.yml

if [ ! -d ""${HOME}/.aws"" ]
then
    echo ""${HOME}/.aws does not exist""
    echo ""you need to make sure you awscli is correctly configured... invoking configure""
    aws configure
fi

```
and my `requirements.txt`

```
ansible
awscli
boto3
botocore
Jinja2
PyYAML
```

it fails on this command `ansible-galaxy install -r ansible/ansible_requirements.yml`

and my `ansible_requirements.txt`

```
collections:
  - name: kubernetes.core
```

Below is the error. any idea?

```
ERROR! Unexpected Exception, this is probably a bug: cannot import name '_ADDITIONAL_CHECKS' from 'ansible.module_utils.common.parameters' (/home/kant/infrastructure/venv/lib/python3.10/site-packages/ansible/module_utils/common/parameters.py)
```



### Issue Type

Bug Report

### Component Name

pip

### Ansible Version

```console
$ ansible --version

ansible [core 2.13.5]
  config file = None
  configured module search path = ['/home/kant/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /home/kant/.local/lib/python3.10/site-packages/ansible
  ansible collection location = /home/kant/.ansible/collections:/usr/share/ansible/collections
  executable location = /home/kant/.local/bin/ansible
  python version = 3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]
  jinja version = 3.1.2
  libyaml = True
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
none
```


### OS / Environment

ubuntu 22.04

### Steps to Reproduce

just run `setup.sh` as stated above


### Expected Results

I expected it to be installed successfully

### Actual Results

```console
ERROR! Unexpected Exception, this is probably a bug: cannot import name '_ADDITIONAL_CHECKS' from 'ansible.module_utils.common.parameters' (/home/kant/infrastructure/venv/lib/python3.10/site-packages/ansible/module_utils/common/parameters.py)
```
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-01-13T11:45:14Z,5,Create a YAML Ansible playbook to exhibit the following issue: ansible galaxy install fails with a bug ,"```
---
- name: Demonstrate Ansible Galaxy Install Bug
  hosts: localhost
  gather_facts: false

  tasks:
    - name: Install Ansible Galaxy Role
      community.general.galaxy_collection:
        name: community.general
        state: present

    - name: Install Specific Galaxy Role
      community.general.collection:
        name: ansible.posix
        version: ""1.2.3""
        state: present
  ```
Note: This playbook is for demonstration purposes only and assumes that you have the necessary permissions to install ansible-galaxy roles. You can replace the example name and version of ansible.posix with the ones that are relevant to your use case.",1,"
---
- name: Demonstrate Ansible Galaxy Install Bug
  hosts: localhost
  gather_facts: false

  tasks:
    - name: Install Ansible Galaxy Role
      community.general.galaxy_collection:
        name: community.general
        state: present

    - name: Install Specific Galaxy Role
      community.general.collection:
        name: ansible.posix
        version: ""1.2.3""
        state: present
  "
88,79723,"Add filename to error message ""A vault password must be specified to decrypt data""","### Summary

`ansible-lint` stops working with the error message ""A vault password must be specified to decrypt data"". It is difficult to understand which of the vault files is causing the problem.

So I ask you to extend the error messages in

https://github.com/ansible/ansible/blob/61d5586c7cf3b5f821bbe748aaff9d421da13cd8/lib/ansible/parsing/vault/__init__.py#L604

and

https://github.com/ansible/ansible/blob/61d5586c7cf3b5f821bbe748aaff9d421da13cd8/lib/ansible/parsing/vault/__init__.py#L661

with the filename like in:

https://github.com/ansible/ansible/blob/61d5586c7cf3b5f821bbe748aaff9d421da13cd8/lib/ansible/parsing/vault/__init__.py#L665-L667

Example: Current behaviour
```
# ansible-lint roles/myrole/tasks/vars/config_vault.yml
A vault password must be specified to decrypt data
```

Suggested result:
```
# ansible-lint roles/myrole/tasks/vars/config_vault.yml
A vault password must be specified to decrypt data in roles/myrole/tasks/vars/config_vault.yml
```


### Issue Type

Bug Report

### Component Name

vault

### Ansible Version

```console
$ ansible --version
ansible [core 2.13.7]
  config file = None
  configured module search path = ['/home/carsten/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /home/carsten/virtualenv/lib64/python3.10/site-packages/ansible
  ansible collection location = /home/carsten/.ansible/collections:/usr/share/ansible/collections
  executable location = /home/carsten/virtualenv/bin/ansible
  python version = 3.10.8 (main, Oct 28 2022, 17:28:32) [GCC]
  jinja version = 3.1.2
  libyaml = True
```


### Configuration

```console
n/a
```


### OS / Environment

SUSE Linux Enterprise Server 15 SP4

### Steps to Reproduce

see summary

### Expected Results

see summary

### Actual Results

```console
see summary
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-01-12T07:44:56Z,4,"Create a YAML Ansible playbook to exhibit the following issue: Add filename to error message ""A vault password must be specified to decrypt data""","```
---
- hosts: localhost
  gather_facts: no
  tasks:
  - name: Test error message
    command: ansible-vault view testfile --vault-password-file=missing_file
    ignore_errors: yes
  - name: Print error message with filename
    debug:
      var: ansible_failed_result | json_query('msg') + "" {{ ansible_failed_result | json_query('invocation.module_args._uses_shell') | ternary(ansible_failed_result.cmd, ansible_failed_result.module)}}, "" + ansible_failed_result | json_query('invocation.module_args._raw_params')
    when: ansible_failed_result is defined and ""A vault password must be specified to decrypt data"" in ansible_failed_result.msg
...
```",1,"
---
- hosts: localhost
  gather_facts: no
  tasks:
  - name: Test error message
    command: ansible-vault view testfile --vault-password-file=missing_file
    ignore_errors: yes
  - name: Print error message with filename
    debug:
      var: ansible_failed_result | json_query('msg') + "" {{ ansible_failed_result | json_query('invocation.module_args._uses_shell') | ternary(ansible_failed_result.cmd, ansible_failed_result.module)}}, "" + ansible_failed_result | json_query('invocation.module_args._raw_params')
    when: ansible_failed_result is defined and ""A vault password must be specified to decrypt data"" in ansible_failed_result.msg
...
"
89,79717,"ansible.builtin.get_url module throws sslv3 alert handshake failure, ansible.builtin.uri module does not","### Summary

The webpage uses old ciphers so I am using the ciphers parameter with the correct cipher.
I testet the following on the target system:
```
Python 3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import ssl
>>> from urllib.request import urlopen
>>> context = ssl.create_default_context()
>>> urlopen('https://nexus.hectorts.de/repository/files/apt-keys/public.gpg', context=context).read()
```
Throws: urllib.error.URLError: <urlopen error [SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:997)>

```
>>> import ssl
>>> from urllib.request import urlopen
>>> context = ssl.create_default_context()
>>>context.set_ciphers('AES128-SHA')
>>> urlopen('https://nexus.hectorts.de/repository/files/apt-keys/public.gpg', context=context).read()
```

this works. So i used ciphers: 'AES256-SHA' in the ansible.builtin.get_url module and it throws the SSLV3 handshake error

```
    - name: services - Add apt key for hector repo
      ansible.builtin.get_url:
        url: https://nexus.hectorts.de/repository/files/apt-keys/public.gpg
        ciphers: 'AES256-SHA'
        dest: /etc/apt/trusted.gpg.d/hector.asc
```

```
    - name: services - Add apt key for hector repo
      ansible.builtin.uri:
        url: https://nexus.hectorts.de/repository/files/apt-keys/public.gpg
        ciphers: 'AES256-SHA'
```

The same request in the uri module works fine.
I also noticed that if i misspell the cipher in uri it throws an error in get_url it does not.

### Issue Type

Bug Report

### Component Name

ansible.builtin.get_url module

### Ansible Version

```console
ansible [core 2.14.1]
  config file = /etc/ansible/ansible.cfg
  configured module search path = ['/home/hector/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /home/hector/.local/lib/python3.10/site-packages/ansible
  ansible collection location = /home/hector/.ansible/collections:/usr/share/ansible/collections
  executable location = /home/hector/.local/bin/ansible
  python version = 3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0] (/usr/bin/python3)
  jinja version = 3.0.3
  libyaml = True
```


### Configuration

```console
CONFIG_FILE() = /etc/ansible/ansible.cfg
DEFAULT_FORKS(/etc/ansible/ansible.cfg) = 10
DEFAULT_HOST_LIST(/etc/ansible/ansible.cfg) = ['/etc/ansible/inv']
HOST_KEY_CHECKING(/etc/ansible/ansible.cfg) = False

CONNECTION:
==========

paramiko_ssh:
____________
host_key_checking(/etc/ansible/ansible.cfg) = False

ssh:
___
host_key_checking(/etc/ansible/ansible.cfg) = False
```


### OS / Environment

Target:
Distributor ID: Ubuntu
Description:    Ubuntu 22.04.1 LTS
Release:        22.04
Codename:       jammy

Controller:
Distributor ID: Ubuntu
Description:    Ubuntu 22.04.1 LTS
Release:        22.04
Codename:       jammy


### Steps to Reproduce

Does not work:
```
    - name: services - Add apt key for hector repo
      ansible.builtin.get_url:
        url: https://nexus.hectorts.de/repository/files/apt-keys/public.gpg
        ciphers: 'AES256-SHA'
        dest: /etc/apt/trusted.gpg.d/hector.asc
```

Works:
```
    - name: services - Add apt key for hector repo
      ansible.builtin.uri:
        url: https://nexus.hectorts.de/repository/files/apt-keys/public.gpg
        ciphers: 'AES256-SHA'
```

### Expected Results

That I get the file to the dest location.

### Actual Results

```console
<172.18.19.216> ESTABLISH SSH CONNECTION FOR USER: services-user
<172.18.19.216> SSH: EXEC sshpass -d10 ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o StrictHostKeyChecking=no -o Port=59111 -o 'User=""services-user""' -o ConnectTimeout=10 -o 'ControlPath=""/home/hector/.ansible/cp/d19d83f373""' 172.18.19.216 '/bin/sh -c '""'""'echo ~services-user && sleep 0'""'""''
<172.18.19.216> (0, b'/home/services-user\n', b'OpenSSH_8.9p1 Ubuntu-3ubuntu0.1, OpenSSL 3.0.2 15 Mar 2022\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 19: include /etc/ssh/ssh_config.d/*.conf matched no files\r\ndebug1: /etc/ssh/ssh_config line 21: Applying options for *\r\ndebug2: resolve_canonicalize: hostname 172.18.19.216 is address\r\ndebug3: expanded UserKnownHostsFile \'~/.ssh/known_hosts\' -> \'/home/hector/.ssh/known_hosts\'\r\ndebug3: expanded UserKnownHostsFile \'~/.ssh/known_hosts2\' -> \'/home/hector/.ssh/known_hosts2\'\r\ndebug1: auto-mux: Trying existing master\r\ndebug1: Control socket ""/home/hector/.ansible/cp/d19d83f373"" does not exist\r\ndebug3: ssh_connect_direct: entering\r\ndebug1: Connecting to 172.18.19.216 [172.18.19.216] port 59111.\r\ndebug3: set_sock_tos: set socket 3 IP_TOS 0x10\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug1: fd 3 clearing O_NONBLOCK\r\ndebug1: Connection established.\r\ndebug3: timeout: 10000 ms remain after connect\r\ndebug1: identity file /home/hector/.ssh/id_rsa type -1\r\ndebug1: identity file /home/hector/.ssh/id_rsa-cert type -1\r\ndebug1: identity file /home/hector/.ssh/id_ecdsa type -1\r\ndebug1: identity file /home/hector/.ssh/id_ecdsa-cert type -1\r\ndebug1: identity file /home/hector/.ssh/id_ecdsa_sk type -1\r\ndebug1: identity file /home/hector/.ssh/id_ecdsa_sk-cert type -1\r\ndebug1: identity file /home/hector/.ssh/id_ed25519 type 3\r\ndebug1: identity file /home/hector/.ssh/id_ed25519-cert type -1\r\ndebug1: identity file /home/hector/.ssh/id_ed25519_sk type -1\r\ndebug1: identity file /home/hector/.ssh/id_ed25519_sk-cert type -1\r\ndebug1: identity file /home/hector/.ssh/id_xmss type -1\r\ndebug1: identity file /home/hector/.ssh/id_xmss-cert type -1\r\ndebug1: identity file /home/hector/.ssh/id_dsa type -1\r\ndebug1: identity file /home/hector/.ssh/id_dsa-cert type -1\r\ndebug1: Local version string SSH-2.0-OpenSSH_8.9p1 Ubuntu-3ubuntu0.1\r\ndebug1: Remote protocol version 2.0, remote software version OpenSSH_8.9p1 Ubuntu-3ubuntu0.1\r\ndebug1: compat_banner: match: OpenSSH_8.9p1 Ubuntu-3ubuntu0.1 pat OpenSSH* compat 0x04000000\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug1: Authenticating to 172.18.19.216:59111 as \'services-user\'\r\ndebug3: put_host_port: [172.18.19.216]:59111\r\ndebug3: record_hostkey: found key type ECDSA in file /home/hector/.ssh/known_hosts:8\r\ndebug3: load_hostkeys_file: loaded 1 keys from [172.18.19.216]:59111\r\ndebug1: load_hostkeys: fopen /home/hector/.ssh/known_hosts2: No such file or directory\r\ndebug1: load_hostkeys: fopen /etc/ssh/ssh_known_hosts: No such file or directory\r\ndebug1: load_hostkeys: fopen /etc/ssh/ssh_known_hosts2: No such file or directory\r\ndebug3: order_hostkeyalgs: prefer hostkeyalgs: ecdsa-sha2-nistp256-cert-v01@openssh.com,ecdsa-sha2-nistp256\r\ndebug3: send packet: type 20\r\ndebug1: SSH2_MSG_KEXINIT sent\r\ndebug3: receive packet: type 20\r\ndebug1: SSH2_MSG_KEXINIT received\r\ndebug2: local client KEXINIT proposal\r\ndebug2: KEX algorithms: curve25519-sha256,curve25519-sha256@libssh.org,ecdh-sha2-nistp256,ecdh-sha2-nistp384,ecdh-sha2-nistp521,sntrup761x25519-sha512@openssh.com,diffie-hellman-group-exchange-sha256,diffie-hellman-group16-sha512,diffie-hellman-group18-sha512,diffie-hellman-group14-sha256,ext-info-c\r\ndebug2: host key algorithms: ecdsa-sha2-nistp256-cert-v01@openssh.com,ecdsa-sha2-nistp256,ssh-ed25519-cert-v01@openssh.com,ecdsa-sha2-nistp384-cert-v01@openssh.com,ecdsa-sha2-nistp521-cert-v01@openssh.com,sk-ssh-ed25519-cert-v01@openssh.com,sk-ecdsa-sha2-nistp256-cert-v01@openssh.com,rsa-sha2-512-cert-v01@openssh.com,rsa-sha2-256-cert-v01@openssh.com,ssh-ed25519,ecdsa-sha2-nistp384,ecdsa-sha2-nistp521,sk-ssh-ed25519@openssh.com,sk-ecdsa-sha2-nistp256@openssh.com,rsa-sha2-512,rsa-sha2-256\r\ndebug2: ciphers ctos: chacha20-poly1305@openssh.com,aes128-ctr,aes192-ctr,aes256-ctr,aes128-gcm@openssh.com,aes256-gcm@openssh.com\r\ndebug2: ciphers stoc: chacha20-poly1305@openssh.com,aes128-ctr,aes192-ctr,aes256-ctr,aes128-gcm@openssh.com,aes256-gcm@openssh.com\r\ndebug2: MACs ctos: umac-64-etm@openssh.com,umac-128-etm@openssh.com,hmac-sha2-256-etm@openssh.com,hmac-sha2-512-etm@openssh.com,hmac-sha1-etm@openssh.com,umac-64@openssh.com,umac-128@openssh.com,hmac-sha2-256,hmac-sha2-512,hmac-sha1\r\ndebug2: MACs stoc: umac-64-etm@openssh.com,umac-128-etm@openssh.com,hmac-sha2-256-etm@openssh.com,hmac-sha2-512-etm@openssh.com,hmac-sha1-etm@openssh.com,umac-64@openssh.com,umac-128@openssh.com,hmac-sha2-256,hmac-sha2-512,hmac-sha1\r\ndebug2: compression ctos: zlib@openssh.com,zlib,none\r\ndebug2: compression stoc: zlib@openssh.com,zlib,none\r\ndebug2: languages ctos: \r\ndebug2: languages stoc: \r\ndebug2: first_kex_follows 0 \r\ndebug2: reserved 0 \r\ndebug2: peer server KEXINIT proposal\r\ndebug2: KEX algorithms: curve25519-sha256,curve25519-sha256@libssh.org,ecdh-sha2-nistp256,ecdh-sha2-nistp384,ecdh-sha2-nistp521,sntrup761x25519-sha512@openssh.com,diffie-hellman-group-exchange-sha256,diffie-hellman-group16-sha512,diffie-hellman-group18-sha512,diffie-hellman-group14-sha256\r\ndebug2: host key algorithms: rsa-sha2-512,rsa-sha2-256,ecdsa-sha2-nistp256,ssh-ed25519\r\ndebug2: ciphers ctos: chacha20-poly1305@openssh.com,aes128-ctr,aes192-ctr,aes256-ctr,aes128-gcm@openssh.com,aes256-gcm@openssh.com\r\ndebug2: ciphers stoc: chacha20-poly1305@openssh.com,aes128-ctr,aes192-ctr,aes256-ctr,aes128-gcm@openssh.com,aes256-gcm@openssh.com\r\ndebug2: MACs ctos: umac-64-etm@openssh.com,umac-128-etm@openssh.com,hmac-sha2-256-etm@openssh.com,hmac-sha2-512-etm@openssh.com,hmac-sha1-etm@openssh.com,umac-64@openssh.com,umac-128@openssh.com,hmac-sha2-256,hmac-sha2-512,hmac-sha1\r\ndebug2: MACs stoc: umac-64-etm@openssh.com,umac-128-etm@openssh.com,hmac-sha2-256-etm@openssh.com,hmac-sha2-512-etm@openssh.com,hmac-sha1-etm@openssh.com,umac-64@openssh.com,umac-128@openssh.com,hmac-sha2-256,hmac-sha2-512,hmac-sha1\r\ndebug2: compression ctos: none,zlib@openssh.com\r\ndebug2: compression stoc: none,zlib@openssh.com\r\ndebug2: languages ctos: \r\ndebug2: languages stoc: \r\ndebug2: first_kex_follows 0 \r\ndebug2: reserved 0 \r\ndebug1: kex: algorithm: curve25519-sha256\r\ndebug1: kex: host key algorithm: ecdsa-sha2-nistp256\r\ndebug1: kex: server->client cipher: chacha20-poly1305@openssh.com MAC: <implicit> compression: zlib@openssh.com\r\ndebug1: kex: client->server cipher: chacha20-poly1305@openssh.com MAC: <implicit> compression: zlib@openssh.com\r\ndebug3: send packet: type 30\r\ndebug1: expecting SSH2_MSG_KEX_ECDH_REPLY\r\ndebug3: receive packet: type 31\r\ndebug1: SSH2_MSG_KEX_ECDH_REPLY received\r\ndebug1: Server host key: ecdsa-sha2-nistp256 SHA256:vi8mcfyqgLcEAESF3l0vYwWMljOgZLeoTKr/HSDU1qk\r\ndebug3: put_host_port: [172.18.19.216]:59111\r\ndebug3: put_host_port: [172.18.19.216]:59111\r\ndebug3: record_hostkey: found key type ECDSA in file /home/hector/.ssh/known_hosts:8\r\ndebug3: load_hostkeys_file: loaded 1 keys from [172.18.19.216]:59111\r\ndebug1: load_hostkeys: fopen /home/hector/.ssh/known_hosts2: No such file or directory\r\ndebug1: load_hostkeys: fopen /etc/ssh/ssh_known_hosts: No such file or directory\r\ndebug1: load_hostkeys: fopen /etc/ssh/ssh_known_hosts2: No such file or directory\r\ndebug1: Host \'[172.18.19.216]:59111\' is known and matches the ECDSA host key.\r\ndebug1: Found key in /home/hector/.ssh/known_hosts:8\r\ndebug3: send packet: type 21\r\ndebug2: ssh_set_newkeys: mode 1\r\ndebug1: rekey out after 134217728 blocks\r\ndebug1: SSH2_MSG_NEWKEYS sent\r\ndebug1: expecting SSH2_MSG_NEWKEYS\r\ndebug3: receive packet: type 21\r\ndebug1: SSH2_MSG_NEWKEYS received\r\ndebug2: ssh_set_newkeys: mode 0\r\ndebug1: rekey in after 134217728 blocks\r\ndebug1: Will attempt key: /home/hector/.ssh/id_rsa \r\ndebug1: Will attempt key: /home/hector/.ssh/id_ecdsa \r\ndebug1: Will attempt key: /home/hector/.ssh/id_ecdsa_sk \r\ndebug1: Will attempt key: /home/hector/.ssh/id_ed25519 ED25519 SHA256:jHEtmhrA7POvLnRIFRW11IEctpbZrxSSXcy/rBqTdoU\r\ndebug1: Will attempt key: /home/hector/.ssh/id_ed25519_sk \r\ndebug1: Will attempt key: /home/hector/.ssh/id_xmss \r\ndebug1: Will attempt key: /home/hector/.ssh/id_dsa \r\ndebug2: pubkey_prepare: done\r\ndebug3: send packet: type 5\r\ndebug3: receive packet: type 7\r\ndebug1: SSH2_MSG_EXT_INFO received\r\ndebug1: kex_input_ext_info: server-sig-algs=<ssh-ed25519,sk-ssh-ed25519@openssh.com,ssh-rsa,rsa-sha2-256,rsa-sha2-512,ssh-dss,ecdsa-sha2-nistp256,ecdsa-sha2-nistp384,ecdsa-sha2-nistp521,sk-ecdsa-sha2-nistp256@openssh.com,webauthn-sk-ecdsa-sha2-nistp256@openssh.com>\r\ndebug1: kex_input_ext_info: publickey-hostbound@openssh.com=<0>\r\ndebug3: receive packet: type 6\r\ndebug2: service_accept: ssh-userauth\r\ndebug1: SSH2_MSG_SERVICE_ACCEPT received\r\ndebug3: send packet: type 50\r\ndebug3: receive packet: type 51\r\ndebug1: Authentications that can continue: publickey,password\r\ndebug3: start over, passed a different list publickey,password\r\ndebug3: preferred gssapi-with-mic,publickey,keyboard-interactive,password\r\ndebug3: authmethod_lookup publickey\r\ndebug3: remaining preferred: keyboard-interactive,password\r\ndebug3: authmethod_is_enabled publickey\r\ndebug1: Next authentication method: publickey\r\ndebug1: Trying private key: /home/hector/.ssh/id_rsa\r\ndebug3: no such identity: /home/hector/.ssh/id_rsa: No such file or directory\r\ndebug1: Trying private key: /home/hector/.ssh/id_ecdsa\r\ndebug3: no such identity: /home/hector/.ssh/id_ecdsa: No such file or directory\r\ndebug1: Trying private key: /home/hector/.ssh/id_ecdsa_sk\r\ndebug3: no such identity: /home/hector/.ssh/id_ecdsa_sk: No such file or directory\r\ndebug1: Offering public key: /home/hector/.ssh/id_ed25519 ED25519 SHA256:jHEtmhrA7POvLnRIFRW11IEctpbZrxSSXcy/rBqTdoU\r\ndebug3: send packet: type 50\r\ndebug2: we sent a publickey packet, wait for reply\r\ndebug3: receive packet: type 51\r\ndebug1: Authentications that can continue: publickey,password\r\ndebug1: Trying private key: /home/hector/.ssh/id_ed25519_sk\r\ndebug3: no such identity: /home/hector/.ssh/id_ed25519_sk: No such file or directory\r\ndebug1: Trying private key: /home/hector/.ssh/id_xmss\r\ndebug3: no such identity: /home/hector/.ssh/id_xmss: No such file or directory\r\ndebug1: Trying private key: /home/hector/.ssh/id_dsa\r\ndebug3: no such identity: /home/hector/.ssh/id_dsa: No such file or directory\r\ndebug2: we did not send a packet, disable method\r\ndebug3: authmethod_lookup password\r\ndebug3: remaining preferred: ,password\r\ndebug3: authmethod_is_enabled password\r\ndebug1: Next authentication method: password\r\ndebug3: send packet: type 50\r\ndebug2: we sent a password packet, wait for reply\r\ndebug3: receive packet: type 52\r\ndebug1: Enabling compression at level 6.\r\nAuthenticated to 172.18.19.216 ([172.18.19.216]:59111) using ""password"".\r\ndebug1: setting up multiplex master socket\r\ndebug3: muxserver_listen: temporary control path /home/hector/.ansible/cp/d19d83f373.TNT61PM0pQZjxc3j\r\ndebug2: fd 4 setting O_NONBLOCK\r\ndebug3: fd 4 is O_NONBLOCK\r\ndebug3: fd 4 is O_NONBLOCK\r\ndebug1: channel 0: new [/home/hector/.ansible/cp/d19d83f373]\r\ndebug3: muxserver_listen: mux listener channel 0 fd 4\r\ndebug2: fd 3 setting TCP_NODELAY\r\ndebug3: set_sock_tos: set socket 3 IP_TOS 0x08\r\ndebug1: control_persist_detach: backgrounding master process\r\ndebug2: control_persist_detach: background process is 2551\r\ndebug2: fd 4 setting O_NONBLOCK\r\ndebug1: forking to background\r\ndebug1: Entering interactive session.\r\ndebug1: pledge: id\r\ndebug2: set_control_persist_exit_time: schedule exit in 60 seconds\r\ndebug1: multiplexing control connection\r\ndebug2: fd 5 setting O_NONBLOCK\r\ndebug3: fd 5 is O_NONBLOCK\r\ndebug1: channel 1: new [mux-control]\r\ndebug3: channel_post_mux_listener: new mux channel 1 fd 5\r\ndebug3: mux_master_read_cb: channel 1: hello sent\r\ndebug2: set_control_persist_exit_time: cancel scheduled exit\r\ndebug3: mux_master_read_cb: channel 1 packet type 0x00000001 len 4\r\ndebug2: mux_master_process_hello: channel 1 client version 4\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_master_read_cb: channel 1 packet type 0x10000004 len 4\r\ndebug2: mux_master_process_alive_check: channel 1: alive check\r\ndebug3: mux_client_request_alive: done pid = 2553\r\ndebug3: mux_client_request_session: session request sent\r\ndebug3: mux_master_read_cb: channel 1 packet type 0x10000002 len 104\r\ndebug2: mux_master_process_new_session: channel 1: request tty 0, X 0, agent 0, subsys 0, term ""xterm"", cmd ""/bin/sh -c \'echo ~services-user && sleep 0\'"", env 1\r\ndebug3: mux_master_process_new_session: got fds stdin 6, stdout 7, stderr 8\r\ndebug1: channel 2: new [client-session]\r\ndebug2: mux_master_process_new_session: channel_new: 2 linked to control channel 1\r\ndebug2: channel 2: send open\r\ndebug3: send packet: type 90\r\ndebug3: receive packet: type 80\r\ndebug1: client_input_global_request: rtype hostkeys-00@openssh.com want_reply 0\r\ndebug3: client_input_hostkeys: received RSA key SHA256:H2G+jm88GVmH8l6p0EaMDEe7uuLQ8g6PBB9+FqV3BbU\r\ndebug3: client_input_hostkeys: received ECDSA key SHA256:vi8mcfyqgLcEAESF3l0vYwWMljOgZLeoTKr/HSDU1qk\r\ndebug3: client_input_hostkeys: received ED25519 key SHA256:wB37JBN+60e2v9sG1MA2Zh+7kl7iAVoV+SGvmruFyv4\r\ndebug3: put_host_port: [172.18.19.216]:59111\r\ndebug1: client_input_hostkeys: searching /home/hector/.ssh/known_hosts for [172.18.19.216]:59111 / (none)\r\ndebug3: hostkeys_foreach: reading file ""/home/hector/.ssh/known_hosts""\r\ndebug3: hostkeys_find: found ecdsa-sha2-nistp256 key under different name/addr at /home/hector/.ssh/known_hosts:3\r\ndebug3: hostkeys_find: found ecdsa-sha2-nistp256 key under different name/addr at /home/hector/.ssh/known_hosts:5\r\ndebug3: hostkeys_find: found ecdsa-sha2-nistp256 key at /home/hector/.ssh/known_hosts:8\r\ndebug1: client_input_hostkeys: searching /home/hector/.ssh/known_hosts2 for [172.18.19.216]:59111 / (none)\r\ndebug1: client_input_hostkeys: hostkeys file /home/hector/.ssh/known_hosts2 does not exist\r\ndebug3: client_input_hostkeys: 3 server keys: 2 new, 18446744073709551615 retained, 2 incomplete match. 0 to remove\r\ndebug1: client_input_hostkeys: host key found matching a different name/address, skipping UserKnownHostsFile update\r\ndebug3: receive packet: type 91\r\ndebug2: channel_input_open_confirmation: channel 2: callback start\r\ndebug2: client_session2_setup: id 2\r\ndebug1: Sending environment.\r\ndebug1: channel 2: setting env LANG = ""en_US.UTF-8""\r\ndebug2: channel 2: request env confirm 0\r\ndebug3: send packet: type 98\r\ndebug1: Sending command: /bin/sh -c \'echo ~services-user && sleep 0\'\r\ndebug2: channel 2: request exec confirm 1\r\ndebug3: send packet: type 98\r\ndebug3: mux_session_confirm: sending success reply\r\ndebug2: channel_input_open_confirmation: channel 2: callback done\r\ndebug2: channel 2: open confirm rwindow 0 rmax 32768\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug2: channel 2: rcvd adjust 2097152\r\ndebug3: receive packet: type 99\r\ndebug2: channel_input_status_confirm: type 99 id 2\r\ndebug2: exec request accepted on channel 2\r\ndebug3: receive packet: type 96\r\ndebug2: channel 2: rcvd eof\r\ndebug2: channel 2: output open -> drain\r\ndebug2: channel 2: obuf empty\r\ndebug2: chan_shutdown_write: channel 2: (i0 o1 sock -1 wfd 7 efd 8 [write])\r\ndebug2: channel 2: output drain -> closed\r\ndebug3: receive packet: type 98\r\ndebug1: client_input_channel_req: channel 2 rtype exit-status reply 0\r\ndebug3: mux_exit_message: channel 2: exit message, exitval 0\r\ndebug3: receive packet: type 98\r\ndebug1: client_input_channel_req: channel 2 rtype eow@openssh.com reply 0\r\ndebug2: channel 2: rcvd eow\r\ndebug2: chan_shutdown_read: channel 2: (i0 o3 sock -1 wfd 6 efd 8 [write])\r\ndebug2: channel 2: input open -> closed\r\ndebug3: receive packet: type 97\r\ndebug2: channel 2: rcvd close\r\ndebug3: channel 2: will not send data after close\r\ndebug2: channel 2: send close\r\ndebug3: send packet: type 97\r\ndebug2: channel 2: is dead\r\ndebug2: channel 2: gc: notify user\r\ndebug3: mux_master_session_cleanup_cb: entering for channel 2\r\ndebug2: channel 1: rcvd close\r\ndebug2: channel 1: output open -> drain\r\ndebug2: chan_shutdown_read: channel 1: (i0 o1 sock 5 wfd 5 efd -1 [closed])\r\ndebug2: channel 1: input open -> closed\r\ndebug2: channel 2: gc: user detached\r\ndebug2: channel 2: is dead\r\ndebug2: channel 2: garbage collecting\r\ndebug1: channel 2: free: client-session, nchannels 3\r\ndebug3: channel 2: status: The following connections are open:\r\n  #1 mux-control (t16 nr0 i3/0 o1/16 e[closed]/0 fd 5/5/-1 sock 5 cc -1 io 0x03/0x00)\r\n  #2 client-session (t4 r0 i3/0 o3/0 e[write]/0 fd -1/-1/8 sock -1 cc -1 io 0x00/0x00)\r\n\r\ndebug2: channel 1: obuf empty\r\ndebug2: chan_shutdown_write: channel 1: (i3 o1 sock 5 wfd 5 efd -1 [closed])\r\ndebug2: channel 1: output drain -> closed\r\ndebug2: channel 1: is dead (local)\r\ndebug2: channel 1: gc: notify user\r\ndebug3: mux_master_control_cleanup_cb: entering for channel 1\r\ndebug2: channel 1: gc: user detached\r\ndebug2: channel 1: is dead (local)\r\ndebug2: channel 1: garbage collecting\r\ndebug1: channel 1: free: mux-control, nchannels 2\r\ndebug3: channel 1: status: The following connections are open:\r\n  #1 mux-control (t16 nr0 i3/0 o3/0 e[closed]/0 fd 5/5/-1 sock 5 cc -1 io 0x00/0x03)\r\n\r\ndebug2: set_control_persist_exit_time: schedule exit in 60 seconds\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n')
<172.18.19.216> ESTABLISH SSH CONNECTION FOR USER: services-user
<172.18.19.216> SSH: EXEC sshpass -d10 ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o StrictHostKeyChecking=no -o Port=59111 -o 'User=""services-user""' -o ConnectTimeout=10 -o 'ControlPath=""/home/hector/.ansible/cp/d19d83f373""' 172.18.19.216 '/bin/sh -c '""'""'( umask 77 && mkdir -p ""` echo /home/services-user/.ansible/tmp `""&& mkdir ""` echo /home/services-user/.ansible/tmp/ansible-tmp-1673443145.7380567-2546-29556654641786 `"" && echo ansible-tmp-1673443145.7380567-2546-29556654641786=""` echo /home/services-user/.ansible/tmp/ansible-tmp-1673443145.7380567-2546-29556654641786 `"" ) && sleep 0'""'""''
<172.18.19.216> (0, b'ansible-tmp-1673443145.7380567-2546-29556654641786=/home/services-user/.ansible/tmp/ansible-tmp-1673443145.7380567-2546-29556654641786\n', b""OpenSSH_8.9p1 Ubuntu-3ubuntu0.1, OpenSSL 3.0.2 15 Mar 2022\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 19: include /etc/ssh/ssh_config.d/*.conf matched no files\r\ndebug1: /etc/ssh/ssh_config line 21: Applying options for *\r\ndebug2: resolve_canonicalize: hostname 172.18.19.216 is address\r\ndebug3: expanded UserKnownHostsFile '~/.ssh/known_hosts' -> '/home/hector/.ssh/known_hosts'\r\ndebug3: expanded UserKnownHostsFile '~/.ssh/known_hosts2' -> '/home/hector/.ssh/known_hosts2'\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 2553\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n"")
Using module file /home/hector/.local/lib/python3.10/site-packages/ansible/modules/get_url.py
<172.18.19.216> PUT /home/hector/.ansible/tmp/ansible-local-25422dnzuu7l/tmp3von1wo7 TO /home/services-user/.ansible/tmp/ansible-tmp-1673443145.7380567-2546-29556654641786/AnsiballZ_get_url.py
<172.18.19.216> SSH: EXEC sshpass -d10 sftp -o BatchMode=no -b - -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o StrictHostKeyChecking=no -o Port=59111 -o 'User=""services-user""' -o ConnectTimeout=10 -o 'ControlPath=""/home/hector/.ansible/cp/d19d83f373""' '[172.18.19.216]'
<172.18.19.216> (0, b'sftp> put /home/hector/.ansible/tmp/ansible-local-25422dnzuu7l/tmp3von1wo7 /home/services-user/.ansible/tmp/ansible-tmp-1673443145.7380567-2546-29556654641786/AnsiballZ_get_url.py\n', b'OpenSSH_8.9p1 Ubuntu-3ubuntu0.1, OpenSSL 3.0.2 15 Mar 2022\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 19: include /etc/ssh/ssh_config.d/*.conf matched no files\r\ndebug1: /etc/ssh/ssh_config line 21: Applying options for *\r\ndebug2: resolve_canonicalize: hostname 172.18.19.216 is address\r\ndebug3: expanded UserKnownHostsFile \'~/.ssh/known_hosts\' -> \'/home/hector/.ssh/known_hosts\'\r\ndebug3: expanded UserKnownHostsFile \'~/.ssh/known_hosts2\' -> \'/home/hector/.ssh/known_hosts2\'\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 2553\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug2: Remote version: 3\r\ndebug2: Server supports extension ""posix-rename@openssh.com"" revision 1\r\ndebug2: Server supports extension ""statvfs@openssh.com"" revision 2\r\ndebug2: Server supports extension ""fstatvfs@openssh.com"" revision 2\r\ndebug2: Server supports extension ""hardlink@openssh.com"" revision 1\r\ndebug2: Server supports extension ""fsync@openssh.com"" revision 1\r\ndebug2: Server supports extension ""lsetstat@openssh.com"" revision 1\r\ndebug2: Server supports extension ""limits@openssh.com"" revision 1\r\ndebug2: Server supports extension ""expand-path@openssh.com"" revision 1\r\ndebug3: Sent message limits@openssh.com I:1\r\ndebug3: Received limits reply T:201 I:1\r\ndebug1: Using server download size 261120\r\ndebug1: Using server upload size 261120\r\ndebug1: Server handle limit 1019; using 64\r\ndebug2: Sending SSH2_FXP_REALPATH "".""\r\ndebug3: Sent message fd 3 T:16 I:2\r\ndebug3: SSH2_FXP_REALPATH . -> /home/services-user\r\ndebug3: Looking up /home/hector/.ansible/tmp/ansible-local-25422dnzuu7l/tmp3von1wo7\r\ndebug2: Sending SSH2_FXP_STAT ""/home/services-user/.ansible/tmp/ansible-tmp-1673443145.7380567-2546-29556654641786/AnsiballZ_get_url.py""\r\ndebug3: Sent message fd 3 T:17 I:3\r\ndebug1: stat remote: No such file or directory\r\ndebug2: do_upload: upload local ""/home/hector/.ansible/tmp/ansible-local-25422dnzuu7l/tmp3von1wo7"" to remote ""/home/services-user/.ansible/tmp/ansible-tmp-1673443145.7380567-2546-29556654641786/AnsiballZ_get_url.py""\r\ndebug2: Sending SSH2_FXP_OPEN ""/home/services-user/.ansible/tmp/ansible-tmp-1673443145.7380567-2546-29556654641786/AnsiballZ_get_url.py""\r\ndebug3: Sent dest message SSH2_FXP_OPEN I:4 P:/home/services-user/.ansible/tmp/ansible-tmp-1673443145.7380567-2546-29556654641786/AnsiballZ_get_url.py M:0x001a\r\ndebug3: Sent message SSH2_FXP_WRITE I:6 O:0 S:168500\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 6 168500 bytes at 0\r\ndebug3: Sent message SSH2_FXP_CLOSE I:5\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n')
<172.18.19.216> ESTABLISH SSH CONNECTION FOR USER: services-user
<172.18.19.216> SSH: EXEC sshpass -d10 ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o StrictHostKeyChecking=no -o Port=59111 -o 'User=""services-user""' -o ConnectTimeout=10 -o 'ControlPath=""/home/hector/.ansible/cp/d19d83f373""' 172.18.19.216 '/bin/sh -c '""'""'chmod u+x /home/services-user/.ansible/tmp/ansible-tmp-1673443145.7380567-2546-29556654641786/ /home/services-user/.ansible/tmp/ansible-tmp-1673443145.7380567-2546-29556654641786/AnsiballZ_get_url.py && sleep 0'""'""''
<172.18.19.216> (0, b'', b""OpenSSH_8.9p1 Ubuntu-3ubuntu0.1, OpenSSL 3.0.2 15 Mar 2022\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 19: include /etc/ssh/ssh_config.d/*.conf matched no files\r\ndebug1: /etc/ssh/ssh_config line 21: Applying options for *\r\ndebug2: resolve_canonicalize: hostname 172.18.19.216 is address\r\ndebug3: expanded UserKnownHostsFile '~/.ssh/known_hosts' -> '/home/hector/.ssh/known_hosts'\r\ndebug3: expanded UserKnownHostsFile '~/.ssh/known_hosts2' -> '/home/hector/.ssh/known_hosts2'\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 2553\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n"")
<172.18.19.216> ESTABLISH SSH CONNECTION FOR USER: services-user
<172.18.19.216> SSH: EXEC sshpass -d10 ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o StrictHostKeyChecking=no -o Port=59111 -o 'User=""services-user""' -o ConnectTimeout=10 -o 'ControlPath=""/home/hector/.ansible/cp/d19d83f373""' -tt 172.18.19.216 '/bin/sh -c '""'""'/usr/bin/python3 /home/services-user/.ansible/tmp/ansible-tmp-1673443145.7380567-2546-29556654641786/AnsiballZ_get_url.py && sleep 0'""'""''
<172.18.19.216> (1, b'\r\n{""url"": ""https://nexus.hectorts.de/repository/files/apt-keys/public.gpg"", ""dest"": ""/etc/apt/trusted.gpg.d/hector.asc"", ""elapsed"": 0, ""failed"": true, ""msg"": ""Request failed: <urlopen error [SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:997)>"", ""invocation"": {""module_args"": {""url"": ""https://nexus.hectorts.de/repository/files/apt-keys/public.gpg"", ""ciphers"": [""AES256-SHA""], ""dest"": ""/etc/apt/trusted.gpg.d/hector.asc"", ""force"": false, ""http_agent"": ""ansible-httpget"", ""use_proxy"": true, ""validate_certs"": true, ""force_basic_auth"": false, ""use_gssapi"": false, ""backup"": false, ""checksum"": """", ""timeout"": 10, ""unredirected_headers"": [], ""decompress"": true, ""use_netrc"": true, ""unsafe_writes"": false, ""url_username"": null, ""url_password"": null, ""client_cert"": null, ""client_key"": null, ""headers"": null, ""tmp_dest"": null, ""mode"": null, ""owner"": null, ""group"": null, ""seuser"": null, ""serole"": null, ""selevel"": null, ""setype"": null, ""attributes"": null}}}\r\n', b""OpenSSH_8.9p1 Ubuntu-3ubuntu0.1, OpenSSL 3.0.2 15 Mar 2022\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 19: include /etc/ssh/ssh_config.d/*.conf matched no files\r\ndebug1: /etc/ssh/ssh_config line 21: Applying options for *\r\ndebug2: resolve_canonicalize: hostname 172.18.19.216 is address\r\ndebug3: expanded UserKnownHostsFile '~/.ssh/known_hosts' -> '/home/hector/.ssh/known_hosts'\r\ndebug3: expanded UserKnownHostsFile '~/.ssh/known_hosts2' -> '/home/hector/.ssh/known_hosts2'\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 2553\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 1\r\nShared connection to 172.18.19.216 closed.\r\n"")
<172.18.19.216> Failed to connect to the host via ssh: OpenSSH_8.9p1 Ubuntu-3ubuntu0.1, OpenSSL 3.0.2 15 Mar 2022
debug1: Reading configuration data /etc/ssh/ssh_config
debug1: /etc/ssh/ssh_config line 19: include /etc/ssh/ssh_config.d/*.conf matched no files
debug1: /etc/ssh/ssh_config line 21: Applying options for *
debug2: resolve_canonicalize: hostname 172.18.19.216 is address
debug3: expanded UserKnownHostsFile '~/.ssh/known_hosts' -> '/home/hector/.ssh/known_hosts'
debug3: expanded UserKnownHostsFile '~/.ssh/known_hosts2' -> '/home/hector/.ssh/known_hosts2'
debug1: auto-mux: Trying existing master
debug2: fd 3 setting O_NONBLOCK
debug2: mux_client_hello_exchange: master version 4
debug3: mux_client_forwards: request forwardings: 0 local, 0 remote
debug3: mux_client_request_session: entering
debug3: mux_client_request_alive: entering
debug3: mux_client_request_alive: done pid = 2553
debug3: mux_client_request_session: session request sent
debug1: mux_client_request_session: master session id: 2
debug3: mux_client_read_packet: read header failed: Broken pipe
debug2: Received exit status from master 1
Shared connection to 172.18.19.216 closed.
<172.18.19.216> ESTABLISH SSH CONNECTION FOR USER: services-user
<172.18.19.216> SSH: EXEC sshpass -d10 ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o StrictHostKeyChecking=no -o Port=59111 -o 'User=""services-user""' -o ConnectTimeout=10 -o 'ControlPath=""/home/hector/.ansible/cp/d19d83f373""' 172.18.19.216 '/bin/sh -c '""'""'rm -f -r /home/services-user/.ansible/tmp/ansible-tmp-1673443145.7380567-2546-29556654641786/ > /dev/null 2>&1 && sleep 0'""'""''
<172.18.19.216> (0, b'', b""OpenSSH_8.9p1 Ubuntu-3ubuntu0.1, OpenSSL 3.0.2 15 Mar 2022\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 19: include /etc/ssh/ssh_config.d/*.conf matched no files\r\ndebug1: /etc/ssh/ssh_config line 21: Applying options for *\r\ndebug2: resolve_canonicalize: hostname 172.18.19.216 is address\r\ndebug3: expanded UserKnownHostsFile '~/.ssh/known_hosts' -> '/home/hector/.ssh/known_hosts'\r\ndebug3: expanded UserKnownHostsFile '~/.ssh/known_hosts2' -> '/home/hector/.ssh/known_hosts2'\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 2553\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n"")
fatal: [SVCDAILY]: FAILED! => {
    ""changed"": false,
    ""dest"": ""/etc/apt/trusted.gpg.d/hector.asc"",
    ""elapsed"": 0,
    ""invocation"": {
        ""module_args"": {
            ""attributes"": null,
            ""backup"": false,
            ""checksum"": """",
            ""ciphers"": [
                ""AES256-SHA""
            ],
            ""client_cert"": null,
            ""client_key"": null,
            ""decompress"": true,
            ""dest"": ""/etc/apt/trusted.gpg.d/hector.asc"",
            ""force"": false,
            ""force_basic_auth"": false,
            ""group"": null,
            ""headers"": null,
            ""http_agent"": ""ansible-httpget"",
            ""mode"": null,
            ""owner"": null,
            ""selevel"": null,
            ""serole"": null,
            ""setype"": null,
            ""seuser"": null,
            ""timeout"": 10,
            ""tmp_dest"": null,
            ""unredirected_headers"": [],
            ""unsafe_writes"": false,
            ""url"": ""https://nexus.hectorts.de/repository/files/apt-keys/public.gpg"",
            ""url_password"": null,
            ""url_username"": null,
            ""use_gssapi"": false,
            ""use_netrc"": true,
            ""use_proxy"": true,
            ""validate_certs"": true
        }
    },
    ""msg"": ""Request failed: <urlopen error [SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:997)>"",
    ""url"": ""https://nexus.hectorts.de/repository/files/apt-keys/public.gpg""
}
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-01-11T13:20:33Z,1,"Create a YAML Ansible playbook to exhibit the following issue: ansible.builtin.get_url module throws sslv3 alert handshake failure, ansible.builtin.uri module does not","```
---
- name: Exhibit get_url SSL issue
  hosts: localhost
  gather_facts: false

  tasks:
    - name: Download a file using get_url
      ansible.builtin.get_url:
        url: https://www.example.com/file.tar.gz
        dest: /tmp/file.tar.gz
```
```python
---
- name: Exhibit successful download using uri
  hosts: localhost
  gather_facts: false

  tasks:
    - name: Download a file using uri
      ansible.builtin.uri:
        url: https://www.example.com/file.tar.gz
        dest: /tmp/file.tar.gz
```
Note: The first playbook would exhibit the issue mentioned in the prompt where there would be an SSL Handshake failure while running the `get_url` module, whereas the second playbook is a way to download the same file using the `uri` module which should not throw any errors.",1,"
---
- name: Exhibit get_url SSL issue
  hosts: localhost
  gather_facts: false

  tasks:
    - name: Download a file using get_url
      ansible.builtin.get_url:
        url: https://www.example.com/file.tar.gz
        dest: /tmp/file.tar.gz
"
90,79711,PLAY RECAP Incorrectly Considers Failures as Rescues in Block Rescue,"### Summary

I did not find this bug reported when I tried searching for it previously, so I am reporting it here.

Problem:
When using a block: rescue: in Ansible 7.1.0 (Core 2.14.1), any failures in the rescue: are considered another rescue in the ""PLAY RECAP"" ""rescued="" counter, causing ""failed="" to not be incremented correctly. Luckily the host still fails internally and will not continue performing tasks however to the user its as if not nothing failed at all considering the PLAY_RECAP shows ""failed="" as not being incremented.

Expectation:
When using the block: rescue:, the ""rescue="" and ""failed="" PLAY RECAP values should be incremented in such a way that ""rescue=1"" and ""failed=1"" as it acts in Ansible 6.5.0 (Core 2.13.7) and not ""rescue=2"", ""failed=0"" as it currently does in Ansible 7.1.0 (Core 2.14.1)


During my small amount of testing I found the issue to be the is_any_block_rescuing() function in executor/play_iterator.py. Since its change from 2.13.7 to 2.14.1, it now checks whether its currently in a rescue block based on the condition ""if state.get_current_block().rescue:"" instead of checking its state. When changing it back to the original first condition check in 2.13.7 ""if state.run_state == IteratingStates.RESCUE:"", I was able to replicate the original results that were expected and received in 2.13.7.

For awareness I do not certify this as the guaranteed fix as my testing was minimal.


### Issue Type

Bug Report

### Component Name

executor/play_iterator.py

### Ansible Version

```console
$ ansible --version
ansible [core 2.14.1]
  config file = None
  configured module search path = ['/home/<USERNAME>/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /home/<USERNAME>/.local/lib/python3.10/site-packages/ansible
  ansible collection location = /home/<USERNAME>/.ansible/collections:/usr/share/ansible/collections
  executable location = /home/<USERNAME>/.local/bin/ansible
  python version = 3.10.7 (main, Oct  1 2022, 04:31:04) [GCC 12.2.0] (/usr/bin/python3)
  jinja version = 3.1.2
  libyaml = True
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
CONFIG_FILE() = None
```


### OS / Environment

Ubuntu 22.04
And Tested on
WSL Kali GNU/Linux 2022.1

### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->
```yaml (paste below)
- hosts: localhost
  tasks:
    - block:
        - debug:
            msg: ""{{ asdasd }}""
      rescue:
        - debug:
            msg: ""{{ ansible_failed_task }}""
        - debug:
            msg: ""{{ pppp }}""
# OR 
- hosts: localhost
  tasks:
    - block:
        - debug:
            msg: ""{{ asdasd }}""
      rescue:
        - debug:
            msg: ""{{ ansible_failed_task }}""
        - fail:
            msg: ""rescued""
```


### Expected Results

In Ansible 6.5.0 (Core 2.13.7), ""failed=1"" and ""rescued=1"" for the steps to reproduce, while in ansible 7.1.0 (Core 2.14.1) it shows ""rescued=2"" and ""failed=0"".

### Actual Results

```console
ansible-playbook [core 2.14.1]
  config file = /home/<USERNAME>/projects/ansible/ansible.cfg
  configured module search path = ['/home/<USERNAME>/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /home/<USERNAME>/.local/lib/python3.10/site-packages/ansible
  ansible collection location = /home/<USERNAME>/.ansible/collections:/usr/share/ansible/collections
  executable location = /home/<USERNAME>/.local/bin/ansible-playbook
  python version = 3.10.7 (main, Oct  1 2022, 04:31:04) [GCC 12.2.0] (/usr/bin/python3)
  jinja version = 3.1.2
  libyaml = True
Using /home/<USERNAME>/projects/ansible/ansible.cfg as config file
setting up inventory plugins
host_list declined parsing /home/<USERNAME>/projects/ansible/hosts as it did not pass its verify_file() method
script declined parsing /home/<USERNAME>/projects/ansible/hosts as it did not pass its verify_file() method
auto declined parsing /home/<USERNAME>/projects/ansible/hosts as it did not pass its verify_file() method
Parsed /home/<USERNAME>/projects/ansible/hosts inventory source with yaml plugin
Loading callback plugin default of type stdout, v2.0 from /home/<USERNAME>/.local/lib/python3.10/site-packages/ansible/plugins/callback/default.py
Skipping callback 'default', as we already have a stdout callback.
Skipping callback 'minimal', as we already have a stdout callback.
Skipping callback 'oneline', as we already have a stdout callback.

PLAYBOOK: testing.yml **********************************************************
Positional arguments: testing.yml
verbosity: 4
connection: smart
timeout: 10
become_method: sudo
tags: ('all',)
inventory: ('/home/<USERNAME>/projects/ansible/hosts',)
forks: 5
2 plays in testing.yml

PLAY [localhost] ***************************************************************

TASK [Gathering Facts] *********************************************************
task path: /home/<USERNAME>/projects/ansible/testing.yml:1
<127.0.0.1> ESTABLISH LOCAL CONNECTION FOR USER: <USERNAME>
<127.0.0.1> EXEC /bin/sh -c 'echo ~<USERNAME> && sleep 0'
<127.0.0.1> EXEC /bin/sh -c '( umask 77 && mkdir -p ""` echo /home/<USERNAME>/.ansible/tmp `""&& mkdir ""` echo /home/<USERNAME>/.ansible/tmp/ansible-tmp-1673393142.3067427-3561-14584735740540 `"" && echo ansible-tmp-1673393142.3067427-3561-14584735740540=""` echo /home/<USERNAME>/.ansible/tmp/ansible-tmp-1673393142.3067427-3561-14584735740540 `"" ) && sleep 0'
Using module file /home/<USERNAME>/.local/lib/python3.10/site-packages/ansible/modules/setup.py
<127.0.0.1> PUT /home/<USERNAME>/.ansible/tmp/ansible-local-3556vcjpazw1/tmp5pmc_5id TO /home/<USERNAME>/.ansible/tmp/ansible-tmp-1673393142.3067427-3561-14584735740540/AnsiballZ_setup.py
<127.0.0.1> EXEC /bin/sh -c 'chmod u+x /home/<USERNAME>/.ansible/tmp/ansible-tmp-1673393142.3067427-3561-14584735740540/ /home/<USERNAME>/.ansible/tmp/ansible-tmp-1673393142.3067427-3561-14584735740540/AnsiballZ_setup.py && sleep 0'
<127.0.0.1> EXEC /bin/sh -c '/usr/bin/python3 /home/<USERNAME>/.ansible/tmp/ansible-tmp-1673393142.3067427-3561-14584735740540/AnsiballZ_setup.py && sleep 0'
<127.0.0.1> EXEC /bin/sh -c 'rm -f -r /home/<USERNAME>/.ansible/tmp/ansible-tmp-1673393142.3067427-3561-14584735740540/ > /dev/null 2>&1 && sleep 0'
ok: [localhost]

TASK [debug] *******************************************************************
task path: /home/<USERNAME>/projects/ansible/testing.yml:4
fatal: [localhost]: FAILED! => {
    ""msg"": ""The task includes an option with an undefined variable. The error was: 'asdasd' is undefined. 'asdasd' is undefined\n\nThe error appears to be in '/home/<USERNAME>/projects/ansible/testing.yml': line 4, column 11, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n    - block:\n        - debug:\n          ^ here\n""
}

TASK [debug] *******************************************************************
task path: /home/<USERNAME>/projects/ansible/testing.yml:7
ok: [localhost] => {
    ""msg"": {
        ""action"": ""debug"",
        ""any_errors_fatal"": false,
        ""args"": {
            ""msg"": ""{{ asdasd }}""
        },
        ""async"": 0,
        ""async_val"": 0,
        ""become"": false,
        ""become_exe"": null,
        ""become_flags"": null,
        ""become_method"": ""sudo"",
        ""become_user"": null,
        ""changed_when"": [],
        ""check_mode"": false,
        ""collections"": [],
        ""connection"": ""ssh"",
        ""debugger"": null,
        ""delay"": 5,
        ""delegate_facts"": null,
        ""delegate_to"": null,
        ""diff"": false,
        ""environment"": [
            {}
        ],
        ""failed_when"": [],
        ""finalized"": true,
        ""ignore_errors"": null,
        ""ignore_unreachable"": null,
        ""loop"": null,
        ""loop_control"": {
            ""extended"": null,
            ""extended_allitems"": true,
            ""finalized"": false,
            ""index_var"": null,
            ""label"": null,
            ""loop_var"": ""item"",
            ""pause"": 0,
            ""squashed"": false,
            ""uuid"": ""00155d9c-3005-7d48-6a63-00000000001d""
        },
        ""loop_with"": null,
        ""module_defaults"": [],
        ""name"": """",
        ""no_log"": null,
        ""notify"": null,
        ""poll"": 15,
        ""port"": null,
        ""register"": null,
        ""remote_user"": null,
        ""retries"": 3,
        ""run_once"": null,
        ""squashed"": true,
        ""tags"": [],
        ""throttle"": 0,
        ""timeout"": 0,
        ""until"": [],
        ""uuid"": ""00155d9c-3005-7d48-6a63-000000000004"",
        ""vars"": {},
        ""when"": []
    }
}

TASK [debug] *******************************************************************
task path: /home/<USERNAME>/projects/ansible/testing.yml:9
fatal: [localhost]: FAILED! => {
    ""msg"": ""The task includes an option with an undefined variable. The error was: 'pppp' is undefined. 'pppp' is undefined\n\nThe error appears to be in '/home/<USERNAME>/projects/ansible/testing.yml': line 9, column 11, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n            msg: \""{{ ansible_failed_task }}\""\n        - debug:\n          ^ here\n""
}

PLAY RECAP *********************************************************************
localhost                  : ok=2    changed=0    unreachable=0    failed=0    skipped=0    rescued=2    ignored=0
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-01-10T23:36:34Z,1,Create a YAML Ansible playbook to exhibit the following issue: PLAY RECAP Incorrectly Considers Failures as Rescues in Block Rescue,"```
---
- name: Show issue with PLAY RECAP
  hosts: localhost
  gather_facts: false

  tasks:

    - block:

        - name: Command that will fail
          command: /bin/false

      rescue:

        - name: Failed command rescue task
          debug:
            msg: ""This should only appear in the rescue section""

  handlers:
    - name: Restart the service
      service:
        name: myservice
        state: restarted
  ```
",1,"
---
- name: Show issue with PLAY RECAP
  hosts: localhost
  gather_facts: false

  tasks:

    - block:

        - name: Command that will fail
          command: /bin/false

      rescue:

        - name: Failed command rescue task
          debug:
            msg: ""This should only appear in the rescue section""

  handlers:
    - name: Restart the service
      service:
        name: myservice
        state: restarted
  "
91,79702,Ansible is stucking at `Gathering Facts`,"### Summary

Ansible gets stuck at `Gathering Facts`. The special thing about the host is that it is only accessible via IPv6.

Inventory:
```
[nodes]
reseau.mk16.de ansible_host=marek@2a01:cb05:8fdb:2555:1469:3dff:fee3:97e9
```

### Issue Type

Bug Report

### Component Name

ansible

### Ansible Version

```console
$ ansible --version
$ansible --version
ansible [core 2.14.1]
  config file = None
  configured module search path = ['/home/marek/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /home/marek/.local/lib/python3.9/site-packages/ansible
  ansible collection location = /home/marek/.ansible/collections:/usr/share/ansible/collections
  executable location = /home/marek/.local/bin/ansible
  python version = 3.9.2 (default, Feb 28 2021, 17:03:44) [GCC 10.2.1 20210110] (/usr/bin/python3)
  jinja version = 3.0.3
  libyaml = True
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
CONFIG_FILE() = /home/marek/Downloads/ansible-crxn-router/ansible.cfg
DEFAULT_HOST_LIST(/home/marek/Downloads/ansible-crxn-router/ansible.cfg) = ['/home/marek/Downloads/ansible-crxn-router/inventory.ini']
DEFAULT_VAULT_PASSWORD_FILE(/home/marek/Downloads/ansible-crxn-router/ansible.cfg) = /home/marek/Downloads/password
```


### OS / Environment

Debian-based OS
Parrot OS 5.1 (Electro Ara) x86_64

### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->
```yaml (paste below)

```


### Expected Results

No timeout like when I do it manuelly:
```
$ssh -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o ConnectTimeout=10 marek@2a01:cb05:8fdb:2555:1469:3dff:fee3:97e9 '/bin/sh -c '""'""'echo ~ && sleep 0'""'""''
/home/marek
```

### Actual Results

```console
ansible-playbook reseau.mk16.de.yml -vvv
ansible-playbook [core 2.14.1]
  config file = /home/marek/Downloads/ansible-crxn-router/ansible.cfg
  configured module search path = ['/home/marek/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /home/marek/.local/lib/python3.9/site-packages/ansible
  ansible collection location = /home/marek/.ansible/collections:/usr/share/ansible/collections
  executable location = /home/marek/.local/bin/ansible-playbook
  python version = 3.9.2 (default, Feb 28 2021, 17:03:44) [GCC 10.2.1 20210110] (/usr/bin/python3)
  jinja version = 3.0.3
  libyaml = True
Using /home/marek/Downloads/ansible-crxn-router/ansible.cfg as config file
host_list declined parsing /home/marek/Downloads/ansible-crxn-router/inventory.ini as it did not pass its verify_file() method
script declined parsing /home/marek/Downloads/ansible-crxn-router/inventory.ini as it did not pass its verify_file() method
auto declined parsing /home/marek/Downloads/ansible-crxn-router/inventory.ini as it did not pass its verify_file() method
yaml declined parsing /home/marek/Downloads/ansible-crxn-router/inventory.ini as it did not pass its verify_file() method
Parsed /home/marek/Downloads/ansible-crxn-router/inventory.ini inventory source with ini plugin
Skipping callback 'default', as we already have a stdout callback.
Skipping callback 'minimal', as we already have a stdout callback.
Skipping callback 'oneline', as we already have a stdout callback.

PLAYBOOK: reseau.mk16.de.yml *****************************************************************************************************************
1 plays in reseau.mk16.de.yml

PLAY [Setup reseau.mk16.de] ******************************************************************************************************************

TASK [Gathering Facts] ***********************************************************************************************************************
task path: /home/marek/Downloads/ansible-crxn-router/reseau.mk16.de.yml:2
<marek@2a01:cb05:8fdb:2555:1469:3dff:fee3:97e9> ESTABLISH SSH CONNECTION FOR USER: None
<marek@2a01:cb05:8fdb:2555:1469:3dff:fee3:97e9> SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o ConnectTimeout=10 -o 'ControlPath=""/home/marek/.ansible/cp/cc82229a6f""' marek@2a01:cb05:8fdb:2555:1469:3dff:fee3:97e9 '/bin/sh -c '""'""'echo ~ && sleep 0'""'""''
<marek@2a01:cb05:8fdb:2555:1469:3dff:fee3:97e9> (255, b'/home/marek\n', b'')
fatal: [reseau.mk16.de]: UNREACHABLE! => {
    ""changed"": false,
    ""msg"": ""Failed to connect to the host via ssh: "",
    ""unreachable"": true
}

PLAY RECAP ***********************************************************************************************************************************
reseau.mk16.de             : ok=0    changed=0    unreachable=1    failed=0    skipped=0    rescued=0    ignored=0
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-01-10T11:26:42Z,5,Create a YAML Ansible playbook to exhibit the following issue: Ansible is stucking at `Gathering Facts`,"```
---
- name: Gather Facts Hang
  hosts: server
  gather_facts: no
  tasks:
    - name: Hang task
      shell: sleep 30
```

Note: This playbook disables fact gathering using the `gather_facts` directive on the play level.",1,"
---
- name: Gather Facts Hang
  hosts: server
  gather_facts: no
  tasks:
    - name: Hang task
      shell: sleep 30
"
92,79697,Ansible Galaxy fails to install any collection (Ubuntu 22.10 fresh install) due to bad version of resolvelib,"### Summary

On a freshly installed Ubuntu 22.10 system with a freshly installed ansible from 'pip', ansible-galaxy fails to install any collection. A workaround is to manually downgrade resolvelib.

Issue was opened with ansible-galaxy digital-ocean team some time ago here: https://github.com/ansible-collections/community.digitalocean/issues/132

To repro:
- fresh install of Ubuntu 22.10
- fresh install of ansible-core
- try to install anything with ansible-galaxy and it crashes

Specific repro steps (from a clean system)
```
sudo apt update
sudo apt upgrade

sudo apt install -y python3 python-is-python3 pip
pip install ansible-core
ansible-galaxy collection install community.general
```

The above fails with: `TypeError: find_matches() got an unexpected keyword argument 'identifier'`
(full stack trace is in [ansible galaxy issue #132](https://github.com/ansible-collections/community.digitalocean/issues/132))

A work around is to manually downgrade the version of resolvelib, the below works:
```
sudo apt install -y pip
pip install ansible-core
pip install -Iv 'resolvelib<0.6.0'
ansible-galaxy collection install community.general
```

The [ansible-galaxy team suggested](https://github.com/ansible-collections/community.digitalocean/issues/132#issuecomment-934488635)  this could be fixed by updating: https://github.com/ansible/ansible/blob/devel/requirements.txt




### Issue Type

Bug Report

### Component Name

ansible-galaxy

### Ansible Version

```console
$ ansible --version
ansible [core 2.12.4]

$ ansible-galaxy --version
ansible-galaxy [core 2.12.4]

$ python3 --version
Python 3.10.7
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all

BECOME:
======

CACHE:
=====

CALLBACK:
========

CLICONF:
=======

CONNECTION:
==========

HTTPAPI:
=======

INVENTORY:
=========

LOOKUP:
======

NETCONF:
=======

SHELL:
=====

VARS:
====
```


### OS / Environment

Ubuntu 22.10

### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->

With a fresh install of OS Ubuntu 22.10 (any ansible-galaxy collection fails to install, the below is an example):

```bash
sudo apt install -y python3 python-is-python3 pip
pip install ansible-core
ansible-galaxy collection install community.general

```


### Expected Results

ansible-galaxy command should succeed

### Actual Results

```console
$ ansible-galaxy collection install community.general -vvvv
ansible-galaxy [core 2.12.4]
  config file = None
  configured module search path = ['/home/vanatta/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /usr/lib/python3/dist-packages/ansible
  ansible collection location = /home/vanatta/.ansible/collections:/usr/share/ansible/collections
  executable location = /usr/bin/ansible-galaxy
  python version = 3.10.7 (main, Nov 24 2022, 19:45:47) [GCC 12.2.0]
  jinja version = 3.0.3
  libyaml = True
No config file found; using defaults
Starting galaxy collection install process
Process install dependency map
ERROR! Unexpected Exception, this is probably a bug: CollectionDependencyProvider.find_matches() got an unexpected keyword argument 'identifier'
the full traceback was:

Traceback (most recent call last):
  File ""/usr/bin/ansible-galaxy"", line 128, in <module>
    exit_code = cli.run()
  File ""/usr/lib/python3/dist-packages/ansible/cli/galaxy.py"", line 569, in run
    return context.CLIARGS['func']()
  File ""/usr/lib/python3/dist-packages/ansible/cli/galaxy.py"", line 86, in method_wrapper
    return wrapped_method(*args, **kwargs)
  File ""/usr/lib/python3/dist-packages/ansible/cli/galaxy.py"", line 1203, in execute_install
    self._execute_install_collection(
  File ""/usr/lib/python3/dist-packages/ansible/cli/galaxy.py"", line 1230, in _execute_install_collection
    install_collections(
  File ""/usr/lib/python3/dist-packages/ansible/galaxy/collection/__init__.py"", line 548, in install_collections
    dependency_map = _resolve_depenency_map(
  File ""/usr/lib/python3/dist-packages/ansible/galaxy/collection/__init__.py"", line 1364, in _resolve_depenency_map
    return collection_dep_resolver.resolve(
  File ""/usr/lib/python3/dist-packages/resolvelib/resolvers.py"", line 481, in resolve
    state = resolution.resolve(requirements, max_rounds=max_rounds)
  File ""/usr/lib/python3/dist-packages/resolvelib/resolvers.py"", line 348, in resolve
    self._add_to_criteria(self.state.criteria, r, parent=None)
  File ""/usr/lib/python3/dist-packages/resolvelib/resolvers.py"", line 147, in _add_to_criteria
    matches = self._p.find_matches(
TypeError: CollectionDependencyProvider.find_matches() got an unexpected keyword argument 'identifier'
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-01-09T17:39:37Z,5,Create a YAML Ansible playbook to exhibit the following issue: Ansible Galaxy fails to install any collection (Ubuntu 22.10 fresh install) due to bad version of resolvelib,"```
---
- name: Ansible Galaxy Collection Installation Issue Demo
  hosts: localhost
  tasks:
    - name: Install Ansible and dependencies
      become: true
      apt:
        name: ""{{ item }}""
        state: present
      loop:
        - python3-pip
        - python3-setuptools
        - python3-dev
        - build-essential
    - name: Install problematic version of resolvelib
      pip:
        name: resolvelib==0.5.3
        state: present
        executable: pip3
    - name: Install an example collection
      shell: ansible-galaxy collection install community.general
```
Note: This playbook installs Ansible and dependencies using apt module, installs resolvelib version 0.5.3 using pip, and then attempts to install the community.general collection (which fails due to the bad version of resolvelib).",1,"
---
- name: Ansible Galaxy Collection Installation Issue Demo
  hosts: localhost
  tasks:
    - name: Install Ansible and dependencies
      become: true
      apt:
        name: ""{{ item }}""
        state: present
      loop:
        - python3-pip
        - python3-setuptools
        - python3-dev
        - build-essential
    - name: Install problematic version of resolvelib
      pip:
        name: resolvelib==0.5.3
        state: present
        executable: pip3
    - name: Install an example collection
      shell: ansible-galaxy collection install community.general
"
93,79691,ansible.netcommon.httpapi remote_user not set to logged in user by default,"### Summary

When using the ansible.netcommon.httpapi connection plugin for RESTCONF, authentication against the remote device fails by default. It's suspected, that the logged in Linux username is not used by default as stated in the `ansible.netcommon.httpapi` documentation



### Issue Type

Bug Report

### Component Name

ansible.netcommon.httpapi

### Ansible Version

```console
$ ansible --version
ansible [core 2.14.1]
  config file = /home/student01/module03-3/ansible/ansible.cfg
  configured module search path = ['/home/student01/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /home/student01/module03-3/venv/lib/python3.9/site-packages/ansible
  ansible collection location = /home/student01/.ansible/collections:/usr/share/ansible/collections
  executable location = /home/student01/module03-3/venv/bin/ansible
  python version = 3.9.2 (default, Feb 28 2021, 17:03:44) [GCC 10.2.1 20210110] (/home/student01/module03-3/venv/bin/python3)
  jinja version = 3.1.2
  libyaml = True
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
CONFIG_FILE() = /home/student01/module03-3/ansible/ansible.cfg
HOST_KEY_CHECKING(/home/student01/module03-3/ansible/ansible.cfg) = False

CONNECTION:
==========

paramiko_ssh:
____________
host_key_checking(/home/student01/module03-3/ansible/ansible.cfg) = False

ssh:
___
host_key_checking(/home/student01/module03-3/ansible/ansible.cfg) = False
```


### OS / Environment

Debian Linux 11
Cisco IOS-XE 17.9 (Catalyst 8000V)

### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->
Inventory
```ini
c8k_student01-1 ansible_host=10.21.128.202
```

Playbook:
```yaml
- name: ""RESTCONF test playbook""
  hosts: ""all""
  gather_facts: false

  tasks:
    - name: get list of resource modules for given network_os
      vars:
        ansible_connection: ansible.netcommon.httpapi
        ansible_network_os: ansible.netcommon.restconf
        ansible_httpapi_use_ssl: true
        ansible_httpapi_validate_certs: false
        ansible_httpapi_port: 443
        ansible_httpapi_restconf_root: /restconf/data/
      ansible.netcommon.restconf_get:
        path: /ietf-interfaces:interfaces
      register: ""test_var""
```

Run:
```bash
ansible-playbook -i inventory.ini play_restconf_test.yml -k
```

### Expected Results

It's expected, that when the playbook is started, the user is prompted for the password, because of the `-k` CLI parameter. Because no `remote_user` (variable `ansible_user`) is set explicitly, the logged in username should be used as stated in the documentation (https://docs.ansible.com/ansible/latest/collections/ansible/netcommon/httpapi_connection.html)

> `remote_user`: The username used to authenticate to the remote device when the API connection is first established. If the remote_user is not specified, the connection will use the username of the logged in user.

However, the task fails with a HTTP 401 error.

If setting the `ansible_user` variable or setting the user via the `--user` CLI variable, the task runs successfully.
Example working task vars (added the `ansible_user` variable:
```yaml
      vars:
        ansible_connection: ansible.netcommon.httpapi
        ansible_network_os: ansible.netcommon.restconf
        ansible_httpapi_use_ssl: true
        ansible_httpapi_validate_certs: false
        ansible_httpapi_port: 443
        ansible_httpapi_restconf_root: /restconf/data/
        ansible_user: ""{{ lookup('env', 'USER') }}""
```

### Actual Results

```console
$ ansible-playbook -i inventory.ini play_restconf_test.yml -k -vvvv
ansible-playbook [core 2.14.1]
  config file = /home/student01/module03-3/ansible/ansible.cfg
  configured module search path = ['/home/student01/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /home/student01/module03-3/venv/lib/python3.9/site-packages/ansible
  ansible collection location = /home/student01/.ansible/collections:/usr/share/ansible/collections
  executable location = /home/student01/module03-3/venv/bin/ansible-playbook
  python version = 3.9.2 (default, Feb 28 2021, 17:03:44) [GCC 10.2.1 20210110] (/home/student01/module03-3/venv/bin/python3)
  jinja version = 3.1.2
  libyaml = True
Using /home/student01/module03-3/ansible/ansible.cfg as config file
SSH password: 
setting up inventory plugins
host_list declined parsing /home/student01/module03-3/ansible/inventory.ini as it did not pass its verify_file() method
script declined parsing /home/student01/module03-3/ansible/inventory.ini as it did not pass its verify_file() method
auto declined parsing /home/student01/module03-3/ansible/inventory.ini as it did not pass its verify_file() method
yaml declined parsing /home/student01/module03-3/ansible/inventory.ini as it did not pass its verify_file() method
Parsed /home/student01/module03-3/ansible/inventory.ini inventory source with ini plugin
Loading collection ansible.netcommon from /home/student01/module03-3/venv/lib/python3.9/site-packages/ansible_collections/ansible/netcommon
Loading callback plugin default of type stdout, v2.0 from /home/student01/module03-3/venv/lib/python3.9/site-packages/ansible/plugins/callback/default.py
Skipping callback 'default', as we already have a stdout callback.
Skipping callback 'minimal', as we already have a stdout callback.
Skipping callback 'oneline', as we already have a stdout callback.

PLAYBOOK: play_restconf_test.yml ***************************************************************************************************************************************************************************************************************************************************
Positional arguments: play_restconf_test.yml
verbosity: 4
connection: smart
timeout: 10
ask_pass: True
become_method: sudo
tags: ('all',)
inventory: ('/home/student01/module03-3/ansible/inventory.ini',)
forks: 5
1 plays in play_restconf_test.yml

PLAY [RESTCONF test playbook] ******************************************************************************************************************************************************************************************************************************************************

TASK [get list of resource modules for given network_os] ***************************************************************************************************************************************************************************************************************************
task path: /home/student01/module03-3/ansible/play_restconf_test.yml:7
<10.21.128.202> attempting to start connection
<10.21.128.202> using connection plugin ansible.netcommon.httpapi
Found ansible-connection at path /home/student01/module03-3/venv/bin/ansible-connection
<10.21.128.202> local domain socket does not exist, starting it
<10.21.128.202> control socket path is /home/student01/.ansible/pc/1c3550ebe3
<10.21.128.202> Loading collection ansible.netcommon from /home/student01/module03-3/venv/lib/python3.9/site-packages/ansible_collections/ansible/netcommon
<10.21.128.202> local domain socket listeners started successfully
<10.21.128.202> loaded API plugin ansible_collections.ansible.netcommon.plugins.httpapi.restconf from path /home/student01/module03-3/venv/lib/python3.9/site-packages/ansible_collections/ansible/netcommon/plugins/httpapi/restconf.py for platform type ansible.netcommon.restconf
<10.21.128.202> 
<10.21.128.202> local domain socket path is /home/student01/.ansible/pc/1c3550ebe3
<10.21.128.202> ESTABLISH LOCAL CONNECTION FOR USER: student01
<10.21.128.202> EXEC /bin/sh -c '( umask 77 && mkdir -p ""` echo /home/student01/.ansible/tmp/ansible-local-1929783zoorheb `""&& mkdir ""` echo /home/student01/.ansible/tmp/ansible-local-1929783zoorheb/ansible-tmp-1673249353.6277976-192997-49736109577898 `"" && echo ansible-tmp-1673249353.6277976-192997-49736109577898=""` echo /home/student01/.ansible/tmp/ansible-local-1929783zoorheb/ansible-tmp-1673249353.6277976-192997-49736109577898 `"" ) && sleep 0'
Using module file /home/student01/module03-3/venv/lib/python3.9/site-packages/ansible_collections/ansible/netcommon/plugins/modules/restconf_get.py
<10.21.128.202> PUT /home/student01/.ansible/tmp/ansible-local-1929783zoorheb/tmpkkmvuf5e TO /home/student01/.ansible/tmp/ansible-local-1929783zoorheb/ansible-tmp-1673249353.6277976-192997-49736109577898/AnsiballZ_restconf_get.py
<10.21.128.202> EXEC /bin/sh -c 'chmod u+x /home/student01/.ansible/tmp/ansible-local-1929783zoorheb/ansible-tmp-1673249353.6277976-192997-49736109577898/ /home/student01/.ansible/tmp/ansible-local-1929783zoorheb/ansible-tmp-1673249353.6277976-192997-49736109577898/AnsiballZ_restconf_get.py && sleep 0'
<10.21.128.202> EXEC /bin/sh -c '/home/student01/module03-3/venv/bin/python3 /home/student01/.ansible/tmp/ansible-local-1929783zoorheb/ansible-tmp-1673249353.6277976-192997-49736109577898/AnsiballZ_restconf_get.py && sleep 0'
<10.21.128.202> EXEC /bin/sh -c 'rm -f -r /home/student01/.ansible/tmp/ansible-local-1929783zoorheb/ansible-tmp-1673249353.6277976-192997-49736109577898/ > /dev/null 2>&1 && sleep 0'
The full traceback is:
  File ""/tmp/ansible_ansible.netcommon.restconf_get_payload_8greruxe/ansible_ansible.netcommon.restconf_get_payload.zip/ansible_collections/ansible/netcommon/plugins/modules/restconf_get.py"", line 111, in main
  File ""/tmp/ansible_ansible.netcommon.restconf_get_payload_8greruxe/ansible_ansible.netcommon.restconf_get_payload.zip/ansible_collections/ansible/netcommon/plugins/module_utils/network/restconf/restconf.py"", line 32, in get
    return connection.send_request(
  File ""/tmp/ansible_ansible.netcommon.restconf_get_payload_8greruxe/ansible_ansible.netcommon.restconf_get_payload.zip/ansible/module_utils/connection.py"", line 200, in __rpc__
    raise ConnectionError(to_text(msg, errors='surrogate_then_replace'), code=code)
fatal: [c8k_student01-1]: FAILED! => {
    ""changed"": false,
    ""code"": -32603,
    ""invocation"": {
        ""module_args"": {
            ""content"": null,
            ""output"": ""json"",
            ""path"": ""/ietf-interfaces:interfaces""
        }
    },
    ""msg"": ""HTTP Error 401: Unauthorized""
}

PLAY RECAP *************************************************************************************************************************************************************************************************************************************************************************
c8k_student01-1            : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-01-09T07:33:29Z,2,Create a YAML Ansible playbook to exhibit the following issue: ansible.netcommon.httpapi remote_user not set to logged in user by default,"```
---
- name: Test Ansible.netcommon.httpapi issue
  hosts: localhost
  connection: local
  gather_facts: no
  
  tasks:
    - name: Set up variables
      set_fact:
          ansible_user: ""{{ lookup('env', 'USER') }}""
          ansible_password: ""{{ lookup('env', 'PASSWORD') }}""
          
    - name: Test HTTP API connection
      ansible.netcommon.httpapi:
        host: ""{{ inventory_hostname }}""
        username: ""{{ ansible_user }}""
        password: ""{{ ansible_password }}""
        validate_certs: false
      register: result
      
    - name: Display result
      debug:
        var: result
```
This playbook sets up the required variables for the HTTP API connection with the user's username and password. It then attempts to connect to the specified host using the ansible.netcommon.httpapi module and registers the result. Finally, it displays the result of the debugging. By default, the remote_user is not set to the logged-in user, which will be evident when running the playbook.",1,"
---
- name: Test Ansible.netcommon.httpapi issue
  hosts: localhost
  connection: local
  gather_facts: no
  
  tasks:
    - name: Set up variables
      set_fact:
          ansible_user: ""{{ lookup('env', 'USER') }}""
          ansible_password: ""{{ lookup('env', 'PASSWORD') }}""
          
    - name: Test HTTP API connection
      ansible.netcommon.httpapi:
        host: ""{{ inventory_hostname }}""
        username: ""{{ ansible_user }}""
        password: ""{{ ansible_password }}""
        validate_certs: false
      register: result
      
    - name: Display result
      debug:
        var: result
"
94,79680,removed_at_date and removed_in_version in argument spec stopped working,"### Summary

This was likely caused by the refactoring in abacf6a108b038571a0c3daeae63da0897c8fcb6; the old code was calling `list_deprecations()` from `AnsibleModule._handle_no_log_values()`, and the new code renamed the function to `_list_deprecations()`, but doesn't seem to call it *at all*. (There also seem to be no integration tests for this, so this went unnoticed.)

Ref: https://github.com/ansible-collections/community.zabbix/issues/857#issuecomment-1354637050

### Issue Type

Bug Report

### Component Name

AnsibleModule / argument spec validation

### Ansible Version

```console
2.11 to devel
```


### Configuration

```console
-
```


### OS / Environment

-

### Steps to Reproduce

-

### Expected Results

-

### Actual Results

```console
-
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-01-06T10:28:06Z,4,Create a YAML Ansible playbook to exhibit the following issue: removed_at_date and removed_in_version in argument spec stopped working,"```
---
- name: Testing issue with argument spec 
  hosts: localhost
  gather_facts: false

  tasks:
    - name: Run the failing module with removed_at_date and removed_in_version
      my_module:
        arg1: foo
        arg2: bar
        removed_at_date: '2022-01-01'
        removed_in_version: '2.0'
      register: result

    - name: Print output
      debug:
        var: result
```",1,"
---
- name: Testing issue with argument spec 
  hosts: localhost
  gather_facts: false

  tasks:
    - name: Run the failing module with removed_at_date and removed_in_version
      my_module:
        arg1: foo
        arg2: bar
        removed_at_date: '2022-01-01'
        removed_in_version: '2.0'
      register: result

    - name: Print output
      debug:
        var: result
"
95,79676,AttributeError: 'int' object has no attribute 'startswith',"### Summary

Running a playbook :https://dpaste.org/WJEwm#L98 against a Windows 10 target, the first When: block is ignored correctly, the first task in the second When: block errors out with:

```
task path: /etc/ansible/devel/sysops/code/ansible/Update-splunkuf-spl.yml:54
The full traceback is:
Traceback (most recent call last):
  File ""/home/svc-ansiblemgmt/.local/lib/python3.9/site-packages/ansible/executor/task_executor.py"", line 158, in run
    res = self._execute()
  File ""/home/svc-ansiblemgmt/.local/lib/python3.9/site-packages/ansible/executor/task_executor.py"", line 556, in _execute
    plugin_vars = self._set_connection_options(cvars, templar)
  File ""/home/svc-ansiblemgmt/.local/lib/python3.9/site-packages/ansible/executor/task_executor.py"", line 1038, in _set_connection_options
    if k.startswith('ansible_%s_' % self._connection._load_name) and k not in options:
AttributeError: 'int' object has no attribute 'startswith'
fatal: [windows-host1]: FAILED! => {
    ""msg"": ""Unexpected failure during module execution: 'int' object has no attribute 'startswith'"",
    ""stdout"": """"
}
```

As per #mackerman & #bcoca the offending line is 33

          when: 200.stat.exists == false

Having an integer where a string should be

### Issue Type

Bug Report

### Component Name

register

### Ansible Version

```console
$ ansible --version
ansible [core 2.14.1]
  config file = /etc/ansible/ansible.cfg
  configured module search path = ['/home/svc-ansiblemgmt/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /home/svc-ansiblemgmt/.local/lib/python3.9/site-packages/ansible
  ansible collection location = /home/svc-ansiblemgmt/.ansible/collections:/usr/share/ansible/collections
  executable location = /home/svc-ansiblemgmt/.local/bin/ansible
  python version = 3.9.5 (default, Nov 23 2021, 15:27:38) [GCC 9.3.0] (/usr/bin/python)
  jinja version = 3.1.2
  libyaml = False
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
ANSIBLE_COW_SELECTION(/etc/ansible/ansible.cfg) = default
CONFIG_FILE() = /etc/ansible/ansible.cfg
DEFAULT_CALLBACK_PLUGIN_PATH(/etc/ansible/ansible.cfg) = ['/usr/share/ansible/plugins/callback']
DEFAULT_HOST_LIST(/etc/ansible/ansible.cfg) = ['/etc/ansible/inventory']
GALAXY_SERVER_LIST(/etc/ansible/ansible.cfg) = ['aaphub_linux']
HOST_KEY_CHECKING(/etc/ansible/ansible.cfg) = False
INVENTORY_IGNORE_EXTS(/etc/ansible/ansible.cfg) = ['~', '.orig', '.bak', '.ini', '.cfg', '.retry', '.pyc', '.pyo']

CONNECTION:
==========

paramiko_ssh:
____________
host_key_checking(/etc/ansible/ansible.cfg) = False

ssh:
___
host_key_checking(/etc/ansible/ansible.cfg) = False
```


### OS / Environment

Ubuntu 20.04.5

### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->
```yaml (paste below)
- name: Update SplunkUF SPL file
  become: yes 
  become_method: runas
  hosts: ""{{ targets }}""
  tasks:
    - when: '""Linux"" in ansible_system'
      block:
        - name: Check to see if Splunk path exists
          stat:
            path: /opt/splunkforwarder/
          register: splunk
​
        - name: If splunk does not exist skip host
          meta: end_host
          when: splunk.stat.exists == false
​
        - name: Get SPL file, copy to Splunks working directory
          copy:
            src: /etc/ansible/playbooks/files/splunk/splunkclouduf.spl
            dest: /root/installed/splunkclouduf.spl
            owner: root
            group: root
​
        - name: Extract and set ownership of SPL file to 100
          shell: |
            tar -zxvf /root/installed/splunkclouduf.spl -C /opt/splunkforwarder/etc/apps/
            chown -r root:root /opt/splunkforwarder/etc/apps/100_splunkcloud
          debugger: on_failed
​
        - name: Does target have a 200_splunkcloud directory?
          stat:  
            path: /opt/splunkforwarder/etc/apps/200_splunkcloud/
          register: 200
​
        - name: Extract and set ownership of SPL file to 200
          shell: |
            tar -zxvf /root/installed/splunkclouduf.spl -C /opt/splunkforwarder/etc/apps/
            chown -r root:root /opt/splunkforwarder/etc/apps/200_splunkcloud
          debugger: on_failed
          when: 200.stat.exists == false
​
        - name: Restart splunk daemon 
          shell: /opt/splunkforwarder/bin/splunk restart
          register: service_status
          async: 10
        - debug: msg=""{{ service_status.stdout }}""
​
    - when: '""Win32NT"" in ansible_system'
      block:
        - name: Check for existing SplunkForwarder service before proceeding
          win_service:
            name: SplunkForwarder
          register: win_splunk
​
        - name: fail when service exists
          meta: end_host
          when: service_info.exists == true
​
        - name: Create destination directory if not exit
          win_file:
            path: C:\it_temp
            state: directory
          when: win_splunk.stat.isdir is defined and win_splunk.stat.isdir
​
        - name: Copy Jamf splunk app directory to 100 app
          win_copy:
            src: /etc/ansible/playbooks/files/splunk/100_splunkcloud/
            dest: 'C:\Program Files\SplunkUniversalForwarder\etc\apps'
​
        - name: Does target have a 200_splunkcloud directory?
          win_stat:  
            path: 'C:\Program Files\SplunkUniversalForwarder\etc\apps\200_splunkcloud\'
          register: win_200
​
        - name: Copy splunk app directory to 200 app
          win_copy:
            src: 'C:\Program Files\SplunkUniversalForwarder\etc\apps\100_splunkcloud\'
            dest: 'C:\Program Files\SplunkUniversalForwarder\etc\apps\200_splunkcloud\'
            remote_src: yes
          debugger: on_failed
          when: win_200.stat.exists == true
​
        - name: Restart Splunk
          win_command:
            cmd: '""C:\Program Files\SplunkUniversalForwarder\bin\splunk.exe"" ""restart""'
```


### Expected Results

Playbook processes each when: block according to OS facts correctly

### Actual Results

```console
task path: /etc/ansible/devel/sysops/code/ansible/Update-splunkuf-spl.yml:54
The full traceback is:
Traceback (most recent call last):
  File ""/home/svc-ansiblemgmt/.local/lib/python3.9/site-packages/ansible/executor/task_executor.py"", line 158, in run
    res = self._execute()
  File ""/home/svc-ansiblemgmt/.local/lib/python3.9/site-packages/ansible/executor/task_executor.py"", line 556, in _execute
    plugin_vars = self._set_connection_options(cvars, templar)
  File ""/home/svc-ansiblemgmt/.local/lib/python3.9/site-packages/ansible/executor/task_executor.py"", line 1038, in _set_connection_options
    if k.startswith('ansible_%s_' % self._connection._load_name) and k not in options:
AttributeError: 'int' object has no attribute 'startswith'
fatal: [windows-host1]: FAILED! => {
    ""msg"": ""Unexpected failure during module execution: 'int' object has no attribute 'startswith'"",
    ""stdout"": """"
}
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-01-05T22:28:43Z,9,Create a YAML Ansible playbook to exhibit the following issue: AttributeError: 'int' object has no attribute 'startswith',"```
---
- name: Testing AttributeError 
  hosts: localhost
  gather_facts: no
  
  vars:
    number: 12345

  tasks:
    - name: Attempt to call startswith on an integer
      debug:
        var: ""{{ number.startswith('123') }}""
...
```",1,"
---
- name: Testing AttributeError 
  hosts: localhost
  gather_facts: no
  
  vars:
    number: 12345

  tasks:
    - name: Attempt to call startswith on an integer
      debug:
        var: ""{{ number.startswith('123') }}""
...
"
96,79665,shebang doesn't use ansible_python_interpreter,"### Summary

https://github.com/ansible/ansible/pull/76677/files

In this commit, it looks like the shebang of modules take precedence over `interpreter_python` and `ansible_python_interpreter`, however none of this is noted in the docs: https://docs.ansible.com/ansible/latest/reference_appendices/interpreter_discovery.html

i.e if the ansible module starts with `#!/usr/bin/env python` (which  points to Python 2.7) and the `ansible_python_interpreter` is set to `/usr/bin/python3`, Python 2.7 will be used. 

I noticed this issue when upgrading from 2.12

The code also performs a config variable lookup of the base path of the shebang, which can be incorrect in many cases. i.e if the shebang is `#!/usr/bin/env python` or even `#!/usr/bin/python2.7` then the variable lookup will be `ansible_env_interpreter` and `ansible_python2.7_interpreter`, respectively . This definitely seems unintentional. 

Some clarification on this would be helpful since this behavior is ambiguous. 



### Issue Type

Bug Report

### Component Name

ansible

### Ansible Version

```console
$ ansible --version
ansible-playbook [core 2.14.1]
  config file = /home/m-aj/ansible-repo/ansible.cfg
  configured module search path = ['/home/m-aj/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /home/m-aj/.venvs/ansible-2.14.x/lib/python3.9/site-packages/ansible
  ansible collection location = /home/m-aj/ansible-repo/collections
  executable location = /home/m-aj/.venvs/ansible-2.14.x/bin/ansible-playbook
  python version = 3.9.2 (default, Jan 19 2022, 12:26:41) [GCC 11.1.0] (/home/m-aj/.venvs/ansible-2.14.x/bin/python3)
  jinja version = 3.0.3
  libyaml = True
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
ANSIBLE_PIPELINING(/home/m-aj/ansible-repo/ansible.cfg) = True
COLLECTIONS_PATHS(/home/m-aj/ansible-repo/ansible.cfg) = ['/home/m-aj/ansible-repo/collections']
CONFIG_FILE() = /home/m-aj/ansible-repo/ansible.cfg
DEFAULT_CALLBACK_PLUGIN_PATH(/home/m-aj/ansible-repo/ansible.cfg) = ['/home/m-aj/ansible-repo/plugins/callback']
DEFAULT_FILTER_PLUGIN_PATH(/home/m-aj/ansible-repo/ansible.cfg) = ['/home/m-aj/ansible-repo/plugins/filter']
DEFAULT_FORKS(/home/m-aj/ansible-repo/ansible.cfg) = 400
DEFAULT_GATHERING(/home/m-aj/ansible-repo/ansible.cfg) = explicit
DEFAULT_GATHER_SUBSET(/home/m-aj/ansible-repo/ansible.cfg) = ['!all']
DEFAULT_INVENTORY_PLUGIN_PATH(/home/m-aj/ansible-repo/ansible.cfg) = ['/home/m-aj/ansible-repo/plugins/inventory']
DEFAULT_LOG_PATH(/home/m-aj/ansible-repo/ansible.cfg) = /home/m-aj/ansible-repo/ansible.log
DEFAULT_LOOKUP_PLUGIN_PATH(/home/m-aj/ansible-repo/ansible.cfg) = ['/home/m-aj/ansible-repo/plugins/lookup']
DEFAULT_ROLES_PATH(/home/m-aj/ansible-repo/ansible.cfg) = ['/home/m-aj/ansible-repo/roles/internal', '/home/armariy>
INTERPRETER_PYTHON(/home/m-aj/ansible-repo/ansible.cfg) = /usr/bin/python3
RETRY_FILES_ENABLED(/home/m-aj/ansible-repo/ansible.cfg) = True
RETRY_FILES_SAVE_PATH(/home/m-aj/ansible-repo/ansible.cfg) = /home/m-aj/ansible-repo/retry-files

CONNECTION:
==========

local:
_____
pipelining(/home/m-aj/ansible-repo/ansible.cfg) = True

paramiko_ssh:
____________
ssh_args(/home/m-aj/ansible-repo/ansible.cfg) = -C -o ControlMaster=auto -o ControlPersist=30m

psrp:
____
pipelining(/home/m-aj/ansible-repo/ansible.cfg) = True

ssh:
___
pipelining(/home/m-aj/ansible-repo/ansible.cfg) = True
scp_if_ssh(/home/m-aj/ansible-repo/ansible.cfg) = true
ssh_args(/home/m-aj/ansible-repo/ansible.cfg) = -C -o ControlMaster=auto -o ControlPersist=30m

winrm:
_____
pipelining(/home/m-aj/ansible-repo/ansible.cfg) = True
```


### OS / Environment

RHEL 8

### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->
play.yml
```yaml (paste below)
- hosts: localhost
  vars:
    ansible_python_interpreter: ""/usr/bin/python3""
  tasks:
    - name: Test that my module works
      test:
      register: result
```
library/test.py
```python
#!/usr/bin/env python

from ansible.module_utils.basic import *

def main():

        module = AnsibleModule(argument_spec={})
        response = {""test"": ""test""}
        module.exit_json(changed=False, meta=response)


if __name__ == '__main__':
    main()
```
`ansible-playbook  -i {non-local-host}, play.yml -vvv`

`ansible.cfg` has the `/usr/bin/python3` interpreter (along with the task var in the play) however this play gets ran with `/usr/bin/env python` (which is python2 in my environment). The shebang gets used, not the ansible python interpreter variables. Unsure if this is the right intention as the docs explain this config key will be used. This same issue applies with other shebangs. Note that the second bug here is that the code looks up `ansible_env_interpreter` in the config, this might actually be a bug. 

### Expected Results

I expected to see python3 as the interpreter in the debug `<127.0.0.1> EXEC /bin/sh -c '/usr/bin/python3 && sleep 0'` and not `<127.0.0.1> EXEC /bin/sh -c '/usr/bin/env python && sleep 0'`

### Actual Results

```console
`<127.0.0.1> EXEC /bin/sh -c '/usr/bin/env python && sleep 0'`
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-01-04T21:40:27Z,9,Create a YAML Ansible playbook to exhibit the following issue: shebang doesn't use ansible_python_interpreter,"```
---
- name: Display ansible_python_interpreter issue
  hosts: all
  gather_facts: true

  tasks:
  - name: Display path to python interpreter
    debug:
      msg: ""{{ ansible_playbook_python }}""
  - name: Display path to Python interpreter
    command: ""which python""
    register: cmd_out
  - name: Display result of command output
    debug:
      var: cmd_out.stdout
  - name: Install python-requests
    pip:
      name: requests
      executable: ""{{ ansible_python_interpreter }}""
... 
```",1,"
---
- name: Display ansible_python_interpreter issue
  hosts: all
  gather_facts: true

  tasks:
  - name: Display path to python interpreter
    debug:
      msg: ""{{ ansible_playbook_python }}""
  - name: Display path to Python interpreter
    command: ""which python""
    register: cmd_out
  - name: Display result of command output
    debug:
      var: cmd_out.stdout
  - name: Install python-requests
    pip:
      name: requests
      executable: ""{{ ansible_python_interpreter }}""
... 
"
97,79661,package_facts requires python-rpm on SUSE systems  in ansible 2.12.1,"### Summary

This bug report is identical to #60707, which is about missing documentation for package_facts module, but affects the missing documention requirement for python-rpm on SUSE distributions.



### Issue Type

Bug Report

### Component Name

package_facts

### Ansible Version

```console
$ ansible --version
ansible [core 2.12.10]
```


### Configuration

```console
Not applicable
```


### OS / Environment

SUSE Enterprise 12
SUSE Enterprise 15
OpenSUSE Tumbleweed 15.3

### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->
```
zypper rm python3-rpm
```
Then run the following playbook on an ansible controller node to test locally.
```
 name: Playbook to test package_facts module locally on Suse based systems.
  hosts: localhost
  become: yes
  connection: local
  gather_facts: yes
  tasks:
    - name: Gather package facts on Suse based systems
      package_facts:
        manager: auto

```

### Expected Results

```
$ ansible-playbook package.yml

PLAY [Playbook to test package_facts module locally on Suse based systems.] *******

TASK [Gathering Facts] *****************************************************************
ok: [localhost]

TASK [Gather package facts on Suse based systems] ************************************
ok: [localhost]

PLAY RECAP *****************************************************************************
localhost                  : ok=2    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
ACTUAL RESULTS
$ ansible-playbook package.yml

PLAY [Playbook to test package_facts module locally on Suse based system.] *******

TASK [Gathering Facts] *****************************************************************
ok: [localhost]

TASK [Gather package facts on Suse based systems] ************************************
[WARNING]: Found ""rpm"" but Failed to import the required Python library (rpm) on localhost's Python /usr/bin/python3.6. Please read the module
documentation and install it in the appropriate location. If the required library is installed, but Ansible is using the wrong Python interpreter,
please consult the documentation on ansible_python_interpreter

fatal: [localhost]: FAILED! => {""changed"": false, ""msg"": ""Could not detect a supported package manager from the following list: ['portage', 'rpm', 'apk', 'pkg', 'pacman', 'apt'], or the required Python library is not installed. Check warnings for details.""}
```

Temporary workaround:
To install python-rpm package on any Suse based systems where package_facts module is going to be used for.


### Actual Results

```console
$ ansible-playbook package.yml

PLAY [Playbook to test package_facts module locally on Suse based system.] *******

TASK [Gathering Facts] *****************************************************************
ok: [localhost]

TASK [Gather package facts on Suse based systems] ************************************
[WARNING]: Found ""rpm"" but Failed to import the required Python library (rpm) on lab-224's Python /usr/bin/python3.6. Please read the module
documentation and install it in the appropriate location. If the required library is installed, but Ansible is using the wrong Python interpreter,
please consult the documentation on ansible_python_interpreter
fatal: [localhost]: FAILED! => {""changed"": false, ""msg"": ""Could not detect a supported package manager from the following list: ['portage', 'rpm', 'apk', 'pkg', 'pacman', 'apt'], or the required Python library is not installed. Check warnings for details.""}

PLAY RECAP *****************************************************************************
localhost                  : ok=1    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-01-04T13:08:06Z,3,Create a YAML Ansible playbook to exhibit the following issue: package_facts requires python-rpm on SUSE systems  in ansible 2.12.1,"```
---
- name: Example playbook to exhibit package_facts issue
  hosts: localhost
  gather_facts: no
  vars:
    ansible_python_interpreter: /usr/bin/python3

  tasks:
    - name: Install python-rpm package on SUSE systems
      package:
        name: python-rpm
        state: present

    - name: Fetch package facts
      package_facts:
      register: package_info

    - name: Display package information
      debug:
        var: package_info
```
",1,"
---
- name: Example playbook to exhibit package_facts issue
  hosts: localhost
  gather_facts: no
  vars:
    ansible_python_interpreter: /usr/bin/python3

  tasks:
    - name: Install python-rpm package on SUSE systems
      package:
        name: python-rpm
        state: present

    - name: Fetch package facts
      package_facts:
      register: package_info

    - name: Display package information
      debug:
        var: package_info
"
98,79646,ansible-test disallows an underscore as a variable name,"### Summary

I have noticed that pylint (ansible-test sanity) marks as a disallowed name a single underscore. Using a single underscore for a variable that is not used is a widely code convention. Is this a bug or intended? 

Example: 
```python
import asyncio

proc = await asyncio.subprocess.create_subprocess_shell(""echo hello"", stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE)
await proc.wait()
if proc.returncode != 0:
    _, stderr = await proc.communicate()
    print(f""ERROR: {stderr}"")
```

### Issue Type

Bug Report

### Component Name

ansible-test

### Ansible Version

```console
core 2.13.5
```


### Configuration

```console
default
```


### OS / Environment

any

### Steps to Reproduce


run `ansible-test sanity` against this code:
```python
import asyncio

proc = await asyncio.subprocess.create_subprocess_shell(""echo hello"", stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE)
await proc.wait()
if proc.returncode != 0:
    _, stderr = await proc.communicate()
    print(f""ERROR: {stderr}"")
```

### Expected Results

No errors

### Actual Results

```console
ERROR: Found 1 pylint issue(s) which need to be resolved:
ERROR: example.py: disallowed-name: Disallowed name ""_""
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2023-01-02T18:50:00Z,3,Create a YAML Ansible playbook to exhibit the following issue: ansible-test disallows an underscore as a variable name,"```
---
- name: Testing ansible-test
  hosts: localhost
  gather_facts: false
  
  tasks:
  - name: Testing variable names
    set_fact:
      foo_bar: ""testing""
    debug:
      var: foo_bar
```",1,"
---
- name: Testing ansible-test
  hosts: localhost
  gather_facts: false
  
  tasks:
  - name: Testing variable names
    set_fact:
      foo_bar: ""testing""
    debug:
      var: foo_bar
"
99,79640,Ansible Galaxy installation fail on some AWS IP / OpenSSL3.X issue,"### Summary

Hi,

I'm struggling while tring to install some collections.
After looking for many diffrents bugs I finally end on an issue that looks like coming from AWS.
As a difference, here is on lect what has succeeded from a french localisation and on the right what failed in an OVH DataCenter
![image](https://user-images.githubusercontent.com/1043935/210084212-21b568a0-3b69-4cc5-b435-9308155e33dc.png)

It doesn't failed always on the same collection nor IP.
I've tried with `--pre` with a deletion of all the collection folder etc...
It failed frequently but not on the same servers/collection

Please tell me what can I do to help for the analysis.

Thanks for the time spent on this issue,

Regards

### Issue Type

Bug Report

### Component Name

ansible-galaxy

### Ansible Version

```console
$ ansible --version
ansible [core 2.14.1]
  config file = /var/lib/rundeck/ansible_folder/infra-ansible-tools/infra-ansible-serverplaybooks/ansible.cfg
  configured module search path = ['/var/lib/rundeck/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /var/lib/rundeck/.local/lib/python3.9/site-packages/ansible
  ansible collection location = /var/lib/rundeck/ansible_folder/all-ansible-tools/ansible_collections
  executable location = /var/lib/rundeck/.local/bin/ansible
  python version = 3.9.14 (main, Nov  7 2022, 00:00:00) [GCC 11.3.1 20220421 (Red Hat 11.3.1-2)] (/usr/bin/python3)
  jinja version = 3.1.2
  libyaml = True
```


### Configuration

```console
# if using a version older than ansible-core 2.12 you should omit the '-t all'
$ ansible-config dump --only-changed -t all
ansible-config dump --only-changed -t all
COLLECTIONS_PATHS(/var/lib/rundeck/ansible_folder/infra-ansible-tools/infra-ansible-serverplaybooks/ansible.cfg) = ['/var/lib/rundeck/ansible_folder/all-ansible-tools/ansible_collections']
CONFIG_FILE() = /var/lib/rundeck/ansible_folder/infra-ansible-tools/infra-ansible-serverplaybooks/ansible.cfg
DEFAULT_GATHERING(/var/lib/rundeck/ansible_folder/infra-ansible-tools/infra-ansible-serverplaybooks/ansible.cfg) = smart
DEFAULT_HOST_LIST(/var/lib/rundeck/ansible_folder/infra-ansible-tools/infra-ansible-serverplaybooks/ansible.cfg) = ['/var/lib/rundeck/ansible_folder/all-ansible-tools/ansible-inventories/mindandgo-ansible-inventory/inventory->
DEFAULT_ROLES_PATH(/var/lib/rundeck/ansible_folder/infra-ansible-tools/infra-ansible-serverplaybooks/ansible.cfg) = ['/var/lib/rundeck/ansible_folder/all-ansible-tools/ansible-roles', '/var/lib/rundeck/ansible_folder/infra-an>
DEFAULT_TRANSPORT(/var/lib/rundeck/ansible_folder/infra-ansible-tools/infra-ansible-serverplaybooks/ansible.cfg) = ssh
HOST_KEY_CHECKING(/var/lib/rundeck/ansible_folder/infra-ansible-tools/infra-ansible-serverplaybooks/ansible.cfg) = False

CONNECTION:
==========

paramiko_ssh:
____________
host_key_checking(/var/lib/rundeck/ansible_folder/infra-ansible-tools/infra-ansible-serverplaybooks/ansible.cfg) = False
ssh_args(/var/lib/rundeck/ansible_folder/infra-ansible-tools/infra-ansible-serverplaybooks/ansible.cfg) = -C -o ControlMaster=auto -o ControlPersist=30m

ssh:
___
host_key_checking(/var/lib/rundeck/ansible_folder/infra-ansible-tools/infra-ansible-serverplaybooks/ansible.cfg) = True
pipelining(/var/lib/rundeck/ansible_folder/infra-ansible-tools/infra-ansible-serverplaybooks/ansible.cfg) = True
ssh_args(/var/lib/rundeck/ansible_folder/infra-ansible-tools/infra-ansible-serverplaybooks/ansible.cfg) = -C -o ControlMaster=auto -o ControlPersist=30m
timeout(/var/lib/rundeck/ansible_folder/infra-ansible-tools/infra-ansible-serverplaybooks/ansible.cfg) = 30
```


### OS / Environment

Rocky 9

### Steps to Reproduce

<!--- Paste example playbooks or commands between quotes below -->
```
ansible-galaxy collection install community.crypto  -vvvvv => failed
wget https://galaxy.ansible.com/download/community-crypto-2.9.0.tar.gz => failed

```
also failed with other collections import

### Expected Results

collection installation succeed

### Actual Results

```console
failed after the end of the installation process :

.../...
Starting galaxy collection install process
Process install dependency map
Initial connection to galaxy_server: https://galaxy.ansible.com
Found API version 'v1, v2' with Galaxy server default (https://galaxy.ansible.com/api/)
Opened /var/lib/rundeck/.ansible/galaxy_token
Calling Galaxy at https://galaxy.ansible.com/api/v2/collections/community/crypto/
Starting collection install process
Fetching a collection tarball for 'community.crypto:2.9.0' from Ansible Galaxy
Downloading https://galaxy.ansible.com/download/community-crypto-2.9.0.tar.gz to /var/lib/rundeck/.ansible/tmp/ansible-local-105300o0tcll1u/tmpq37itu93/community-crypto-2.9.0-buczfrep
ERROR! Failed to download collection tar from 'default': <urlopen error TLS/SSL connection has been closed (EOF) (_ssl.c:1129)>

```
```


### Code of Conduct

- [X] I agree to follow the Ansible Code of Conduct",2022-12-30T15:10:48Z,14,Create a YAML Ansible playbook to exhibit the following issue: Ansible Galaxy installation fail on some AWS IP / OpenSSL3.X issue,"```
---
- name: Install Ansible Galaxy
  hosts: all
  tasks:
    - name: Install pip
      become: true
      apt:
        name: python3-pip
        state: present
    
    - name: Install Ansible Galaxy
      become: true
      pip:
        name: ansible-galaxy
        state: present
```
Note: This playbook alone cannot cause an OpenSSL3.X issue. However, it may help replicate the failure on some AWS IP. The issue itself requires additional investigation to pinpoint its root cause, which may include conflicts with outdated or incompatible packages, misconfigured SSL certificates, and others.",1,"
---
- name: Install Ansible Galaxy
  hosts: all
  tasks:
    - name: Install pip
      become: true
      apt:
        name: python3-pip
        state: present
    
    - name: Install Ansible Galaxy
      become: true
      pip:
        name: ansible-galaxy
        state: present
"
